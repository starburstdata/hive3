// $ANTLR 3.5.2 org/apache/hadoop/hive/ql/parse/HiveParser.g 2020-05-20 18:31:02

package org.apache.hadoop.hive.ql.parse;

import java.util.Arrays;
import java.util.Collection;
import java.util.HashMap;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hive.conf.HiveConf;


import org.antlr.runtime.*;
import java.util.Stack;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;

import org.antlr.runtime.tree.*;


/**
   Licensed to the Apache Software Foundation (ASF) under one or more 
   contributor license agreements.  See the NOTICE file distributed with 
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with 
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
*/
@SuppressWarnings("all")
public class HiveParser extends Parser {
	public static final String[] tokenNames = new String[] {
		"<invalid>", "<EOR>", "<DOWN>", "<UP>", "AMPERSAND", "BITWISEOR", "BITWISEXOR", 
		"ByteLengthLiteral", "COLON", "COMMA", "CONCATENATE", "CharSetLiteral", 
		"CharSetName", "DIV", "DIVIDE", "DOLLAR", "DOT", "Digit", "EQUAL", "EQUAL_NS", 
		"Exponent", "GREATERTHAN", "GREATERTHANOREQUALTO", "HexDigit", "Identifier", 
		"IntegralLiteral", "KW_ABORT", "KW_ACTIVATE", "KW_ACTIVE", "KW_ADD", "KW_ADMIN", 
		"KW_AFTER", "KW_ALL", "KW_ALLOC_FRACTION", "KW_ALTER", "KW_ANALYZE", "KW_AND", 
		"KW_ANY", "KW_APPLICATION", "KW_ARCHIVE", "KW_ARRAY", "KW_AS", "KW_ASC", 
		"KW_AT", "KW_AUTHORIZATION", "KW_AUTOCOMMIT", "KW_BEFORE", "KW_BETWEEN", 
		"KW_BIGINT", "KW_BINARY", "KW_BOOLEAN", "KW_BOTH", "KW_BUCKET", "KW_BUCKETS", 
		"KW_BY", "KW_CACHE", "KW_CASCADE", "KW_CASE", "KW_CAST", "KW_CBO", "KW_CHANGE", 
		"KW_CHAR", "KW_CHECK", "KW_CLUSTER", "KW_CLUSTERED", "KW_CLUSTERSTATUS", 
		"KW_COLLECTION", "KW_COLUMN", "KW_COLUMNS", "KW_COMMENT", "KW_COMMIT", 
		"KW_COMPACT", "KW_COMPACTIONS", "KW_COMPUTE", "KW_CONCATENATE", "KW_CONF", 
		"KW_CONSTRAINT", "KW_CONTINUE", "KW_COST", "KW_CREATE", "KW_CRON", "KW_CROSS", 
		"KW_CUBE", "KW_CURRENT", "KW_CURRENT_DATE", "KW_CURRENT_TIMESTAMP", "KW_CURSOR", 
		"KW_DATA", "KW_DATABASE", "KW_DATABASES", "KW_DATE", "KW_DATETIME", "KW_DAY", 
		"KW_DBPROPERTIES", "KW_DEBUG", "KW_DECIMAL", "KW_DEFAULT", "KW_DEFERRED", 
		"KW_DEFINED", "KW_DELETE", "KW_DELIMITED", "KW_DEPENDENCY", "KW_DESC", 
		"KW_DESCRIBE", "KW_DETAIL", "KW_DIRECTORIES", "KW_DIRECTORY", "KW_DISABLE", 
		"KW_DISTINCT", "KW_DISTRIBUTE", "KW_DISTRIBUTED", "KW_DO", "KW_DOUBLE", 
		"KW_DOW", "KW_DROP", "KW_DUMP", "KW_ELEM_TYPE", "KW_ELSE", "KW_ENABLE", 
		"KW_END", "KW_ENFORCED", "KW_ESCAPED", "KW_EVERY", "KW_EXCEPT", "KW_EXCHANGE", 
		"KW_EXCLUSIVE", "KW_EXECUTE", "KW_EXECUTED", "KW_EXISTS", "KW_EXPLAIN", 
		"KW_EXPORT", "KW_EXPRESSION", "KW_EXTENDED", "KW_EXTERNAL", "KW_EXTRACT", 
		"KW_FALSE", "KW_FETCH", "KW_FIELDS", "KW_FILE", "KW_FILEFORMAT", "KW_FIRST", 
		"KW_FLOAT", "KW_FLOOR", "KW_FOLLOWING", "KW_FOR", "KW_FORCE", "KW_FOREIGN", 
		"KW_FORMAT", "KW_FORMATTED", "KW_FROM", "KW_FULL", "KW_FUNCTION", "KW_FUNCTIONS", 
		"KW_GRANT", "KW_GROUP", "KW_GROUPING", "KW_HAVING", "KW_HOUR", "KW_IDXPROPERTIES", 
		"KW_IF", "KW_IMPORT", "KW_IN", "KW_INDEX", "KW_INDEXES", "KW_INNER", "KW_INPATH", 
		"KW_INPUTDRIVER", "KW_INPUTFORMAT", "KW_INSERT", "KW_INT", "KW_INTERSECT", 
		"KW_INTERVAL", "KW_INTO", "KW_IS", "KW_ISOLATION", "KW_ITEMS", "KW_JAR", 
		"KW_JOIN", "KW_JOINCOST", "KW_KEY", "KW_KEYS", "KW_KEY_TYPE", "KW_KILL", 
		"KW_LAST", "KW_LATERAL", "KW_LEFT", "KW_LESS", "KW_LEVEL", "KW_LIKE", 
		"KW_LIMIT", "KW_LINES", "KW_LOAD", "KW_LOCAL", "KW_LOCATION", "KW_LOCK", 
		"KW_LOCKS", "KW_LOGICAL", "KW_LONG", "KW_MACRO", "KW_MANAGEDLOCATION", 
		"KW_MANAGEMENT", "KW_MAP", "KW_MAPJOIN", "KW_MAPPING", "KW_MATCHED", "KW_MATERIALIZED", 
		"KW_MERGE", "KW_METADATA", "KW_MINUS", "KW_MINUTE", "KW_MONTH", "KW_MORE", 
		"KW_MOVE", "KW_MSCK", "KW_NONE", "KW_NORELY", "KW_NOSCAN", "KW_NOT", "KW_NOVALIDATE", 
		"KW_NULL", "KW_NULLS", "KW_OF", "KW_OFFSET", "KW_ON", "KW_ONLY", "KW_OPERATOR", 
		"KW_OPTION", "KW_OR", "KW_ORDER", "KW_OUT", "KW_OUTER", "KW_OUTPUTDRIVER", 
		"KW_OUTPUTFORMAT", "KW_OVER", "KW_OVERWRITE", "KW_OWNER", "KW_PARTITION", 
		"KW_PARTITIONED", "KW_PARTITIONS", "KW_PATH", "KW_PERCENT", "KW_PLAN", 
		"KW_PLANS", "KW_PLUS", "KW_POOL", "KW_PRECEDING", "KW_PRECISION", "KW_PRESERVE", 
		"KW_PRIMARY", "KW_PRINCIPALS", "KW_PROCEDURE", "KW_PURGE", "KW_QUARTER", 
		"KW_QUERY", "KW_QUERY_PARALLELISM", "KW_RANGE", "KW_READ", "KW_READS", 
		"KW_REBUILD", "KW_RECORDREADER", "KW_RECORDWRITER", "KW_REDUCE", "KW_REFERENCES", 
		"KW_REGEXP", "KW_RELOAD", "KW_RELY", "KW_RENAME", "KW_REOPTIMIZATION", 
		"KW_REPAIR", "KW_REPL", "KW_REPLACE", "KW_REPLICATION", "KW_RESOURCE", 
		"KW_RESTRICT", "KW_REVOKE", "KW_REWRITE", "KW_RIGHT", "KW_RLIKE", "KW_ROLE", 
		"KW_ROLES", "KW_ROLLBACK", "KW_ROLLUP", "KW_ROW", "KW_ROWS", "KW_SCHEDULED", 
		"KW_SCHEDULING_POLICY", "KW_SCHEMA", "KW_SCHEMAS", "KW_SECOND", "KW_SELECT", 
		"KW_SEMI", "KW_SERDE", "KW_SERDEPROPERTIES", "KW_SERVER", "KW_SET", "KW_SETS", 
		"KW_SHARED", "KW_SHOW", "KW_SHOW_DATABASE", "KW_SKEWED", "KW_SMALLINT", 
		"KW_SNAPSHOT", "KW_SORT", "KW_SORTED", "KW_SSL", "KW_START", "KW_STATISTICS", 
		"KW_STATUS", "KW_STORED", "KW_STREAMTABLE", "KW_STRING", "KW_STRUCT", 
		"KW_SUMMARY", "KW_SYNC", "KW_TABLE", "KW_TABLES", "KW_TABLESAMPLE", "KW_TBLPROPERTIES", 
		"KW_TEMPORARY", "KW_TERMINATED", "KW_THEN", "KW_TIME", "KW_TIMESTAMP", 
		"KW_TIMESTAMPLOCALTZ", "KW_TINYINT", "KW_TO", "KW_TOUCH", "KW_TRANSACTION", 
		"KW_TRANSACTIONAL", "KW_TRANSACTIONS", "KW_TRANSFORM", "KW_TRIGGER", "KW_TRUE", 
		"KW_TRUNCATE", "KW_UNARCHIVE", "KW_UNBOUNDED", "KW_UNDO", "KW_UNION", 
		"KW_UNIONTYPE", "KW_UNIQUE", "KW_UNIQUEJOIN", "KW_UNLOCK", "KW_UNMANAGED", 
		"KW_UNSET", "KW_UNSIGNED", "KW_UPDATE", "KW_URI", "KW_USE", "KW_USER", 
		"KW_USING", "KW_UTC", "KW_UTCTIMESTAMP", "KW_VALIDATE", "KW_VALUES", "KW_VALUE_TYPE", 
		"KW_VARCHAR", "KW_VECTORIZATION", "KW_VIEW", "KW_VIEWS", "KW_WAIT", "KW_WEEK", 
		"KW_WHEN", "KW_WHERE", "KW_WHILE", "KW_WINDOW", "KW_WITH", "KW_WORK", 
		"KW_WORKLOAD", "KW_WRITE", "KW_YEAR", "KW_ZONE", "LCURLY", "LESSTHAN", 
		"LESSTHANOREQUALTO", "LINE_COMMENT", "LPAREN", "LSQUARE", "Letter", "MINUS", 
		"MOD", "NOTEQUAL", "Number", "NumberLiteral", "PLUS", "QUERY_HINT", "QUESTION", 
		"QuotedIdentifier", "RCURLY", "RPAREN", "RSQUARE", "RegexComponent", "SEMICOLON", 
		"STAR", "StringLiteral", "TILDE", "WS", "KW_BATCH", "KW_DAYOFWEEK", "KW_HOLD_DDLTIME", 
		"KW_IGNORE", "KW_NO_DROP", "KW_OFFLINE", "KW_PROTECTION", "KW_READONLY", 
		"KW_TIMESTAMPTZ", "TOK_ABORT_TRANSACTIONS", "TOK_ACTIVATE", "TOK_ADD_TRIGGER", 
		"TOK_ADMIN_OPTION_FOR", "TOK_ALIASLIST", "TOK_ALLCOLREF", "TOK_ALLOC_FRACTION", 
		"TOK_ALTERDATABASE_LOCATION", "TOK_ALTERDATABASE_MANAGEDLOCATION", "TOK_ALTERDATABASE_OWNER", 
		"TOK_ALTERDATABASE_PROPERTIES", "TOK_ALTERPARTITION_BUCKETS", "TOK_ALTERPARTITION_FILEFORMAT", 
		"TOK_ALTERPARTITION_LOCATION", "TOK_ALTERPARTITION_MERGEFILES", "TOK_ALTERPARTITION_SERDEPROPERTIES", 
		"TOK_ALTERPARTITION_SERIALIZER", "TOK_ALTERPARTITION_UPDATECOLSTATS", 
		"TOK_ALTERPARTITION_UPDATESTATS", "TOK_ALTERTABLE", "TOK_ALTERTABLE_ADDCOLS", 
		"TOK_ALTERTABLE_ADDCONSTRAINT", "TOK_ALTERTABLE_ADDPARTS", "TOK_ALTERTABLE_ARCHIVE", 
		"TOK_ALTERTABLE_BUCKETS", "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION", "TOK_ALTERTABLE_CLUSTER_SORT", 
		"TOK_ALTERTABLE_COMPACT", "TOK_ALTERTABLE_DROPCONSTRAINT", "TOK_ALTERTABLE_DROPPARTS", 
		"TOK_ALTERTABLE_DROPPROPERTIES", "TOK_ALTERTABLE_EXCHANGEPARTITION", "TOK_ALTERTABLE_FILEFORMAT", 
		"TOK_ALTERTABLE_LOCATION", "TOK_ALTERTABLE_MERGEFILES", "TOK_ALTERTABLE_OWNER", 
		"TOK_ALTERTABLE_PARTCOLTYPE", "TOK_ALTERTABLE_PROPERTIES", "TOK_ALTERTABLE_RENAME", 
		"TOK_ALTERTABLE_RENAMECOL", "TOK_ALTERTABLE_RENAMEPART", "TOK_ALTERTABLE_REPLACECOLS", 
		"TOK_ALTERTABLE_SERDEPROPERTIES", "TOK_ALTERTABLE_SERIALIZER", "TOK_ALTERTABLE_SKEWED", 
		"TOK_ALTERTABLE_SKEWED_LOCATION", "TOK_ALTERTABLE_TOUCH", "TOK_ALTERTABLE_UNARCHIVE", 
		"TOK_ALTERTABLE_UPDATECOLSTATS", "TOK_ALTERTABLE_UPDATECOLUMNS", "TOK_ALTERTABLE_UPDATESTATS", 
		"TOK_ALTERVIEW", "TOK_ALTERVIEW_ADDPARTS", "TOK_ALTERVIEW_DROPPARTS", 
		"TOK_ALTERVIEW_DROPPROPERTIES", "TOK_ALTERVIEW_PROPERTIES", "TOK_ALTERVIEW_RENAME", 
		"TOK_ALTER_MAPPING", "TOK_ALTER_MATERIALIZED_VIEW", "TOK_ALTER_MATERIALIZED_VIEW_REBUILD", 
		"TOK_ALTER_MATERIALIZED_VIEW_REWRITE", "TOK_ALTER_POOL", "TOK_ALTER_POOL_ADD_TRIGGER", 
		"TOK_ALTER_POOL_DROP_TRIGGER", "TOK_ALTER_RP_DISABLE", "TOK_ALTER_RP_ENABLE", 
		"TOK_ALTER_RP_RENAME", "TOK_ALTER_RP_REPLACE", "TOK_ALTER_RP_SET", "TOK_ALTER_RP_UNSET", 
		"TOK_ALTER_RP_VALIDATE", "TOK_ALTER_SCHEDULED_QUERY", "TOK_ALTER_TRIGGER", 
		"TOK_ANALYZE", "TOK_ARCHIVE", "TOK_BIGINT", "TOK_BINARY", "TOK_BLOCKING", 
		"TOK_BOOLEAN", "TOK_CACHE_METADATA", "TOK_CASCADE", "TOK_CHAR", "TOK_CHARSETLITERAL", 
		"TOK_CHECK_CONSTRAINT", "TOK_CLUSTERBY", "TOK_COLTYPELIST", "TOK_COL_NAME", 
		"TOK_COMMIT", "TOK_CONSTRAINT_NAME", "TOK_CREATEDATABASE", "TOK_CREATEFUNCTION", 
		"TOK_CREATEMACRO", "TOK_CREATEROLE", "TOK_CREATETABLE", "TOK_CREATEVIEW", 
		"TOK_CREATE_MAPPING", "TOK_CREATE_MATERIALIZED_VIEW", "TOK_CREATE_POOL", 
		"TOK_CREATE_RP", "TOK_CREATE_SCHEDULED_QUERY", "TOK_CREATE_TRIGGER", "TOK_CRON", 
		"TOK_CROSSJOIN", "TOK_CTE", "TOK_CUBE_GROUPBY", "TOK_DATABASECOMMENT", 
		"TOK_DATABASELOCATION", "TOK_DATABASEPROPERTIES", "TOK_DATABASE_MANAGEDLOCATION", 
		"TOK_DATE", "TOK_DATELITERAL", "TOK_DATETIME", "TOK_DBNAME", "TOK_DBPROPLIST", 
		"TOK_DB_TYPE", "TOK_DECIMAL", "TOK_DEFAULT_POOL", "TOK_DEFAULT_VALUE", 
		"TOK_DELETE", "TOK_DELETE_FROM", "TOK_DESCDATABASE", "TOK_DESCFUNCTION", 
		"TOK_DESCTABLE", "TOK_DESTINATION", "TOK_DETAIL", "TOK_DIR", "TOK_DISABLE", 
		"TOK_DISTRIBUTEBY", "TOK_DOUBLE", "TOK_DROPDATABASE", "TOK_DROPFUNCTION", 
		"TOK_DROPMACRO", "TOK_DROPROLE", "TOK_DROPTABLE", "TOK_DROPVIEW", "TOK_DROP_MAPPING", 
		"TOK_DROP_MATERIALIZED_VIEW", "TOK_DROP_POOL", "TOK_DROP_RP", "TOK_DROP_SCHEDULED_QUERY", 
		"TOK_DROP_TRIGGER", "TOK_ENABLE", "TOK_EVERY", "TOK_EXCEPTALL", "TOK_EXCEPTDISTINCT", 
		"TOK_EXECUTE", "TOK_EXECUTED_AS", "TOK_EXPLAIN", "TOK_EXPLAIN_SQ_REWRITE", 
		"TOK_EXPLIST", "TOK_EXPORT", "TOK_EXPRESSION", "TOK_FALSE", "TOK_FILE", 
		"TOK_FILEFORMAT_GENERIC", "TOK_FLOAT", "TOK_FORCE", "TOK_FOREIGN_KEY", 
		"TOK_FROM", "TOK_FULLOUTERJOIN", "TOK_FUNCTION", "TOK_FUNCTIONDI", "TOK_FUNCTIONSTAR", 
		"TOK_GRANT", "TOK_GRANT_OPTION_FOR", "TOK_GRANT_ROLE", "TOK_GRANT_WITH_ADMIN_OPTION", 
		"TOK_GRANT_WITH_OPTION", "TOK_GROUP", "TOK_GROUPBY", "TOK_GROUPING_SETS", 
		"TOK_GROUPING_SETS_EXPRESSION", "TOK_HAVING", "TOK_IFEXISTS", "TOK_IFNOTEXISTS", 
		"TOK_IMPORT", "TOK_INPUTFORMAT", "TOK_INSERT", "TOK_INSERT_INTO", "TOK_INT", 
		"TOK_INTERSECTALL", "TOK_INTERSECTDISTINCT", "TOK_INTERVAL_DAY_LITERAL", 
		"TOK_INTERVAL_DAY_TIME", "TOK_INTERVAL_DAY_TIME_LITERAL", "TOK_INTERVAL_HOUR_LITERAL", 
		"TOK_INTERVAL_MINUTE_LITERAL", "TOK_INTERVAL_MONTH_LITERAL", "TOK_INTERVAL_SECOND_LITERAL", 
		"TOK_INTERVAL_YEAR_LITERAL", "TOK_INTERVAL_YEAR_MONTH", "TOK_INTERVAL_YEAR_MONTH_LITERAL", 
		"TOK_ISOLATION_LEVEL", "TOK_ISOLATION_SNAPSHOT", "TOK_JAR", "TOK_JOIN", 
		"TOK_KILL_QUERY", "TOK_LATERAL_VIEW", "TOK_LATERAL_VIEW_OUTER", "TOK_LEFTOUTERJOIN", 
		"TOK_LEFTSEMIJOIN", "TOK_LENGTH", "TOK_LIKERP", "TOK_LIKETABLE", "TOK_LIMIT", 
		"TOK_LIST", "TOK_LOAD", "TOK_LOCKDB", "TOK_LOCKTABLE", "TOK_MAP", "TOK_MATCHED", 
		"TOK_MERGE", "TOK_METADATA", "TOK_MSCK", "TOK_NORELY", "TOK_NOT_CLUSTERED", 
		"TOK_NOT_MATCHED", "TOK_NOT_NULL", "TOK_NOT_SORTED", "TOK_NOVALIDATE", 
		"TOK_NO_DROP", "TOK_NULL", "TOK_NULLS_FIRST", "TOK_NULLS_LAST", "TOK_OFFLINE", 
		"TOK_OFFSET", "TOK_ONLY", "TOK_OPERATOR", "TOK_OP_ADD", "TOK_OP_AND", 
		"TOK_OP_BITAND", "TOK_OP_BITNOT", "TOK_OP_BITOR", "TOK_OP_BITXOR", "TOK_OP_DIV", 
		"TOK_OP_EQ", "TOK_OP_GE", "TOK_OP_GT", "TOK_OP_LE", "TOK_OP_LIKE", "TOK_OP_LT", 
		"TOK_OP_MOD", "TOK_OP_MUL", "TOK_OP_NE", "TOK_OP_NOT", "TOK_OP_OR", "TOK_OP_SUB", 
		"TOK_ORDERBY", "TOK_ORREPLACE", "TOK_PARTITIONINGSPEC", "TOK_PARTITIONLOCATION", 
		"TOK_PARTSPEC", "TOK_PARTVAL", "TOK_PATH", "TOK_PERCENT", "TOK_PRIMARY_KEY", 
		"TOK_PRINCIPAL_NAME", "TOK_PRIVILEGE", "TOK_PRIVILEGE_LIST", "TOK_PRIV_ALL", 
		"TOK_PRIV_ALTER_DATA", "TOK_PRIV_ALTER_METADATA", "TOK_PRIV_CREATE", "TOK_PRIV_DELETE", 
		"TOK_PRIV_DROP", "TOK_PRIV_INSERT", "TOK_PRIV_LOCK", "TOK_PRIV_OBJECT", 
		"TOK_PRIV_OBJECT_COL", "TOK_PRIV_SELECT", "TOK_PRIV_SHOW_DATABASE", "TOK_PTBLFUNCTION", 
		"TOK_QUERY", "TOK_QUERY_PARALLELISM", "TOK_READONLY", "TOK_RECORDREADER", 
		"TOK_RECORDWRITER", "TOK_RELOADFUNCTIONS", "TOK_RELY", "TOK_RENAME", "TOK_REPLACE", 
		"TOK_REPLICATION", "TOK_REPL_CONFIG", "TOK_REPL_CONFIG_LIST", "TOK_REPL_DUMP", 
		"TOK_REPL_LOAD", "TOK_REPL_STATUS", "TOK_REPL_TABLES", "TOK_REPL_TABLES_LIST", 
		"TOK_RESOURCE_ALL", "TOK_RESOURCE_LIST", "TOK_RESOURCE_URI", "TOK_RESTRICT", 
		"TOK_REVOKE", "TOK_REVOKE_ROLE", "TOK_REWRITE_DISABLED", "TOK_REWRITE_ENABLED", 
		"TOK_RIGHTOUTERJOIN", "TOK_ROLE", "TOK_ROLLBACK", "TOK_ROLLUP_GROUPBY", 
		"TOK_ROWCOUNT", "TOK_SCHEDULE", "TOK_SCHEDULING_POLICY", "TOK_SELECT", 
		"TOK_SELECTDI", "TOK_SELEXPR", "TOK_SERDE", "TOK_SERDENAME", "TOK_SERDEPROPS", 
		"TOK_SERVER_TYPE", "TOK_SETCOLREF", "TOK_SET_AUTOCOMMIT", "TOK_SET_COLUMNS_CLAUSE", 
		"TOK_SET_ROLE", "TOK_SHOWCOLUMNS", "TOK_SHOWCONF", "TOK_SHOWDATABASES", 
		"TOK_SHOWDBLOCKS", "TOK_SHOWFUNCTIONS", "TOK_SHOWLOCKS", "TOK_SHOWMATERIALIZEDVIEWS", 
		"TOK_SHOWPARTITIONS", "TOK_SHOWTABLES", "TOK_SHOWVIEWS", "TOK_SHOW_COMPACTIONS", 
		"TOK_SHOW_CREATEDATABASE", "TOK_SHOW_CREATETABLE", "TOK_SHOW_CURRENT_ROLE", 
		"TOK_SHOW_GRANT", "TOK_SHOW_ROLES", "TOK_SHOW_ROLE_GRANT", "TOK_SHOW_ROLE_PRINCIPALS", 
		"TOK_SHOW_RP", "TOK_SHOW_TABLESTATUS", "TOK_SHOW_TBLPROPERTIES", "TOK_SHOW_TRANSACTIONS", 
		"TOK_SKEWED_LOCATIONS", "TOK_SKEWED_LOCATION_LIST", "TOK_SKEWED_LOCATION_MAP", 
		"TOK_SMALLINT", "TOK_SORTBY", "TOK_START_TRANSACTION", "TOK_STORAGEHANDLER", 
		"TOK_STOREDASDIRS", "TOK_STRING", "TOK_STRINGLITERALSEQUENCE", "TOK_STRUCT", 
		"TOK_SUBQUERY", "TOK_SUBQUERY_EXPR", "TOK_SUBQUERY_OP", "TOK_SUBQUERY_OP_NOTEXISTS", 
		"TOK_SUBQUERY_OP_NOTIN", "TOK_SUMMARY", "TOK_SWITCHDATABASE", "TOK_TAB", 
		"TOK_TABALIAS", "TOK_TABCOL", "TOK_TABCOLLIST", "TOK_TABCOLNAME", "TOK_TABCOLVALUE", 
		"TOK_TABCOLVALUES", "TOK_TABCOLVALUE_PAIR", "TOK_TABLEBUCKETSAMPLE", "TOK_TABLECOMMENT", 
		"TOK_TABLEFILEFORMAT", "TOK_TABLELOCATION", "TOK_TABLEPARTCOLNAMES", "TOK_TABLEPARTCOLS", 
		"TOK_TABLEPROPERTIES", "TOK_TABLEPROPERTY", "TOK_TABLEPROPLIST", "TOK_TABLEROWFORMAT", 
		"TOK_TABLEROWFORMATCOLLITEMS", "TOK_TABLEROWFORMATFIELD", "TOK_TABLEROWFORMATLINES", 
		"TOK_TABLEROWFORMATMAPKEYS", "TOK_TABLEROWFORMATNULL", "TOK_TABLESERIALIZER", 
		"TOK_TABLESKEWED", "TOK_TABLESPLITSAMPLE", "TOK_TABLE_OR_COL", "TOK_TABLE_PARTITION", 
		"TOK_TABLE_TYPE", "TOK_TABNAME", "TOK_TABREF", "TOK_TABSORTCOLNAMEASC", 
		"TOK_TABSORTCOLNAMEDESC", "TOK_TABSRC", "TOK_TABTYPE", "TOK_TEMPORARY", 
		"TOK_TIMESTAMP", "TOK_TIMESTAMPLITERAL", "TOK_TIMESTAMPLOCALTZ", "TOK_TIMESTAMPLOCALTZLITERAL", 
		"TOK_TINYINT", "TOK_TMP_FILE", "TOK_TO", "TOK_TRANSFORM", "TOK_TRIGGER_EXPRESSION", 
		"TOK_TRUE", "TOK_TRUNCATETABLE", "TOK_TXN_ACCESS_MODE", "TOK_TXN_READ_ONLY", 
		"TOK_TXN_READ_WRITE", "TOK_UNIONALL", "TOK_UNIONDISTINCT", "TOK_UNIONTYPE", 
		"TOK_UNIQUE", "TOK_UNIQUEJOIN", "TOK_UNLOCKDB", "TOK_UNLOCKTABLE", "TOK_UNMANAGED", 
		"TOK_UPDATE", "TOK_UPDATE_TABLE", "TOK_URI_TYPE", "TOK_USER", "TOK_USERSCRIPTCOLNAMES", 
		"TOK_USERSCRIPTCOLSCHEMA", "TOK_VALIDATE", "TOK_VARCHAR", "TOK_VIEWCLUSTERCOLS", 
		"TOK_VIEWDISTRIBUTECOLS", "TOK_VIEWPARTCOLS", "TOK_VIEWSORTCOLS", "TOK_WHERE", 
		"TOK_WINDOWDEF", "TOK_WINDOWRANGE", "TOK_WINDOWSPEC", "TOK_WINDOWVALUES"
	};
	public static final int EOF=-1;
	public static final int AMPERSAND=4;
	public static final int BITWISEOR=5;
	public static final int BITWISEXOR=6;
	public static final int ByteLengthLiteral=7;
	public static final int COLON=8;
	public static final int COMMA=9;
	public static final int CONCATENATE=10;
	public static final int CharSetLiteral=11;
	public static final int CharSetName=12;
	public static final int DIV=13;
	public static final int DIVIDE=14;
	public static final int DOLLAR=15;
	public static final int DOT=16;
	public static final int Digit=17;
	public static final int EQUAL=18;
	public static final int EQUAL_NS=19;
	public static final int Exponent=20;
	public static final int GREATERTHAN=21;
	public static final int GREATERTHANOREQUALTO=22;
	public static final int HexDigit=23;
	public static final int Identifier=24;
	public static final int IntegralLiteral=25;
	public static final int KW_ABORT=26;
	public static final int KW_ACTIVATE=27;
	public static final int KW_ACTIVE=28;
	public static final int KW_ADD=29;
	public static final int KW_ADMIN=30;
	public static final int KW_AFTER=31;
	public static final int KW_ALL=32;
	public static final int KW_ALLOC_FRACTION=33;
	public static final int KW_ALTER=34;
	public static final int KW_ANALYZE=35;
	public static final int KW_AND=36;
	public static final int KW_ANY=37;
	public static final int KW_APPLICATION=38;
	public static final int KW_ARCHIVE=39;
	public static final int KW_ARRAY=40;
	public static final int KW_AS=41;
	public static final int KW_ASC=42;
	public static final int KW_AT=43;
	public static final int KW_AUTHORIZATION=44;
	public static final int KW_AUTOCOMMIT=45;
	public static final int KW_BEFORE=46;
	public static final int KW_BETWEEN=47;
	public static final int KW_BIGINT=48;
	public static final int KW_BINARY=49;
	public static final int KW_BOOLEAN=50;
	public static final int KW_BOTH=51;
	public static final int KW_BUCKET=52;
	public static final int KW_BUCKETS=53;
	public static final int KW_BY=54;
	public static final int KW_CACHE=55;
	public static final int KW_CASCADE=56;
	public static final int KW_CASE=57;
	public static final int KW_CAST=58;
	public static final int KW_CBO=59;
	public static final int KW_CHANGE=60;
	public static final int KW_CHAR=61;
	public static final int KW_CHECK=62;
	public static final int KW_CLUSTER=63;
	public static final int KW_CLUSTERED=64;
	public static final int KW_CLUSTERSTATUS=65;
	public static final int KW_COLLECTION=66;
	public static final int KW_COLUMN=67;
	public static final int KW_COLUMNS=68;
	public static final int KW_COMMENT=69;
	public static final int KW_COMMIT=70;
	public static final int KW_COMPACT=71;
	public static final int KW_COMPACTIONS=72;
	public static final int KW_COMPUTE=73;
	public static final int KW_CONCATENATE=74;
	public static final int KW_CONF=75;
	public static final int KW_CONSTRAINT=76;
	public static final int KW_CONTINUE=77;
	public static final int KW_COST=78;
	public static final int KW_CREATE=79;
	public static final int KW_CRON=80;
	public static final int KW_CROSS=81;
	public static final int KW_CUBE=82;
	public static final int KW_CURRENT=83;
	public static final int KW_CURRENT_DATE=84;
	public static final int KW_CURRENT_TIMESTAMP=85;
	public static final int KW_CURSOR=86;
	public static final int KW_DATA=87;
	public static final int KW_DATABASE=88;
	public static final int KW_DATABASES=89;
	public static final int KW_DATE=90;
	public static final int KW_DATETIME=91;
	public static final int KW_DAY=92;
	public static final int KW_DBPROPERTIES=93;
	public static final int KW_DEBUG=94;
	public static final int KW_DECIMAL=95;
	public static final int KW_DEFAULT=96;
	public static final int KW_DEFERRED=97;
	public static final int KW_DEFINED=98;
	public static final int KW_DELETE=99;
	public static final int KW_DELIMITED=100;
	public static final int KW_DEPENDENCY=101;
	public static final int KW_DESC=102;
	public static final int KW_DESCRIBE=103;
	public static final int KW_DETAIL=104;
	public static final int KW_DIRECTORIES=105;
	public static final int KW_DIRECTORY=106;
	public static final int KW_DISABLE=107;
	public static final int KW_DISTINCT=108;
	public static final int KW_DISTRIBUTE=109;
	public static final int KW_DISTRIBUTED=110;
	public static final int KW_DO=111;
	public static final int KW_DOUBLE=112;
	public static final int KW_DOW=113;
	public static final int KW_DROP=114;
	public static final int KW_DUMP=115;
	public static final int KW_ELEM_TYPE=116;
	public static final int KW_ELSE=117;
	public static final int KW_ENABLE=118;
	public static final int KW_END=119;
	public static final int KW_ENFORCED=120;
	public static final int KW_ESCAPED=121;
	public static final int KW_EVERY=122;
	public static final int KW_EXCEPT=123;
	public static final int KW_EXCHANGE=124;
	public static final int KW_EXCLUSIVE=125;
	public static final int KW_EXECUTE=126;
	public static final int KW_EXECUTED=127;
	public static final int KW_EXISTS=128;
	public static final int KW_EXPLAIN=129;
	public static final int KW_EXPORT=130;
	public static final int KW_EXPRESSION=131;
	public static final int KW_EXTENDED=132;
	public static final int KW_EXTERNAL=133;
	public static final int KW_EXTRACT=134;
	public static final int KW_FALSE=135;
	public static final int KW_FETCH=136;
	public static final int KW_FIELDS=137;
	public static final int KW_FILE=138;
	public static final int KW_FILEFORMAT=139;
	public static final int KW_FIRST=140;
	public static final int KW_FLOAT=141;
	public static final int KW_FLOOR=142;
	public static final int KW_FOLLOWING=143;
	public static final int KW_FOR=144;
	public static final int KW_FORCE=145;
	public static final int KW_FOREIGN=146;
	public static final int KW_FORMAT=147;
	public static final int KW_FORMATTED=148;
	public static final int KW_FROM=149;
	public static final int KW_FULL=150;
	public static final int KW_FUNCTION=151;
	public static final int KW_FUNCTIONS=152;
	public static final int KW_GRANT=153;
	public static final int KW_GROUP=154;
	public static final int KW_GROUPING=155;
	public static final int KW_HAVING=156;
	public static final int KW_HOUR=157;
	public static final int KW_IDXPROPERTIES=158;
	public static final int KW_IF=159;
	public static final int KW_IMPORT=160;
	public static final int KW_IN=161;
	public static final int KW_INDEX=162;
	public static final int KW_INDEXES=163;
	public static final int KW_INNER=164;
	public static final int KW_INPATH=165;
	public static final int KW_INPUTDRIVER=166;
	public static final int KW_INPUTFORMAT=167;
	public static final int KW_INSERT=168;
	public static final int KW_INT=169;
	public static final int KW_INTERSECT=170;
	public static final int KW_INTERVAL=171;
	public static final int KW_INTO=172;
	public static final int KW_IS=173;
	public static final int KW_ISOLATION=174;
	public static final int KW_ITEMS=175;
	public static final int KW_JAR=176;
	public static final int KW_JOIN=177;
	public static final int KW_JOINCOST=178;
	public static final int KW_KEY=179;
	public static final int KW_KEYS=180;
	public static final int KW_KEY_TYPE=181;
	public static final int KW_KILL=182;
	public static final int KW_LAST=183;
	public static final int KW_LATERAL=184;
	public static final int KW_LEFT=185;
	public static final int KW_LESS=186;
	public static final int KW_LEVEL=187;
	public static final int KW_LIKE=188;
	public static final int KW_LIMIT=189;
	public static final int KW_LINES=190;
	public static final int KW_LOAD=191;
	public static final int KW_LOCAL=192;
	public static final int KW_LOCATION=193;
	public static final int KW_LOCK=194;
	public static final int KW_LOCKS=195;
	public static final int KW_LOGICAL=196;
	public static final int KW_LONG=197;
	public static final int KW_MACRO=198;
	public static final int KW_MANAGEDLOCATION=199;
	public static final int KW_MANAGEMENT=200;
	public static final int KW_MAP=201;
	public static final int KW_MAPJOIN=202;
	public static final int KW_MAPPING=203;
	public static final int KW_MATCHED=204;
	public static final int KW_MATERIALIZED=205;
	public static final int KW_MERGE=206;
	public static final int KW_METADATA=207;
	public static final int KW_MINUS=208;
	public static final int KW_MINUTE=209;
	public static final int KW_MONTH=210;
	public static final int KW_MORE=211;
	public static final int KW_MOVE=212;
	public static final int KW_MSCK=213;
	public static final int KW_NONE=214;
	public static final int KW_NORELY=215;
	public static final int KW_NOSCAN=216;
	public static final int KW_NOT=217;
	public static final int KW_NOVALIDATE=218;
	public static final int KW_NULL=219;
	public static final int KW_NULLS=220;
	public static final int KW_OF=221;
	public static final int KW_OFFSET=222;
	public static final int KW_ON=223;
	public static final int KW_ONLY=224;
	public static final int KW_OPERATOR=225;
	public static final int KW_OPTION=226;
	public static final int KW_OR=227;
	public static final int KW_ORDER=228;
	public static final int KW_OUT=229;
	public static final int KW_OUTER=230;
	public static final int KW_OUTPUTDRIVER=231;
	public static final int KW_OUTPUTFORMAT=232;
	public static final int KW_OVER=233;
	public static final int KW_OVERWRITE=234;
	public static final int KW_OWNER=235;
	public static final int KW_PARTITION=236;
	public static final int KW_PARTITIONED=237;
	public static final int KW_PARTITIONS=238;
	public static final int KW_PATH=239;
	public static final int KW_PERCENT=240;
	public static final int KW_PLAN=241;
	public static final int KW_PLANS=242;
	public static final int KW_PLUS=243;
	public static final int KW_POOL=244;
	public static final int KW_PRECEDING=245;
	public static final int KW_PRECISION=246;
	public static final int KW_PRESERVE=247;
	public static final int KW_PRIMARY=248;
	public static final int KW_PRINCIPALS=249;
	public static final int KW_PROCEDURE=250;
	public static final int KW_PURGE=251;
	public static final int KW_QUARTER=252;
	public static final int KW_QUERY=253;
	public static final int KW_QUERY_PARALLELISM=254;
	public static final int KW_RANGE=255;
	public static final int KW_READ=256;
	public static final int KW_READS=257;
	public static final int KW_REBUILD=258;
	public static final int KW_RECORDREADER=259;
	public static final int KW_RECORDWRITER=260;
	public static final int KW_REDUCE=261;
	public static final int KW_REFERENCES=262;
	public static final int KW_REGEXP=263;
	public static final int KW_RELOAD=264;
	public static final int KW_RELY=265;
	public static final int KW_RENAME=266;
	public static final int KW_REOPTIMIZATION=267;
	public static final int KW_REPAIR=268;
	public static final int KW_REPL=269;
	public static final int KW_REPLACE=270;
	public static final int KW_REPLICATION=271;
	public static final int KW_RESOURCE=272;
	public static final int KW_RESTRICT=273;
	public static final int KW_REVOKE=274;
	public static final int KW_REWRITE=275;
	public static final int KW_RIGHT=276;
	public static final int KW_RLIKE=277;
	public static final int KW_ROLE=278;
	public static final int KW_ROLES=279;
	public static final int KW_ROLLBACK=280;
	public static final int KW_ROLLUP=281;
	public static final int KW_ROW=282;
	public static final int KW_ROWS=283;
	public static final int KW_SCHEDULED=284;
	public static final int KW_SCHEDULING_POLICY=285;
	public static final int KW_SCHEMA=286;
	public static final int KW_SCHEMAS=287;
	public static final int KW_SECOND=288;
	public static final int KW_SELECT=289;
	public static final int KW_SEMI=290;
	public static final int KW_SERDE=291;
	public static final int KW_SERDEPROPERTIES=292;
	public static final int KW_SERVER=293;
	public static final int KW_SET=294;
	public static final int KW_SETS=295;
	public static final int KW_SHARED=296;
	public static final int KW_SHOW=297;
	public static final int KW_SHOW_DATABASE=298;
	public static final int KW_SKEWED=299;
	public static final int KW_SMALLINT=300;
	public static final int KW_SNAPSHOT=301;
	public static final int KW_SORT=302;
	public static final int KW_SORTED=303;
	public static final int KW_SSL=304;
	public static final int KW_START=305;
	public static final int KW_STATISTICS=306;
	public static final int KW_STATUS=307;
	public static final int KW_STORED=308;
	public static final int KW_STREAMTABLE=309;
	public static final int KW_STRING=310;
	public static final int KW_STRUCT=311;
	public static final int KW_SUMMARY=312;
	public static final int KW_SYNC=313;
	public static final int KW_TABLE=314;
	public static final int KW_TABLES=315;
	public static final int KW_TABLESAMPLE=316;
	public static final int KW_TBLPROPERTIES=317;
	public static final int KW_TEMPORARY=318;
	public static final int KW_TERMINATED=319;
	public static final int KW_THEN=320;
	public static final int KW_TIME=321;
	public static final int KW_TIMESTAMP=322;
	public static final int KW_TIMESTAMPLOCALTZ=323;
	public static final int KW_TINYINT=324;
	public static final int KW_TO=325;
	public static final int KW_TOUCH=326;
	public static final int KW_TRANSACTION=327;
	public static final int KW_TRANSACTIONAL=328;
	public static final int KW_TRANSACTIONS=329;
	public static final int KW_TRANSFORM=330;
	public static final int KW_TRIGGER=331;
	public static final int KW_TRUE=332;
	public static final int KW_TRUNCATE=333;
	public static final int KW_UNARCHIVE=334;
	public static final int KW_UNBOUNDED=335;
	public static final int KW_UNDO=336;
	public static final int KW_UNION=337;
	public static final int KW_UNIONTYPE=338;
	public static final int KW_UNIQUE=339;
	public static final int KW_UNIQUEJOIN=340;
	public static final int KW_UNLOCK=341;
	public static final int KW_UNMANAGED=342;
	public static final int KW_UNSET=343;
	public static final int KW_UNSIGNED=344;
	public static final int KW_UPDATE=345;
	public static final int KW_URI=346;
	public static final int KW_USE=347;
	public static final int KW_USER=348;
	public static final int KW_USING=349;
	public static final int KW_UTC=350;
	public static final int KW_UTCTIMESTAMP=351;
	public static final int KW_VALIDATE=352;
	public static final int KW_VALUES=353;
	public static final int KW_VALUE_TYPE=354;
	public static final int KW_VARCHAR=355;
	public static final int KW_VECTORIZATION=356;
	public static final int KW_VIEW=357;
	public static final int KW_VIEWS=358;
	public static final int KW_WAIT=359;
	public static final int KW_WEEK=360;
	public static final int KW_WHEN=361;
	public static final int KW_WHERE=362;
	public static final int KW_WHILE=363;
	public static final int KW_WINDOW=364;
	public static final int KW_WITH=365;
	public static final int KW_WORK=366;
	public static final int KW_WORKLOAD=367;
	public static final int KW_WRITE=368;
	public static final int KW_YEAR=369;
	public static final int KW_ZONE=370;
	public static final int LCURLY=371;
	public static final int LESSTHAN=372;
	public static final int LESSTHANOREQUALTO=373;
	public static final int LINE_COMMENT=374;
	public static final int LPAREN=375;
	public static final int LSQUARE=376;
	public static final int Letter=377;
	public static final int MINUS=378;
	public static final int MOD=379;
	public static final int NOTEQUAL=380;
	public static final int Number=381;
	public static final int NumberLiteral=382;
	public static final int PLUS=383;
	public static final int QUERY_HINT=384;
	public static final int QUESTION=385;
	public static final int QuotedIdentifier=386;
	public static final int RCURLY=387;
	public static final int RPAREN=388;
	public static final int RSQUARE=389;
	public static final int RegexComponent=390;
	public static final int SEMICOLON=391;
	public static final int STAR=392;
	public static final int StringLiteral=393;
	public static final int TILDE=394;
	public static final int WS=395;
	public static final int KW_BATCH=432;
	public static final int KW_DAYOFWEEK=472;
	public static final int KW_HOLD_DDLTIME=524;
	public static final int KW_IGNORE=528;
	public static final int KW_NO_DROP=577;
	public static final int KW_OFFLINE=581;
	public static final int KW_PROTECTION=607;
	public static final int KW_READONLY=614;
	public static final int KW_TIMESTAMPTZ=675;
	public static final int TOK_ABORT_TRANSACTIONS=735;
	public static final int TOK_ACTIVATE=736;
	public static final int TOK_ADD_TRIGGER=737;
	public static final int TOK_ADMIN_OPTION_FOR=738;
	public static final int TOK_ALIASLIST=739;
	public static final int TOK_ALLCOLREF=740;
	public static final int TOK_ALLOC_FRACTION=741;
	public static final int TOK_ALTERDATABASE_LOCATION=742;
	public static final int TOK_ALTERDATABASE_MANAGEDLOCATION=743;
	public static final int TOK_ALTERDATABASE_OWNER=744;
	public static final int TOK_ALTERDATABASE_PROPERTIES=745;
	public static final int TOK_ALTERPARTITION_BUCKETS=746;
	public static final int TOK_ALTERPARTITION_FILEFORMAT=747;
	public static final int TOK_ALTERPARTITION_LOCATION=748;
	public static final int TOK_ALTERPARTITION_MERGEFILES=749;
	public static final int TOK_ALTERPARTITION_SERDEPROPERTIES=750;
	public static final int TOK_ALTERPARTITION_SERIALIZER=751;
	public static final int TOK_ALTERPARTITION_UPDATECOLSTATS=752;
	public static final int TOK_ALTERPARTITION_UPDATESTATS=753;
	public static final int TOK_ALTERTABLE=754;
	public static final int TOK_ALTERTABLE_ADDCOLS=755;
	public static final int TOK_ALTERTABLE_ADDCONSTRAINT=756;
	public static final int TOK_ALTERTABLE_ADDPARTS=757;
	public static final int TOK_ALTERTABLE_ARCHIVE=758;
	public static final int TOK_ALTERTABLE_BUCKETS=759;
	public static final int TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION=760;
	public static final int TOK_ALTERTABLE_CLUSTER_SORT=761;
	public static final int TOK_ALTERTABLE_COMPACT=762;
	public static final int TOK_ALTERTABLE_DROPCONSTRAINT=763;
	public static final int TOK_ALTERTABLE_DROPPARTS=764;
	public static final int TOK_ALTERTABLE_DROPPROPERTIES=765;
	public static final int TOK_ALTERTABLE_EXCHANGEPARTITION=766;
	public static final int TOK_ALTERTABLE_FILEFORMAT=767;
	public static final int TOK_ALTERTABLE_LOCATION=768;
	public static final int TOK_ALTERTABLE_MERGEFILES=769;
	public static final int TOK_ALTERTABLE_OWNER=770;
	public static final int TOK_ALTERTABLE_PARTCOLTYPE=771;
	public static final int TOK_ALTERTABLE_PROPERTIES=772;
	public static final int TOK_ALTERTABLE_RENAME=773;
	public static final int TOK_ALTERTABLE_RENAMECOL=774;
	public static final int TOK_ALTERTABLE_RENAMEPART=775;
	public static final int TOK_ALTERTABLE_REPLACECOLS=776;
	public static final int TOK_ALTERTABLE_SERDEPROPERTIES=777;
	public static final int TOK_ALTERTABLE_SERIALIZER=778;
	public static final int TOK_ALTERTABLE_SKEWED=779;
	public static final int TOK_ALTERTABLE_SKEWED_LOCATION=780;
	public static final int TOK_ALTERTABLE_TOUCH=781;
	public static final int TOK_ALTERTABLE_UNARCHIVE=782;
	public static final int TOK_ALTERTABLE_UPDATECOLSTATS=783;
	public static final int TOK_ALTERTABLE_UPDATECOLUMNS=784;
	public static final int TOK_ALTERTABLE_UPDATESTATS=785;
	public static final int TOK_ALTERVIEW=786;
	public static final int TOK_ALTERVIEW_ADDPARTS=787;
	public static final int TOK_ALTERVIEW_DROPPARTS=788;
	public static final int TOK_ALTERVIEW_DROPPROPERTIES=789;
	public static final int TOK_ALTERVIEW_PROPERTIES=790;
	public static final int TOK_ALTERVIEW_RENAME=791;
	public static final int TOK_ALTER_MAPPING=792;
	public static final int TOK_ALTER_MATERIALIZED_VIEW=793;
	public static final int TOK_ALTER_MATERIALIZED_VIEW_REBUILD=794;
	public static final int TOK_ALTER_MATERIALIZED_VIEW_REWRITE=795;
	public static final int TOK_ALTER_POOL=796;
	public static final int TOK_ALTER_POOL_ADD_TRIGGER=797;
	public static final int TOK_ALTER_POOL_DROP_TRIGGER=798;
	public static final int TOK_ALTER_RP_DISABLE=799;
	public static final int TOK_ALTER_RP_ENABLE=800;
	public static final int TOK_ALTER_RP_RENAME=801;
	public static final int TOK_ALTER_RP_REPLACE=802;
	public static final int TOK_ALTER_RP_SET=803;
	public static final int TOK_ALTER_RP_UNSET=804;
	public static final int TOK_ALTER_RP_VALIDATE=805;
	public static final int TOK_ALTER_SCHEDULED_QUERY=806;
	public static final int TOK_ALTER_TRIGGER=807;
	public static final int TOK_ANALYZE=808;
	public static final int TOK_ARCHIVE=809;
	public static final int TOK_BIGINT=810;
	public static final int TOK_BINARY=811;
	public static final int TOK_BLOCKING=812;
	public static final int TOK_BOOLEAN=813;
	public static final int TOK_CACHE_METADATA=814;
	public static final int TOK_CASCADE=815;
	public static final int TOK_CHAR=816;
	public static final int TOK_CHARSETLITERAL=817;
	public static final int TOK_CHECK_CONSTRAINT=818;
	public static final int TOK_CLUSTERBY=819;
	public static final int TOK_COLTYPELIST=820;
	public static final int TOK_COL_NAME=821;
	public static final int TOK_COMMIT=822;
	public static final int TOK_CONSTRAINT_NAME=823;
	public static final int TOK_CREATEDATABASE=824;
	public static final int TOK_CREATEFUNCTION=825;
	public static final int TOK_CREATEMACRO=826;
	public static final int TOK_CREATEROLE=827;
	public static final int TOK_CREATETABLE=828;
	public static final int TOK_CREATEVIEW=829;
	public static final int TOK_CREATE_MAPPING=830;
	public static final int TOK_CREATE_MATERIALIZED_VIEW=831;
	public static final int TOK_CREATE_POOL=832;
	public static final int TOK_CREATE_RP=833;
	public static final int TOK_CREATE_SCHEDULED_QUERY=834;
	public static final int TOK_CREATE_TRIGGER=835;
	public static final int TOK_CRON=836;
	public static final int TOK_CROSSJOIN=837;
	public static final int TOK_CTE=838;
	public static final int TOK_CUBE_GROUPBY=839;
	public static final int TOK_DATABASECOMMENT=840;
	public static final int TOK_DATABASELOCATION=841;
	public static final int TOK_DATABASEPROPERTIES=842;
	public static final int TOK_DATABASE_MANAGEDLOCATION=843;
	public static final int TOK_DATE=844;
	public static final int TOK_DATELITERAL=845;
	public static final int TOK_DATETIME=846;
	public static final int TOK_DBNAME=847;
	public static final int TOK_DBPROPLIST=848;
	public static final int TOK_DB_TYPE=849;
	public static final int TOK_DECIMAL=850;
	public static final int TOK_DEFAULT_POOL=851;
	public static final int TOK_DEFAULT_VALUE=852;
	public static final int TOK_DELETE=853;
	public static final int TOK_DELETE_FROM=854;
	public static final int TOK_DESCDATABASE=855;
	public static final int TOK_DESCFUNCTION=856;
	public static final int TOK_DESCTABLE=857;
	public static final int TOK_DESTINATION=858;
	public static final int TOK_DETAIL=859;
	public static final int TOK_DIR=860;
	public static final int TOK_DISABLE=861;
	public static final int TOK_DISTRIBUTEBY=862;
	public static final int TOK_DOUBLE=863;
	public static final int TOK_DROPDATABASE=864;
	public static final int TOK_DROPFUNCTION=865;
	public static final int TOK_DROPMACRO=866;
	public static final int TOK_DROPROLE=867;
	public static final int TOK_DROPTABLE=868;
	public static final int TOK_DROPVIEW=869;
	public static final int TOK_DROP_MAPPING=870;
	public static final int TOK_DROP_MATERIALIZED_VIEW=871;
	public static final int TOK_DROP_POOL=872;
	public static final int TOK_DROP_RP=873;
	public static final int TOK_DROP_SCHEDULED_QUERY=874;
	public static final int TOK_DROP_TRIGGER=875;
	public static final int TOK_ENABLE=876;
	public static final int TOK_EVERY=877;
	public static final int TOK_EXCEPTALL=878;
	public static final int TOK_EXCEPTDISTINCT=879;
	public static final int TOK_EXECUTE=880;
	public static final int TOK_EXECUTED_AS=881;
	public static final int TOK_EXPLAIN=882;
	public static final int TOK_EXPLAIN_SQ_REWRITE=883;
	public static final int TOK_EXPLIST=884;
	public static final int TOK_EXPORT=885;
	public static final int TOK_EXPRESSION=886;
	public static final int TOK_FALSE=887;
	public static final int TOK_FILE=888;
	public static final int TOK_FILEFORMAT_GENERIC=889;
	public static final int TOK_FLOAT=890;
	public static final int TOK_FORCE=891;
	public static final int TOK_FOREIGN_KEY=892;
	public static final int TOK_FROM=893;
	public static final int TOK_FULLOUTERJOIN=894;
	public static final int TOK_FUNCTION=895;
	public static final int TOK_FUNCTIONDI=896;
	public static final int TOK_FUNCTIONSTAR=897;
	public static final int TOK_GRANT=898;
	public static final int TOK_GRANT_OPTION_FOR=899;
	public static final int TOK_GRANT_ROLE=900;
	public static final int TOK_GRANT_WITH_ADMIN_OPTION=901;
	public static final int TOK_GRANT_WITH_OPTION=902;
	public static final int TOK_GROUP=903;
	public static final int TOK_GROUPBY=904;
	public static final int TOK_GROUPING_SETS=905;
	public static final int TOK_GROUPING_SETS_EXPRESSION=906;
	public static final int TOK_HAVING=907;
	public static final int TOK_IFEXISTS=908;
	public static final int TOK_IFNOTEXISTS=909;
	public static final int TOK_IMPORT=910;
	public static final int TOK_INPUTFORMAT=911;
	public static final int TOK_INSERT=912;
	public static final int TOK_INSERT_INTO=913;
	public static final int TOK_INT=914;
	public static final int TOK_INTERSECTALL=915;
	public static final int TOK_INTERSECTDISTINCT=916;
	public static final int TOK_INTERVAL_DAY_LITERAL=917;
	public static final int TOK_INTERVAL_DAY_TIME=918;
	public static final int TOK_INTERVAL_DAY_TIME_LITERAL=919;
	public static final int TOK_INTERVAL_HOUR_LITERAL=920;
	public static final int TOK_INTERVAL_MINUTE_LITERAL=921;
	public static final int TOK_INTERVAL_MONTH_LITERAL=922;
	public static final int TOK_INTERVAL_SECOND_LITERAL=923;
	public static final int TOK_INTERVAL_YEAR_LITERAL=924;
	public static final int TOK_INTERVAL_YEAR_MONTH=925;
	public static final int TOK_INTERVAL_YEAR_MONTH_LITERAL=926;
	public static final int TOK_ISOLATION_LEVEL=927;
	public static final int TOK_ISOLATION_SNAPSHOT=928;
	public static final int TOK_JAR=929;
	public static final int TOK_JOIN=930;
	public static final int TOK_KILL_QUERY=931;
	public static final int TOK_LATERAL_VIEW=932;
	public static final int TOK_LATERAL_VIEW_OUTER=933;
	public static final int TOK_LEFTOUTERJOIN=934;
	public static final int TOK_LEFTSEMIJOIN=935;
	public static final int TOK_LENGTH=936;
	public static final int TOK_LIKERP=937;
	public static final int TOK_LIKETABLE=938;
	public static final int TOK_LIMIT=939;
	public static final int TOK_LIST=940;
	public static final int TOK_LOAD=941;
	public static final int TOK_LOCKDB=942;
	public static final int TOK_LOCKTABLE=943;
	public static final int TOK_MAP=944;
	public static final int TOK_MATCHED=945;
	public static final int TOK_MERGE=946;
	public static final int TOK_METADATA=947;
	public static final int TOK_MSCK=948;
	public static final int TOK_NORELY=949;
	public static final int TOK_NOT_CLUSTERED=950;
	public static final int TOK_NOT_MATCHED=951;
	public static final int TOK_NOT_NULL=952;
	public static final int TOK_NOT_SORTED=953;
	public static final int TOK_NOVALIDATE=954;
	public static final int TOK_NO_DROP=955;
	public static final int TOK_NULL=956;
	public static final int TOK_NULLS_FIRST=957;
	public static final int TOK_NULLS_LAST=958;
	public static final int TOK_OFFLINE=959;
	public static final int TOK_OFFSET=960;
	public static final int TOK_ONLY=961;
	public static final int TOK_OPERATOR=962;
	public static final int TOK_OP_ADD=963;
	public static final int TOK_OP_AND=964;
	public static final int TOK_OP_BITAND=965;
	public static final int TOK_OP_BITNOT=966;
	public static final int TOK_OP_BITOR=967;
	public static final int TOK_OP_BITXOR=968;
	public static final int TOK_OP_DIV=969;
	public static final int TOK_OP_EQ=970;
	public static final int TOK_OP_GE=971;
	public static final int TOK_OP_GT=972;
	public static final int TOK_OP_LE=973;
	public static final int TOK_OP_LIKE=974;
	public static final int TOK_OP_LT=975;
	public static final int TOK_OP_MOD=976;
	public static final int TOK_OP_MUL=977;
	public static final int TOK_OP_NE=978;
	public static final int TOK_OP_NOT=979;
	public static final int TOK_OP_OR=980;
	public static final int TOK_OP_SUB=981;
	public static final int TOK_ORDERBY=982;
	public static final int TOK_ORREPLACE=983;
	public static final int TOK_PARTITIONINGSPEC=984;
	public static final int TOK_PARTITIONLOCATION=985;
	public static final int TOK_PARTSPEC=986;
	public static final int TOK_PARTVAL=987;
	public static final int TOK_PATH=988;
	public static final int TOK_PERCENT=989;
	public static final int TOK_PRIMARY_KEY=990;
	public static final int TOK_PRINCIPAL_NAME=991;
	public static final int TOK_PRIVILEGE=992;
	public static final int TOK_PRIVILEGE_LIST=993;
	public static final int TOK_PRIV_ALL=994;
	public static final int TOK_PRIV_ALTER_DATA=995;
	public static final int TOK_PRIV_ALTER_METADATA=996;
	public static final int TOK_PRIV_CREATE=997;
	public static final int TOK_PRIV_DELETE=998;
	public static final int TOK_PRIV_DROP=999;
	public static final int TOK_PRIV_INSERT=1000;
	public static final int TOK_PRIV_LOCK=1001;
	public static final int TOK_PRIV_OBJECT=1002;
	public static final int TOK_PRIV_OBJECT_COL=1003;
	public static final int TOK_PRIV_SELECT=1004;
	public static final int TOK_PRIV_SHOW_DATABASE=1005;
	public static final int TOK_PTBLFUNCTION=1006;
	public static final int TOK_QUERY=1007;
	public static final int TOK_QUERY_PARALLELISM=1008;
	public static final int TOK_READONLY=1009;
	public static final int TOK_RECORDREADER=1010;
	public static final int TOK_RECORDWRITER=1011;
	public static final int TOK_RELOADFUNCTIONS=1012;
	public static final int TOK_RELY=1013;
	public static final int TOK_RENAME=1014;
	public static final int TOK_REPLACE=1015;
	public static final int TOK_REPLICATION=1016;
	public static final int TOK_REPL_CONFIG=1017;
	public static final int TOK_REPL_CONFIG_LIST=1018;
	public static final int TOK_REPL_DUMP=1019;
	public static final int TOK_REPL_LOAD=1020;
	public static final int TOK_REPL_STATUS=1021;
	public static final int TOK_REPL_TABLES=1022;
	public static final int TOK_REPL_TABLES_LIST=1023;
	public static final int TOK_RESOURCE_ALL=1024;
	public static final int TOK_RESOURCE_LIST=1025;
	public static final int TOK_RESOURCE_URI=1026;
	public static final int TOK_RESTRICT=1027;
	public static final int TOK_REVOKE=1028;
	public static final int TOK_REVOKE_ROLE=1029;
	public static final int TOK_REWRITE_DISABLED=1030;
	public static final int TOK_REWRITE_ENABLED=1031;
	public static final int TOK_RIGHTOUTERJOIN=1032;
	public static final int TOK_ROLE=1033;
	public static final int TOK_ROLLBACK=1034;
	public static final int TOK_ROLLUP_GROUPBY=1035;
	public static final int TOK_ROWCOUNT=1036;
	public static final int TOK_SCHEDULE=1037;
	public static final int TOK_SCHEDULING_POLICY=1038;
	public static final int TOK_SELECT=1039;
	public static final int TOK_SELECTDI=1040;
	public static final int TOK_SELEXPR=1041;
	public static final int TOK_SERDE=1042;
	public static final int TOK_SERDENAME=1043;
	public static final int TOK_SERDEPROPS=1044;
	public static final int TOK_SERVER_TYPE=1045;
	public static final int TOK_SETCOLREF=1046;
	public static final int TOK_SET_AUTOCOMMIT=1047;
	public static final int TOK_SET_COLUMNS_CLAUSE=1048;
	public static final int TOK_SET_ROLE=1049;
	public static final int TOK_SHOWCOLUMNS=1050;
	public static final int TOK_SHOWCONF=1051;
	public static final int TOK_SHOWDATABASES=1052;
	public static final int TOK_SHOWDBLOCKS=1053;
	public static final int TOK_SHOWFUNCTIONS=1054;
	public static final int TOK_SHOWLOCKS=1055;
	public static final int TOK_SHOWMATERIALIZEDVIEWS=1056;
	public static final int TOK_SHOWPARTITIONS=1057;
	public static final int TOK_SHOWTABLES=1058;
	public static final int TOK_SHOWVIEWS=1059;
	public static final int TOK_SHOW_COMPACTIONS=1060;
	public static final int TOK_SHOW_CREATEDATABASE=1061;
	public static final int TOK_SHOW_CREATETABLE=1062;
	public static final int TOK_SHOW_CURRENT_ROLE=1063;
	public static final int TOK_SHOW_GRANT=1064;
	public static final int TOK_SHOW_ROLES=1065;
	public static final int TOK_SHOW_ROLE_GRANT=1066;
	public static final int TOK_SHOW_ROLE_PRINCIPALS=1067;
	public static final int TOK_SHOW_RP=1068;
	public static final int TOK_SHOW_TABLESTATUS=1069;
	public static final int TOK_SHOW_TBLPROPERTIES=1070;
	public static final int TOK_SHOW_TRANSACTIONS=1071;
	public static final int TOK_SKEWED_LOCATIONS=1072;
	public static final int TOK_SKEWED_LOCATION_LIST=1073;
	public static final int TOK_SKEWED_LOCATION_MAP=1074;
	public static final int TOK_SMALLINT=1075;
	public static final int TOK_SORTBY=1076;
	public static final int TOK_START_TRANSACTION=1077;
	public static final int TOK_STORAGEHANDLER=1078;
	public static final int TOK_STOREDASDIRS=1079;
	public static final int TOK_STRING=1080;
	public static final int TOK_STRINGLITERALSEQUENCE=1081;
	public static final int TOK_STRUCT=1082;
	public static final int TOK_SUBQUERY=1083;
	public static final int TOK_SUBQUERY_EXPR=1084;
	public static final int TOK_SUBQUERY_OP=1085;
	public static final int TOK_SUBQUERY_OP_NOTEXISTS=1086;
	public static final int TOK_SUBQUERY_OP_NOTIN=1087;
	public static final int TOK_SUMMARY=1088;
	public static final int TOK_SWITCHDATABASE=1089;
	public static final int TOK_TAB=1090;
	public static final int TOK_TABALIAS=1091;
	public static final int TOK_TABCOL=1092;
	public static final int TOK_TABCOLLIST=1093;
	public static final int TOK_TABCOLNAME=1094;
	public static final int TOK_TABCOLVALUE=1095;
	public static final int TOK_TABCOLVALUES=1096;
	public static final int TOK_TABCOLVALUE_PAIR=1097;
	public static final int TOK_TABLEBUCKETSAMPLE=1098;
	public static final int TOK_TABLECOMMENT=1099;
	public static final int TOK_TABLEFILEFORMAT=1100;
	public static final int TOK_TABLELOCATION=1101;
	public static final int TOK_TABLEPARTCOLNAMES=1102;
	public static final int TOK_TABLEPARTCOLS=1103;
	public static final int TOK_TABLEPROPERTIES=1104;
	public static final int TOK_TABLEPROPERTY=1105;
	public static final int TOK_TABLEPROPLIST=1106;
	public static final int TOK_TABLEROWFORMAT=1107;
	public static final int TOK_TABLEROWFORMATCOLLITEMS=1108;
	public static final int TOK_TABLEROWFORMATFIELD=1109;
	public static final int TOK_TABLEROWFORMATLINES=1110;
	public static final int TOK_TABLEROWFORMATMAPKEYS=1111;
	public static final int TOK_TABLEROWFORMATNULL=1112;
	public static final int TOK_TABLESERIALIZER=1113;
	public static final int TOK_TABLESKEWED=1114;
	public static final int TOK_TABLESPLITSAMPLE=1115;
	public static final int TOK_TABLE_OR_COL=1116;
	public static final int TOK_TABLE_PARTITION=1117;
	public static final int TOK_TABLE_TYPE=1118;
	public static final int TOK_TABNAME=1119;
	public static final int TOK_TABREF=1120;
	public static final int TOK_TABSORTCOLNAMEASC=1121;
	public static final int TOK_TABSORTCOLNAMEDESC=1122;
	public static final int TOK_TABSRC=1123;
	public static final int TOK_TABTYPE=1124;
	public static final int TOK_TEMPORARY=1125;
	public static final int TOK_TIMESTAMP=1126;
	public static final int TOK_TIMESTAMPLITERAL=1127;
	public static final int TOK_TIMESTAMPLOCALTZ=1128;
	public static final int TOK_TIMESTAMPLOCALTZLITERAL=1129;
	public static final int TOK_TINYINT=1130;
	public static final int TOK_TMP_FILE=1131;
	public static final int TOK_TO=1132;
	public static final int TOK_TRANSFORM=1133;
	public static final int TOK_TRIGGER_EXPRESSION=1134;
	public static final int TOK_TRUE=1135;
	public static final int TOK_TRUNCATETABLE=1136;
	public static final int TOK_TXN_ACCESS_MODE=1137;
	public static final int TOK_TXN_READ_ONLY=1138;
	public static final int TOK_TXN_READ_WRITE=1139;
	public static final int TOK_UNIONALL=1140;
	public static final int TOK_UNIONDISTINCT=1141;
	public static final int TOK_UNIONTYPE=1142;
	public static final int TOK_UNIQUE=1143;
	public static final int TOK_UNIQUEJOIN=1144;
	public static final int TOK_UNLOCKDB=1145;
	public static final int TOK_UNLOCKTABLE=1146;
	public static final int TOK_UNMANAGED=1147;
	public static final int TOK_UPDATE=1148;
	public static final int TOK_UPDATE_TABLE=1149;
	public static final int TOK_URI_TYPE=1150;
	public static final int TOK_USER=1151;
	public static final int TOK_USERSCRIPTCOLNAMES=1152;
	public static final int TOK_USERSCRIPTCOLSCHEMA=1153;
	public static final int TOK_VALIDATE=1154;
	public static final int TOK_VARCHAR=1155;
	public static final int TOK_VIEWCLUSTERCOLS=1156;
	public static final int TOK_VIEWDISTRIBUTECOLS=1157;
	public static final int TOK_VIEWPARTCOLS=1158;
	public static final int TOK_VIEWSORTCOLS=1159;
	public static final int TOK_WHERE=1160;
	public static final int TOK_WINDOWDEF=1161;
	public static final int TOK_WINDOWRANGE=1162;
	public static final int TOK_WINDOWSPEC=1163;
	public static final int TOK_WINDOWVALUES=1164;

	// delegates
	public HiveParser_SelectClauseParser gSelectClauseParser;
	public HiveParser_FromClauseParser gFromClauseParser;
	public HiveParser_IdentifiersParser gIdentifiersParser;
	public HiveParser_ResourcePlanParser gResourcePlanParser;
	public Parser[] getDelegates() {
		return new Parser[] {gSelectClauseParser, gFromClauseParser, gIdentifiersParser, gResourcePlanParser};
	}

	// delegators


	public HiveParser(TokenStream input) {
		this(input, new RecognizerSharedState());
	}
	public HiveParser(TokenStream input, RecognizerSharedState state) {
		super(input, state);
		gSelectClauseParser = new HiveParser_SelectClauseParser(input, state, this);
		gFromClauseParser = new HiveParser_FromClauseParser(input, state, this);
		gIdentifiersParser = new HiveParser_IdentifiersParser(input, state, this);
		gResourcePlanParser = new HiveParser_ResourcePlanParser(input, state, this);
	}

	protected TreeAdaptor adaptor = new CommonTreeAdaptor();

	public void setTreeAdaptor(TreeAdaptor adaptor) {
		this.adaptor = adaptor;
		gSelectClauseParser.setTreeAdaptor(this.adaptor);gFromClauseParser.setTreeAdaptor(this.adaptor);gIdentifiersParser.setTreeAdaptor(this.adaptor);gResourcePlanParser.setTreeAdaptor(this.adaptor);
	}
	public TreeAdaptor getTreeAdaptor() {
		return adaptor;
	}
	@Override public String[] getTokenNames() { return HiveParser.tokenNames; }
	@Override public String getGrammarFileName() { return "org/apache/hadoop/hive/ql/parse/HiveParser.g"; }


	  ArrayList<ParseError> errors = new ArrayList<ParseError>();
	  Stack msgs = new Stack<String>();

	  private static HashMap<String, String> xlateMap;
	  static {
	    //this is used to support auto completion in CLI
	    xlateMap = new HashMap<String, String>();

	    // Keywords
	    xlateMap.put("KW_TRUE", "TRUE");
	    xlateMap.put("KW_FALSE", "FALSE");
	    xlateMap.put("KW_ALL", "ALL");
	    xlateMap.put("KW_NONE", "NONE");
	    xlateMap.put("KW_AND", "AND");
	    xlateMap.put("KW_OR", "OR");
	    xlateMap.put("KW_NOT", "NOT");
	    xlateMap.put("KW_LIKE", "LIKE");

	    xlateMap.put("KW_ASC", "ASC");
	    xlateMap.put("KW_DESC", "DESC");
	    xlateMap.put("KW_NULLS", "NULLS");
	    xlateMap.put("KW_LAST", "LAST");
	    xlateMap.put("KW_ORDER", "ORDER");
	    xlateMap.put("KW_BY", "BY");
	    xlateMap.put("KW_GROUP", "GROUP");
	    xlateMap.put("KW_WHERE", "WHERE");
	    xlateMap.put("KW_FROM", "FROM");
	    xlateMap.put("KW_AS", "AS");
	    xlateMap.put("KW_SELECT", "SELECT");
	    xlateMap.put("KW_DISTINCT", "DISTINCT");
	    xlateMap.put("KW_INSERT", "INSERT");
	    xlateMap.put("KW_OVERWRITE", "OVERWRITE");
	    xlateMap.put("KW_OUTER", "OUTER");
	    xlateMap.put("KW_JOIN", "JOIN");
	    xlateMap.put("KW_LEFT", "LEFT");
	    xlateMap.put("KW_RIGHT", "RIGHT");
	    xlateMap.put("KW_FULL", "FULL");
	    xlateMap.put("KW_ON", "ON");
	    xlateMap.put("KW_PARTITION", "PARTITION");
	    xlateMap.put("KW_PARTITIONS", "PARTITIONS");
	    xlateMap.put("KW_TABLE", "TABLE");
	    xlateMap.put("KW_TABLES", "TABLES");
	    xlateMap.put("KW_TBLPROPERTIES", "TBLPROPERTIES");
	    xlateMap.put("KW_SHOW", "SHOW");
	    xlateMap.put("KW_MSCK", "MSCK");
	    xlateMap.put("KW_DIRECTORY", "DIRECTORY");
	    xlateMap.put("KW_LOCAL", "LOCAL");
	    xlateMap.put("KW_TRANSFORM", "TRANSFORM");
	    xlateMap.put("KW_USING", "USING");
	    xlateMap.put("KW_CLUSTER", "CLUSTER");
	    xlateMap.put("KW_DISTRIBUTE", "DISTRIBUTE");
	    xlateMap.put("KW_SORT", "SORT");
	    xlateMap.put("KW_SYNC", "SYNC");
	    xlateMap.put("KW_UNION", "UNION");
	    xlateMap.put("KW_INTERSECT", "INTERSECT");
	    xlateMap.put("KW_EXCEPT", "EXCEPT");
	    xlateMap.put("KW_LOAD", "LOAD");
	    xlateMap.put("KW_DATA", "DATA");
	    xlateMap.put("KW_INPATH", "INPATH");
	    xlateMap.put("KW_IS", "IS");
	    xlateMap.put("KW_NULL", "NULL");
	    xlateMap.put("KW_CREATE", "CREATE");
	    xlateMap.put("KW_EXTERNAL", "EXTERNAL");
	    xlateMap.put("KW_ALTER", "ALTER");
	    xlateMap.put("KW_DESCRIBE", "DESCRIBE");
	    xlateMap.put("KW_DROP", "DROP");
	    xlateMap.put("KW_RENAME", "RENAME");
	    xlateMap.put("KW_TO", "TO");
	    xlateMap.put("KW_COMMENT", "COMMENT");
	    xlateMap.put("KW_BOOLEAN", "BOOLEAN");
	    xlateMap.put("KW_TINYINT", "TINYINT");
	    xlateMap.put("KW_SMALLINT", "SMALLINT");
	    xlateMap.put("KW_INT", "INT");
	    xlateMap.put("KW_BIGINT", "BIGINT");
	    xlateMap.put("KW_FLOAT", "FLOAT");
	    xlateMap.put("KW_DOUBLE", "DOUBLE");
	    xlateMap.put("KW_PRECISION", "PRECISION");
	    xlateMap.put("KW_DATE", "DATE");
	    xlateMap.put("KW_DATETIME", "DATETIME");
	    xlateMap.put("KW_TIMESTAMP", "TIMESTAMP");
	    xlateMap.put("KW_TIMESTAMPLOCALTZ", "TIMESTAMPLOCALTZ");
	    xlateMap.put("KW_TIME", "TIME");
	    xlateMap.put("KW_ZONE", "ZONE");
	    xlateMap.put("KW_STRING", "STRING");
	    xlateMap.put("KW_BINARY", "BINARY");
	    xlateMap.put("KW_ARRAY", "ARRAY");
	    xlateMap.put("KW_MAP", "MAP");
	    xlateMap.put("KW_REDUCE", "REDUCE");
	    xlateMap.put("KW_PARTITIONED", "PARTITIONED");
	    xlateMap.put("KW_CLUSTERED", "CLUSTERED");
	    xlateMap.put("KW_SORTED", "SORTED");
	    xlateMap.put("KW_INTO", "INTO");
	    xlateMap.put("KW_BUCKETS", "BUCKETS");
	    xlateMap.put("KW_ROW", "ROW");
	    xlateMap.put("KW_FORMAT", "FORMAT");
	    xlateMap.put("KW_DELIMITED", "DELIMITED");
	    xlateMap.put("KW_FIELDS", "FIELDS");
	    xlateMap.put("KW_TERMINATED", "TERMINATED");
	    xlateMap.put("KW_COLLECTION", "COLLECTION");
	    xlateMap.put("KW_ITEMS", "ITEMS");
	    xlateMap.put("KW_KEYS", "KEYS");
	    xlateMap.put("KW_KEY_TYPE", "$KEY$");
	    xlateMap.put("KW_LINES", "LINES");
	    xlateMap.put("KW_STORED", "STORED");
	    xlateMap.put("KW_SEQUENCEFILE", "SEQUENCEFILE");
	    xlateMap.put("KW_TEXTFILE", "TEXTFILE");
	    xlateMap.put("KW_INPUTFORMAT", "INPUTFORMAT");
	    xlateMap.put("KW_OUTPUTFORMAT", "OUTPUTFORMAT");
	    xlateMap.put("KW_LOCATION", "LOCATION");
	    xlateMap.put("KW_MANAGEDLOCATION", "MANAGEDLOCATION");
	    xlateMap.put("KW_TABLESAMPLE", "TABLESAMPLE");
	    xlateMap.put("KW_BUCKET", "BUCKET");
	    xlateMap.put("KW_OUT", "OUT");
	    xlateMap.put("KW_OF", "OF");
	    xlateMap.put("KW_CAST", "CAST");
	    xlateMap.put("KW_ADD", "ADD");
	    xlateMap.put("KW_REPLACE", "REPLACE");
	    xlateMap.put("KW_COLUMNS", "COLUMNS");
	    xlateMap.put("KW_RLIKE", "RLIKE");
	    xlateMap.put("KW_REGEXP", "REGEXP");
	    xlateMap.put("KW_TEMPORARY", "TEMPORARY");
	    xlateMap.put("KW_FUNCTION", "FUNCTION");
	    xlateMap.put("KW_FUNCTIONS", "FUNCTIONS");
	    xlateMap.put("KW_EXPLAIN", "EXPLAIN");
	    xlateMap.put("KW_EXTENDED", "EXTENDED");
	    xlateMap.put("KW_DEBUG", "DEBUG");
	    xlateMap.put("KW_SERDE", "SERDE");
	    xlateMap.put("KW_WITH", "WITH");
	    xlateMap.put("KW_SERDEPROPERTIES", "SERDEPROPERTIES");
	    xlateMap.put("KW_LIMIT", "LIMIT");
	    xlateMap.put("KW_OFFSET", "OFFSET");
	    xlateMap.put("KW_SET", "SET");
	    xlateMap.put("KW_PROPERTIES", "TBLPROPERTIES");
	    xlateMap.put("KW_VALUE_TYPE", "$VALUE$");
	    xlateMap.put("KW_ELEM_TYPE", "$ELEM$");
	    xlateMap.put("KW_DEFINED", "DEFINED");
	    xlateMap.put("KW_SUBQUERY", "SUBQUERY");
	    xlateMap.put("KW_REWRITE", "REWRITE");
	    xlateMap.put("KW_UPDATE", "UPDATE");
	    xlateMap.put("KW_VALUES", "VALUES");
	    xlateMap.put("KW_PURGE", "PURGE");
	    xlateMap.put("KW_UNIQUE", "UNIQUE");
	    xlateMap.put("KW_PRIMARY", "PRIMARY");
	    xlateMap.put("KW_FOREIGN", "FOREIGN");
	    xlateMap.put("KW_KEY", "KEY");
	    xlateMap.put("KW_REFERENCES", "REFERENCES");
	    xlateMap.put("KW_CONSTRAINT", "CONSTRAINT");
	    xlateMap.put("KW_ENABLE", "ENABLE");
	    xlateMap.put("KW_DISABLE", "DISABLE");
	    xlateMap.put("KW_VALIDATE", "VALIDATE");
	    xlateMap.put("KW_NOVALIDATE", "NOVALIDATE");
	    xlateMap.put("KW_RELY", "RELY");
	    xlateMap.put("KW_NORELY", "NORELY");
	    xlateMap.put("KW_ABORT", "ABORT");
	    xlateMap.put("KW_TRANSACTIONS", "TRANSACTIONS");
	    xlateMap.put("KW_COMPACTIONS", "COMPACTIONS");
	    xlateMap.put("KW_COMPACT", "COMPACT");
	    xlateMap.put("KW_WAIT", "WAIT");
	    xlateMap.put("KW_KILL", "KILL");
	    xlateMap.put("KW_QUERY", "QUERY");
	    xlateMap.put("KW_RESOURCE", "RESOURCE");
	    xlateMap.put("KW_PLAN", "PLAN");
	    xlateMap.put("KW_QUERY_PARALLELISM", "QUERY_PARALLELISM");
	    xlateMap.put("KW_PLANS", "PLANS");
	    xlateMap.put("KW_ACTIVATE", "ACTIVATE");
	    xlateMap.put("KW_DEFAULT", "DEFAULT");
	    xlateMap.put("KW_CHECK", "CHECK");
	    xlateMap.put("KW_POOL", "POOL");
	    xlateMap.put("KW_MOVE", "MOVE");
	    xlateMap.put("KW_DO", "DO");
	    xlateMap.put("KW_ALLOC_FRACTION", "ALLOC_FRACTION");
	    xlateMap.put("KW_SCHEDULING_POLICY", "SCHEDULING_POLICY");
	    xlateMap.put("KW_PATH", "PATH");
	    xlateMap.put("KW_AST", "AST");
	    xlateMap.put("KW_TRANSACTIONAL", "TRANSACTIONAL");

	    // Operators
	    xlateMap.put("DOT", ".");
	    xlateMap.put("COLON", ":");
	    xlateMap.put("COMMA", ",");
	    xlateMap.put("SEMICOLON", ");");

	    xlateMap.put("LPAREN", "(");
	    xlateMap.put("RPAREN", ")");
	    xlateMap.put("LSQUARE", "[");
	    xlateMap.put("RSQUARE", "]");

	    xlateMap.put("EQUAL", "=");
	    xlateMap.put("NOTEQUAL", "<>");
	    xlateMap.put("EQUAL_NS", "<=>");
	    xlateMap.put("LESSTHANOREQUALTO", "<=");
	    xlateMap.put("LESSTHAN", "<");
	    xlateMap.put("GREATERTHANOREQUALTO", ">=");
	    xlateMap.put("GREATERTHAN", ">");

	    xlateMap.put("DIVIDE", "/");
	    xlateMap.put("PLUS", "+");
	    xlateMap.put("MINUS", "-");
	    xlateMap.put("STAR", "*");
	    xlateMap.put("MOD", "%");

	    xlateMap.put("AMPERSAND", "&");
	    xlateMap.put("TILDE", "~");
	    xlateMap.put("BITWISEOR", "|");
	    xlateMap.put("BITWISEXOR", "^");
	    xlateMap.put("CharSetLiteral", "\\'");
	  }

	  public static Collection<String> getKeywords() {
	    return xlateMap.values();
	  }

	  private static String xlate(String name) {

	    String ret = xlateMap.get(name);
	    if (ret == null) {
	      ret = name;
	    }

	    return ret;
	  }

	  @Override
	  public Object recoverFromMismatchedSet(IntStream input,
	      RecognitionException re, BitSet follow) throws RecognitionException {
	    throw re;
	  }

	  @Override
	  public void displayRecognitionError(String[] tokenNames,
	      RecognitionException e) {
	    errors.add(new ParseError(this, e, tokenNames));
	  }

	  @Override
	  public String getErrorHeader(RecognitionException e) {
	    String header = null;
	    if (e.charPositionInLine < 0 && input.LT(-1) != null) {
	      Token t = input.LT(-1);
	      header = "line " + t.getLine() + ":" + t.getCharPositionInLine();
	    } else {
	      header = super.getErrorHeader(e);
	    }

	    return header;
	  }
	  
	  @Override
	  public String getErrorMessage(RecognitionException e, String[] tokenNames) {
	    String msg = null;

	    // Translate the token names to something that the user can understand
	    String[] xlateNames = new String[tokenNames.length];
	    for (int i = 0; i < tokenNames.length; ++i) {
	      xlateNames[i] = HiveParser.xlate(tokenNames[i]);
	    }

	    if (e instanceof NoViableAltException) {
	      @SuppressWarnings("unused")
	      NoViableAltException nvae = (NoViableAltException) e;
	      // for development, can add
	      // "decision=<<"+nvae.grammarDecisionDescription+">>"
	      // and "(decision="+nvae.decisionNumber+") and
	      // "state "+nvae.stateNumber
	      msg = "cannot recognize input near"
	              + (input.LT(1) != null ? " " + getTokenErrorDisplay(input.LT(1)) : "")
	              + (input.LT(2) != null ? " " + getTokenErrorDisplay(input.LT(2)) : "")
	              + (input.LT(3) != null ? " " + getTokenErrorDisplay(input.LT(3)) : "");
	    } else if (e instanceof MismatchedTokenException) {
	      MismatchedTokenException mte = (MismatchedTokenException) e;
	      msg = super.getErrorMessage(e, xlateNames) + (input.LT(-1) == null ? "":" near '" + input.LT(-1).getText()) + "'";
	    } else if (e instanceof FailedPredicateException) {
	      FailedPredicateException fpe = (FailedPredicateException) e;
	      msg = "Failed to recognize predicate '" + fpe.token.getText() + "'. Failed rule: '" + fpe.ruleName + "'";
	    } else {
	      msg = super.getErrorMessage(e, xlateNames);
	    }

	    if (msgs.size() > 0) {
	      msg = msg + " in " + msgs.peek();
	    }
	    return msg;
	  }
	  
	  public void pushMsg(String msg, RecognizerSharedState state) {
	    // ANTLR generated code does not wrap the @init code wit this backtracking check,
	    //  even if the matching @after has it. If we have parser rules with that are doing
	    // some lookahead with syntactic predicates this can cause the push() and pop() calls
	    // to become unbalanced, so make sure both push/pop check the backtracking state.
	    if (state.backtracking == 0) {
	      msgs.push(msg);
	    }
	  }

	  public void popMsg(RecognizerSharedState state) {
	    if (state.backtracking == 0) {
	      Object o = msgs.pop();
	    }
	  }

	  // counter to generate unique union aliases
	  private int aliasCounter;
	  private String generateUnionAlias() {
	    return "__u" + (++aliasCounter);
	  }
	  private char [] excludedCharForColumnName = {'.', ':'};
	  private boolean containExcludedCharForCreateTableColumnName(String input) {
	    for(char c : excludedCharForColumnName) {
	      if(input.indexOf(c)>-1) {
	        return true;
	      }
	    }
	    return false;
	  }
	  private CommonTree throwSetOpException() throws RecognitionException {
	    throw new FailedPredicateException(input, "orderByClause clusterByClause distributeByClause sortByClause limitClause can only be applied to the whole union.", "");
	  }
	  private CommonTree throwColumnNameException() throws RecognitionException {
	    throw new FailedPredicateException(input, Arrays.toString(excludedCharForColumnName) + " can not be used in column name in create table statement.", "");
	  }
	  private Configuration hiveConf;
	  public void setHiveConf(Configuration hiveConf) {
	    this.hiveConf = hiveConf;
	  }
	  protected boolean nullsLast() {
	    if(hiveConf == null){
	      return false;
	    }
	    return HiveConf.getBoolVar(hiveConf, HiveConf.ConfVars.HIVE_DEFAULT_NULLS_LAST);
	  }


	public static class statement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "statement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:816:1: statement : ( explainStatement EOF | execStatement EOF );
	public final HiveParser.statement_return statement() throws RecognitionException {
		HiveParser.statement_return retval = new HiveParser.statement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token EOF2=null;
		Token EOF4=null;
		ParserRuleReturnScope explainStatement1 =null;
		ParserRuleReturnScope execStatement3 =null;

		ASTNode EOF2_tree=null;
		ASTNode EOF4_tree=null;

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:817:2: ( explainStatement EOF | execStatement EOF )
			int alt1=2;
			int LA1_0 = input.LA(1);
			if ( (LA1_0==KW_EXPLAIN) ) {
				alt1=1;
			}
			else if ( (LA1_0==KW_ABORT||(LA1_0 >= KW_ALTER && LA1_0 <= KW_ANALYZE)||LA1_0==KW_COMMIT||LA1_0==KW_CREATE||LA1_0==KW_DELETE||(LA1_0 >= KW_DESC && LA1_0 <= KW_DESCRIBE)||LA1_0==KW_DISABLE||LA1_0==KW_DROP||LA1_0==KW_ENABLE||LA1_0==KW_EXPORT||LA1_0==KW_FROM||LA1_0==KW_GRANT||LA1_0==KW_IMPORT||LA1_0==KW_INSERT||LA1_0==KW_KILL||LA1_0==KW_LOAD||LA1_0==KW_LOCK||LA1_0==KW_MAP||LA1_0==KW_MERGE||LA1_0==KW_MSCK||LA1_0==KW_REDUCE||LA1_0==KW_RELOAD||(LA1_0 >= KW_REPL && LA1_0 <= KW_REPLACE)||LA1_0==KW_REVOKE||LA1_0==KW_ROLLBACK||LA1_0==KW_SELECT||LA1_0==KW_SET||LA1_0==KW_SHOW||LA1_0==KW_START||LA1_0==KW_TRUNCATE||LA1_0==KW_UNLOCK||LA1_0==KW_UPDATE||LA1_0==KW_USE||LA1_0==KW_WITH||LA1_0==LPAREN) ) {
				alt1=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 1, 0, input);
				throw nvae;
			}

			switch (alt1) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:817:4: explainStatement EOF
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_explainStatement_in_statement1376);
					explainStatement1=explainStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, explainStatement1.getTree());

					EOF2=(Token)match(input,EOF,FOLLOW_EOF_in_statement1378); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					EOF2_tree = (ASTNode)adaptor.create(EOF2);
					adaptor.addChild(root_0, EOF2_tree);
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:818:4: execStatement EOF
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_execStatement_in_statement1383);
					execStatement3=execStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, execStatement3.getTree());

					EOF4=(Token)match(input,EOF,FOLLOW_EOF_in_statement1385); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					EOF4_tree = (ASTNode)adaptor.create(EOF4);
					adaptor.addChild(root_0, EOF4_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "statement"


	public static class explainStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "explainStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:821:1: explainStatement : KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) ;
	public final HiveParser.explainStatement_return explainStatement() throws RecognitionException {
		HiveParser.explainStatement_return retval = new HiveParser.explainStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_EXPLAIN5=null;
		Token KW_REWRITE8=null;
		ParserRuleReturnScope explainOption6 =null;
		ParserRuleReturnScope execStatement7 =null;
		ParserRuleReturnScope queryStatementExpression9 =null;

		ASTNode KW_EXPLAIN5_tree=null;
		ASTNode KW_REWRITE8_tree=null;
		RewriteRuleTokenStream stream_KW_REWRITE=new RewriteRuleTokenStream(adaptor,"token KW_REWRITE");
		RewriteRuleTokenStream stream_KW_EXPLAIN=new RewriteRuleTokenStream(adaptor,"token KW_EXPLAIN");
		RewriteRuleSubtreeStream stream_queryStatementExpression=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpression");
		RewriteRuleSubtreeStream stream_explainOption=new RewriteRuleSubtreeStream(adaptor,"rule explainOption");
		RewriteRuleSubtreeStream stream_execStatement=new RewriteRuleSubtreeStream(adaptor,"rule execStatement");

		 pushMsg("explain statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:824:2: ( KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:824:4: KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
			{
			KW_EXPLAIN5=(Token)match(input,KW_EXPLAIN,FOLLOW_KW_EXPLAIN_in_explainStatement1406); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXPLAIN.add(KW_EXPLAIN5);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:824:15: ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
			int alt3=2;
			int LA3_0 = input.LA(1);
			if ( (LA3_0==KW_ABORT||(LA3_0 >= KW_ALTER && LA3_0 <= KW_ANALYZE)||LA3_0==KW_AUTHORIZATION||LA3_0==KW_CBO||LA3_0==KW_COMMIT||LA3_0==KW_CREATE||LA3_0==KW_DEBUG||LA3_0==KW_DELETE||(LA3_0 >= KW_DEPENDENCY && LA3_0 <= KW_DESCRIBE)||LA3_0==KW_DISABLE||LA3_0==KW_DROP||LA3_0==KW_ENABLE||LA3_0==KW_EXPORT||LA3_0==KW_EXTENDED||(LA3_0 >= KW_FORMATTED && LA3_0 <= KW_FROM)||LA3_0==KW_GRANT||LA3_0==KW_IMPORT||LA3_0==KW_INSERT||LA3_0==KW_KILL||LA3_0==KW_LOAD||(LA3_0 >= KW_LOCK && LA3_0 <= KW_LOGICAL)||LA3_0==KW_MAP||LA3_0==KW_MERGE||LA3_0==KW_MSCK||LA3_0==KW_REDUCE||LA3_0==KW_RELOAD||LA3_0==KW_REOPTIMIZATION||(LA3_0 >= KW_REPL && LA3_0 <= KW_REPLACE)||LA3_0==KW_REVOKE||LA3_0==KW_ROLLBACK||LA3_0==KW_SELECT||LA3_0==KW_SET||LA3_0==KW_SHOW||LA3_0==KW_START||LA3_0==KW_TRUNCATE||LA3_0==KW_UNLOCK||LA3_0==KW_UPDATE||LA3_0==KW_USE||LA3_0==KW_VECTORIZATION||LA3_0==KW_WITH||LA3_0==LPAREN) ) {
				alt3=1;
			}
			else if ( (LA3_0==KW_REWRITE) ) {
				alt3=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 3, 0, input);
				throw nvae;
			}

			switch (alt3) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:825:6: ( explainOption )* execStatement
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:825:6: ( explainOption )*
					loop2:
					while (true) {
						int alt2=2;
						alt2 = dfa2.predict(input);
						switch (alt2) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:825:6: explainOption
							{
							pushFollow(FOLLOW_explainOption_in_explainStatement1415);
							explainOption6=explainOption();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_explainOption.add(explainOption6.getTree());
							}
							break;

						default :
							break loop2;
						}
					}

					pushFollow(FOLLOW_execStatement_in_explainStatement1418);
					execStatement7=execStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_execStatement.add(execStatement7.getTree());
					// AST REWRITE
					// elements: explainOption, execStatement
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 825:35: -> ^( TOK_EXPLAIN execStatement ( explainOption )* )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:825:38: ^( TOK_EXPLAIN execStatement ( explainOption )* )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPLAIN, "TOK_EXPLAIN"), root_1);
						adaptor.addChild(root_1, stream_execStatement.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:825:66: ( explainOption )*
						while ( stream_explainOption.hasNext() ) {
							adaptor.addChild(root_1, stream_explainOption.nextTree());
						}
						stream_explainOption.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:827:9: KW_REWRITE queryStatementExpression
					{
					KW_REWRITE8=(Token)match(input,KW_REWRITE,FOLLOW_KW_REWRITE_in_explainStatement1449); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REWRITE.add(KW_REWRITE8);

					pushFollow(FOLLOW_queryStatementExpression_in_explainStatement1451);
					queryStatementExpression9=queryStatementExpression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_queryStatementExpression.add(queryStatementExpression9.getTree());
					// AST REWRITE
					// elements: queryStatementExpression
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 827:45: -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:827:48: ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPLAIN_SQ_REWRITE, "TOK_EXPLAIN_SQ_REWRITE"), root_1);
						adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "explainStatement"


	public static class explainOption_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "explainOption"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:831:1: explainOption : ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_CBO ( KW_COST | KW_JOINCOST )? | KW_LOGICAL | KW_AUTHORIZATION | KW_ANALYZE | KW_REOPTIMIZATION | KW_LOCKS | ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? ) | KW_DEBUG );
	public final HiveParser.explainOption_return explainOption() throws RecognitionException {
		HiveParser.explainOption_return retval = new HiveParser.explainOption_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_EXTENDED10=null;
		Token KW_FORMATTED11=null;
		Token KW_DEPENDENCY12=null;
		Token KW_CBO13=null;
		Token set14=null;
		Token KW_LOGICAL15=null;
		Token KW_AUTHORIZATION16=null;
		Token KW_ANALYZE17=null;
		Token KW_REOPTIMIZATION18=null;
		Token KW_LOCKS19=null;
		Token KW_VECTORIZATION20=null;
		Token KW_DEBUG23=null;
		ParserRuleReturnScope vectorizationOnly21 =null;
		ParserRuleReturnScope vectorizatonDetail22 =null;

		ASTNode KW_EXTENDED10_tree=null;
		ASTNode KW_FORMATTED11_tree=null;
		ASTNode KW_DEPENDENCY12_tree=null;
		ASTNode KW_CBO13_tree=null;
		ASTNode set14_tree=null;
		ASTNode KW_LOGICAL15_tree=null;
		ASTNode KW_AUTHORIZATION16_tree=null;
		ASTNode KW_ANALYZE17_tree=null;
		ASTNode KW_REOPTIMIZATION18_tree=null;
		ASTNode KW_LOCKS19_tree=null;
		ASTNode KW_VECTORIZATION20_tree=null;
		ASTNode KW_DEBUG23_tree=null;

		 msgs.push("explain option"); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:834:5: ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_CBO ( KW_COST | KW_JOINCOST )? | KW_LOGICAL | KW_AUTHORIZATION | KW_ANALYZE | KW_REOPTIMIZATION | KW_LOCKS | ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? ) | KW_DEBUG )
			int alt7=11;
			switch ( input.LA(1) ) {
			case KW_EXTENDED:
				{
				alt7=1;
				}
				break;
			case KW_FORMATTED:
				{
				alt7=2;
				}
				break;
			case KW_DEPENDENCY:
				{
				alt7=3;
				}
				break;
			case KW_CBO:
				{
				alt7=4;
				}
				break;
			case KW_LOGICAL:
				{
				alt7=5;
				}
				break;
			case KW_AUTHORIZATION:
				{
				alt7=6;
				}
				break;
			case KW_ANALYZE:
				{
				alt7=7;
				}
				break;
			case KW_REOPTIMIZATION:
				{
				alt7=8;
				}
				break;
			case KW_LOCKS:
				{
				alt7=9;
				}
				break;
			case KW_VECTORIZATION:
				{
				alt7=10;
				}
				break;
			case KW_DEBUG:
				{
				alt7=11;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 7, 0, input);
				throw nvae;
			}
			switch (alt7) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:834:7: KW_EXTENDED
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_EXTENDED10=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_explainOption1491); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_EXTENDED10_tree = (ASTNode)adaptor.create(KW_EXTENDED10);
					adaptor.addChild(root_0, KW_EXTENDED10_tree);
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:835:7: KW_FORMATTED
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_FORMATTED11=(Token)match(input,KW_FORMATTED,FOLLOW_KW_FORMATTED_in_explainOption1499); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_FORMATTED11_tree = (ASTNode)adaptor.create(KW_FORMATTED11);
					adaptor.addChild(root_0, KW_FORMATTED11_tree);
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:836:7: KW_DEPENDENCY
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_DEPENDENCY12=(Token)match(input,KW_DEPENDENCY,FOLLOW_KW_DEPENDENCY_in_explainOption1507); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_DEPENDENCY12_tree = (ASTNode)adaptor.create(KW_DEPENDENCY12);
					adaptor.addChild(root_0, KW_DEPENDENCY12_tree);
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:837:7: KW_CBO ( KW_COST | KW_JOINCOST )?
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_CBO13=(Token)match(input,KW_CBO,FOLLOW_KW_CBO_in_explainOption1515); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_CBO13_tree = (ASTNode)adaptor.create(KW_CBO13);
					adaptor.addChild(root_0, KW_CBO13_tree);
					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:837:14: ( KW_COST | KW_JOINCOST )?
					int alt4=2;
					int LA4_0 = input.LA(1);
					if ( (LA4_0==KW_COST||LA4_0==KW_JOINCOST) ) {
						alt4=1;
					}
					switch (alt4) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:
							{
							set14=input.LT(1);
							if ( input.LA(1)==KW_COST||input.LA(1)==KW_JOINCOST ) {
								input.consume();
								if ( state.backtracking==0 ) adaptor.addChild(root_0, (ASTNode)adaptor.create(set14));
								state.errorRecovery=false;
								state.failed=false;
							}
							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								MismatchedSetException mse = new MismatchedSetException(null,input);
								throw mse;
							}
							}
							break;

					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:838:7: KW_LOGICAL
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_LOGICAL15=(Token)match(input,KW_LOGICAL,FOLLOW_KW_LOGICAL_in_explainOption1532); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_LOGICAL15_tree = (ASTNode)adaptor.create(KW_LOGICAL15);
					adaptor.addChild(root_0, KW_LOGICAL15_tree);
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:839:7: KW_AUTHORIZATION
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_AUTHORIZATION16=(Token)match(input,KW_AUTHORIZATION,FOLLOW_KW_AUTHORIZATION_in_explainOption1540); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_AUTHORIZATION16_tree = (ASTNode)adaptor.create(KW_AUTHORIZATION16);
					adaptor.addChild(root_0, KW_AUTHORIZATION16_tree);
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:840:7: KW_ANALYZE
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_ANALYZE17=(Token)match(input,KW_ANALYZE,FOLLOW_KW_ANALYZE_in_explainOption1548); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_ANALYZE17_tree = (ASTNode)adaptor.create(KW_ANALYZE17);
					adaptor.addChild(root_0, KW_ANALYZE17_tree);
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:841:7: KW_REOPTIMIZATION
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_REOPTIMIZATION18=(Token)match(input,KW_REOPTIMIZATION,FOLLOW_KW_REOPTIMIZATION_in_explainOption1556); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_REOPTIMIZATION18_tree = (ASTNode)adaptor.create(KW_REOPTIMIZATION18);
					adaptor.addChild(root_0, KW_REOPTIMIZATION18_tree);
					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:842:7: KW_LOCKS
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_LOCKS19=(Token)match(input,KW_LOCKS,FOLLOW_KW_LOCKS_in_explainOption1564); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_LOCKS19_tree = (ASTNode)adaptor.create(KW_LOCKS19);
					adaptor.addChild(root_0, KW_LOCKS19_tree);
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:843:7: ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:843:7: ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:843:8: KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )?
					{
					KW_VECTORIZATION20=(Token)match(input,KW_VECTORIZATION,FOLLOW_KW_VECTORIZATION_in_explainOption1573); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_VECTORIZATION20_tree = (ASTNode)adaptor.create(KW_VECTORIZATION20);
					adaptor.addChild(root_0, KW_VECTORIZATION20_tree);
					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:843:25: ( vectorizationOnly )?
					int alt5=2;
					int LA5_0 = input.LA(1);
					if ( (LA5_0==KW_ONLY) ) {
						alt5=1;
					}
					switch (alt5) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:843:25: vectorizationOnly
							{
							pushFollow(FOLLOW_vectorizationOnly_in_explainOption1575);
							vectorizationOnly21=vectorizationOnly();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, vectorizationOnly21.getTree());

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:843:44: ( vectorizatonDetail )?
					int alt6=2;
					int LA6_0 = input.LA(1);
					if ( (LA6_0==KW_DETAIL||LA6_0==KW_EXPRESSION||LA6_0==KW_OPERATOR||LA6_0==KW_SUMMARY) ) {
						alt6=1;
					}
					switch (alt6) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:843:44: vectorizatonDetail
							{
							pushFollow(FOLLOW_vectorizatonDetail_in_explainOption1578);
							vectorizatonDetail22=vectorizatonDetail();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, vectorizatonDetail22.getTree());

							}
							break;

					}

					}

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:844:7: KW_DEBUG
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_DEBUG23=(Token)match(input,KW_DEBUG,FOLLOW_KW_DEBUG_in_explainOption1588); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_DEBUG23_tree = (ASTNode)adaptor.create(KW_DEBUG23);
					adaptor.addChild(root_0, KW_DEBUG23_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { msgs.pop(); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "explainOption"


	public static class vectorizationOnly_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "vectorizationOnly"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:847:1: vectorizationOnly : KW_ONLY -> ^( TOK_ONLY ) ;
	public final HiveParser.vectorizationOnly_return vectorizationOnly() throws RecognitionException {
		HiveParser.vectorizationOnly_return retval = new HiveParser.vectorizationOnly_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ONLY24=null;

		ASTNode KW_ONLY24_tree=null;
		RewriteRuleTokenStream stream_KW_ONLY=new RewriteRuleTokenStream(adaptor,"token KW_ONLY");

		 pushMsg("vectorization's only clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:850:5: ( KW_ONLY -> ^( TOK_ONLY ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:850:7: KW_ONLY
			{
			KW_ONLY24=(Token)match(input,KW_ONLY,FOLLOW_KW_ONLY_in_vectorizationOnly1615); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ONLY.add(KW_ONLY24);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 851:5: -> ^( TOK_ONLY )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:851:8: ^( TOK_ONLY )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ONLY, "TOK_ONLY"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "vectorizationOnly"


	public static class vectorizatonDetail_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "vectorizatonDetail"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:854:1: vectorizatonDetail : ( KW_SUMMARY -> ^( TOK_SUMMARY ) | KW_OPERATOR -> ^( TOK_OPERATOR ) | KW_EXPRESSION -> ^( TOK_EXPRESSION ) | KW_DETAIL -> ^( TOK_DETAIL ) );
	public final HiveParser.vectorizatonDetail_return vectorizatonDetail() throws RecognitionException {
		HiveParser.vectorizatonDetail_return retval = new HiveParser.vectorizatonDetail_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SUMMARY25=null;
		Token KW_OPERATOR26=null;
		Token KW_EXPRESSION27=null;
		Token KW_DETAIL28=null;

		ASTNode KW_SUMMARY25_tree=null;
		ASTNode KW_OPERATOR26_tree=null;
		ASTNode KW_EXPRESSION27_tree=null;
		ASTNode KW_DETAIL28_tree=null;
		RewriteRuleTokenStream stream_KW_SUMMARY=new RewriteRuleTokenStream(adaptor,"token KW_SUMMARY");
		RewriteRuleTokenStream stream_KW_DETAIL=new RewriteRuleTokenStream(adaptor,"token KW_DETAIL");
		RewriteRuleTokenStream stream_KW_OPERATOR=new RewriteRuleTokenStream(adaptor,"token KW_OPERATOR");
		RewriteRuleTokenStream stream_KW_EXPRESSION=new RewriteRuleTokenStream(adaptor,"token KW_EXPRESSION");

		 pushMsg("vectorization's detail level clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:857:5: ( KW_SUMMARY -> ^( TOK_SUMMARY ) | KW_OPERATOR -> ^( TOK_OPERATOR ) | KW_EXPRESSION -> ^( TOK_EXPRESSION ) | KW_DETAIL -> ^( TOK_DETAIL ) )
			int alt8=4;
			switch ( input.LA(1) ) {
			case KW_SUMMARY:
				{
				alt8=1;
				}
				break;
			case KW_OPERATOR:
				{
				alt8=2;
				}
				break;
			case KW_EXPRESSION:
				{
				alt8=3;
				}
				break;
			case KW_DETAIL:
				{
				alt8=4;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 8, 0, input);
				throw nvae;
			}
			switch (alt8) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:857:7: KW_SUMMARY
					{
					KW_SUMMARY25=(Token)match(input,KW_SUMMARY,FOLLOW_KW_SUMMARY_in_vectorizatonDetail1652); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SUMMARY.add(KW_SUMMARY25);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 858:5: -> ^( TOK_SUMMARY )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:858:8: ^( TOK_SUMMARY )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUMMARY, "TOK_SUMMARY"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:859:7: KW_OPERATOR
					{
					KW_OPERATOR26=(Token)match(input,KW_OPERATOR,FOLLOW_KW_OPERATOR_in_vectorizatonDetail1670); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OPERATOR.add(KW_OPERATOR26);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 860:5: -> ^( TOK_OPERATOR )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:860:8: ^( TOK_OPERATOR )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_OPERATOR, "TOK_OPERATOR"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:861:7: KW_EXPRESSION
					{
					KW_EXPRESSION27=(Token)match(input,KW_EXPRESSION,FOLLOW_KW_EXPRESSION_in_vectorizatonDetail1688); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXPRESSION.add(KW_EXPRESSION27);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 862:5: -> ^( TOK_EXPRESSION )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:862:8: ^( TOK_EXPRESSION )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPRESSION, "TOK_EXPRESSION"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:863:7: KW_DETAIL
					{
					KW_DETAIL28=(Token)match(input,KW_DETAIL,FOLLOW_KW_DETAIL_in_vectorizatonDetail1706); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DETAIL.add(KW_DETAIL28);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 864:5: -> ^( TOK_DETAIL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:864:8: ^( TOK_DETAIL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DETAIL, "TOK_DETAIL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "vectorizatonDetail"


	public static class execStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "execStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:867:1: execStatement : ( queryStatementExpression | loadStatement | exportStatement | importStatement | replDumpStatement | replLoadStatement | replStatusStatement | ddlStatement | deleteStatement | updateStatement | sqlTransactionStatement | mergeStatement );
	public final HiveParser.execStatement_return execStatement() throws RecognitionException {
		HiveParser.execStatement_return retval = new HiveParser.execStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope queryStatementExpression29 =null;
		ParserRuleReturnScope loadStatement30 =null;
		ParserRuleReturnScope exportStatement31 =null;
		ParserRuleReturnScope importStatement32 =null;
		ParserRuleReturnScope replDumpStatement33 =null;
		ParserRuleReturnScope replLoadStatement34 =null;
		ParserRuleReturnScope replStatusStatement35 =null;
		ParserRuleReturnScope ddlStatement36 =null;
		ParserRuleReturnScope deleteStatement37 =null;
		ParserRuleReturnScope updateStatement38 =null;
		ParserRuleReturnScope sqlTransactionStatement39 =null;
		ParserRuleReturnScope mergeStatement40 =null;


		 pushMsg("statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:870:5: ( queryStatementExpression | loadStatement | exportStatement | importStatement | replDumpStatement | replLoadStatement | replStatusStatement | ddlStatement | deleteStatement | updateStatement | sqlTransactionStatement | mergeStatement )
			int alt9=12;
			switch ( input.LA(1) ) {
			case KW_FROM:
			case KW_INSERT:
			case KW_MAP:
			case KW_REDUCE:
			case KW_SELECT:
			case KW_WITH:
			case LPAREN:
				{
				alt9=1;
				}
				break;
			case KW_LOAD:
				{
				alt9=2;
				}
				break;
			case KW_EXPORT:
				{
				alt9=3;
				}
				break;
			case KW_IMPORT:
				{
				alt9=4;
				}
				break;
			case KW_REPL:
				{
				switch ( input.LA(2) ) {
				case KW_DUMP:
					{
					alt9=5;
					}
					break;
				case KW_LOAD:
					{
					alt9=6;
					}
					break;
				case KW_STATUS:
					{
					alt9=7;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 9, 11, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
				}
				break;
			case KW_ABORT:
			case KW_ALTER:
			case KW_ANALYZE:
			case KW_CREATE:
			case KW_DESC:
			case KW_DESCRIBE:
			case KW_DISABLE:
			case KW_DROP:
			case KW_ENABLE:
			case KW_GRANT:
			case KW_KILL:
			case KW_LOCK:
			case KW_MSCK:
			case KW_RELOAD:
			case KW_REPLACE:
			case KW_REVOKE:
			case KW_SHOW:
			case KW_TRUNCATE:
			case KW_UNLOCK:
			case KW_USE:
				{
				alt9=8;
				}
				break;
			case KW_SET:
				{
				int LA9_27 = input.LA(2);
				if ( (LA9_27==KW_ROLE) ) {
					alt9=8;
				}
				else if ( (LA9_27==KW_AUTOCOMMIT) ) {
					alt9=11;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 9, 27, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_DELETE:
				{
				alt9=9;
				}
				break;
			case KW_UPDATE:
				{
				alt9=10;
				}
				break;
			case KW_COMMIT:
			case KW_ROLLBACK:
			case KW_START:
				{
				alt9=11;
				}
				break;
			case KW_MERGE:
				{
				alt9=12;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 9, 0, input);
				throw nvae;
			}
			switch (alt9) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:870:7: queryStatementExpression
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_queryStatementExpression_in_execStatement1743);
					queryStatementExpression29=queryStatementExpression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, queryStatementExpression29.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:871:7: loadStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_loadStatement_in_execStatement1751);
					loadStatement30=loadStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, loadStatement30.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:872:7: exportStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_exportStatement_in_execStatement1759);
					exportStatement31=exportStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, exportStatement31.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:873:7: importStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_importStatement_in_execStatement1767);
					importStatement32=importStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, importStatement32.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:874:7: replDumpStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_replDumpStatement_in_execStatement1775);
					replDumpStatement33=replDumpStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, replDumpStatement33.getTree());

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:875:7: replLoadStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_replLoadStatement_in_execStatement1783);
					replLoadStatement34=replLoadStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, replLoadStatement34.getTree());

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:876:7: replStatusStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_replStatusStatement_in_execStatement1791);
					replStatusStatement35=replStatusStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, replStatusStatement35.getTree());

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:877:7: ddlStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_ddlStatement_in_execStatement1799);
					ddlStatement36=ddlStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, ddlStatement36.getTree());

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:878:7: deleteStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_deleteStatement_in_execStatement1807);
					deleteStatement37=deleteStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, deleteStatement37.getTree());

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:879:7: updateStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_updateStatement_in_execStatement1815);
					updateStatement38=updateStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, updateStatement38.getTree());

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:880:7: sqlTransactionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_sqlTransactionStatement_in_execStatement1823);
					sqlTransactionStatement39=sqlTransactionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, sqlTransactionStatement39.getTree());

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:881:7: mergeStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_mergeStatement_in_execStatement1831);
					mergeStatement40=mergeStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, mergeStatement40.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "execStatement"


	public static class loadStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "loadStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:884:1: loadStatement : KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) ( inputFileFormat )? -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? ) ;
	public final HiveParser.loadStatement_return loadStatement() throws RecognitionException {
		HiveParser.loadStatement_return retval = new HiveParser.loadStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token islocal=null;
		Token path=null;
		Token isoverwrite=null;
		Token KW_LOAD41=null;
		Token KW_DATA42=null;
		Token KW_INPATH43=null;
		Token KW_INTO44=null;
		Token KW_TABLE45=null;
		ParserRuleReturnScope tab =null;
		ParserRuleReturnScope inputFileFormat46 =null;

		ASTNode islocal_tree=null;
		ASTNode path_tree=null;
		ASTNode isoverwrite_tree=null;
		ASTNode KW_LOAD41_tree=null;
		ASTNode KW_DATA42_tree=null;
		ASTNode KW_INPATH43_tree=null;
		ASTNode KW_INTO44_tree=null;
		ASTNode KW_TABLE45_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_INPATH=new RewriteRuleTokenStream(adaptor,"token KW_INPATH");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
		RewriteRuleTokenStream stream_KW_LOAD=new RewriteRuleTokenStream(adaptor,"token KW_LOAD");
		RewriteRuleTokenStream stream_KW_DATA=new RewriteRuleTokenStream(adaptor,"token KW_DATA");
		RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
		RewriteRuleSubtreeStream stream_inputFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule inputFileFormat");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");

		 pushMsg("load statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:5: ( KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) ( inputFileFormat )? -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:7: KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) ( inputFileFormat )?
			{
			KW_LOAD41=(Token)match(input,KW_LOAD,FOLLOW_KW_LOAD_in_loadStatement1858); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOAD.add(KW_LOAD41);

			KW_DATA42=(Token)match(input,KW_DATA,FOLLOW_KW_DATA_in_loadStatement1860); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DATA.add(KW_DATA42);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:23: (islocal= KW_LOCAL )?
			int alt10=2;
			int LA10_0 = input.LA(1);
			if ( (LA10_0==KW_LOCAL) ) {
				alt10=1;
			}
			switch (alt10) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:24: islocal= KW_LOCAL
					{
					islocal=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_loadStatement1865); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCAL.add(islocal);

					}
					break;

			}

			KW_INPATH43=(Token)match(input,KW_INPATH,FOLLOW_KW_INPATH_in_loadStatement1869); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INPATH.add(KW_INPATH43);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:53: (path= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:54: path= StringLiteral
			{
			path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_loadStatement1874); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(path);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:74: (isoverwrite= KW_OVERWRITE )?
			int alt11=2;
			int LA11_0 = input.LA(1);
			if ( (LA11_0==KW_OVERWRITE) ) {
				alt11=1;
			}
			switch (alt11) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:75: isoverwrite= KW_OVERWRITE
					{
					isoverwrite=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_loadStatement1880); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OVERWRITE.add(isoverwrite);

					}
					break;

			}

			KW_INTO44=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_loadStatement1884); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO44);

			KW_TABLE45=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_loadStatement1886); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE45);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:119: (tab= tableOrPartition )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:120: tab= tableOrPartition
			{
			pushFollow(FOLLOW_tableOrPartition_in_loadStatement1891);
			tab=tableOrPartition();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:142: ( inputFileFormat )?
			int alt12=2;
			int LA12_0 = input.LA(1);
			if ( (LA12_0==KW_INPUTFORMAT) ) {
				alt12=1;
			}
			switch (alt12) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:887:142: inputFileFormat
					{
					pushFollow(FOLLOW_inputFileFormat_in_loadStatement1894);
					inputFileFormat46=inputFileFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_inputFileFormat.add(inputFileFormat46.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: islocal, inputFileFormat, path, tab, isoverwrite
			// token labels: islocal, path, isoverwrite
			// rule labels: tab, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_islocal=new RewriteRuleTokenStream(adaptor,"token islocal",islocal);
			RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
			RewriteRuleTokenStream stream_isoverwrite=new RewriteRuleTokenStream(adaptor,"token isoverwrite",isoverwrite);
			RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 888:5: -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:888:8: ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LOAD, "TOK_LOAD"), root_1);
				adaptor.addChild(root_1, stream_path.nextNode());
				adaptor.addChild(root_1, stream_tab.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:888:31: ( $islocal)?
				if ( stream_islocal.hasNext() ) {
					adaptor.addChild(root_1, stream_islocal.nextNode());
				}
				stream_islocal.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:888:41: ( $isoverwrite)?
				if ( stream_isoverwrite.hasNext() ) {
					adaptor.addChild(root_1, stream_isoverwrite.nextNode());
				}
				stream_isoverwrite.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:888:54: ( inputFileFormat )?
				if ( stream_inputFileFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_inputFileFormat.nextTree());
				}
				stream_inputFileFormat.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "loadStatement"


	public static class replicationClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replicationClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:891:1: replicationClause : KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) ;
	public final HiveParser.replicationClause_return replicationClause() throws RecognitionException {
		HiveParser.replicationClause_return retval = new HiveParser.replicationClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token isMetadataOnly=null;
		Token replId=null;
		Token KW_FOR47=null;
		Token KW_REPLICATION48=null;
		Token LPAREN49=null;
		Token RPAREN50=null;

		ASTNode isMetadataOnly_tree=null;
		ASTNode replId_tree=null;
		ASTNode KW_FOR47_tree=null;
		ASTNode KW_REPLICATION48_tree=null;
		ASTNode LPAREN49_tree=null;
		ASTNode RPAREN50_tree=null;
		RewriteRuleTokenStream stream_KW_REPLICATION=new RewriteRuleTokenStream(adaptor,"token KW_REPLICATION");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_METADATA=new RewriteRuleTokenStream(adaptor,"token KW_METADATA");

		 pushMsg("replication clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:894:5: ( KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:894:7: KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN
			{
			KW_FOR47=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_replicationClause1949); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR47);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:894:14: (isMetadataOnly= KW_METADATA )?
			int alt13=2;
			int LA13_0 = input.LA(1);
			if ( (LA13_0==KW_METADATA) ) {
				alt13=1;
			}
			switch (alt13) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:894:15: isMetadataOnly= KW_METADATA
					{
					isMetadataOnly=(Token)match(input,KW_METADATA,FOLLOW_KW_METADATA_in_replicationClause1954); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_METADATA.add(isMetadataOnly);

					}
					break;

			}

			KW_REPLICATION48=(Token)match(input,KW_REPLICATION,FOLLOW_KW_REPLICATION_in_replicationClause1958); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPLICATION.add(KW_REPLICATION48);

			LPAREN49=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_replicationClause1960); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN49);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:894:66: (replId= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:894:67: replId= StringLiteral
			{
			replId=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replicationClause1965); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(replId);

			}

			RPAREN50=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_replicationClause1968); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN50);

			// AST REWRITE
			// elements: replId, isMetadataOnly
			// token labels: replId, isMetadataOnly
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_replId=new RewriteRuleTokenStream(adaptor,"token replId",replId);
			RewriteRuleTokenStream stream_isMetadataOnly=new RewriteRuleTokenStream(adaptor,"token isMetadataOnly",isMetadataOnly);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 895:5: -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:895:8: ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPLICATION, "TOK_REPLICATION"), root_1);
				adaptor.addChild(root_1, stream_replId.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:895:35: ( $isMetadataOnly)?
				if ( stream_isMetadataOnly.hasNext() ) {
					adaptor.addChild(root_1, stream_isMetadataOnly.nextNode());
				}
				stream_isMetadataOnly.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replicationClause"


	public static class exportStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "exportStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:898:1: exportStatement : KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) ;
	public final HiveParser.exportStatement_return exportStatement() throws RecognitionException {
		HiveParser.exportStatement_return retval = new HiveParser.exportStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token path=null;
		Token KW_EXPORT51=null;
		Token KW_TABLE52=null;
		Token KW_TO53=null;
		ParserRuleReturnScope tab =null;
		ParserRuleReturnScope replicationClause54 =null;

		ASTNode path_tree=null;
		ASTNode KW_EXPORT51_tree=null;
		ASTNode KW_TABLE52_tree=null;
		ASTNode KW_TO53_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleTokenStream stream_KW_EXPORT=new RewriteRuleTokenStream(adaptor,"token KW_EXPORT");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
		RewriteRuleSubtreeStream stream_replicationClause=new RewriteRuleSubtreeStream(adaptor,"rule replicationClause");

		 pushMsg("export statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:901:5: ( KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:901:7: KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )?
			{
			KW_EXPORT51=(Token)match(input,KW_EXPORT,FOLLOW_KW_EXPORT_in_exportStatement2012); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXPORT.add(KW_EXPORT51);

			KW_TABLE52=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_exportStatement2020); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE52);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:16: (tab= tableOrPartition )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:17: tab= tableOrPartition
			{
			pushFollow(FOLLOW_tableOrPartition_in_exportStatement2025);
			tab=tableOrPartition();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());
			}

			KW_TO53=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_exportStatement2034); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO53);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:903:13: (path= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:903:14: path= StringLiteral
			{
			path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_exportStatement2039); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(path);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:904:7: ( replicationClause )?
			int alt14=2;
			int LA14_0 = input.LA(1);
			if ( (LA14_0==KW_FOR) ) {
				alt14=1;
			}
			switch (alt14) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:904:7: replicationClause
					{
					pushFollow(FOLLOW_replicationClause_in_exportStatement2048);
					replicationClause54=replicationClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replicationClause.add(replicationClause54.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: path, tab, replicationClause
			// token labels: path
			// rule labels: tab, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
			RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 905:5: -> ^( TOK_EXPORT $tab $path ( replicationClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:905:8: ^( TOK_EXPORT $tab $path ( replicationClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPORT, "TOK_EXPORT"), root_1);
				adaptor.addChild(root_1, stream_tab.nextTree());
				adaptor.addChild(root_1, stream_path.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:905:32: ( replicationClause )?
				if ( stream_replicationClause.hasNext() ) {
					adaptor.addChild(root_1, stream_replicationClause.nextTree());
				}
				stream_replicationClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "exportStatement"


	public static class importStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "importStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:908:1: importStatement : KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? ) ;
	public final HiveParser.importStatement_return importStatement() throws RecognitionException {
		HiveParser.importStatement_return retval = new HiveParser.importStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token ext=null;
		Token path=null;
		Token KW_IMPORT55=null;
		Token KW_TABLE56=null;
		Token KW_FROM57=null;
		ParserRuleReturnScope tab =null;
		ParserRuleReturnScope tableLocation58 =null;

		ASTNode ext_tree=null;
		ASTNode path_tree=null;
		ASTNode KW_IMPORT55_tree=null;
		ASTNode KW_TABLE56_tree=null;
		ASTNode KW_FROM57_tree=null;
		RewriteRuleTokenStream stream_KW_EXTERNAL=new RewriteRuleTokenStream(adaptor,"token KW_EXTERNAL");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_IMPORT=new RewriteRuleTokenStream(adaptor,"token KW_IMPORT");
		RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");

		 pushMsg("import statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:911:8: ( KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:911:10: KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )?
			{
			KW_IMPORT55=(Token)match(input,KW_IMPORT,FOLLOW_KW_IMPORT_in_importStatement2098); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_IMPORT.add(KW_IMPORT55);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:912:10: ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )?
			int alt16=2;
			int LA16_0 = input.LA(1);
			if ( (LA16_0==KW_EXTERNAL||LA16_0==KW_TABLE) ) {
				alt16=1;
			}
			switch (alt16) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:912:11: (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:912:11: (ext= KW_EXTERNAL )?
					int alt15=2;
					int LA15_0 = input.LA(1);
					if ( (LA15_0==KW_EXTERNAL) ) {
						alt15=1;
					}
					switch (alt15) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:912:12: ext= KW_EXTERNAL
							{
							ext=(Token)match(input,KW_EXTERNAL,FOLLOW_KW_EXTERNAL_in_importStatement2113); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTERNAL.add(ext);

							}
							break;

					}

					KW_TABLE56=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_importStatement2117); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE56);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:912:39: (tab= tableOrPartition )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:912:40: tab= tableOrPartition
					{
					pushFollow(FOLLOW_tableOrPartition_in_importStatement2122);
					tab=tableOrPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());
					}

					}
					break;

			}

			KW_FROM57=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_importStatement2136); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM57);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:913:18: (path= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:913:19: path= StringLiteral
			{
			path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_importStatement2141); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(path);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:914:10: ( tableLocation )?
			int alt17=2;
			int LA17_0 = input.LA(1);
			if ( (LA17_0==KW_LOCATION) ) {
				alt17=1;
			}
			switch (alt17) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:914:10: tableLocation
					{
					pushFollow(FOLLOW_tableLocation_in_importStatement2153);
					tableLocation58=tableLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation58.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: ext, tableLocation, tab, path
			// token labels: ext, path
			// rule labels: tab, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_ext=new RewriteRuleTokenStream(adaptor,"token ext",ext);
			RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
			RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 915:5: -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:915:8: ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_IMPORT, "TOK_IMPORT"), root_1);
				adaptor.addChild(root_1, stream_path.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:915:28: ( $tab)?
				if ( stream_tab.hasNext() ) {
					adaptor.addChild(root_1, stream_tab.nextTree());
				}
				stream_tab.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:915:34: ( $ext)?
				if ( stream_ext.hasNext() ) {
					adaptor.addChild(root_1, stream_ext.nextNode());
				}
				stream_ext.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:915:39: ( tableLocation )?
				if ( stream_tableLocation.hasNext() ) {
					adaptor.addChild(root_1, stream_tableLocation.nextTree());
				}
				stream_tableLocation.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "importStatement"


	public static class replDumpStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replDumpStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:918:1: replDumpStatement : KW_REPL KW_DUMP (dbPolicy= replDbPolicy ) ( KW_REPLACE oldDbPolicy= replDbPolicy )? ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )? ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? ( $replConf)? ) ;
	public final HiveParser.replDumpStatement_return replDumpStatement() throws RecognitionException {
		HiveParser.replDumpStatement_return retval = new HiveParser.replDumpStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token eventId=null;
		Token rangeEnd=null;
		Token batchSize=null;
		Token KW_REPL59=null;
		Token KW_DUMP60=null;
		Token KW_REPLACE61=null;
		Token KW_FROM62=null;
		Token KW_TO63=null;
		Token KW_LIMIT64=null;
		Token KW_WITH65=null;
		ParserRuleReturnScope dbPolicy =null;
		ParserRuleReturnScope oldDbPolicy =null;
		ParserRuleReturnScope replConf =null;

		ASTNode eventId_tree=null;
		ASTNode rangeEnd_tree=null;
		ASTNode batchSize_tree=null;
		ASTNode KW_REPL59_tree=null;
		ASTNode KW_DUMP60_tree=null;
		ASTNode KW_REPLACE61_tree=null;
		ASTNode KW_FROM62_tree=null;
		ASTNode KW_TO63_tree=null;
		ASTNode KW_LIMIT64_tree=null;
		ASTNode KW_WITH65_tree=null;
		RewriteRuleTokenStream stream_KW_DUMP=new RewriteRuleTokenStream(adaptor,"token KW_DUMP");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_LIMIT=new RewriteRuleTokenStream(adaptor,"token KW_LIMIT");
		RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
		RewriteRuleSubtreeStream stream_replDbPolicy=new RewriteRuleSubtreeStream(adaptor,"rule replDbPolicy");
		RewriteRuleSubtreeStream stream_replConfigs=new RewriteRuleSubtreeStream(adaptor,"rule replConfigs");

		 pushMsg("Replication dump statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:921:7: ( KW_REPL KW_DUMP (dbPolicy= replDbPolicy ) ( KW_REPLACE oldDbPolicy= replDbPolicy )? ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )? ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? ( $replConf)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:921:9: KW_REPL KW_DUMP (dbPolicy= replDbPolicy ) ( KW_REPLACE oldDbPolicy= replDbPolicy )? ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )? ( KW_WITH replConf= replConfigs )?
			{
			KW_REPL59=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replDumpStatement2207); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL59);

			KW_DUMP60=(Token)match(input,KW_DUMP,FOLLOW_KW_DUMP_in_replDumpStatement2209); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DUMP.add(KW_DUMP60);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:922:9: (dbPolicy= replDbPolicy )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:922:10: dbPolicy= replDbPolicy
			{
			pushFollow(FOLLOW_replDbPolicy_in_replDumpStatement2222);
			dbPolicy=replDbPolicy();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_replDbPolicy.add(dbPolicy.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:923:9: ( KW_REPLACE oldDbPolicy= replDbPolicy )?
			int alt18=2;
			int LA18_0 = input.LA(1);
			if ( (LA18_0==KW_REPLACE) ) {
				alt18=1;
			}
			switch (alt18) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:923:10: KW_REPLACE oldDbPolicy= replDbPolicy
					{
					KW_REPLACE61=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_replDumpStatement2234); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REPLACE.add(KW_REPLACE61);

					pushFollow(FOLLOW_replDbPolicy_in_replDumpStatement2238);
					oldDbPolicy=replDbPolicy();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replDbPolicy.add(oldDbPolicy.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:924:9: ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )?
			int alt21=2;
			int LA21_0 = input.LA(1);
			if ( (LA21_0==KW_FROM) ) {
				alt21=1;
			}
			switch (alt21) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:924:10: KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )?
					{
					KW_FROM62=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_replDumpStatement2251); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM62);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:924:18: (eventId= Number )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:924:19: eventId= Number
					{
					eventId=(Token)match(input,Number,FOLLOW_Number_in_replDumpStatement2256); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(eventId);

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:925:11: ( KW_TO (rangeEnd= Number ) )?
					int alt19=2;
					int LA19_0 = input.LA(1);
					if ( (LA19_0==KW_TO) ) {
						alt19=1;
					}
					switch (alt19) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:925:12: KW_TO (rangeEnd= Number )
							{
							KW_TO63=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_replDumpStatement2270); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO63);

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:925:18: (rangeEnd= Number )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:925:19: rangeEnd= Number
							{
							rangeEnd=(Token)match(input,Number,FOLLOW_Number_in_replDumpStatement2275); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(rangeEnd);

							}

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:926:11: ( KW_LIMIT (batchSize= Number ) )?
					int alt20=2;
					int LA20_0 = input.LA(1);
					if ( (LA20_0==KW_LIMIT) ) {
						alt20=1;
					}
					switch (alt20) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:926:12: KW_LIMIT (batchSize= Number )
							{
							KW_LIMIT64=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_replDumpStatement2291); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIMIT.add(KW_LIMIT64);

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:926:21: (batchSize= Number )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:926:22: batchSize= Number
							{
							batchSize=(Token)match(input,Number,FOLLOW_Number_in_replDumpStatement2296); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(batchSize);

							}

							}
							break;

					}

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:928:9: ( KW_WITH replConf= replConfigs )?
			int alt22=2;
			int LA22_0 = input.LA(1);
			if ( (LA22_0==KW_WITH) ) {
				alt22=1;
			}
			switch (alt22) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:928:10: KW_WITH replConf= replConfigs
					{
					KW_WITH65=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_replDumpStatement2321); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH65);

					pushFollow(FOLLOW_replConfigs_in_replDumpStatement2325);
					replConf=replConfigs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replConfigs.add(replConf.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: eventId, dbPolicy, replConf, batchSize, oldDbPolicy, rangeEnd
			// token labels: eventId, batchSize, rangeEnd
			// rule labels: oldDbPolicy, dbPolicy, retval, replConf
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_eventId=new RewriteRuleTokenStream(adaptor,"token eventId",eventId);
			RewriteRuleTokenStream stream_batchSize=new RewriteRuleTokenStream(adaptor,"token batchSize",batchSize);
			RewriteRuleTokenStream stream_rangeEnd=new RewriteRuleTokenStream(adaptor,"token rangeEnd",rangeEnd);
			RewriteRuleSubtreeStream stream_oldDbPolicy=new RewriteRuleSubtreeStream(adaptor,"rule oldDbPolicy",oldDbPolicy!=null?oldDbPolicy.getTree():null);
			RewriteRuleSubtreeStream stream_dbPolicy=new RewriteRuleSubtreeStream(adaptor,"rule dbPolicy",dbPolicy!=null?dbPolicy.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_replConf=new RewriteRuleSubtreeStream(adaptor,"rule replConf",replConf!=null?replConf.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 929:5: -> ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? ( $replConf)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:929:8: ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? ( $replConf)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_DUMP, "TOK_REPL_DUMP"), root_1);
				adaptor.addChild(root_1, stream_dbPolicy.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:929:34: ( ^( TOK_REPLACE $oldDbPolicy) )?
				if ( stream_oldDbPolicy.hasNext() ) {
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:929:34: ^( TOK_REPLACE $oldDbPolicy)
					{
					ASTNode root_2 = (ASTNode)adaptor.nil();
					root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPLACE, "TOK_REPLACE"), root_2);
					adaptor.addChild(root_2, stream_oldDbPolicy.nextTree());
					adaptor.addChild(root_1, root_2);
					}

				}
				stream_oldDbPolicy.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:929:63: ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )?
				if ( stream_eventId.hasNext()||stream_batchSize.hasNext()||stream_rangeEnd.hasNext() ) {
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:929:63: ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? )
					{
					ASTNode root_2 = (ASTNode)adaptor.nil();
					root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
					adaptor.addChild(root_2, stream_eventId.nextNode());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:929:83: ( TOK_TO $rangeEnd)?
					if ( stream_rangeEnd.hasNext() ) {
						adaptor.addChild(root_2, (ASTNode)adaptor.create(TOK_TO, "TOK_TO"));
						adaptor.addChild(root_2, stream_rangeEnd.nextNode());
					}
					stream_rangeEnd.reset();

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:929:103: ( TOK_LIMIT $batchSize)?
					if ( stream_batchSize.hasNext() ) {
						adaptor.addChild(root_2, (ASTNode)adaptor.create(TOK_LIMIT, "TOK_LIMIT"));
						adaptor.addChild(root_2, stream_batchSize.nextNode());
					}
					stream_batchSize.reset();

					adaptor.addChild(root_1, root_2);
					}

				}
				stream_eventId.reset();
				stream_batchSize.reset();
				stream_rangeEnd.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:929:130: ( $replConf)?
				if ( stream_replConf.hasNext() ) {
					adaptor.addChild(root_1, stream_replConf.nextTree());
				}
				stream_replConf.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replDumpStatement"


	public static class replDbPolicy_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replDbPolicy"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:932:1: replDbPolicy : (dbName= identifier ) ( DOT tablePolicy= replTableLevelPolicy )? -> $dbName ( $tablePolicy)? ;
	public final HiveParser.replDbPolicy_return replDbPolicy() throws RecognitionException {
		HiveParser.replDbPolicy_return retval = new HiveParser.replDbPolicy_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token DOT66=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope tablePolicy =null;

		ASTNode DOT66_tree=null;
		RewriteRuleTokenStream stream_DOT=new RewriteRuleTokenStream(adaptor,"token DOT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_replTableLevelPolicy=new RewriteRuleSubtreeStream(adaptor,"rule replTableLevelPolicy");

		 pushMsg("Repl dump DB replication policy", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:935:5: ( (dbName= identifier ) ( DOT tablePolicy= replTableLevelPolicy )? -> $dbName ( $tablePolicy)? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:936:7: (dbName= identifier ) ( DOT tablePolicy= replTableLevelPolicy )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:936:7: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:936:8: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_replDbPolicy2412);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:936:27: ( DOT tablePolicy= replTableLevelPolicy )?
			int alt23=2;
			int LA23_0 = input.LA(1);
			if ( (LA23_0==DOT) ) {
				alt23=1;
			}
			switch (alt23) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:936:28: DOT tablePolicy= replTableLevelPolicy
					{
					DOT66=(Token)match(input,DOT,FOLLOW_DOT_in_replDbPolicy2416); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_DOT.add(DOT66);

					pushFollow(FOLLOW_replTableLevelPolicy_in_replDbPolicy2420);
					tablePolicy=replTableLevelPolicy();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replTableLevelPolicy.add(tablePolicy.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tablePolicy, dbName
			// token labels: 
			// rule labels: dbName, tablePolicy, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_tablePolicy=new RewriteRuleSubtreeStream(adaptor,"rule tablePolicy",tablePolicy!=null?tablePolicy.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 936:67: -> $dbName ( $tablePolicy)?
			{
				adaptor.addChild(root_0, stream_dbName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:936:79: ( $tablePolicy)?
				if ( stream_tablePolicy.hasNext() ) {
					adaptor.addChild(root_0, stream_tablePolicy.nextTree());
				}
				stream_tablePolicy.reset();

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replDbPolicy"


	public static class replLoadStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replLoadStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:939:1: replLoadStatement : KW_REPL KW_LOAD (dbName= identifier )? KW_FROM (path= StringLiteral ) ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_LOAD $path ( ^( TOK_DBNAME $dbName) )? ( $replConf)? ) ;
	public final HiveParser.replLoadStatement_return replLoadStatement() throws RecognitionException {
		HiveParser.replLoadStatement_return retval = new HiveParser.replLoadStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token path=null;
		Token KW_REPL67=null;
		Token KW_LOAD68=null;
		Token KW_FROM69=null;
		Token KW_WITH70=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope replConf =null;

		ASTNode path_tree=null;
		ASTNode KW_REPL67_tree=null;
		ASTNode KW_LOAD68_tree=null;
		ASTNode KW_FROM69_tree=null;
		ASTNode KW_WITH70_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_LOAD=new RewriteRuleTokenStream(adaptor,"token KW_LOAD");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_replConfigs=new RewriteRuleSubtreeStream(adaptor,"rule replConfigs");

		 pushMsg("Replication load statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:942:7: ( KW_REPL KW_LOAD (dbName= identifier )? KW_FROM (path= StringLiteral ) ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_LOAD $path ( ^( TOK_DBNAME $dbName) )? ( $replConf)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:942:9: KW_REPL KW_LOAD (dbName= identifier )? KW_FROM (path= StringLiteral ) ( KW_WITH replConf= replConfigs )?
			{
			KW_REPL67=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replLoadStatement2460); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL67);

			KW_LOAD68=(Token)match(input,KW_LOAD,FOLLOW_KW_LOAD_in_replLoadStatement2462); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOAD.add(KW_LOAD68);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:943:9: (dbName= identifier )?
			int alt24=2;
			int LA24_0 = input.LA(1);
			if ( (LA24_0==Identifier||(LA24_0 >= KW_ABORT && LA24_0 <= KW_AFTER)||LA24_0==KW_ALLOC_FRACTION||LA24_0==KW_ANALYZE||LA24_0==KW_ARCHIVE||(LA24_0 >= KW_ASC && LA24_0 <= KW_AT)||(LA24_0 >= KW_AUTOCOMMIT && LA24_0 <= KW_BEFORE)||(LA24_0 >= KW_BUCKET && LA24_0 <= KW_BUCKETS)||(LA24_0 >= KW_CACHE && LA24_0 <= KW_CASCADE)||(LA24_0 >= KW_CBO && LA24_0 <= KW_CHANGE)||(LA24_0 >= KW_CHECK && LA24_0 <= KW_COLLECTION)||(LA24_0 >= KW_COLUMNS && LA24_0 <= KW_COMMENT)||(LA24_0 >= KW_COMPACT && LA24_0 <= KW_CONCATENATE)||(LA24_0 >= KW_CONTINUE && LA24_0 <= KW_COST)||LA24_0==KW_CRON||LA24_0==KW_DATA||LA24_0==KW_DATABASES||(LA24_0 >= KW_DATETIME && LA24_0 <= KW_DEBUG)||(LA24_0 >= KW_DEFAULT && LA24_0 <= KW_DEFINED)||(LA24_0 >= KW_DELIMITED && LA24_0 <= KW_DESC)||(LA24_0 >= KW_DETAIL && LA24_0 <= KW_DISABLE)||(LA24_0 >= KW_DISTRIBUTE && LA24_0 <= KW_DO)||LA24_0==KW_DOW||(LA24_0 >= KW_DUMP && LA24_0 <= KW_ELEM_TYPE)||LA24_0==KW_ENABLE||(LA24_0 >= KW_ENFORCED && LA24_0 <= KW_EVERY)||(LA24_0 >= KW_EXCLUSIVE && LA24_0 <= KW_EXECUTED)||(LA24_0 >= KW_EXPLAIN && LA24_0 <= KW_EXPRESSION)||(LA24_0 >= KW_FIELDS && LA24_0 <= KW_FIRST)||(LA24_0 >= KW_FORMAT && LA24_0 <= KW_FORMATTED)||LA24_0==KW_FUNCTIONS||(LA24_0 >= KW_HOUR && LA24_0 <= KW_IDXPROPERTIES)||(LA24_0 >= KW_INDEX && LA24_0 <= KW_INDEXES)||(LA24_0 >= KW_INPATH && LA24_0 <= KW_INPUTFORMAT)||(LA24_0 >= KW_ISOLATION && LA24_0 <= KW_JAR)||(LA24_0 >= KW_JOINCOST && LA24_0 <= KW_LAST)||LA24_0==KW_LEVEL||(LA24_0 >= KW_LIMIT && LA24_0 <= KW_LOAD)||(LA24_0 >= KW_LOCATION && LA24_0 <= KW_LONG)||(LA24_0 >= KW_MANAGEDLOCATION && LA24_0 <= KW_MANAGEMENT)||(LA24_0 >= KW_MAPJOIN && LA24_0 <= KW_MATERIALIZED)||LA24_0==KW_METADATA||(LA24_0 >= KW_MINUTE && LA24_0 <= KW_MONTH)||(LA24_0 >= KW_MOVE && LA24_0 <= KW_MSCK)||(LA24_0 >= KW_NORELY && LA24_0 <= KW_NOSCAN)||LA24_0==KW_NOVALIDATE||LA24_0==KW_NULLS||LA24_0==KW_OFFSET||(LA24_0 >= KW_OPERATOR && LA24_0 <= KW_OPTION)||(LA24_0 >= KW_OUTPUTDRIVER && LA24_0 <= KW_OUTPUTFORMAT)||(LA24_0 >= KW_OVERWRITE && LA24_0 <= KW_OWNER)||(LA24_0 >= KW_PARTITIONED && LA24_0 <= KW_PATH)||(LA24_0 >= KW_PLAN && LA24_0 <= KW_POOL)||LA24_0==KW_PRINCIPALS||(LA24_0 >= KW_PURGE && LA24_0 <= KW_QUERY_PARALLELISM)||LA24_0==KW_READ||(LA24_0 >= KW_REBUILD && LA24_0 <= KW_RECORDWRITER)||(LA24_0 >= KW_RELOAD && LA24_0 <= KW_RESTRICT)||LA24_0==KW_REWRITE||(LA24_0 >= KW_ROLE && LA24_0 <= KW_ROLES)||(LA24_0 >= KW_SCHEDULED && LA24_0 <= KW_SECOND)||(LA24_0 >= KW_SEMI && LA24_0 <= KW_SERVER)||(LA24_0 >= KW_SETS && LA24_0 <= KW_SKEWED)||(LA24_0 >= KW_SNAPSHOT && LA24_0 <= KW_SSL)||(LA24_0 >= KW_STATISTICS && LA24_0 <= KW_SUMMARY)||LA24_0==KW_TABLES||(LA24_0 >= KW_TBLPROPERTIES && LA24_0 <= KW_TERMINATED)||LA24_0==KW_TINYINT||(LA24_0 >= KW_TOUCH && LA24_0 <= KW_TRANSACTIONS)||LA24_0==KW_UNARCHIVE||LA24_0==KW_UNDO||LA24_0==KW_UNIONTYPE||(LA24_0 >= KW_UNLOCK && LA24_0 <= KW_UNSIGNED)||(LA24_0 >= KW_URI && LA24_0 <= KW_USE)||(LA24_0 >= KW_UTC && LA24_0 <= KW_VALIDATE)||LA24_0==KW_VALUE_TYPE||(LA24_0 >= KW_VECTORIZATION && LA24_0 <= KW_WEEK)||LA24_0==KW_WHILE||(LA24_0 >= KW_WORK && LA24_0 <= KW_ZONE)||LA24_0==KW_BATCH||LA24_0==KW_DAYOFWEEK||LA24_0==KW_HOLD_DDLTIME||LA24_0==KW_IGNORE||LA24_0==KW_NO_DROP||LA24_0==KW_OFFLINE||LA24_0==KW_PROTECTION||LA24_0==KW_READONLY||LA24_0==KW_TIMESTAMPTZ) ) {
				alt24=1;
			}
			switch (alt24) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:943:10: dbName= identifier
					{
					pushFollow(FOLLOW_identifier_in_replLoadStatement2475);
					dbName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
					}
					break;

			}

			KW_FROM69=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_replLoadStatement2487); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM69);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:944:17: (path= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:944:18: path= StringLiteral
			{
			path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replLoadStatement2492); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(path);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:945:9: ( KW_WITH replConf= replConfigs )?
			int alt25=2;
			int LA25_0 = input.LA(1);
			if ( (LA25_0==KW_WITH) ) {
				alt25=1;
			}
			switch (alt25) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:945:10: KW_WITH replConf= replConfigs
					{
					KW_WITH70=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_replLoadStatement2504); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH70);

					pushFollow(FOLLOW_replConfigs_in_replLoadStatement2508);
					replConf=replConfigs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replConfigs.add(replConf.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: dbName, replConf, path
			// token labels: path
			// rule labels: dbName, retval, replConf
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_replConf=new RewriteRuleSubtreeStream(adaptor,"rule replConf",replConf!=null?replConf.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 946:7: -> ^( TOK_REPL_LOAD $path ( ^( TOK_DBNAME $dbName) )? ( $replConf)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:946:10: ^( TOK_REPL_LOAD $path ( ^( TOK_DBNAME $dbName) )? ( $replConf)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_LOAD, "TOK_REPL_LOAD"), root_1);
				adaptor.addChild(root_1, stream_path.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:946:32: ( ^( TOK_DBNAME $dbName) )?
				if ( stream_dbName.hasNext() ) {
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:946:32: ^( TOK_DBNAME $dbName)
					{
					ASTNode root_2 = (ASTNode)adaptor.nil();
					root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DBNAME, "TOK_DBNAME"), root_2);
					adaptor.addChild(root_2, stream_dbName.nextTree());
					adaptor.addChild(root_1, root_2);
					}

				}
				stream_dbName.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:946:56: ( $replConf)?
				if ( stream_replConf.hasNext() ) {
					adaptor.addChild(root_1, stream_replConf.nextTree());
				}
				stream_replConf.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replLoadStatement"


	public static class replConfigs_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replConfigs"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:949:1: replConfigs : LPAREN replConfigsList RPAREN -> ^( TOK_REPL_CONFIG replConfigsList ) ;
	public final HiveParser.replConfigs_return replConfigs() throws RecognitionException {
		HiveParser.replConfigs_return retval = new HiveParser.replConfigs_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN71=null;
		Token RPAREN73=null;
		ParserRuleReturnScope replConfigsList72 =null;

		ASTNode LPAREN71_tree=null;
		ASTNode RPAREN73_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_replConfigsList=new RewriteRuleSubtreeStream(adaptor,"rule replConfigsList");

		 pushMsg("Repl configurations", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:952:5: ( LPAREN replConfigsList RPAREN -> ^( TOK_REPL_CONFIG replConfigsList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:953:7: LPAREN replConfigsList RPAREN
			{
			LPAREN71=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_replConfigs2572); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN71);

			pushFollow(FOLLOW_replConfigsList_in_replConfigs2574);
			replConfigsList72=replConfigsList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_replConfigsList.add(replConfigsList72.getTree());
			RPAREN73=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_replConfigs2576); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN73);

			// AST REWRITE
			// elements: replConfigsList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 953:37: -> ^( TOK_REPL_CONFIG replConfigsList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:953:40: ^( TOK_REPL_CONFIG replConfigsList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_CONFIG, "TOK_REPL_CONFIG"), root_1);
				adaptor.addChild(root_1, stream_replConfigsList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replConfigs"


	public static class replConfigsList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replConfigsList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:956:1: replConfigsList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ ) ;
	public final HiveParser.replConfigsList_return replConfigsList() throws RecognitionException {
		HiveParser.replConfigsList_return retval = new HiveParser.replConfigsList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA75=null;
		ParserRuleReturnScope keyValueProperty74 =null;
		ParserRuleReturnScope keyValueProperty76 =null;

		ASTNode COMMA75_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");

		 pushMsg("Repl configurations list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:959:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:960:7: keyValueProperty ( COMMA keyValueProperty )*
			{
			pushFollow(FOLLOW_keyValueProperty_in_replConfigsList2617);
			keyValueProperty74=keyValueProperty();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty74.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:960:24: ( COMMA keyValueProperty )*
			loop26:
			while (true) {
				int alt26=2;
				int LA26_0 = input.LA(1);
				if ( (LA26_0==COMMA) ) {
					alt26=1;
				}

				switch (alt26) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:960:25: COMMA keyValueProperty
					{
					COMMA75=(Token)match(input,COMMA,FOLLOW_COMMA_in_replConfigsList2620); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA75);

					pushFollow(FOLLOW_keyValueProperty_in_replConfigsList2622);
					keyValueProperty76=keyValueProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty76.getTree());
					}
					break;

				default :
					break loop26;
				}
			}

			// AST REWRITE
			// elements: keyValueProperty
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 960:50: -> ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:960:53: ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_CONFIG_LIST, "TOK_REPL_CONFIG_LIST"), root_1);
				if ( !(stream_keyValueProperty.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_keyValueProperty.hasNext() ) {
					adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
				}
				stream_keyValueProperty.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replConfigsList"


	public static class replTableLevelPolicy_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replTableLevelPolicy"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:963:1: replTableLevelPolicy : ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? ) -> ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? ) ;
	public final HiveParser.replTableLevelPolicy_return replTableLevelPolicy() throws RecognitionException {
		HiveParser.replTableLevelPolicy_return retval = new HiveParser.replTableLevelPolicy_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token replTablesIncludeList=null;
		Token replTablesExcludeList=null;
		Token DOT77=null;

		ASTNode replTablesIncludeList_tree=null;
		ASTNode replTablesExcludeList_tree=null;
		ASTNode DOT77_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_DOT=new RewriteRuleTokenStream(adaptor,"token DOT");

		 pushMsg("Replication table level policy definition", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:966:5: ( ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? ) -> ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:967:7: ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? )
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:967:7: ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:967:8: (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:967:8: (replTablesIncludeList= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:967:9: replTablesIncludeList= StringLiteral
			{
			replTablesIncludeList=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replTableLevelPolicy2670); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(replTablesIncludeList);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:967:46: ( DOT replTablesExcludeList= StringLiteral )?
			int alt27=2;
			int LA27_0 = input.LA(1);
			if ( (LA27_0==DOT) ) {
				alt27=1;
			}
			switch (alt27) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:967:47: DOT replTablesExcludeList= StringLiteral
					{
					DOT77=(Token)match(input,DOT,FOLLOW_DOT_in_replTableLevelPolicy2674); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_DOT.add(DOT77);

					replTablesExcludeList=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replTableLevelPolicy2678); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(replTablesExcludeList);

					}
					break;

			}

			}

			// AST REWRITE
			// elements: replTablesExcludeList, replTablesIncludeList
			// token labels: replTablesExcludeList, replTablesIncludeList
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_replTablesExcludeList=new RewriteRuleTokenStream(adaptor,"token replTablesExcludeList",replTablesExcludeList);
			RewriteRuleTokenStream stream_replTablesIncludeList=new RewriteRuleTokenStream(adaptor,"token replTablesIncludeList",replTablesIncludeList);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 968:7: -> ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:968:10: ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_TABLES, "TOK_REPL_TABLES"), root_1);
				adaptor.addChild(root_1, stream_replTablesIncludeList.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:968:52: ( $replTablesExcludeList)?
				if ( stream_replTablesExcludeList.hasNext() ) {
					adaptor.addChild(root_1, stream_replTablesExcludeList.nextNode());
				}
				stream_replTablesExcludeList.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replTableLevelPolicy"


	public static class replStatusStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replStatusStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:971:1: replStatusStatement : KW_REPL KW_STATUS (dbName= identifier ) ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_STATUS $dbName ( $replConf)? ) ;
	public final HiveParser.replStatusStatement_return replStatusStatement() throws RecognitionException {
		HiveParser.replStatusStatement_return retval = new HiveParser.replStatusStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REPL78=null;
		Token KW_STATUS79=null;
		Token KW_WITH80=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope replConf =null;

		ASTNode KW_REPL78_tree=null;
		ASTNode KW_STATUS79_tree=null;
		ASTNode KW_WITH80_tree=null;
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_STATUS=new RewriteRuleTokenStream(adaptor,"token KW_STATUS");
		RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_replConfigs=new RewriteRuleSubtreeStream(adaptor,"rule replConfigs");

		 pushMsg("replication status statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:974:7: ( KW_REPL KW_STATUS (dbName= identifier ) ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_STATUS $dbName ( $replConf)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:974:9: KW_REPL KW_STATUS (dbName= identifier ) ( KW_WITH replConf= replConfigs )?
			{
			KW_REPL78=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replStatusStatement2729); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL78);

			KW_STATUS79=(Token)match(input,KW_STATUS,FOLLOW_KW_STATUS_in_replStatusStatement2731); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STATUS.add(KW_STATUS79);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:975:9: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:975:10: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_replStatusStatement2744);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:976:9: ( KW_WITH replConf= replConfigs )?
			int alt28=2;
			int LA28_0 = input.LA(1);
			if ( (LA28_0==KW_WITH) ) {
				alt28=1;
			}
			switch (alt28) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:976:10: KW_WITH replConf= replConfigs
					{
					KW_WITH80=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_replStatusStatement2756); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH80);

					pushFollow(FOLLOW_replConfigs_in_replStatusStatement2760);
					replConf=replConfigs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replConfigs.add(replConf.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: dbName, replConf
			// token labels: 
			// rule labels: dbName, retval, replConf
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_replConf=new RewriteRuleSubtreeStream(adaptor,"rule replConf",replConf!=null?replConf.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 977:7: -> ^( TOK_REPL_STATUS $dbName ( $replConf)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:977:10: ^( TOK_REPL_STATUS $dbName ( $replConf)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_STATUS, "TOK_REPL_STATUS"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:977:37: ( $replConf)?
				if ( stream_replConf.hasNext() ) {
					adaptor.addChild(root_1, stream_replConf.nextTree());
				}
				stream_replConf.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replStatusStatement"


	public static class ddlStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "ddlStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:980:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | createMaterializedViewStatement | createScheduledQueryStatement | alterScheduledQueryStatement | dropScheduledQueryStatement | dropViewStatement | dropMaterializedViewStatement | createFunctionStatement | createMacroStatement | dropFunctionStatement | reloadFunctionsStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement | killQueryStatement | resourcePlanDdlStatements );
	public final HiveParser.ddlStatement_return ddlStatement() throws RecognitionException {
		HiveParser.ddlStatement_return retval = new HiveParser.ddlStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope createDatabaseStatement81 =null;
		ParserRuleReturnScope switchDatabaseStatement82 =null;
		ParserRuleReturnScope dropDatabaseStatement83 =null;
		ParserRuleReturnScope createTableStatement84 =null;
		ParserRuleReturnScope dropTableStatement85 =null;
		ParserRuleReturnScope truncateTableStatement86 =null;
		ParserRuleReturnScope alterStatement87 =null;
		ParserRuleReturnScope descStatement88 =null;
		ParserRuleReturnScope showStatement89 =null;
		ParserRuleReturnScope metastoreCheck90 =null;
		ParserRuleReturnScope createViewStatement91 =null;
		ParserRuleReturnScope createMaterializedViewStatement92 =null;
		ParserRuleReturnScope createScheduledQueryStatement93 =null;
		ParserRuleReturnScope alterScheduledQueryStatement94 =null;
		ParserRuleReturnScope dropScheduledQueryStatement95 =null;
		ParserRuleReturnScope dropViewStatement96 =null;
		ParserRuleReturnScope dropMaterializedViewStatement97 =null;
		ParserRuleReturnScope createFunctionStatement98 =null;
		ParserRuleReturnScope createMacroStatement99 =null;
		ParserRuleReturnScope dropFunctionStatement100 =null;
		ParserRuleReturnScope reloadFunctionsStatement101 =null;
		ParserRuleReturnScope dropMacroStatement102 =null;
		ParserRuleReturnScope analyzeStatement103 =null;
		ParserRuleReturnScope lockStatement104 =null;
		ParserRuleReturnScope unlockStatement105 =null;
		ParserRuleReturnScope lockDatabase106 =null;
		ParserRuleReturnScope unlockDatabase107 =null;
		ParserRuleReturnScope createRoleStatement108 =null;
		ParserRuleReturnScope dropRoleStatement109 =null;
		ParserRuleReturnScope grantPrivileges110 =null;
		ParserRuleReturnScope revokePrivileges111 =null;
		ParserRuleReturnScope showGrants112 =null;
		ParserRuleReturnScope showRoleGrants113 =null;
		ParserRuleReturnScope showRolePrincipals114 =null;
		ParserRuleReturnScope showRoles115 =null;
		ParserRuleReturnScope grantRole116 =null;
		ParserRuleReturnScope revokeRole117 =null;
		ParserRuleReturnScope setRole118 =null;
		ParserRuleReturnScope showCurrentRole119 =null;
		ParserRuleReturnScope abortTransactionStatement120 =null;
		ParserRuleReturnScope killQueryStatement121 =null;
		ParserRuleReturnScope resourcePlanDdlStatements122 =null;


		 pushMsg("ddl statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:983:5: ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | createMaterializedViewStatement | createScheduledQueryStatement | alterScheduledQueryStatement | dropScheduledQueryStatement | dropViewStatement | dropMaterializedViewStatement | createFunctionStatement | createMacroStatement | dropFunctionStatement | reloadFunctionsStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement | killQueryStatement | resourcePlanDdlStatements )
			int alt29=42;
			alt29 = dfa29.predict(input);
			switch (alt29) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:983:7: createDatabaseStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createDatabaseStatement_in_ddlStatement2810);
					createDatabaseStatement81=createDatabaseStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createDatabaseStatement81.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:984:7: switchDatabaseStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_switchDatabaseStatement_in_ddlStatement2818);
					switchDatabaseStatement82=switchDatabaseStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, switchDatabaseStatement82.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:985:7: dropDatabaseStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropDatabaseStatement_in_ddlStatement2826);
					dropDatabaseStatement83=dropDatabaseStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropDatabaseStatement83.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:986:7: createTableStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createTableStatement_in_ddlStatement2834);
					createTableStatement84=createTableStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createTableStatement84.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:987:7: dropTableStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropTableStatement_in_ddlStatement2842);
					dropTableStatement85=dropTableStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropTableStatement85.getTree());

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:988:7: truncateTableStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_truncateTableStatement_in_ddlStatement2850);
					truncateTableStatement86=truncateTableStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, truncateTableStatement86.getTree());

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:989:7: alterStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatement_in_ddlStatement2858);
					alterStatement87=alterStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatement87.getTree());

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:990:7: descStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_descStatement_in_ddlStatement2866);
					descStatement88=descStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, descStatement88.getTree());

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:991:7: showStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showStatement_in_ddlStatement2874);
					showStatement89=showStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showStatement89.getTree());

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:992:7: metastoreCheck
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_metastoreCheck_in_ddlStatement2882);
					metastoreCheck90=metastoreCheck();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, metastoreCheck90.getTree());

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:993:7: createViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createViewStatement_in_ddlStatement2890);
					createViewStatement91=createViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createViewStatement91.getTree());

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:994:7: createMaterializedViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createMaterializedViewStatement_in_ddlStatement2898);
					createMaterializedViewStatement92=createMaterializedViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createMaterializedViewStatement92.getTree());

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:995:7: createScheduledQueryStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createScheduledQueryStatement_in_ddlStatement2906);
					createScheduledQueryStatement93=createScheduledQueryStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createScheduledQueryStatement93.getTree());

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:996:7: alterScheduledQueryStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterScheduledQueryStatement_in_ddlStatement2914);
					alterScheduledQueryStatement94=alterScheduledQueryStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterScheduledQueryStatement94.getTree());

					}
					break;
				case 15 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:997:7: dropScheduledQueryStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropScheduledQueryStatement_in_ddlStatement2922);
					dropScheduledQueryStatement95=dropScheduledQueryStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropScheduledQueryStatement95.getTree());

					}
					break;
				case 16 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:998:7: dropViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropViewStatement_in_ddlStatement2930);
					dropViewStatement96=dropViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropViewStatement96.getTree());

					}
					break;
				case 17 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:999:7: dropMaterializedViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropMaterializedViewStatement_in_ddlStatement2938);
					dropMaterializedViewStatement97=dropMaterializedViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropMaterializedViewStatement97.getTree());

					}
					break;
				case 18 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1000:7: createFunctionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createFunctionStatement_in_ddlStatement2946);
					createFunctionStatement98=createFunctionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createFunctionStatement98.getTree());

					}
					break;
				case 19 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1001:7: createMacroStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createMacroStatement_in_ddlStatement2954);
					createMacroStatement99=createMacroStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createMacroStatement99.getTree());

					}
					break;
				case 20 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1002:7: dropFunctionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropFunctionStatement_in_ddlStatement2962);
					dropFunctionStatement100=dropFunctionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropFunctionStatement100.getTree());

					}
					break;
				case 21 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1003:7: reloadFunctionsStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_reloadFunctionsStatement_in_ddlStatement2970);
					reloadFunctionsStatement101=reloadFunctionsStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, reloadFunctionsStatement101.getTree());

					}
					break;
				case 22 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:7: dropMacroStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropMacroStatement_in_ddlStatement2978);
					dropMacroStatement102=dropMacroStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropMacroStatement102.getTree());

					}
					break;
				case 23 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1005:7: analyzeStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_analyzeStatement_in_ddlStatement2986);
					analyzeStatement103=analyzeStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, analyzeStatement103.getTree());

					}
					break;
				case 24 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1006:7: lockStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_lockStatement_in_ddlStatement2994);
					lockStatement104=lockStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, lockStatement104.getTree());

					}
					break;
				case 25 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1007:7: unlockStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_unlockStatement_in_ddlStatement3002);
					unlockStatement105=unlockStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, unlockStatement105.getTree());

					}
					break;
				case 26 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1008:7: lockDatabase
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_lockDatabase_in_ddlStatement3010);
					lockDatabase106=lockDatabase();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, lockDatabase106.getTree());

					}
					break;
				case 27 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1009:7: unlockDatabase
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_unlockDatabase_in_ddlStatement3018);
					unlockDatabase107=unlockDatabase();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, unlockDatabase107.getTree());

					}
					break;
				case 28 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1010:7: createRoleStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createRoleStatement_in_ddlStatement3026);
					createRoleStatement108=createRoleStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createRoleStatement108.getTree());

					}
					break;
				case 29 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1011:7: dropRoleStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropRoleStatement_in_ddlStatement3034);
					dropRoleStatement109=dropRoleStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropRoleStatement109.getTree());

					}
					break;
				case 30 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1012:7: ( grantPrivileges )=> grantPrivileges
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_grantPrivileges_in_ddlStatement3048);
					grantPrivileges110=grantPrivileges();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, grantPrivileges110.getTree());

					}
					break;
				case 31 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1013:7: ( revokePrivileges )=> revokePrivileges
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_revokePrivileges_in_ddlStatement3062);
					revokePrivileges111=revokePrivileges();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, revokePrivileges111.getTree());

					}
					break;
				case 32 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1014:7: showGrants
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showGrants_in_ddlStatement3070);
					showGrants112=showGrants();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showGrants112.getTree());

					}
					break;
				case 33 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1015:7: showRoleGrants
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showRoleGrants_in_ddlStatement3078);
					showRoleGrants113=showRoleGrants();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showRoleGrants113.getTree());

					}
					break;
				case 34 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1016:7: showRolePrincipals
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showRolePrincipals_in_ddlStatement3086);
					showRolePrincipals114=showRolePrincipals();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showRolePrincipals114.getTree());

					}
					break;
				case 35 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1017:7: showRoles
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showRoles_in_ddlStatement3094);
					showRoles115=showRoles();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showRoles115.getTree());

					}
					break;
				case 36 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1018:7: grantRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_grantRole_in_ddlStatement3102);
					grantRole116=grantRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, grantRole116.getTree());

					}
					break;
				case 37 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1019:7: revokeRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_revokeRole_in_ddlStatement3110);
					revokeRole117=revokeRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, revokeRole117.getTree());

					}
					break;
				case 38 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1020:7: setRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_setRole_in_ddlStatement3118);
					setRole118=setRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, setRole118.getTree());

					}
					break;
				case 39 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:7: showCurrentRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showCurrentRole_in_ddlStatement3126);
					showCurrentRole119=showCurrentRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showCurrentRole119.getTree());

					}
					break;
				case 40 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1022:7: abortTransactionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_abortTransactionStatement_in_ddlStatement3134);
					abortTransactionStatement120=abortTransactionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, abortTransactionStatement120.getTree());

					}
					break;
				case 41 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1023:7: killQueryStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_killQueryStatement_in_ddlStatement3142);
					killQueryStatement121=killQueryStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, killQueryStatement121.getTree());

					}
					break;
				case 42 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:7: resourcePlanDdlStatements
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_resourcePlanDdlStatements_in_ddlStatement3150);
					resourcePlanDdlStatements122=resourcePlanDdlStatements();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, resourcePlanDdlStatements122.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "ddlStatement"


	public static class ifExists_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "ifExists"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1027:1: ifExists : KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) ;
	public final HiveParser.ifExists_return ifExists() throws RecognitionException {
		HiveParser.ifExists_return retval = new HiveParser.ifExists_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_IF123=null;
		Token KW_EXISTS124=null;

		ASTNode KW_IF123_tree=null;
		ASTNode KW_EXISTS124_tree=null;
		RewriteRuleTokenStream stream_KW_EXISTS=new RewriteRuleTokenStream(adaptor,"token KW_EXISTS");
		RewriteRuleTokenStream stream_KW_IF=new RewriteRuleTokenStream(adaptor,"token KW_IF");

		 pushMsg("if exists clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1030:5: ( KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1030:7: KW_IF KW_EXISTS
			{
			KW_IF123=(Token)match(input,KW_IF,FOLLOW_KW_IF_in_ifExists3177); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_IF.add(KW_IF123);

			KW_EXISTS124=(Token)match(input,KW_EXISTS,FOLLOW_KW_EXISTS_in_ifExists3179); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXISTS.add(KW_EXISTS124);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1031:5: -> ^( TOK_IFEXISTS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1031:8: ^( TOK_IFEXISTS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_IFEXISTS, "TOK_IFEXISTS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "ifExists"


	public static class restrictOrCascade_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "restrictOrCascade"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1034:1: restrictOrCascade : ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) );
	public final HiveParser.restrictOrCascade_return restrictOrCascade() throws RecognitionException {
		HiveParser.restrictOrCascade_return retval = new HiveParser.restrictOrCascade_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RESTRICT125=null;
		Token KW_CASCADE126=null;

		ASTNode KW_RESTRICT125_tree=null;
		ASTNode KW_CASCADE126_tree=null;
		RewriteRuleTokenStream stream_KW_CASCADE=new RewriteRuleTokenStream(adaptor,"token KW_CASCADE");
		RewriteRuleTokenStream stream_KW_RESTRICT=new RewriteRuleTokenStream(adaptor,"token KW_RESTRICT");

		 pushMsg("restrict or cascade clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1037:5: ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) )
			int alt30=2;
			int LA30_0 = input.LA(1);
			if ( (LA30_0==KW_RESTRICT) ) {
				alt30=1;
			}
			else if ( (LA30_0==KW_CASCADE) ) {
				alt30=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 30, 0, input);
				throw nvae;
			}

			switch (alt30) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1037:7: KW_RESTRICT
					{
					KW_RESTRICT125=(Token)match(input,KW_RESTRICT,FOLLOW_KW_RESTRICT_in_restrictOrCascade3216); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RESTRICT.add(KW_RESTRICT125);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1038:5: -> ^( TOK_RESTRICT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1038:8: ^( TOK_RESTRICT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESTRICT, "TOK_RESTRICT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1039:7: KW_CASCADE
					{
					KW_CASCADE126=(Token)match(input,KW_CASCADE,FOLLOW_KW_CASCADE_in_restrictOrCascade3234); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CASCADE.add(KW_CASCADE126);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1040:5: -> ^( TOK_CASCADE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1040:8: ^( TOK_CASCADE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CASCADE, "TOK_CASCADE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "restrictOrCascade"


	public static class ifNotExists_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "ifNotExists"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1043:1: ifNotExists : KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) ;
	public final HiveParser.ifNotExists_return ifNotExists() throws RecognitionException {
		HiveParser.ifNotExists_return retval = new HiveParser.ifNotExists_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_IF127=null;
		Token KW_NOT128=null;
		Token KW_EXISTS129=null;

		ASTNode KW_IF127_tree=null;
		ASTNode KW_NOT128_tree=null;
		ASTNode KW_EXISTS129_tree=null;
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_EXISTS=new RewriteRuleTokenStream(adaptor,"token KW_EXISTS");
		RewriteRuleTokenStream stream_KW_IF=new RewriteRuleTokenStream(adaptor,"token KW_IF");

		 pushMsg("if not exists clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1046:5: ( KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1046:7: KW_IF KW_NOT KW_EXISTS
			{
			KW_IF127=(Token)match(input,KW_IF,FOLLOW_KW_IF_in_ifNotExists3271); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_IF.add(KW_IF127);

			KW_NOT128=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_ifNotExists3273); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT128);

			KW_EXISTS129=(Token)match(input,KW_EXISTS,FOLLOW_KW_EXISTS_in_ifNotExists3275); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXISTS.add(KW_EXISTS129);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1047:5: -> ^( TOK_IFNOTEXISTS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1047:8: ^( TOK_IFNOTEXISTS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_IFNOTEXISTS, "TOK_IFNOTEXISTS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "ifNotExists"


	public static class force_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "force"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1050:1: force : KW_FORCE -> ^( TOK_FORCE ) ;
	public final HiveParser.force_return force() throws RecognitionException {
		HiveParser.force_return retval = new HiveParser.force_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_FORCE130=null;

		ASTNode KW_FORCE130_tree=null;
		RewriteRuleTokenStream stream_KW_FORCE=new RewriteRuleTokenStream(adaptor,"token KW_FORCE");

		 msgs.push("force clause"); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1053:5: ( KW_FORCE -> ^( TOK_FORCE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1053:7: KW_FORCE
			{
			KW_FORCE130=(Token)match(input,KW_FORCE,FOLLOW_KW_FORCE_in_force3312); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FORCE.add(KW_FORCE130);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1054:5: -> ^( TOK_FORCE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1054:8: ^( TOK_FORCE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FORCE, "TOK_FORCE"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { msgs.pop(); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "force"


	public static class rewriteEnabled_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rewriteEnabled"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1057:1: rewriteEnabled : KW_ENABLE KW_REWRITE -> ^( TOK_REWRITE_ENABLED ) ;
	public final HiveParser.rewriteEnabled_return rewriteEnabled() throws RecognitionException {
		HiveParser.rewriteEnabled_return retval = new HiveParser.rewriteEnabled_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ENABLE131=null;
		Token KW_REWRITE132=null;

		ASTNode KW_ENABLE131_tree=null;
		ASTNode KW_REWRITE132_tree=null;
		RewriteRuleTokenStream stream_KW_REWRITE=new RewriteRuleTokenStream(adaptor,"token KW_REWRITE");
		RewriteRuleTokenStream stream_KW_ENABLE=new RewriteRuleTokenStream(adaptor,"token KW_ENABLE");

		 pushMsg("rewrite enabled clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1060:5: ( KW_ENABLE KW_REWRITE -> ^( TOK_REWRITE_ENABLED ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1060:7: KW_ENABLE KW_REWRITE
			{
			KW_ENABLE131=(Token)match(input,KW_ENABLE,FOLLOW_KW_ENABLE_in_rewriteEnabled3349); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ENABLE.add(KW_ENABLE131);

			KW_REWRITE132=(Token)match(input,KW_REWRITE,FOLLOW_KW_REWRITE_in_rewriteEnabled3351); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REWRITE.add(KW_REWRITE132);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1061:5: -> ^( TOK_REWRITE_ENABLED )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1061:8: ^( TOK_REWRITE_ENABLED )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REWRITE_ENABLED, "TOK_REWRITE_ENABLED"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rewriteEnabled"


	public static class rewriteDisabled_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rewriteDisabled"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:1: rewriteDisabled : KW_DISABLE KW_REWRITE -> ^( TOK_REWRITE_DISABLED ) ;
	public final HiveParser.rewriteDisabled_return rewriteDisabled() throws RecognitionException {
		HiveParser.rewriteDisabled_return retval = new HiveParser.rewriteDisabled_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DISABLE133=null;
		Token KW_REWRITE134=null;

		ASTNode KW_DISABLE133_tree=null;
		ASTNode KW_REWRITE134_tree=null;
		RewriteRuleTokenStream stream_KW_DISABLE=new RewriteRuleTokenStream(adaptor,"token KW_DISABLE");
		RewriteRuleTokenStream stream_KW_REWRITE=new RewriteRuleTokenStream(adaptor,"token KW_REWRITE");

		 pushMsg("rewrite disabled clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1067:5: ( KW_DISABLE KW_REWRITE -> ^( TOK_REWRITE_DISABLED ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1067:7: KW_DISABLE KW_REWRITE
			{
			KW_DISABLE133=(Token)match(input,KW_DISABLE,FOLLOW_KW_DISABLE_in_rewriteDisabled3388); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DISABLE.add(KW_DISABLE133);

			KW_REWRITE134=(Token)match(input,KW_REWRITE,FOLLOW_KW_REWRITE_in_rewriteDisabled3390); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REWRITE.add(KW_REWRITE134);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1068:5: -> ^( TOK_REWRITE_DISABLED )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1068:8: ^( TOK_REWRITE_DISABLED )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REWRITE_DISABLED, "TOK_REWRITE_DISABLED"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rewriteDisabled"


	public static class storedAsDirs_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "storedAsDirs"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1071:1: storedAsDirs : KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) ;
	public final HiveParser.storedAsDirs_return storedAsDirs() throws RecognitionException {
		HiveParser.storedAsDirs_return retval = new HiveParser.storedAsDirs_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_STORED135=null;
		Token KW_AS136=null;
		Token KW_DIRECTORIES137=null;

		ASTNode KW_STORED135_tree=null;
		ASTNode KW_AS136_tree=null;
		ASTNode KW_DIRECTORIES137_tree=null;
		RewriteRuleTokenStream stream_KW_DIRECTORIES=new RewriteRuleTokenStream(adaptor,"token KW_DIRECTORIES");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_STORED=new RewriteRuleTokenStream(adaptor,"token KW_STORED");

		 pushMsg("stored as directories", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1074:5: ( KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1074:7: KW_STORED KW_AS KW_DIRECTORIES
			{
			KW_STORED135=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_storedAsDirs3427); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED135);

			KW_AS136=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_storedAsDirs3429); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS136);

			KW_DIRECTORIES137=(Token)match(input,KW_DIRECTORIES,FOLLOW_KW_DIRECTORIES_in_storedAsDirs3431); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DIRECTORIES.add(KW_DIRECTORIES137);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1075:5: -> ^( TOK_STOREDASDIRS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1075:8: ^( TOK_STOREDASDIRS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_STOREDASDIRS, "TOK_STOREDASDIRS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "storedAsDirs"


	public static class orReplace_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "orReplace"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1078:1: orReplace : KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) ;
	public final HiveParser.orReplace_return orReplace() throws RecognitionException {
		HiveParser.orReplace_return retval = new HiveParser.orReplace_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_OR138=null;
		Token KW_REPLACE139=null;

		ASTNode KW_OR138_tree=null;
		ASTNode KW_REPLACE139_tree=null;
		RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
		RewriteRuleTokenStream stream_KW_OR=new RewriteRuleTokenStream(adaptor,"token KW_OR");

		 pushMsg("or replace clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1081:5: ( KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1081:7: KW_OR KW_REPLACE
			{
			KW_OR138=(Token)match(input,KW_OR,FOLLOW_KW_OR_in_orReplace3468); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OR.add(KW_OR138);

			KW_REPLACE139=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_orReplace3470); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPLACE.add(KW_REPLACE139);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1082:5: -> ^( TOK_ORREPLACE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1082:8: ^( TOK_ORREPLACE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ORREPLACE, "TOK_ORREPLACE"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "orReplace"


	public static class createDatabaseStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createDatabaseStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1085:1: createDatabaseStatement : KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( dbManagedLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( dbManagedLocation )? ( databaseComment )? ( $dbprops)? ) ;
	public final HiveParser.createDatabaseStatement_return createDatabaseStatement() throws RecognitionException {
		HiveParser.createDatabaseStatement_return retval = new HiveParser.createDatabaseStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE140=null;
		Token KW_DATABASE141=null;
		Token KW_SCHEMA142=null;
		Token KW_WITH147=null;
		Token KW_DBPROPERTIES148=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope dbprops =null;
		ParserRuleReturnScope ifNotExists143 =null;
		ParserRuleReturnScope databaseComment144 =null;
		ParserRuleReturnScope dbLocation145 =null;
		ParserRuleReturnScope dbManagedLocation146 =null;

		ASTNode KW_CREATE140_tree=null;
		ASTNode KW_DATABASE141_tree=null;
		ASTNode KW_SCHEMA142_tree=null;
		ASTNode KW_WITH147_tree=null;
		ASTNode KW_DBPROPERTIES148_tree=null;
		RewriteRuleTokenStream stream_KW_DBPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_DBPROPERTIES");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_dbProperties=new RewriteRuleSubtreeStream(adaptor,"rule dbProperties");
		RewriteRuleSubtreeStream stream_databaseComment=new RewriteRuleSubtreeStream(adaptor,"rule databaseComment");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_dbLocation=new RewriteRuleSubtreeStream(adaptor,"rule dbLocation");
		RewriteRuleSubtreeStream stream_dbManagedLocation=new RewriteRuleSubtreeStream(adaptor,"rule dbManagedLocation");

		 pushMsg("create database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:5: ( KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( dbManagedLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( dbManagedLocation )? ( databaseComment )? ( $dbprops)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:7: KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( dbManagedLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
			{
			KW_CREATE140=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createDatabaseStatement3507); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE140);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:17: ( KW_DATABASE | KW_SCHEMA )
			int alt31=2;
			int LA31_0 = input.LA(1);
			if ( (LA31_0==KW_DATABASE) ) {
				alt31=1;
			}
			else if ( (LA31_0==KW_SCHEMA) ) {
				alt31=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 31, 0, input);
				throw nvae;
			}

			switch (alt31) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:18: KW_DATABASE
					{
					KW_DATABASE141=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_createDatabaseStatement3510); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE141);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:30: KW_SCHEMA
					{
					KW_SCHEMA142=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_createDatabaseStatement3512); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA142);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1089:9: ( ifNotExists )?
			int alt32=2;
			int LA32_0 = input.LA(1);
			if ( (LA32_0==KW_IF) ) {
				alt32=1;
			}
			switch (alt32) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1089:9: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_createDatabaseStatement3523);
					ifNotExists143=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists143.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_createDatabaseStatement3536);
			name=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1091:9: ( databaseComment )?
			int alt33=2;
			int LA33_0 = input.LA(1);
			if ( (LA33_0==KW_COMMENT) ) {
				alt33=1;
			}
			switch (alt33) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1091:9: databaseComment
					{
					pushFollow(FOLLOW_databaseComment_in_createDatabaseStatement3546);
					databaseComment144=databaseComment();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_databaseComment.add(databaseComment144.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:9: ( dbLocation )?
			int alt34=2;
			int LA34_0 = input.LA(1);
			if ( (LA34_0==KW_LOCATION) ) {
				alt34=1;
			}
			switch (alt34) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:9: dbLocation
					{
					pushFollow(FOLLOW_dbLocation_in_createDatabaseStatement3557);
					dbLocation145=dbLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_dbLocation.add(dbLocation145.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1093:9: ( dbManagedLocation )?
			int alt35=2;
			int LA35_0 = input.LA(1);
			if ( (LA35_0==KW_MANAGEDLOCATION) ) {
				alt35=1;
			}
			switch (alt35) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1093:9: dbManagedLocation
					{
					pushFollow(FOLLOW_dbManagedLocation_in_createDatabaseStatement3568);
					dbManagedLocation146=dbManagedLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_dbManagedLocation.add(dbManagedLocation146.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1094:9: ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
			int alt36=2;
			int LA36_0 = input.LA(1);
			if ( (LA36_0==KW_WITH) ) {
				alt36=1;
			}
			switch (alt36) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1094:10: KW_WITH KW_DBPROPERTIES dbprops= dbProperties
					{
					KW_WITH147=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_createDatabaseStatement3580); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH147);

					KW_DBPROPERTIES148=(Token)match(input,KW_DBPROPERTIES,FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement3582); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES148);

					pushFollow(FOLLOW_dbProperties_in_createDatabaseStatement3586);
					dbprops=dbProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_dbProperties.add(dbprops.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: name, ifNotExists, dbManagedLocation, databaseComment, dbprops, dbLocation
			// token labels: 
			// rule labels: name, dbprops, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_dbprops=new RewriteRuleSubtreeStream(adaptor,"rule dbprops",dbprops!=null?dbprops.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1095:5: -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( dbManagedLocation )? ( databaseComment )? ( $dbprops)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1095:8: ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( dbManagedLocation )? ( databaseComment )? ( $dbprops)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEDATABASE, "TOK_CREATEDATABASE"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1095:35: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1095:48: ( dbLocation )?
				if ( stream_dbLocation.hasNext() ) {
					adaptor.addChild(root_1, stream_dbLocation.nextTree());
				}
				stream_dbLocation.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1095:60: ( dbManagedLocation )?
				if ( stream_dbManagedLocation.hasNext() ) {
					adaptor.addChild(root_1, stream_dbManagedLocation.nextTree());
				}
				stream_dbManagedLocation.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1095:79: ( databaseComment )?
				if ( stream_databaseComment.hasNext() ) {
					adaptor.addChild(root_1, stream_databaseComment.nextTree());
				}
				stream_databaseComment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1095:97: ( $dbprops)?
				if ( stream_dbprops.hasNext() ) {
					adaptor.addChild(root_1, stream_dbprops.nextTree());
				}
				stream_dbprops.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createDatabaseStatement"


	public static class dbLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:1: dbLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_DATABASELOCATION $locn) ;
	public final HiveParser.dbLocation_return dbLocation() throws RecognitionException {
		HiveParser.dbLocation_return retval = new HiveParser.dbLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token locn=null;
		Token KW_LOCATION149=null;

		ASTNode locn_tree=null;
		ASTNode KW_LOCATION149_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

		 pushMsg("database location specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1101:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_DATABASELOCATION $locn) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1102:7: KW_LOCATION locn= StringLiteral
			{
			KW_LOCATION149=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_dbLocation3650); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION149);

			locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_dbLocation3654); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(locn);

			// AST REWRITE
			// elements: locn
			// token labels: locn
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1102:38: -> ^( TOK_DATABASELOCATION $locn)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1102:41: ^( TOK_DATABASELOCATION $locn)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATABASELOCATION, "TOK_DATABASELOCATION"), root_1);
				adaptor.addChild(root_1, stream_locn.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbLocation"


	public static class dbManagedLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbManagedLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1105:1: dbManagedLocation : KW_MANAGEDLOCATION locn= StringLiteral -> ^( TOK_DATABASE_MANAGEDLOCATION $locn) ;
	public final HiveParser.dbManagedLocation_return dbManagedLocation() throws RecognitionException {
		HiveParser.dbManagedLocation_return retval = new HiveParser.dbManagedLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token locn=null;
		Token KW_MANAGEDLOCATION150=null;

		ASTNode locn_tree=null;
		ASTNode KW_MANAGEDLOCATION150_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_MANAGEDLOCATION=new RewriteRuleTokenStream(adaptor,"token KW_MANAGEDLOCATION");

		 pushMsg("database managed location specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1108:5: ( KW_MANAGEDLOCATION locn= StringLiteral -> ^( TOK_DATABASE_MANAGEDLOCATION $locn) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1109:7: KW_MANAGEDLOCATION locn= StringLiteral
			{
			KW_MANAGEDLOCATION150=(Token)match(input,KW_MANAGEDLOCATION,FOLLOW_KW_MANAGEDLOCATION_in_dbManagedLocation3696); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MANAGEDLOCATION.add(KW_MANAGEDLOCATION150);

			locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_dbManagedLocation3700); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(locn);

			// AST REWRITE
			// elements: locn
			// token labels: locn
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1109:45: -> ^( TOK_DATABASE_MANAGEDLOCATION $locn)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1109:48: ^( TOK_DATABASE_MANAGEDLOCATION $locn)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATABASE_MANAGEDLOCATION, "TOK_DATABASE_MANAGEDLOCATION"), root_1);
				adaptor.addChild(root_1, stream_locn.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbManagedLocation"


	public static class dbProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1112:1: dbProperties : LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) ;
	public final HiveParser.dbProperties_return dbProperties() throws RecognitionException {
		HiveParser.dbProperties_return retval = new HiveParser.dbProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN151=null;
		Token RPAREN153=null;
		ParserRuleReturnScope dbPropertiesList152 =null;

		ASTNode LPAREN151_tree=null;
		ASTNode RPAREN153_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_dbPropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule dbPropertiesList");

		 pushMsg("dbproperties", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1115:5: ( LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1116:7: LPAREN dbPropertiesList RPAREN
			{
			LPAREN151=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_dbProperties3742); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN151);

			pushFollow(FOLLOW_dbPropertiesList_in_dbProperties3744);
			dbPropertiesList152=dbPropertiesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_dbPropertiesList.add(dbPropertiesList152.getTree());
			RPAREN153=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_dbProperties3746); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN153);

			// AST REWRITE
			// elements: dbPropertiesList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1116:38: -> ^( TOK_DATABASEPROPERTIES dbPropertiesList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1116:41: ^( TOK_DATABASEPROPERTIES dbPropertiesList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATABASEPROPERTIES, "TOK_DATABASEPROPERTIES"), root_1);
				adaptor.addChild(root_1, stream_dbPropertiesList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbProperties"


	public static class dbPropertiesList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbPropertiesList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1119:1: dbPropertiesList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) ;
	public final HiveParser.dbPropertiesList_return dbPropertiesList() throws RecognitionException {
		HiveParser.dbPropertiesList_return retval = new HiveParser.dbPropertiesList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA155=null;
		ParserRuleReturnScope keyValueProperty154 =null;
		ParserRuleReturnScope keyValueProperty156 =null;

		ASTNode COMMA155_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");

		 pushMsg("database properties list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1122:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1123:7: keyValueProperty ( COMMA keyValueProperty )*
			{
			pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList3787);
			keyValueProperty154=keyValueProperty();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty154.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1123:24: ( COMMA keyValueProperty )*
			loop37:
			while (true) {
				int alt37=2;
				int LA37_0 = input.LA(1);
				if ( (LA37_0==COMMA) ) {
					alt37=1;
				}

				switch (alt37) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1123:25: COMMA keyValueProperty
					{
					COMMA155=(Token)match(input,COMMA,FOLLOW_COMMA_in_dbPropertiesList3790); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA155);

					pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList3792);
					keyValueProperty156=keyValueProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty156.getTree());
					}
					break;

				default :
					break loop37;
				}
			}

			// AST REWRITE
			// elements: keyValueProperty
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1123:50: -> ^( TOK_DBPROPLIST ( keyValueProperty )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1123:53: ^( TOK_DBPROPLIST ( keyValueProperty )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DBPROPLIST, "TOK_DBPROPLIST"), root_1);
				if ( !(stream_keyValueProperty.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_keyValueProperty.hasNext() ) {
					adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
				}
				stream_keyValueProperty.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbPropertiesList"


	public static class switchDatabaseStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "switchDatabaseStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1127:1: switchDatabaseStatement : KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) ;
	public final HiveParser.switchDatabaseStatement_return switchDatabaseStatement() throws RecognitionException {
		HiveParser.switchDatabaseStatement_return retval = new HiveParser.switchDatabaseStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_USE157=null;
		ParserRuleReturnScope identifier158 =null;

		ASTNode KW_USE157_tree=null;
		RewriteRuleTokenStream stream_KW_USE=new RewriteRuleTokenStream(adaptor,"token KW_USE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("switch database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1130:5: ( KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1130:7: KW_USE identifier
			{
			KW_USE157=(Token)match(input,KW_USE,FOLLOW_KW_USE_in_switchDatabaseStatement3831); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_USE.add(KW_USE157);

			pushFollow(FOLLOW_identifier_in_switchDatabaseStatement3833);
			identifier158=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier158.getTree());
			// AST REWRITE
			// elements: identifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1131:5: -> ^( TOK_SWITCHDATABASE identifier )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1131:8: ^( TOK_SWITCHDATABASE identifier )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SWITCHDATABASE, "TOK_SWITCHDATABASE"), root_1);
				adaptor.addChild(root_1, stream_identifier.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "switchDatabaseStatement"


	public static class dropDatabaseStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropDatabaseStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1134:1: dropDatabaseStatement : KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) ;
	public final HiveParser.dropDatabaseStatement_return dropDatabaseStatement() throws RecognitionException {
		HiveParser.dropDatabaseStatement_return retval = new HiveParser.dropDatabaseStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP159=null;
		Token KW_DATABASE160=null;
		Token KW_SCHEMA161=null;
		ParserRuleReturnScope ifExists162 =null;
		ParserRuleReturnScope identifier163 =null;
		ParserRuleReturnScope restrictOrCascade164 =null;

		ASTNode KW_DROP159_tree=null;
		ASTNode KW_DATABASE160_tree=null;
		ASTNode KW_SCHEMA161_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
		RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");

		 pushMsg("drop database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:5: ( KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:7: KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )?
			{
			KW_DROP159=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropDatabaseStatement3872); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP159);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:15: ( KW_DATABASE | KW_SCHEMA )
			int alt38=2;
			int LA38_0 = input.LA(1);
			if ( (LA38_0==KW_DATABASE) ) {
				alt38=1;
			}
			else if ( (LA38_0==KW_SCHEMA) ) {
				alt38=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 38, 0, input);
				throw nvae;
			}

			switch (alt38) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:16: KW_DATABASE
					{
					KW_DATABASE160=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_dropDatabaseStatement3875); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE160);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:28: KW_SCHEMA
					{
					KW_SCHEMA161=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_dropDatabaseStatement3877); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA161);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:39: ( ifExists )?
			int alt39=2;
			int LA39_0 = input.LA(1);
			if ( (LA39_0==KW_IF) ) {
				alt39=1;
			}
			switch (alt39) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:39: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropDatabaseStatement3880);
					ifExists162=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists162.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_dropDatabaseStatement3883);
			identifier163=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier163.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:60: ( restrictOrCascade )?
			int alt40=2;
			int LA40_0 = input.LA(1);
			if ( (LA40_0==KW_CASCADE||LA40_0==KW_RESTRICT) ) {
				alt40=1;
			}
			switch (alt40) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:60: restrictOrCascade
					{
					pushFollow(FOLLOW_restrictOrCascade_in_dropDatabaseStatement3885);
					restrictOrCascade164=restrictOrCascade();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade164.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: restrictOrCascade, ifExists, identifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1138:5: -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:8: ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPDATABASE, "TOK_DROPDATABASE"), root_1);
				adaptor.addChild(root_1, stream_identifier.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:38: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:48: ( restrictOrCascade )?
				if ( stream_restrictOrCascade.hasNext() ) {
					adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
				}
				stream_restrictOrCascade.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropDatabaseStatement"


	public static class databaseComment_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "databaseComment"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1141:1: databaseComment : KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) ;
	public final HiveParser.databaseComment_return databaseComment() throws RecognitionException {
		HiveParser.databaseComment_return retval = new HiveParser.databaseComment_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT165=null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT165_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

		 pushMsg("database's comment", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1144:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1144:7: KW_COMMENT comment= StringLiteral
			{
			KW_COMMENT165=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_databaseComment3931); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT165);

			comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_databaseComment3935); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

			// AST REWRITE
			// elements: comment
			// token labels: comment
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1145:5: -> ^( TOK_DATABASECOMMENT $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1145:8: ^( TOK_DATABASECOMMENT $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATABASECOMMENT, "TOK_DATABASECOMMENT"), root_1);
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "databaseComment"


	public static class createTableStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createTableStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:1: createTableStatement : KW_CREATE (temp= KW_TEMPORARY )? (trans= KW_TRANSACTIONAL )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrConstraintList RPAREN )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? ) -> ^( TOK_CREATETABLE $name ( $temp)? ( $trans)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrConstraintList )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? ) ;
	public final HiveParser.createTableStatement_return createTableStatement() throws RecognitionException {
		HiveParser.createTableStatement_return retval = new HiveParser.createTableStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token temp=null;
		Token trans=null;
		Token ext=null;
		Token like=null;
		Token KW_CREATE166=null;
		Token KW_TABLE167=null;
		Token LPAREN173=null;
		Token RPAREN175=null;
		Token KW_AS184=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope likeName =null;
		ParserRuleReturnScope ifNotExists168 =null;
		ParserRuleReturnScope tableRowFormat169 =null;
		ParserRuleReturnScope tableFileFormat170 =null;
		ParserRuleReturnScope tableLocation171 =null;
		ParserRuleReturnScope tablePropertiesPrefixed172 =null;
		ParserRuleReturnScope columnNameTypeOrConstraintList174 =null;
		ParserRuleReturnScope tableComment176 =null;
		ParserRuleReturnScope createTablePartitionSpec177 =null;
		ParserRuleReturnScope tableBuckets178 =null;
		ParserRuleReturnScope tableSkewed179 =null;
		ParserRuleReturnScope tableRowFormat180 =null;
		ParserRuleReturnScope tableFileFormat181 =null;
		ParserRuleReturnScope tableLocation182 =null;
		ParserRuleReturnScope tablePropertiesPrefixed183 =null;
		ParserRuleReturnScope selectStatementWithCTE185 =null;

		ASTNode temp_tree=null;
		ASTNode trans_tree=null;
		ASTNode ext_tree=null;
		ASTNode like_tree=null;
		ASTNode KW_CREATE166_tree=null;
		ASTNode KW_TABLE167_tree=null;
		ASTNode LPAREN173_tree=null;
		ASTNode RPAREN175_tree=null;
		ASTNode KW_AS184_tree=null;
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_EXTERNAL=new RewriteRuleTokenStream(adaptor,"token KW_EXTERNAL");
		RewriteRuleTokenStream stream_KW_TRANSACTIONAL=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTIONAL");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_LIKE=new RewriteRuleTokenStream(adaptor,"token KW_LIKE");
		RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
		RewriteRuleSubtreeStream stream_selectStatementWithCTE=new RewriteRuleSubtreeStream(adaptor,"rule selectStatementWithCTE");
		RewriteRuleSubtreeStream stream_createTablePartitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule createTablePartitionSpec");
		RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
		RewriteRuleSubtreeStream stream_columnNameTypeOrConstraintList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeOrConstraintList");
		RewriteRuleSubtreeStream stream_tableSkewed=new RewriteRuleSubtreeStream(adaptor,"rule tableSkewed");
		RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
		RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
		RewriteRuleSubtreeStream stream_tableBuckets=new RewriteRuleSubtreeStream(adaptor,"rule tableBuckets");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("create table statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:5: ( KW_CREATE (temp= KW_TEMPORARY )? (trans= KW_TRANSACTIONAL )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrConstraintList RPAREN )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? ) -> ^( TOK_CREATETABLE $name ( $temp)? ( $trans)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrConstraintList )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:7: KW_CREATE (temp= KW_TEMPORARY )? (trans= KW_TRANSACTIONAL )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrConstraintList RPAREN )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? )
			{
			KW_CREATE166=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createTableStatement3975); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE166);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:17: (temp= KW_TEMPORARY )?
			int alt41=2;
			int LA41_0 = input.LA(1);
			if ( (LA41_0==KW_TEMPORARY) ) {
				alt41=1;
			}
			switch (alt41) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:18: temp= KW_TEMPORARY
					{
					temp=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createTableStatement3980); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(temp);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:38: (trans= KW_TRANSACTIONAL )?
			int alt42=2;
			int LA42_0 = input.LA(1);
			if ( (LA42_0==KW_TRANSACTIONAL) ) {
				alt42=1;
			}
			switch (alt42) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:39: trans= KW_TRANSACTIONAL
					{
					trans=(Token)match(input,KW_TRANSACTIONAL,FOLLOW_KW_TRANSACTIONAL_in_createTableStatement3987); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TRANSACTIONAL.add(trans);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:64: (ext= KW_EXTERNAL )?
			int alt43=2;
			int LA43_0 = input.LA(1);
			if ( (LA43_0==KW_EXTERNAL) ) {
				alt43=1;
			}
			switch (alt43) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:65: ext= KW_EXTERNAL
					{
					ext=(Token)match(input,KW_EXTERNAL,FOLLOW_KW_EXTERNAL_in_createTableStatement3994); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXTERNAL.add(ext);

					}
					break;

			}

			KW_TABLE167=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_createTableStatement3998); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE167);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:92: ( ifNotExists )?
			int alt44=2;
			int LA44_0 = input.LA(1);
			if ( (LA44_0==KW_IF) ) {
				alt44=1;
			}
			switch (alt44) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:92: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_createTableStatement4000);
					ifNotExists168=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists168.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableName_in_createTableStatement4005);
			name=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(name.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1152:7: (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrConstraintList RPAREN )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? )
			int alt59=2;
			int LA59_0 = input.LA(1);
			if ( (LA59_0==KW_LIKE) ) {
				alt59=1;
			}
			else if ( (LA59_0==EOF||LA59_0==KW_AS||LA59_0==KW_CLUSTERED||LA59_0==KW_COMMENT||LA59_0==KW_LOCATION||LA59_0==KW_PARTITIONED||LA59_0==KW_ROW||LA59_0==KW_SKEWED||LA59_0==KW_STORED||LA59_0==KW_TBLPROPERTIES||LA59_0==LPAREN) ) {
				alt59=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 59, 0, input);
				throw nvae;
			}

			switch (alt59) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1152:10: like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )?
					{
					like=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_createTableStatement4018); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LIKE.add(like);

					pushFollow(FOLLOW_tableName_in_createTableStatement4022);
					likeName=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(likeName.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1153:10: ( tableRowFormat )?
					int alt45=2;
					int LA45_0 = input.LA(1);
					if ( (LA45_0==KW_ROW) ) {
						alt45=1;
					}
					switch (alt45) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1153:10: tableRowFormat
							{
							pushFollow(FOLLOW_tableRowFormat_in_createTableStatement4033);
							tableRowFormat169=tableRowFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat169.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:10: ( tableFileFormat )?
					int alt46=2;
					int LA46_0 = input.LA(1);
					if ( (LA46_0==KW_STORED) ) {
						alt46=1;
					}
					switch (alt46) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:10: tableFileFormat
							{
							pushFollow(FOLLOW_tableFileFormat_in_createTableStatement4045);
							tableFileFormat170=tableFileFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat170.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1155:10: ( tableLocation )?
					int alt47=2;
					int LA47_0 = input.LA(1);
					if ( (LA47_0==KW_LOCATION) ) {
						alt47=1;
					}
					switch (alt47) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1155:10: tableLocation
							{
							pushFollow(FOLLOW_tableLocation_in_createTableStatement4057);
							tableLocation171=tableLocation();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation171.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1156:10: ( tablePropertiesPrefixed )?
					int alt48=2;
					int LA48_0 = input.LA(1);
					if ( (LA48_0==KW_TBLPROPERTIES) ) {
						alt48=1;
					}
					switch (alt48) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1156:10: tablePropertiesPrefixed
							{
							pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement4069);
							tablePropertiesPrefixed172=tablePropertiesPrefixed();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed172.getTree());
							}
							break;

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1157:10: ( LPAREN columnNameTypeOrConstraintList RPAREN )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1157:10: ( LPAREN columnNameTypeOrConstraintList RPAREN )?
					int alt49=2;
					int LA49_0 = input.LA(1);
					if ( (LA49_0==LPAREN) ) {
						alt49=1;
					}
					switch (alt49) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1157:11: LPAREN columnNameTypeOrConstraintList RPAREN
							{
							LPAREN173=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createTableStatement4082); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN173);

							pushFollow(FOLLOW_columnNameTypeOrConstraintList_in_createTableStatement4084);
							columnNameTypeOrConstraintList174=columnNameTypeOrConstraintList();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_columnNameTypeOrConstraintList.add(columnNameTypeOrConstraintList174.getTree());
							RPAREN175=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createTableStatement4086); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN175);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1158:10: ( tableComment )?
					int alt50=2;
					int LA50_0 = input.LA(1);
					if ( (LA50_0==KW_COMMENT) ) {
						alt50=1;
					}
					switch (alt50) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1158:10: tableComment
							{
							pushFollow(FOLLOW_tableComment_in_createTableStatement4099);
							tableComment176=tableComment();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableComment.add(tableComment176.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1159:10: ( createTablePartitionSpec )?
					int alt51=2;
					int LA51_0 = input.LA(1);
					if ( (LA51_0==KW_PARTITIONED) ) {
						alt51=1;
					}
					switch (alt51) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1159:10: createTablePartitionSpec
							{
							pushFollow(FOLLOW_createTablePartitionSpec_in_createTableStatement4111);
							createTablePartitionSpec177=createTablePartitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_createTablePartitionSpec.add(createTablePartitionSpec177.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1160:10: ( tableBuckets )?
					int alt52=2;
					int LA52_0 = input.LA(1);
					if ( (LA52_0==KW_CLUSTERED) ) {
						alt52=1;
					}
					switch (alt52) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1160:10: tableBuckets
							{
							pushFollow(FOLLOW_tableBuckets_in_createTableStatement4123);
							tableBuckets178=tableBuckets();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableBuckets.add(tableBuckets178.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1161:10: ( tableSkewed )?
					int alt53=2;
					int LA53_0 = input.LA(1);
					if ( (LA53_0==KW_SKEWED) ) {
						alt53=1;
					}
					switch (alt53) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1161:10: tableSkewed
							{
							pushFollow(FOLLOW_tableSkewed_in_createTableStatement4135);
							tableSkewed179=tableSkewed();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableSkewed.add(tableSkewed179.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1162:10: ( tableRowFormat )?
					int alt54=2;
					int LA54_0 = input.LA(1);
					if ( (LA54_0==KW_ROW) ) {
						alt54=1;
					}
					switch (alt54) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1162:10: tableRowFormat
							{
							pushFollow(FOLLOW_tableRowFormat_in_createTableStatement4147);
							tableRowFormat180=tableRowFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat180.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:10: ( tableFileFormat )?
					int alt55=2;
					int LA55_0 = input.LA(1);
					if ( (LA55_0==KW_STORED) ) {
						alt55=1;
					}
					switch (alt55) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:10: tableFileFormat
							{
							pushFollow(FOLLOW_tableFileFormat_in_createTableStatement4159);
							tableFileFormat181=tableFileFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat181.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1164:10: ( tableLocation )?
					int alt56=2;
					int LA56_0 = input.LA(1);
					if ( (LA56_0==KW_LOCATION) ) {
						alt56=1;
					}
					switch (alt56) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1164:10: tableLocation
							{
							pushFollow(FOLLOW_tableLocation_in_createTableStatement4171);
							tableLocation182=tableLocation();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation182.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1165:10: ( tablePropertiesPrefixed )?
					int alt57=2;
					int LA57_0 = input.LA(1);
					if ( (LA57_0==KW_TBLPROPERTIES) ) {
						alt57=1;
					}
					switch (alt57) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1165:10: tablePropertiesPrefixed
							{
							pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement4183);
							tablePropertiesPrefixed183=tablePropertiesPrefixed();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed183.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1166:10: ( KW_AS selectStatementWithCTE )?
					int alt58=2;
					int LA58_0 = input.LA(1);
					if ( (LA58_0==KW_AS) ) {
						alt58=1;
					}
					switch (alt58) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1166:11: KW_AS selectStatementWithCTE
							{
							KW_AS184=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createTableStatement4196); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS184);

							pushFollow(FOLLOW_selectStatementWithCTE_in_createTableStatement4198);
							selectStatementWithCTE185=selectStatementWithCTE();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_selectStatementWithCTE.add(selectStatementWithCTE185.getTree());
							}
							break;

					}

					}
					break;

			}

			// AST REWRITE
			// elements: tableRowFormat, tableBuckets, tablePropertiesPrefixed, tableLocation, trans, createTablePartitionSpec, tableFileFormat, name, temp, ifNotExists, columnNameTypeOrConstraintList, ext, tableComment, tableSkewed, selectStatementWithCTE, likeName
			// token labels: ext, temp, trans
			// rule labels: likeName, name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_ext=new RewriteRuleTokenStream(adaptor,"token ext",ext);
			RewriteRuleTokenStream stream_temp=new RewriteRuleTokenStream(adaptor,"token temp",temp);
			RewriteRuleTokenStream stream_trans=new RewriteRuleTokenStream(adaptor,"token trans",trans);
			RewriteRuleSubtreeStream stream_likeName=new RewriteRuleSubtreeStream(adaptor,"rule likeName",likeName!=null?likeName.getTree():null);
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1168:5: -> ^( TOK_CREATETABLE $name ( $temp)? ( $trans)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrConstraintList )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:8: ^( TOK_CREATETABLE $name ( $temp)? ( $trans)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrConstraintList )? ( tableComment )? ( createTablePartitionSpec )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATETABLE, "TOK_CREATETABLE"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:33: ( $temp)?
				if ( stream_temp.hasNext() ) {
					adaptor.addChild(root_1, stream_temp.nextNode());
				}
				stream_temp.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:40: ( $trans)?
				if ( stream_trans.hasNext() ) {
					adaptor.addChild(root_1, stream_trans.nextNode());
				}
				stream_trans.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:48: ( $ext)?
				if ( stream_ext.hasNext() ) {
					adaptor.addChild(root_1, stream_ext.nextNode());
				}
				stream_ext.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:53: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1169:10: ^( TOK_LIKETABLE ( $likeName)? )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LIKETABLE, "TOK_LIKETABLE"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1169:27: ( $likeName)?
				if ( stream_likeName.hasNext() ) {
					adaptor.addChild(root_2, stream_likeName.nextTree());
				}
				stream_likeName.reset();

				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1170:10: ( columnNameTypeOrConstraintList )?
				if ( stream_columnNameTypeOrConstraintList.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameTypeOrConstraintList.nextTree());
				}
				stream_columnNameTypeOrConstraintList.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1171:10: ( tableComment )?
				if ( stream_tableComment.hasNext() ) {
					adaptor.addChild(root_1, stream_tableComment.nextTree());
				}
				stream_tableComment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:10: ( createTablePartitionSpec )?
				if ( stream_createTablePartitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_createTablePartitionSpec.nextTree());
				}
				stream_createTablePartitionSpec.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1173:10: ( tableBuckets )?
				if ( stream_tableBuckets.hasNext() ) {
					adaptor.addChild(root_1, stream_tableBuckets.nextTree());
				}
				stream_tableBuckets.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1174:10: ( tableSkewed )?
				if ( stream_tableSkewed.hasNext() ) {
					adaptor.addChild(root_1, stream_tableSkewed.nextTree());
				}
				stream_tableSkewed.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1175:10: ( tableRowFormat )?
				if ( stream_tableRowFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
				}
				stream_tableRowFormat.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1176:10: ( tableFileFormat )?
				if ( stream_tableFileFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
				}
				stream_tableFileFormat.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:10: ( tableLocation )?
				if ( stream_tableLocation.hasNext() ) {
					adaptor.addChild(root_1, stream_tableLocation.nextTree());
				}
				stream_tableLocation.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1178:10: ( tablePropertiesPrefixed )?
				if ( stream_tablePropertiesPrefixed.hasNext() ) {
					adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
				}
				stream_tablePropertiesPrefixed.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:10: ( selectStatementWithCTE )?
				if ( stream_selectStatementWithCTE.hasNext() ) {
					adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());
				}
				stream_selectStatementWithCTE.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createTableStatement"


	public static class truncateTableStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "truncateTableStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1183:1: truncateTableStatement : KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? ( force )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? ) ;
	public final HiveParser.truncateTableStatement_return truncateTableStatement() throws RecognitionException {
		HiveParser.truncateTableStatement_return retval = new HiveParser.truncateTableStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_TRUNCATE186=null;
		Token KW_TABLE187=null;
		Token KW_COLUMNS189=null;
		Token LPAREN190=null;
		Token RPAREN192=null;
		ParserRuleReturnScope tablePartitionPrefix188 =null;
		ParserRuleReturnScope columnNameList191 =null;
		ParserRuleReturnScope force193 =null;

		ASTNode KW_TRUNCATE186_tree=null;
		ASTNode KW_TABLE187_tree=null;
		ASTNode KW_COLUMNS189_tree=null;
		ASTNode LPAREN190_tree=null;
		ASTNode RPAREN192_tree=null;
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_TRUNCATE=new RewriteRuleTokenStream(adaptor,"token KW_TRUNCATE");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_force=new RewriteRuleSubtreeStream(adaptor,"rule force");
		RewriteRuleSubtreeStream stream_tablePartitionPrefix=new RewriteRuleSubtreeStream(adaptor,"rule tablePartitionPrefix");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("truncate table statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:5: ( KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? ( force )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:7: KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? ( force )?
			{
			KW_TRUNCATE186=(Token)match(input,KW_TRUNCATE,FOLLOW_KW_TRUNCATE_in_truncateTableStatement4409); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TRUNCATE.add(KW_TRUNCATE186);

			KW_TABLE187=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_truncateTableStatement4411); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE187);

			pushFollow(FOLLOW_tablePartitionPrefix_in_truncateTableStatement4413);
			tablePartitionPrefix188=tablePartitionPrefix();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tablePartitionPrefix.add(tablePartitionPrefix188.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:49: ( KW_COLUMNS LPAREN columnNameList RPAREN )?
			int alt60=2;
			int LA60_0 = input.LA(1);
			if ( (LA60_0==KW_COLUMNS) ) {
				alt60=1;
			}
			switch (alt60) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:50: KW_COLUMNS LPAREN columnNameList RPAREN
					{
					KW_COLUMNS189=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_truncateTableStatement4416); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS189);

					LPAREN190=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_truncateTableStatement4418); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN190);

					pushFollow(FOLLOW_columnNameList_in_truncateTableStatement4420);
					columnNameList191=columnNameList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameList.add(columnNameList191.getTree());
					RPAREN192=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_truncateTableStatement4422); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN192);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:92: ( force )?
			int alt61=2;
			int LA61_0 = input.LA(1);
			if ( (LA61_0==KW_FORCE) ) {
				alt61=1;
			}
			switch (alt61) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:92: force
					{
					pushFollow(FOLLOW_force_in_truncateTableStatement4426);
					force193=force();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_force.add(force193.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: force, columnNameList, tablePartitionPrefix
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1187:5: -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:8: ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TRUNCATETABLE, "TOK_TRUNCATETABLE"), root_1);
				adaptor.addChild(root_1, stream_tablePartitionPrefix.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:49: ( columnNameList )?
				if ( stream_columnNameList.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameList.nextTree());
				}
				stream_columnNameList.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:65: ( force )?
				if ( stream_force.hasNext() ) {
					adaptor.addChild(root_1, stream_force.nextTree());
				}
				stream_force.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "truncateTableStatement"


	public static class dropTableStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropTableStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1189:1: dropTableStatement : KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) ;
	public final HiveParser.dropTableStatement_return dropTableStatement() throws RecognitionException {
		HiveParser.dropTableStatement_return retval = new HiveParser.dropTableStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP194=null;
		Token KW_TABLE195=null;
		Token KW_PURGE198=null;
		ParserRuleReturnScope ifExists196 =null;
		ParserRuleReturnScope tableName197 =null;
		ParserRuleReturnScope replicationClause199 =null;

		ASTNode KW_DROP194_tree=null;
		ASTNode KW_TABLE195_tree=null;
		ASTNode KW_PURGE198_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_PURGE=new RewriteRuleTokenStream(adaptor,"token KW_PURGE");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
		RewriteRuleSubtreeStream stream_replicationClause=new RewriteRuleSubtreeStream(adaptor,"rule replicationClause");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("drop statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:5: ( KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:7: KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )?
			{
			KW_DROP194=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropTableStatement4467); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP194);

			KW_TABLE195=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_dropTableStatement4469); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE195);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:24: ( ifExists )?
			int alt62=2;
			int LA62_0 = input.LA(1);
			if ( (LA62_0==KW_IF) ) {
				alt62=1;
			}
			switch (alt62) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:24: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropTableStatement4471);
					ifExists196=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists196.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableName_in_dropTableStatement4474);
			tableName197=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName197.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:44: ( KW_PURGE )?
			int alt63=2;
			int LA63_0 = input.LA(1);
			if ( (LA63_0==KW_PURGE) ) {
				alt63=1;
			}
			switch (alt63) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:44: KW_PURGE
					{
					KW_PURGE198=(Token)match(input,KW_PURGE,FOLLOW_KW_PURGE_in_dropTableStatement4476); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PURGE.add(KW_PURGE198);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:54: ( replicationClause )?
			int alt64=2;
			int LA64_0 = input.LA(1);
			if ( (LA64_0==KW_FOR) ) {
				alt64=1;
			}
			switch (alt64) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:54: replicationClause
					{
					pushFollow(FOLLOW_replicationClause_in_dropTableStatement4479);
					replicationClause199=replicationClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replicationClause.add(replicationClause199.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: KW_PURGE, replicationClause, tableName, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1193:5: -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1193:8: ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPTABLE, "TOK_DROPTABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1193:34: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1193:44: ( KW_PURGE )?
				if ( stream_KW_PURGE.hasNext() ) {
					adaptor.addChild(root_1, stream_KW_PURGE.nextNode());
				}
				stream_KW_PURGE.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1193:54: ( replicationClause )?
				if ( stream_replicationClause.hasNext() ) {
					adaptor.addChild(root_1, stream_replicationClause.nextTree());
				}
				stream_replicationClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropTableStatement"


	public static class alterStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1196:1: alterStatement : ( KW_ALTER KW_TABLE tableName alterTableStatementSuffix -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix ) | KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix ) | KW_ALTER KW_MATERIALIZED KW_VIEW tableNameTree= tableName alterMaterializedViewStatementSuffix[$tableNameTree.tree] -> alterMaterializedViewStatementSuffix | KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix -> alterDatabaseStatementSuffix );
	public final HiveParser.alterStatement_return alterStatement() throws RecognitionException {
		HiveParser.alterStatement_return retval = new HiveParser.alterStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ALTER200=null;
		Token KW_TABLE201=null;
		Token KW_ALTER204=null;
		Token KW_VIEW205=null;
		Token KW_AS207=null;
		Token KW_ALTER209=null;
		Token KW_MATERIALIZED210=null;
		Token KW_VIEW211=null;
		Token KW_ALTER213=null;
		Token KW_DATABASE214=null;
		Token KW_SCHEMA215=null;
		ParserRuleReturnScope tableNameTree =null;
		ParserRuleReturnScope tableName202 =null;
		ParserRuleReturnScope alterTableStatementSuffix203 =null;
		ParserRuleReturnScope tableName206 =null;
		ParserRuleReturnScope alterViewStatementSuffix208 =null;
		ParserRuleReturnScope alterMaterializedViewStatementSuffix212 =null;
		ParserRuleReturnScope alterDatabaseStatementSuffix216 =null;

		ASTNode KW_ALTER200_tree=null;
		ASTNode KW_TABLE201_tree=null;
		ASTNode KW_ALTER204_tree=null;
		ASTNode KW_VIEW205_tree=null;
		ASTNode KW_AS207_tree=null;
		ASTNode KW_ALTER209_tree=null;
		ASTNode KW_MATERIALIZED210_tree=null;
		ASTNode KW_VIEW211_tree=null;
		ASTNode KW_ALTER213_tree=null;
		ASTNode KW_DATABASE214_tree=null;
		ASTNode KW_SCHEMA215_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_ALTER=new RewriteRuleTokenStream(adaptor,"token KW_ALTER");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_MATERIALIZED=new RewriteRuleTokenStream(adaptor,"token KW_MATERIALIZED");
		RewriteRuleSubtreeStream stream_alterMaterializedViewStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterMaterializedViewStatementSuffix");
		RewriteRuleSubtreeStream stream_alterTableStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterTableStatementSuffix");
		RewriteRuleSubtreeStream stream_alterViewStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterViewStatementSuffix");
		RewriteRuleSubtreeStream stream_alterDatabaseStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterDatabaseStatementSuffix");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("alter statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1199:5: ( KW_ALTER KW_TABLE tableName alterTableStatementSuffix -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix ) | KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix ) | KW_ALTER KW_MATERIALIZED KW_VIEW tableNameTree= tableName alterMaterializedViewStatementSuffix[$tableNameTree.tree] -> alterMaterializedViewStatementSuffix | KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix -> alterDatabaseStatementSuffix )
			int alt67=4;
			int LA67_0 = input.LA(1);
			if ( (LA67_0==KW_ALTER) ) {
				switch ( input.LA(2) ) {
				case KW_TABLE:
					{
					alt67=1;
					}
					break;
				case KW_VIEW:
					{
					alt67=2;
					}
					break;
				case KW_MATERIALIZED:
					{
					alt67=3;
					}
					break;
				case KW_DATABASE:
				case KW_SCHEMA:
					{
					alt67=4;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 67, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 67, 0, input);
				throw nvae;
			}

			switch (alt67) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1199:7: KW_ALTER KW_TABLE tableName alterTableStatementSuffix
					{
					KW_ALTER200=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4528); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER200);

					KW_TABLE201=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_alterStatement4530); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE201);

					pushFollow(FOLLOW_tableName_in_alterStatement4532);
					tableName202=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName202.getTree());
					pushFollow(FOLLOW_alterTableStatementSuffix_in_alterStatement4534);
					alterTableStatementSuffix203=alterTableStatementSuffix();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterTableStatementSuffix.add(alterTableStatementSuffix203.getTree());
					// AST REWRITE
					// elements: tableName, alterTableStatementSuffix
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1199:61: -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1199:64: ^( TOK_ALTERTABLE tableName alterTableStatementSuffix )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE, "TOK_ALTERTABLE"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						adaptor.addChild(root_1, stream_alterTableStatementSuffix.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1200:7: KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix
					{
					KW_ALTER204=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4552); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER204);

					KW_VIEW205=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_alterStatement4554); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW205);

					pushFollow(FOLLOW_tableName_in_alterStatement4556);
					tableName206=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName206.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1200:34: ( KW_AS )?
					int alt65=2;
					int LA65_0 = input.LA(1);
					if ( (LA65_0==KW_AS) ) {
						alt65=1;
					}
					switch (alt65) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1200:34: KW_AS
							{
							KW_AS207=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_alterStatement4558); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS207);

							}
							break;

					}

					pushFollow(FOLLOW_alterViewStatementSuffix_in_alterStatement4561);
					alterViewStatementSuffix208=alterViewStatementSuffix();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterViewStatementSuffix.add(alterViewStatementSuffix208.getTree());
					// AST REWRITE
					// elements: tableName, alterViewStatementSuffix
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1200:66: -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1200:69: ^( TOK_ALTERVIEW tableName alterViewStatementSuffix )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW, "TOK_ALTERVIEW"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						adaptor.addChild(root_1, stream_alterViewStatementSuffix.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1201:7: KW_ALTER KW_MATERIALIZED KW_VIEW tableNameTree= tableName alterMaterializedViewStatementSuffix[$tableNameTree.tree]
					{
					KW_ALTER209=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4579); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER209);

					KW_MATERIALIZED210=(Token)match(input,KW_MATERIALIZED,FOLLOW_KW_MATERIALIZED_in_alterStatement4581); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MATERIALIZED.add(KW_MATERIALIZED210);

					KW_VIEW211=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_alterStatement4583); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW211);

					pushFollow(FOLLOW_tableName_in_alterStatement4587);
					tableNameTree=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableNameTree.getTree());
					pushFollow(FOLLOW_alterMaterializedViewStatementSuffix_in_alterStatement4589);
					alterMaterializedViewStatementSuffix212=alterMaterializedViewStatementSuffix((tableNameTree!=null?((ASTNode)tableNameTree.getTree()):null));
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterMaterializedViewStatementSuffix.add(alterMaterializedViewStatementSuffix212.getTree());
					// AST REWRITE
					// elements: alterMaterializedViewStatementSuffix
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1201:122: -> alterMaterializedViewStatementSuffix
					{
						adaptor.addChild(root_0, stream_alterMaterializedViewStatementSuffix.nextTree());
					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1202:7: KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix
					{
					KW_ALTER213=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4602); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER213);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1202:16: ( KW_DATABASE | KW_SCHEMA )
					int alt66=2;
					int LA66_0 = input.LA(1);
					if ( (LA66_0==KW_DATABASE) ) {
						alt66=1;
					}
					else if ( (LA66_0==KW_SCHEMA) ) {
						alt66=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 66, 0, input);
						throw nvae;
					}

					switch (alt66) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1202:17: KW_DATABASE
							{
							KW_DATABASE214=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_alterStatement4605); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE214);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1202:29: KW_SCHEMA
							{
							KW_SCHEMA215=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_alterStatement4607); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA215);

							}
							break;

					}

					pushFollow(FOLLOW_alterDatabaseStatementSuffix_in_alterStatement4610);
					alterDatabaseStatementSuffix216=alterDatabaseStatementSuffix();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterDatabaseStatementSuffix.add(alterDatabaseStatementSuffix216.getTree());
					// AST REWRITE
					// elements: alterDatabaseStatementSuffix
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1202:69: -> alterDatabaseStatementSuffix
					{
						adaptor.addChild(root_0, stream_alterDatabaseStatementSuffix.nextTree());
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatement"


	public static class alterTableStatementSuffix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterTableStatementSuffix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:1: alterTableStatementSuffix : ( ( alterStatementSuffixRename[true] )=> alterStatementSuffixRename[true] | alterStatementSuffixDropPartitions[true] | alterStatementSuffixAddPartitions[true] | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition | alterStatementPartitionKeyType | alterStatementSuffixDropConstraint | alterStatementSuffixAddConstraint | alterTblPartitionStatementSuffix[false] | partitionSpec alterTblPartitionStatementSuffix[true] -> alterTblPartitionStatementSuffix partitionSpec | alterStatementSuffixSetOwner );
	public final HiveParser.alterTableStatementSuffix_return alterTableStatementSuffix() throws RecognitionException {
		HiveParser.alterTableStatementSuffix_return retval = new HiveParser.alterTableStatementSuffix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterStatementSuffixRename217 =null;
		ParserRuleReturnScope alterStatementSuffixDropPartitions218 =null;
		ParserRuleReturnScope alterStatementSuffixAddPartitions219 =null;
		ParserRuleReturnScope alterStatementSuffixTouch220 =null;
		ParserRuleReturnScope alterStatementSuffixArchive221 =null;
		ParserRuleReturnScope alterStatementSuffixUnArchive222 =null;
		ParserRuleReturnScope alterStatementSuffixProperties223 =null;
		ParserRuleReturnScope alterStatementSuffixSkewedby224 =null;
		ParserRuleReturnScope alterStatementSuffixExchangePartition225 =null;
		ParserRuleReturnScope alterStatementPartitionKeyType226 =null;
		ParserRuleReturnScope alterStatementSuffixDropConstraint227 =null;
		ParserRuleReturnScope alterStatementSuffixAddConstraint228 =null;
		ParserRuleReturnScope alterTblPartitionStatementSuffix229 =null;
		ParserRuleReturnScope partitionSpec230 =null;
		ParserRuleReturnScope alterTblPartitionStatementSuffix231 =null;
		ParserRuleReturnScope alterStatementSuffixSetOwner232 =null;

		RewriteRuleSubtreeStream stream_alterTblPartitionStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterTblPartitionStatementSuffix");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");

		 pushMsg("alter table statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1208:5: ( ( alterStatementSuffixRename[true] )=> alterStatementSuffixRename[true] | alterStatementSuffixDropPartitions[true] | alterStatementSuffixAddPartitions[true] | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition | alterStatementPartitionKeyType | alterStatementSuffixDropConstraint | alterStatementSuffixAddConstraint | alterTblPartitionStatementSuffix[false] | partitionSpec alterTblPartitionStatementSuffix[true] -> alterTblPartitionStatementSuffix partitionSpec | alterStatementSuffixSetOwner )
			int alt68=15;
			switch ( input.LA(1) ) {
			case KW_RENAME:
				{
				int LA68_1 = input.LA(2);
				if ( (LA68_1==KW_TO) ) {
					int LA68_20 = input.LA(3);
					if ( (LA68_20==Identifier) && (synpred3_HiveParser())) {
						alt68=1;
					}
					else if ( ((LA68_20 >= KW_ABORT && LA68_20 <= KW_AFTER)||LA68_20==KW_ALLOC_FRACTION||LA68_20==KW_ANALYZE||LA68_20==KW_ARCHIVE||(LA68_20 >= KW_ASC && LA68_20 <= KW_AT)||(LA68_20 >= KW_AUTOCOMMIT && LA68_20 <= KW_BEFORE)||(LA68_20 >= KW_BUCKET && LA68_20 <= KW_BUCKETS)||(LA68_20 >= KW_CACHE && LA68_20 <= KW_CASCADE)||(LA68_20 >= KW_CBO && LA68_20 <= KW_CHANGE)||(LA68_20 >= KW_CHECK && LA68_20 <= KW_COLLECTION)||(LA68_20 >= KW_COLUMNS && LA68_20 <= KW_COMMENT)||(LA68_20 >= KW_COMPACT && LA68_20 <= KW_CONCATENATE)||(LA68_20 >= KW_CONTINUE && LA68_20 <= KW_COST)||LA68_20==KW_CRON||LA68_20==KW_DATA||LA68_20==KW_DATABASES||(LA68_20 >= KW_DATETIME && LA68_20 <= KW_DEBUG)||(LA68_20 >= KW_DEFAULT && LA68_20 <= KW_DEFINED)||(LA68_20 >= KW_DELIMITED && LA68_20 <= KW_DESC)||(LA68_20 >= KW_DETAIL && LA68_20 <= KW_DISABLE)||(LA68_20 >= KW_DISTRIBUTE && LA68_20 <= KW_DO)||LA68_20==KW_DOW||(LA68_20 >= KW_DUMP && LA68_20 <= KW_ELEM_TYPE)||LA68_20==KW_ENABLE||(LA68_20 >= KW_ENFORCED && LA68_20 <= KW_EVERY)||(LA68_20 >= KW_EXCLUSIVE && LA68_20 <= KW_EXECUTED)||(LA68_20 >= KW_EXPLAIN && LA68_20 <= KW_EXPRESSION)||(LA68_20 >= KW_FIELDS && LA68_20 <= KW_FIRST)||(LA68_20 >= KW_FORMAT && LA68_20 <= KW_FORMATTED)||LA68_20==KW_FUNCTIONS||(LA68_20 >= KW_HOUR && LA68_20 <= KW_IDXPROPERTIES)||(LA68_20 >= KW_INDEX && LA68_20 <= KW_INDEXES)||(LA68_20 >= KW_INPATH && LA68_20 <= KW_INPUTFORMAT)||(LA68_20 >= KW_ISOLATION && LA68_20 <= KW_JAR)||(LA68_20 >= KW_JOINCOST && LA68_20 <= KW_LAST)||LA68_20==KW_LEVEL||(LA68_20 >= KW_LIMIT && LA68_20 <= KW_LOAD)||(LA68_20 >= KW_LOCATION && LA68_20 <= KW_LONG)||(LA68_20 >= KW_MANAGEDLOCATION && LA68_20 <= KW_MANAGEMENT)||(LA68_20 >= KW_MAPJOIN && LA68_20 <= KW_MATERIALIZED)||LA68_20==KW_METADATA||(LA68_20 >= KW_MINUTE && LA68_20 <= KW_MONTH)||(LA68_20 >= KW_MOVE && LA68_20 <= KW_MSCK)||(LA68_20 >= KW_NORELY && LA68_20 <= KW_NOSCAN)||LA68_20==KW_NOVALIDATE||LA68_20==KW_NULLS||LA68_20==KW_OFFSET||(LA68_20 >= KW_OPERATOR && LA68_20 <= KW_OPTION)||(LA68_20 >= KW_OUTPUTDRIVER && LA68_20 <= KW_OUTPUTFORMAT)||(LA68_20 >= KW_OVERWRITE && LA68_20 <= KW_OWNER)||(LA68_20 >= KW_PARTITIONED && LA68_20 <= KW_PATH)||(LA68_20 >= KW_PLAN && LA68_20 <= KW_POOL)||LA68_20==KW_PRINCIPALS||(LA68_20 >= KW_PURGE && LA68_20 <= KW_QUERY_PARALLELISM)||LA68_20==KW_READ||(LA68_20 >= KW_REBUILD && LA68_20 <= KW_RECORDWRITER)||(LA68_20 >= KW_RELOAD && LA68_20 <= KW_RESTRICT)||LA68_20==KW_REWRITE||(LA68_20 >= KW_ROLE && LA68_20 <= KW_ROLES)||(LA68_20 >= KW_SCHEDULED && LA68_20 <= KW_SECOND)||(LA68_20 >= KW_SEMI && LA68_20 <= KW_SERVER)||(LA68_20 >= KW_SETS && LA68_20 <= KW_SKEWED)||(LA68_20 >= KW_SNAPSHOT && LA68_20 <= KW_SSL)||(LA68_20 >= KW_STATISTICS && LA68_20 <= KW_SUMMARY)||LA68_20==KW_TABLES||(LA68_20 >= KW_TBLPROPERTIES && LA68_20 <= KW_TERMINATED)||LA68_20==KW_TINYINT||(LA68_20 >= KW_TOUCH && LA68_20 <= KW_TRANSACTIONS)||LA68_20==KW_UNARCHIVE||LA68_20==KW_UNDO||LA68_20==KW_UNIONTYPE||(LA68_20 >= KW_UNLOCK && LA68_20 <= KW_UNSIGNED)||(LA68_20 >= KW_URI && LA68_20 <= KW_USE)||(LA68_20 >= KW_UTC && LA68_20 <= KW_VALIDATE)||LA68_20==KW_VALUE_TYPE||(LA68_20 >= KW_VECTORIZATION && LA68_20 <= KW_WEEK)||LA68_20==KW_WHILE||(LA68_20 >= KW_WORK && LA68_20 <= KW_ZONE)||LA68_20==KW_BATCH||LA68_20==KW_DAYOFWEEK||LA68_20==KW_HOLD_DDLTIME||LA68_20==KW_IGNORE||LA68_20==KW_NO_DROP||LA68_20==KW_OFFLINE||LA68_20==KW_PROTECTION||LA68_20==KW_READONLY||LA68_20==KW_TIMESTAMPTZ) && (synpred3_HiveParser())) {
						alt68=1;
					}
					else if ( (LA68_20==KW_PARTITION) ) {
						alt68=13;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 68, 20, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_DROP:
				{
				int LA68_2 = input.LA(2);
				if ( (LA68_2==KW_CONSTRAINT) ) {
					alt68=11;
				}
				else if ( (LA68_2==KW_IF||LA68_2==KW_PARTITION) ) {
					alt68=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_ADD:
				{
				switch ( input.LA(2) ) {
				case KW_IF:
				case KW_PARTITION:
					{
					alt68=3;
					}
					break;
				case KW_CONSTRAINT:
					{
					alt68=12;
					}
					break;
				case KW_COLUMNS:
					{
					alt68=13;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 3, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
				}
				break;
			case KW_TOUCH:
				{
				alt68=4;
				}
				break;
			case KW_ARCHIVE:
				{
				alt68=5;
				}
				break;
			case KW_UNARCHIVE:
				{
				alt68=6;
				}
				break;
			case KW_SET:
				{
				switch ( input.LA(2) ) {
				case KW_TBLPROPERTIES:
					{
					alt68=7;
					}
					break;
				case KW_FILEFORMAT:
				case KW_LOCATION:
				case KW_SERDE:
				case KW_SERDEPROPERTIES:
				case KW_SKEWED:
					{
					alt68=13;
					}
					break;
				case KW_OWNER:
					{
					alt68=15;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 7, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
				}
				break;
			case KW_UNSET:
				{
				alt68=7;
				}
				break;
			case KW_SKEWED:
				{
				alt68=8;
				}
				break;
			case KW_NOT:
				{
				int LA68_10 = input.LA(2);
				if ( (LA68_10==KW_SKEWED||LA68_10==KW_STORED) ) {
					alt68=8;
				}
				else if ( (LA68_10==KW_CLUSTERED||LA68_10==KW_SORTED) ) {
					alt68=13;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 10, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_EXCHANGE:
				{
				alt68=9;
				}
				break;
			case KW_PARTITION:
				{
				int LA68_12 = input.LA(2);
				if ( (LA68_12==KW_COLUMN) ) {
					alt68=10;
				}
				else if ( (LA68_12==LPAREN) ) {
					alt68=14;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 68, 12, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_CHANGE:
			case KW_CLUSTERED:
			case KW_COMPACT:
			case KW_CONCATENATE:
			case KW_INTO:
			case KW_REPLACE:
			case KW_UPDATE:
				{
				alt68=13;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 68, 0, input);
				throw nvae;
			}
			switch (alt68) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1208:7: ( alterStatementSuffixRename[true] )=> alterStatementSuffixRename[true]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix4648);
					alterStatementSuffixRename217=alterStatementSuffixRename(true);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRename217.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1209:7: alterStatementSuffixDropPartitions[true]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix4657);
					alterStatementSuffixDropPartitions218=alterStatementSuffixDropPartitions(true);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixDropPartitions218.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:7: alterStatementSuffixAddPartitions[true]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix4666);
					alterStatementSuffixAddPartitions219=alterStatementSuffixAddPartitions(true);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddPartitions219.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:7: alterStatementSuffixTouch
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix4675);
					alterStatementSuffixTouch220=alterStatementSuffixTouch();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixTouch220.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:7: alterStatementSuffixArchive
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix4683);
					alterStatementSuffixArchive221=alterStatementSuffixArchive();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixArchive221.getTree());

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1213:7: alterStatementSuffixUnArchive
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix4691);
					alterStatementSuffixUnArchive222=alterStatementSuffixUnArchive();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixUnArchive222.getTree());

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1214:7: alterStatementSuffixProperties
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix4699);
					alterStatementSuffixProperties223=alterStatementSuffixProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixProperties223.getTree());

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:7: alterStatementSuffixSkewedby
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix4707);
					alterStatementSuffixSkewedby224=alterStatementSuffixSkewedby();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixSkewedby224.getTree());

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1216:7: alterStatementSuffixExchangePartition
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix4715);
					alterStatementSuffixExchangePartition225=alterStatementSuffixExchangePartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixExchangePartition225.getTree());

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:7: alterStatementPartitionKeyType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementPartitionKeyType_in_alterTableStatementSuffix4723);
					alterStatementPartitionKeyType226=alterStatementPartitionKeyType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementPartitionKeyType226.getTree());

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:7: alterStatementSuffixDropConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixDropConstraint_in_alterTableStatementSuffix4731);
					alterStatementSuffixDropConstraint227=alterStatementSuffixDropConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixDropConstraint227.getTree());

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1219:7: alterStatementSuffixAddConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixAddConstraint_in_alterTableStatementSuffix4739);
					alterStatementSuffixAddConstraint228=alterStatementSuffixAddConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddConstraint228.getTree());

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1220:7: alterTblPartitionStatementSuffix[false]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix4747);
					alterTblPartitionStatementSuffix229=alterTblPartitionStatementSuffix(false);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterTblPartitionStatementSuffix229.getTree());

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1221:7: partitionSpec alterTblPartitionStatementSuffix[true]
					{
					pushFollow(FOLLOW_partitionSpec_in_alterTableStatementSuffix4756);
					partitionSpec230=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec230.getTree());
					pushFollow(FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix4758);
					alterTblPartitionStatementSuffix231=alterTblPartitionStatementSuffix(true);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterTblPartitionStatementSuffix.add(alterTblPartitionStatementSuffix231.getTree());
					// AST REWRITE
					// elements: alterTblPartitionStatementSuffix, partitionSpec
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1221:60: -> alterTblPartitionStatementSuffix partitionSpec
					{
						adaptor.addChild(root_0, stream_alterTblPartitionStatementSuffix.nextTree());
						adaptor.addChild(root_0, stream_partitionSpec.nextTree());
					}


					retval.tree = root_0;
					}

					}
					break;
				case 15 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1222:7: alterStatementSuffixSetOwner
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixSetOwner_in_alterTableStatementSuffix4773);
					alterStatementSuffixSetOwner232=alterStatementSuffixSetOwner();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixSetOwner232.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterTableStatementSuffix"


	public static class alterTblPartitionStatementSuffix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterTblPartitionStatementSuffix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:1: alterTblPartitionStatementSuffix[boolean partition] : ( alterStatementSuffixFileFormat[partition] | alterStatementSuffixLocation[partition] | alterStatementSuffixMergeFiles[partition] | alterStatementSuffixSerdeProperties[partition] | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum[partition] | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby | alterStatementSuffixCompact | alterStatementSuffixUpdateStatsCol[partition] | alterStatementSuffixUpdateStats[partition] | alterStatementSuffixRenameCol | alterStatementSuffixAddCol | alterStatementSuffixUpdateColumns );
	public final HiveParser.alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix(boolean partition) throws RecognitionException {
		HiveParser.alterTblPartitionStatementSuffix_return retval = new HiveParser.alterTblPartitionStatementSuffix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterStatementSuffixFileFormat233 =null;
		ParserRuleReturnScope alterStatementSuffixLocation234 =null;
		ParserRuleReturnScope alterStatementSuffixMergeFiles235 =null;
		ParserRuleReturnScope alterStatementSuffixSerdeProperties236 =null;
		ParserRuleReturnScope alterStatementSuffixRenamePart237 =null;
		ParserRuleReturnScope alterStatementSuffixBucketNum238 =null;
		ParserRuleReturnScope alterTblPartitionStatementSuffixSkewedLocation239 =null;
		ParserRuleReturnScope alterStatementSuffixClusterbySortby240 =null;
		ParserRuleReturnScope alterStatementSuffixCompact241 =null;
		ParserRuleReturnScope alterStatementSuffixUpdateStatsCol242 =null;
		ParserRuleReturnScope alterStatementSuffixUpdateStats243 =null;
		ParserRuleReturnScope alterStatementSuffixRenameCol244 =null;
		ParserRuleReturnScope alterStatementSuffixAddCol245 =null;
		ParserRuleReturnScope alterStatementSuffixUpdateColumns246 =null;


		pushMsg("alter table partition statement suffix", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1228:3: ( alterStatementSuffixFileFormat[partition] | alterStatementSuffixLocation[partition] | alterStatementSuffixMergeFiles[partition] | alterStatementSuffixSerdeProperties[partition] | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum[partition] | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby | alterStatementSuffixCompact | alterStatementSuffixUpdateStatsCol[partition] | alterStatementSuffixUpdateStats[partition] | alterStatementSuffixRenameCol | alterStatementSuffixAddCol | alterStatementSuffixUpdateColumns )
			int alt69=14;
			switch ( input.LA(1) ) {
			case KW_SET:
				{
				switch ( input.LA(2) ) {
				case KW_FILEFORMAT:
					{
					alt69=1;
					}
					break;
				case KW_LOCATION:
					{
					alt69=2;
					}
					break;
				case KW_SERDE:
				case KW_SERDEPROPERTIES:
					{
					alt69=4;
					}
					break;
				case KW_SKEWED:
					{
					alt69=7;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 69, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
				}
				break;
			case KW_CONCATENATE:
				{
				alt69=3;
				}
				break;
			case KW_RENAME:
				{
				alt69=5;
				}
				break;
			case KW_INTO:
				{
				alt69=6;
				}
				break;
			case KW_CLUSTERED:
			case KW_NOT:
				{
				alt69=8;
				}
				break;
			case KW_COMPACT:
				{
				alt69=9;
				}
				break;
			case KW_UPDATE:
				{
				int LA69_8 = input.LA(2);
				if ( (LA69_8==KW_STATISTICS) ) {
					int LA69_17 = input.LA(3);
					if ( (LA69_17==KW_FOR) ) {
						alt69=10;
					}
					else if ( (LA69_17==KW_SET) ) {
						alt69=11;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 69, 17, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( (LA69_8==KW_COLUMNS) ) {
					alt69=14;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 69, 8, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_CHANGE:
				{
				alt69=12;
				}
				break;
			case KW_ADD:
			case KW_REPLACE:
				{
				alt69=13;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 69, 0, input);
				throw nvae;
			}
			switch (alt69) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1228:5: alterStatementSuffixFileFormat[partition]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix4799);
					alterStatementSuffixFileFormat233=alterStatementSuffixFileFormat(partition);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixFileFormat233.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1229:5: alterStatementSuffixLocation[partition]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix4806);
					alterStatementSuffixLocation234=alterStatementSuffixLocation(partition);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixLocation234.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1230:5: alterStatementSuffixMergeFiles[partition]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix4813);
					alterStatementSuffixMergeFiles235=alterStatementSuffixMergeFiles(partition);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixMergeFiles235.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:5: alterStatementSuffixSerdeProperties[partition]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix4820);
					alterStatementSuffixSerdeProperties236=alterStatementSuffixSerdeProperties(partition);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixSerdeProperties236.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1232:5: alterStatementSuffixRenamePart
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix4827);
					alterStatementSuffixRenamePart237=alterStatementSuffixRenamePart();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRenamePart237.getTree());

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1233:5: alterStatementSuffixBucketNum[partition]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix4833);
					alterStatementSuffixBucketNum238=alterStatementSuffixBucketNum(partition);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixBucketNum238.getTree());

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:5: alterTblPartitionStatementSuffixSkewedLocation
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix4840);
					alterTblPartitionStatementSuffixSkewedLocation239=alterTblPartitionStatementSuffixSkewedLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterTblPartitionStatementSuffixSkewedLocation239.getTree());

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:5: alterStatementSuffixClusterbySortby
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix4846);
					alterStatementSuffixClusterbySortby240=alterStatementSuffixClusterbySortby();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixClusterbySortby240.getTree());

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1236:5: alterStatementSuffixCompact
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixCompact_in_alterTblPartitionStatementSuffix4852);
					alterStatementSuffixCompact241=alterStatementSuffixCompact();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixCompact241.getTree());

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1237:5: alterStatementSuffixUpdateStatsCol[partition]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTblPartitionStatementSuffix4858);
					alterStatementSuffixUpdateStatsCol242=alterStatementSuffixUpdateStatsCol(partition);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixUpdateStatsCol242.getTree());

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1238:5: alterStatementSuffixUpdateStats[partition]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixUpdateStats_in_alterTblPartitionStatementSuffix4865);
					alterStatementSuffixUpdateStats243=alterStatementSuffixUpdateStats(partition);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixUpdateStats243.getTree());

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1239:5: alterStatementSuffixRenameCol
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixRenameCol_in_alterTblPartitionStatementSuffix4872);
					alterStatementSuffixRenameCol244=alterStatementSuffixRenameCol();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRenameCol244.getTree());

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1240:5: alterStatementSuffixAddCol
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixAddCol_in_alterTblPartitionStatementSuffix4878);
					alterStatementSuffixAddCol245=alterStatementSuffixAddCol();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddCol245.getTree());

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1241:5: alterStatementSuffixUpdateColumns
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixUpdateColumns_in_alterTblPartitionStatementSuffix4884);
					alterStatementSuffixUpdateColumns246=alterStatementSuffixUpdateColumns();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixUpdateColumns246.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterTblPartitionStatementSuffix"


	public static class alterStatementPartitionKeyType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementPartitionKeyType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1244:1: alterStatementPartitionKeyType : KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType ) ;
	public final HiveParser.alterStatementPartitionKeyType_return alterStatementPartitionKeyType() throws RecognitionException {
		HiveParser.alterStatementPartitionKeyType_return retval = new HiveParser.alterStatementPartitionKeyType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_PARTITION247=null;
		Token KW_COLUMN248=null;
		Token LPAREN249=null;
		Token RPAREN251=null;
		ParserRuleReturnScope columnNameType250 =null;

		ASTNode KW_PARTITION247_tree=null;
		ASTNode KW_COLUMN248_tree=null;
		ASTNode LPAREN249_tree=null;
		ASTNode RPAREN251_tree=null;
		RewriteRuleTokenStream stream_KW_PARTITION=new RewriteRuleTokenStream(adaptor,"token KW_PARTITION");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
		RewriteRuleSubtreeStream stream_columnNameType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameType");

		msgs.push("alter partition key type"); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1247:2: ( KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1247:4: KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN
			{
			KW_PARTITION247=(Token)match(input,KW_PARTITION,FOLLOW_KW_PARTITION_in_alterStatementPartitionKeyType4906); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_PARTITION.add(KW_PARTITION247);

			KW_COLUMN248=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementPartitionKeyType4908); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN248);

			LPAREN249=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_alterStatementPartitionKeyType4910); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN249);

			pushFollow(FOLLOW_columnNameType_in_alterStatementPartitionKeyType4912);
			columnNameType250=columnNameType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameType.add(columnNameType250.getTree());
			RPAREN251=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_alterStatementPartitionKeyType4914); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN251);

			// AST REWRITE
			// elements: columnNameType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1248:2: -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1248:5: ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_PARTCOLTYPE, "TOK_ALTERTABLE_PARTCOLTYPE"), root_1);
				adaptor.addChild(root_1, stream_columnNameType.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {msgs.pop();}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementPartitionKeyType"


	public static class alterViewStatementSuffix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterViewStatementSuffix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1251:1: alterViewStatementSuffix : ( alterViewSuffixProperties | alterStatementSuffixRename[false] | alterStatementSuffixAddPartitions[false] | alterStatementSuffixDropPartitions[false] | selectStatementWithCTE );
	public final HiveParser.alterViewStatementSuffix_return alterViewStatementSuffix() throws RecognitionException {
		HiveParser.alterViewStatementSuffix_return retval = new HiveParser.alterViewStatementSuffix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterViewSuffixProperties252 =null;
		ParserRuleReturnScope alterStatementSuffixRename253 =null;
		ParserRuleReturnScope alterStatementSuffixAddPartitions254 =null;
		ParserRuleReturnScope alterStatementSuffixDropPartitions255 =null;
		ParserRuleReturnScope selectStatementWithCTE256 =null;


		 pushMsg("alter view statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1254:5: ( alterViewSuffixProperties | alterStatementSuffixRename[false] | alterStatementSuffixAddPartitions[false] | alterStatementSuffixDropPartitions[false] | selectStatementWithCTE )
			int alt70=5;
			switch ( input.LA(1) ) {
			case KW_SET:
			case KW_UNSET:
				{
				alt70=1;
				}
				break;
			case KW_RENAME:
				{
				alt70=2;
				}
				break;
			case KW_ADD:
				{
				alt70=3;
				}
				break;
			case KW_DROP:
				{
				alt70=4;
				}
				break;
			case KW_MAP:
			case KW_REDUCE:
			case KW_SELECT:
			case KW_WITH:
			case LPAREN:
				{
				alt70=5;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 70, 0, input);
				throw nvae;
			}
			switch (alt70) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1254:7: alterViewSuffixProperties
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix4947);
					alterViewSuffixProperties252=alterViewSuffixProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterViewSuffixProperties252.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1255:7: alterStatementSuffixRename[false]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix4955);
					alterStatementSuffixRename253=alterStatementSuffixRename(false);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRename253.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1256:7: alterStatementSuffixAddPartitions[false]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix4964);
					alterStatementSuffixAddPartitions254=alterStatementSuffixAddPartitions(false);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddPartitions254.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1257:7: alterStatementSuffixDropPartitions[false]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix4973);
					alterStatementSuffixDropPartitions255=alterStatementSuffixDropPartitions(false);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixDropPartitions255.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1258:7: selectStatementWithCTE
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_selectStatementWithCTE_in_alterViewStatementSuffix4982);
					selectStatementWithCTE256=selectStatementWithCTE();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, selectStatementWithCTE256.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterViewStatementSuffix"


	public static class alterMaterializedViewStatementSuffix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterMaterializedViewStatementSuffix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1261:1: alterMaterializedViewStatementSuffix[CommonTree tableNameTree] : ( alterMaterializedViewSuffixRewrite[tableNameTree] | alterMaterializedViewSuffixRebuild[tableNameTree] );
	public final HiveParser.alterMaterializedViewStatementSuffix_return alterMaterializedViewStatementSuffix(CommonTree tableNameTree) throws RecognitionException {
		HiveParser.alterMaterializedViewStatementSuffix_return retval = new HiveParser.alterMaterializedViewStatementSuffix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterMaterializedViewSuffixRewrite257 =null;
		ParserRuleReturnScope alterMaterializedViewSuffixRebuild258 =null;


		 pushMsg("alter materialized view statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1264:5: ( alterMaterializedViewSuffixRewrite[tableNameTree] | alterMaterializedViewSuffixRebuild[tableNameTree] )
			int alt71=2;
			int LA71_0 = input.LA(1);
			if ( (LA71_0==KW_DISABLE||LA71_0==KW_ENABLE) ) {
				alt71=1;
			}
			else if ( (LA71_0==KW_REBUILD) ) {
				alt71=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 71, 0, input);
				throw nvae;
			}

			switch (alt71) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1264:7: alterMaterializedViewSuffixRewrite[tableNameTree]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterMaterializedViewSuffixRewrite_in_alterMaterializedViewStatementSuffix5010);
					alterMaterializedViewSuffixRewrite257=alterMaterializedViewSuffixRewrite(tableNameTree);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterMaterializedViewSuffixRewrite257.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1265:7: alterMaterializedViewSuffixRebuild[tableNameTree]
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterMaterializedViewSuffixRebuild_in_alterMaterializedViewStatementSuffix5019);
					alterMaterializedViewSuffixRebuild258=alterMaterializedViewSuffixRebuild(tableNameTree);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterMaterializedViewSuffixRebuild258.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterMaterializedViewStatementSuffix"


	public static class alterMaterializedViewSuffixRewrite_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterMaterializedViewSuffixRewrite"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1268:1: alterMaterializedViewSuffixRewrite[CommonTree tableNameTree] : (mvRewriteFlag= rewriteEnabled |mvRewriteFlag= rewriteDisabled ) -> ^( TOK_ALTER_MATERIALIZED_VIEW_REWRITE $mvRewriteFlag) ;
	public final HiveParser.alterMaterializedViewSuffixRewrite_return alterMaterializedViewSuffixRewrite(CommonTree tableNameTree) throws RecognitionException {
		HiveParser.alterMaterializedViewSuffixRewrite_return retval = new HiveParser.alterMaterializedViewSuffixRewrite_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope mvRewriteFlag =null;

		RewriteRuleSubtreeStream stream_rewriteEnabled=new RewriteRuleSubtreeStream(adaptor,"rule rewriteEnabled");
		RewriteRuleSubtreeStream stream_rewriteDisabled=new RewriteRuleSubtreeStream(adaptor,"rule rewriteDisabled");

		 pushMsg("alter materialized view rewrite statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1271:5: ( (mvRewriteFlag= rewriteEnabled |mvRewriteFlag= rewriteDisabled ) -> ^( TOK_ALTER_MATERIALIZED_VIEW_REWRITE $mvRewriteFlag) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1271:7: (mvRewriteFlag= rewriteEnabled |mvRewriteFlag= rewriteDisabled )
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1271:7: (mvRewriteFlag= rewriteEnabled |mvRewriteFlag= rewriteDisabled )
			int alt72=2;
			int LA72_0 = input.LA(1);
			if ( (LA72_0==KW_ENABLE) ) {
				alt72=1;
			}
			else if ( (LA72_0==KW_DISABLE) ) {
				alt72=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 72, 0, input);
				throw nvae;
			}

			switch (alt72) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1271:8: mvRewriteFlag= rewriteEnabled
					{
					pushFollow(FOLLOW_rewriteEnabled_in_alterMaterializedViewSuffixRewrite5051);
					mvRewriteFlag=rewriteEnabled();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rewriteEnabled.add(mvRewriteFlag.getTree());
					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1271:39: mvRewriteFlag= rewriteDisabled
					{
					pushFollow(FOLLOW_rewriteDisabled_in_alterMaterializedViewSuffixRewrite5057);
					mvRewriteFlag=rewriteDisabled();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rewriteDisabled.add(mvRewriteFlag.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: mvRewriteFlag
			// token labels: 
			// rule labels: mvRewriteFlag, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_mvRewriteFlag=new RewriteRuleSubtreeStream(adaptor,"rule mvRewriteFlag",mvRewriteFlag!=null?mvRewriteFlag.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1272:5: -> ^( TOK_ALTER_MATERIALIZED_VIEW_REWRITE $mvRewriteFlag)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1272:8: ^( TOK_ALTER_MATERIALIZED_VIEW_REWRITE $mvRewriteFlag)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTER_MATERIALIZED_VIEW_REWRITE, "TOK_ALTER_MATERIALIZED_VIEW_REWRITE"), root_1);
				adaptor.addChild(root_1, tableNameTree);
				adaptor.addChild(root_1, stream_mvRewriteFlag.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterMaterializedViewSuffixRewrite"


	public static class alterMaterializedViewSuffixRebuild_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterMaterializedViewSuffixRebuild"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1275:1: alterMaterializedViewSuffixRebuild[CommonTree tableNameTree] : KW_REBUILD -> ^( TOK_ALTER_MATERIALIZED_VIEW_REBUILD ) ;
	public final HiveParser.alterMaterializedViewSuffixRebuild_return alterMaterializedViewSuffixRebuild(CommonTree tableNameTree) throws RecognitionException {
		HiveParser.alterMaterializedViewSuffixRebuild_return retval = new HiveParser.alterMaterializedViewSuffixRebuild_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REBUILD259=null;

		ASTNode KW_REBUILD259_tree=null;
		RewriteRuleTokenStream stream_KW_REBUILD=new RewriteRuleTokenStream(adaptor,"token KW_REBUILD");

		 pushMsg("alter materialized view rebuild statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:5: ( KW_REBUILD -> ^( TOK_ALTER_MATERIALIZED_VIEW_REBUILD ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:7: KW_REBUILD
			{
			KW_REBUILD259=(Token)match(input,KW_REBUILD,FOLLOW_KW_REBUILD_in_alterMaterializedViewSuffixRebuild5101); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REBUILD.add(KW_REBUILD259);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1278:18: -> ^( TOK_ALTER_MATERIALIZED_VIEW_REBUILD )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:21: ^( TOK_ALTER_MATERIALIZED_VIEW_REBUILD )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTER_MATERIALIZED_VIEW_REBUILD, "TOK_ALTER_MATERIALIZED_VIEW_REBUILD"), root_1);
				adaptor.addChild(root_1, tableNameTree);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterMaterializedViewSuffixRebuild"


	public static class alterDatabaseStatementSuffix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterDatabaseStatementSuffix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1281:1: alterDatabaseStatementSuffix : ( alterDatabaseSuffixProperties | alterDatabaseSuffixSetOwner | alterDatabaseSuffixSetLocation );
	public final HiveParser.alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix() throws RecognitionException {
		HiveParser.alterDatabaseStatementSuffix_return retval = new HiveParser.alterDatabaseStatementSuffix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterDatabaseSuffixProperties260 =null;
		ParserRuleReturnScope alterDatabaseSuffixSetOwner261 =null;
		ParserRuleReturnScope alterDatabaseSuffixSetLocation262 =null;


		 pushMsg("alter database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:5: ( alterDatabaseSuffixProperties | alterDatabaseSuffixSetOwner | alterDatabaseSuffixSetLocation )
			int alt73=3;
			int LA73_0 = input.LA(1);
			if ( (LA73_0==Identifier) ) {
				int LA73_1 = input.LA(2);
				if ( (LA73_1==KW_SET) ) {
					switch ( input.LA(3) ) {
					case KW_DBPROPERTIES:
						{
						alt73=1;
						}
						break;
					case KW_OWNER:
						{
						alt73=2;
						}
						break;
					case KW_LOCATION:
					case KW_MANAGEDLOCATION:
						{
						alt73=3;
						}
						break;
					default:
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 73, 3, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 73, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( ((LA73_0 >= KW_ABORT && LA73_0 <= KW_AFTER)||LA73_0==KW_ALLOC_FRACTION||LA73_0==KW_ANALYZE||LA73_0==KW_ARCHIVE||(LA73_0 >= KW_ASC && LA73_0 <= KW_AT)||(LA73_0 >= KW_AUTOCOMMIT && LA73_0 <= KW_BEFORE)||(LA73_0 >= KW_BUCKET && LA73_0 <= KW_BUCKETS)||(LA73_0 >= KW_CACHE && LA73_0 <= KW_CASCADE)||(LA73_0 >= KW_CBO && LA73_0 <= KW_CHANGE)||(LA73_0 >= KW_CHECK && LA73_0 <= KW_COLLECTION)||(LA73_0 >= KW_COLUMNS && LA73_0 <= KW_COMMENT)||(LA73_0 >= KW_COMPACT && LA73_0 <= KW_CONCATENATE)||(LA73_0 >= KW_CONTINUE && LA73_0 <= KW_COST)||LA73_0==KW_CRON||LA73_0==KW_DATA||LA73_0==KW_DATABASES||(LA73_0 >= KW_DATETIME && LA73_0 <= KW_DEBUG)||(LA73_0 >= KW_DEFAULT && LA73_0 <= KW_DEFINED)||(LA73_0 >= KW_DELIMITED && LA73_0 <= KW_DESC)||(LA73_0 >= KW_DETAIL && LA73_0 <= KW_DISABLE)||(LA73_0 >= KW_DISTRIBUTE && LA73_0 <= KW_DO)||LA73_0==KW_DOW||(LA73_0 >= KW_DUMP && LA73_0 <= KW_ELEM_TYPE)||LA73_0==KW_ENABLE||(LA73_0 >= KW_ENFORCED && LA73_0 <= KW_EVERY)||(LA73_0 >= KW_EXCLUSIVE && LA73_0 <= KW_EXECUTED)||(LA73_0 >= KW_EXPLAIN && LA73_0 <= KW_EXPRESSION)||(LA73_0 >= KW_FIELDS && LA73_0 <= KW_FIRST)||(LA73_0 >= KW_FORMAT && LA73_0 <= KW_FORMATTED)||LA73_0==KW_FUNCTIONS||(LA73_0 >= KW_HOUR && LA73_0 <= KW_IDXPROPERTIES)||(LA73_0 >= KW_INDEX && LA73_0 <= KW_INDEXES)||(LA73_0 >= KW_INPATH && LA73_0 <= KW_INPUTFORMAT)||(LA73_0 >= KW_ISOLATION && LA73_0 <= KW_JAR)||(LA73_0 >= KW_JOINCOST && LA73_0 <= KW_LAST)||LA73_0==KW_LEVEL||(LA73_0 >= KW_LIMIT && LA73_0 <= KW_LOAD)||(LA73_0 >= KW_LOCATION && LA73_0 <= KW_LONG)||(LA73_0 >= KW_MANAGEDLOCATION && LA73_0 <= KW_MANAGEMENT)||(LA73_0 >= KW_MAPJOIN && LA73_0 <= KW_MATERIALIZED)||LA73_0==KW_METADATA||(LA73_0 >= KW_MINUTE && LA73_0 <= KW_MONTH)||(LA73_0 >= KW_MOVE && LA73_0 <= KW_MSCK)||(LA73_0 >= KW_NORELY && LA73_0 <= KW_NOSCAN)||LA73_0==KW_NOVALIDATE||LA73_0==KW_NULLS||LA73_0==KW_OFFSET||(LA73_0 >= KW_OPERATOR && LA73_0 <= KW_OPTION)||(LA73_0 >= KW_OUTPUTDRIVER && LA73_0 <= KW_OUTPUTFORMAT)||(LA73_0 >= KW_OVERWRITE && LA73_0 <= KW_OWNER)||(LA73_0 >= KW_PARTITIONED && LA73_0 <= KW_PATH)||(LA73_0 >= KW_PLAN && LA73_0 <= KW_POOL)||LA73_0==KW_PRINCIPALS||(LA73_0 >= KW_PURGE && LA73_0 <= KW_QUERY_PARALLELISM)||LA73_0==KW_READ||(LA73_0 >= KW_REBUILD && LA73_0 <= KW_RECORDWRITER)||(LA73_0 >= KW_RELOAD && LA73_0 <= KW_RESTRICT)||LA73_0==KW_REWRITE||(LA73_0 >= KW_ROLE && LA73_0 <= KW_ROLES)||(LA73_0 >= KW_SCHEDULED && LA73_0 <= KW_SECOND)||(LA73_0 >= KW_SEMI && LA73_0 <= KW_SERVER)||(LA73_0 >= KW_SETS && LA73_0 <= KW_SKEWED)||(LA73_0 >= KW_SNAPSHOT && LA73_0 <= KW_SSL)||(LA73_0 >= KW_STATISTICS && LA73_0 <= KW_SUMMARY)||LA73_0==KW_TABLES||(LA73_0 >= KW_TBLPROPERTIES && LA73_0 <= KW_TERMINATED)||LA73_0==KW_TINYINT||(LA73_0 >= KW_TOUCH && LA73_0 <= KW_TRANSACTIONS)||LA73_0==KW_UNARCHIVE||LA73_0==KW_UNDO||LA73_0==KW_UNIONTYPE||(LA73_0 >= KW_UNLOCK && LA73_0 <= KW_UNSIGNED)||(LA73_0 >= KW_URI && LA73_0 <= KW_USE)||(LA73_0 >= KW_UTC && LA73_0 <= KW_VALIDATE)||LA73_0==KW_VALUE_TYPE||(LA73_0 >= KW_VECTORIZATION && LA73_0 <= KW_WEEK)||LA73_0==KW_WHILE||(LA73_0 >= KW_WORK && LA73_0 <= KW_ZONE)||LA73_0==KW_BATCH||LA73_0==KW_DAYOFWEEK||LA73_0==KW_HOLD_DDLTIME||LA73_0==KW_IGNORE||LA73_0==KW_NO_DROP||LA73_0==KW_OFFLINE||LA73_0==KW_PROTECTION||LA73_0==KW_READONLY||LA73_0==KW_TIMESTAMPTZ) ) {
				int LA73_2 = input.LA(2);
				if ( (LA73_2==KW_SET) ) {
					switch ( input.LA(3) ) {
					case KW_DBPROPERTIES:
						{
						alt73=1;
						}
						break;
					case KW_OWNER:
						{
						alt73=2;
						}
						break;
					case KW_LOCATION:
					case KW_MANAGEDLOCATION:
						{
						alt73=3;
						}
						break;
					default:
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 73, 4, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 73, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 73, 0, input);
				throw nvae;
			}

			switch (alt73) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:7: alterDatabaseSuffixProperties
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix5136);
					alterDatabaseSuffixProperties260=alterDatabaseSuffixProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterDatabaseSuffixProperties260.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:7: alterDatabaseSuffixSetOwner
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterDatabaseSuffixSetOwner_in_alterDatabaseStatementSuffix5144);
					alterDatabaseSuffixSetOwner261=alterDatabaseSuffixSetOwner();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterDatabaseSuffixSetOwner261.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1286:7: alterDatabaseSuffixSetLocation
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterDatabaseSuffixSetLocation_in_alterDatabaseStatementSuffix5152);
					alterDatabaseSuffixSetLocation262=alterDatabaseSuffixSetLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterDatabaseSuffixSetLocation262.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterDatabaseStatementSuffix"


	public static class alterDatabaseSuffixProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterDatabaseSuffixProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1289:1: alterDatabaseSuffixProperties : name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) ;
	public final HiveParser.alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties() throws RecognitionException {
		HiveParser.alterDatabaseSuffixProperties_return retval = new HiveParser.alterDatabaseSuffixProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET263=null;
		Token KW_DBPROPERTIES264=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope dbProperties265 =null;

		ASTNode KW_SET263_tree=null;
		ASTNode KW_DBPROPERTIES264_tree=null;
		RewriteRuleTokenStream stream_KW_DBPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_DBPROPERTIES");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_dbProperties=new RewriteRuleSubtreeStream(adaptor,"rule dbProperties");

		 pushMsg("alter database properties statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1292:5: (name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1292:7: name= identifier KW_SET KW_DBPROPERTIES dbProperties
			{
			pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixProperties5181);
			name=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
			KW_SET263=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterDatabaseSuffixProperties5183); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET263);

			KW_DBPROPERTIES264=(Token)match(input,KW_DBPROPERTIES,FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties5185); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES264);

			pushFollow(FOLLOW_dbProperties_in_alterDatabaseSuffixProperties5187);
			dbProperties265=dbProperties();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_dbProperties.add(dbProperties265.getTree());
			// AST REWRITE
			// elements: name, dbProperties
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1293:5: -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1293:8: ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERDATABASE_PROPERTIES, "TOK_ALTERDATABASE_PROPERTIES"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				adaptor.addChild(root_1, stream_dbProperties.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterDatabaseSuffixProperties"


	public static class alterDatabaseSuffixSetOwner_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterDatabaseSuffixSetOwner"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:1: alterDatabaseSuffixSetOwner : dbName= identifier KW_SET KW_OWNER principalName -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName ) ;
	public final HiveParser.alterDatabaseSuffixSetOwner_return alterDatabaseSuffixSetOwner() throws RecognitionException {
		HiveParser.alterDatabaseSuffixSetOwner_return retval = new HiveParser.alterDatabaseSuffixSetOwner_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET266=null;
		Token KW_OWNER267=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope principalName268 =null;

		ASTNode KW_SET266_tree=null;
		ASTNode KW_OWNER267_tree=null;
		RewriteRuleTokenStream stream_KW_OWNER=new RewriteRuleTokenStream(adaptor,"token KW_OWNER");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		 pushMsg("alter database set owner", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1299:5: (dbName= identifier KW_SET KW_OWNER principalName -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1299:7: dbName= identifier KW_SET KW_OWNER principalName
			{
			pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixSetOwner5231);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			KW_SET266=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterDatabaseSuffixSetOwner5233); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET266);

			KW_OWNER267=(Token)match(input,KW_OWNER,FOLLOW_KW_OWNER_in_alterDatabaseSuffixSetOwner5235); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OWNER.add(KW_OWNER267);

			pushFollow(FOLLOW_principalName_in_alterDatabaseSuffixSetOwner5237);
			principalName268=principalName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalName.add(principalName268.getTree());
			// AST REWRITE
			// elements: principalName, dbName
			// token labels: 
			// rule labels: dbName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1300:5: -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:8: ^( TOK_ALTERDATABASE_OWNER $dbName principalName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERDATABASE_OWNER, "TOK_ALTERDATABASE_OWNER"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				adaptor.addChild(root_1, stream_principalName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterDatabaseSuffixSetOwner"


	public static class alterDatabaseSuffixSetLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterDatabaseSuffixSetLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1303:1: alterDatabaseSuffixSetLocation : (dbName= identifier KW_SET KW_LOCATION newLocation= StringLiteral -> ^( TOK_ALTERDATABASE_LOCATION $dbName $newLocation) |dbName= identifier KW_SET KW_MANAGEDLOCATION newLocation= StringLiteral -> ^( TOK_ALTERDATABASE_MANAGEDLOCATION $dbName $newLocation) );
	public final HiveParser.alterDatabaseSuffixSetLocation_return alterDatabaseSuffixSetLocation() throws RecognitionException {
		HiveParser.alterDatabaseSuffixSetLocation_return retval = new HiveParser.alterDatabaseSuffixSetLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token newLocation=null;
		Token KW_SET269=null;
		Token KW_LOCATION270=null;
		Token KW_SET271=null;
		Token KW_MANAGEDLOCATION272=null;
		ParserRuleReturnScope dbName =null;

		ASTNode newLocation_tree=null;
		ASTNode KW_SET269_tree=null;
		ASTNode KW_LOCATION270_tree=null;
		ASTNode KW_SET271_tree=null;
		ASTNode KW_MANAGEDLOCATION272_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");
		RewriteRuleTokenStream stream_KW_MANAGEDLOCATION=new RewriteRuleTokenStream(adaptor,"token KW_MANAGEDLOCATION");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("alter database set location", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1306:5: (dbName= identifier KW_SET KW_LOCATION newLocation= StringLiteral -> ^( TOK_ALTERDATABASE_LOCATION $dbName $newLocation) |dbName= identifier KW_SET KW_MANAGEDLOCATION newLocation= StringLiteral -> ^( TOK_ALTERDATABASE_MANAGEDLOCATION $dbName $newLocation) )
			int alt74=2;
			int LA74_0 = input.LA(1);
			if ( (LA74_0==Identifier) ) {
				int LA74_1 = input.LA(2);
				if ( (LA74_1==KW_SET) ) {
					int LA74_3 = input.LA(3);
					if ( (LA74_3==KW_LOCATION) ) {
						alt74=1;
					}
					else if ( (LA74_3==KW_MANAGEDLOCATION) ) {
						alt74=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 74, 3, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 74, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( ((LA74_0 >= KW_ABORT && LA74_0 <= KW_AFTER)||LA74_0==KW_ALLOC_FRACTION||LA74_0==KW_ANALYZE||LA74_0==KW_ARCHIVE||(LA74_0 >= KW_ASC && LA74_0 <= KW_AT)||(LA74_0 >= KW_AUTOCOMMIT && LA74_0 <= KW_BEFORE)||(LA74_0 >= KW_BUCKET && LA74_0 <= KW_BUCKETS)||(LA74_0 >= KW_CACHE && LA74_0 <= KW_CASCADE)||(LA74_0 >= KW_CBO && LA74_0 <= KW_CHANGE)||(LA74_0 >= KW_CHECK && LA74_0 <= KW_COLLECTION)||(LA74_0 >= KW_COLUMNS && LA74_0 <= KW_COMMENT)||(LA74_0 >= KW_COMPACT && LA74_0 <= KW_CONCATENATE)||(LA74_0 >= KW_CONTINUE && LA74_0 <= KW_COST)||LA74_0==KW_CRON||LA74_0==KW_DATA||LA74_0==KW_DATABASES||(LA74_0 >= KW_DATETIME && LA74_0 <= KW_DEBUG)||(LA74_0 >= KW_DEFAULT && LA74_0 <= KW_DEFINED)||(LA74_0 >= KW_DELIMITED && LA74_0 <= KW_DESC)||(LA74_0 >= KW_DETAIL && LA74_0 <= KW_DISABLE)||(LA74_0 >= KW_DISTRIBUTE && LA74_0 <= KW_DO)||LA74_0==KW_DOW||(LA74_0 >= KW_DUMP && LA74_0 <= KW_ELEM_TYPE)||LA74_0==KW_ENABLE||(LA74_0 >= KW_ENFORCED && LA74_0 <= KW_EVERY)||(LA74_0 >= KW_EXCLUSIVE && LA74_0 <= KW_EXECUTED)||(LA74_0 >= KW_EXPLAIN && LA74_0 <= KW_EXPRESSION)||(LA74_0 >= KW_FIELDS && LA74_0 <= KW_FIRST)||(LA74_0 >= KW_FORMAT && LA74_0 <= KW_FORMATTED)||LA74_0==KW_FUNCTIONS||(LA74_0 >= KW_HOUR && LA74_0 <= KW_IDXPROPERTIES)||(LA74_0 >= KW_INDEX && LA74_0 <= KW_INDEXES)||(LA74_0 >= KW_INPATH && LA74_0 <= KW_INPUTFORMAT)||(LA74_0 >= KW_ISOLATION && LA74_0 <= KW_JAR)||(LA74_0 >= KW_JOINCOST && LA74_0 <= KW_LAST)||LA74_0==KW_LEVEL||(LA74_0 >= KW_LIMIT && LA74_0 <= KW_LOAD)||(LA74_0 >= KW_LOCATION && LA74_0 <= KW_LONG)||(LA74_0 >= KW_MANAGEDLOCATION && LA74_0 <= KW_MANAGEMENT)||(LA74_0 >= KW_MAPJOIN && LA74_0 <= KW_MATERIALIZED)||LA74_0==KW_METADATA||(LA74_0 >= KW_MINUTE && LA74_0 <= KW_MONTH)||(LA74_0 >= KW_MOVE && LA74_0 <= KW_MSCK)||(LA74_0 >= KW_NORELY && LA74_0 <= KW_NOSCAN)||LA74_0==KW_NOVALIDATE||LA74_0==KW_NULLS||LA74_0==KW_OFFSET||(LA74_0 >= KW_OPERATOR && LA74_0 <= KW_OPTION)||(LA74_0 >= KW_OUTPUTDRIVER && LA74_0 <= KW_OUTPUTFORMAT)||(LA74_0 >= KW_OVERWRITE && LA74_0 <= KW_OWNER)||(LA74_0 >= KW_PARTITIONED && LA74_0 <= KW_PATH)||(LA74_0 >= KW_PLAN && LA74_0 <= KW_POOL)||LA74_0==KW_PRINCIPALS||(LA74_0 >= KW_PURGE && LA74_0 <= KW_QUERY_PARALLELISM)||LA74_0==KW_READ||(LA74_0 >= KW_REBUILD && LA74_0 <= KW_RECORDWRITER)||(LA74_0 >= KW_RELOAD && LA74_0 <= KW_RESTRICT)||LA74_0==KW_REWRITE||(LA74_0 >= KW_ROLE && LA74_0 <= KW_ROLES)||(LA74_0 >= KW_SCHEDULED && LA74_0 <= KW_SECOND)||(LA74_0 >= KW_SEMI && LA74_0 <= KW_SERVER)||(LA74_0 >= KW_SETS && LA74_0 <= KW_SKEWED)||(LA74_0 >= KW_SNAPSHOT && LA74_0 <= KW_SSL)||(LA74_0 >= KW_STATISTICS && LA74_0 <= KW_SUMMARY)||LA74_0==KW_TABLES||(LA74_0 >= KW_TBLPROPERTIES && LA74_0 <= KW_TERMINATED)||LA74_0==KW_TINYINT||(LA74_0 >= KW_TOUCH && LA74_0 <= KW_TRANSACTIONS)||LA74_0==KW_UNARCHIVE||LA74_0==KW_UNDO||LA74_0==KW_UNIONTYPE||(LA74_0 >= KW_UNLOCK && LA74_0 <= KW_UNSIGNED)||(LA74_0 >= KW_URI && LA74_0 <= KW_USE)||(LA74_0 >= KW_UTC && LA74_0 <= KW_VALIDATE)||LA74_0==KW_VALUE_TYPE||(LA74_0 >= KW_VECTORIZATION && LA74_0 <= KW_WEEK)||LA74_0==KW_WHILE||(LA74_0 >= KW_WORK && LA74_0 <= KW_ZONE)||LA74_0==KW_BATCH||LA74_0==KW_DAYOFWEEK||LA74_0==KW_HOLD_DDLTIME||LA74_0==KW_IGNORE||LA74_0==KW_NO_DROP||LA74_0==KW_OFFLINE||LA74_0==KW_PROTECTION||LA74_0==KW_READONLY||LA74_0==KW_TIMESTAMPTZ) ) {
				int LA74_2 = input.LA(2);
				if ( (LA74_2==KW_SET) ) {
					int LA74_4 = input.LA(3);
					if ( (LA74_4==KW_LOCATION) ) {
						alt74=1;
					}
					else if ( (LA74_4==KW_MANAGEDLOCATION) ) {
						alt74=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 74, 4, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 74, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 74, 0, input);
				throw nvae;
			}

			switch (alt74) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1306:7: dbName= identifier KW_SET KW_LOCATION newLocation= StringLiteral
					{
					pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixSetLocation5281);
					dbName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
					KW_SET269=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterDatabaseSuffixSetLocation5283); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET269);

					KW_LOCATION270=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_alterDatabaseSuffixSetLocation5285); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION270);

					newLocation=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterDatabaseSuffixSetLocation5289); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(newLocation);

					// AST REWRITE
					// elements: newLocation, dbName
					// token labels: newLocation
					// rule labels: dbName, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_newLocation=new RewriteRuleTokenStream(adaptor,"token newLocation",newLocation);
					RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1307:5: -> ^( TOK_ALTERDATABASE_LOCATION $dbName $newLocation)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:8: ^( TOK_ALTERDATABASE_LOCATION $dbName $newLocation)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERDATABASE_LOCATION, "TOK_ALTERDATABASE_LOCATION"), root_1);
						adaptor.addChild(root_1, stream_dbName.nextTree());
						adaptor.addChild(root_1, stream_newLocation.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1308:7: dbName= identifier KW_SET KW_MANAGEDLOCATION newLocation= StringLiteral
					{
					pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixSetLocation5315);
					dbName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
					KW_SET271=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterDatabaseSuffixSetLocation5317); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET271);

					KW_MANAGEDLOCATION272=(Token)match(input,KW_MANAGEDLOCATION,FOLLOW_KW_MANAGEDLOCATION_in_alterDatabaseSuffixSetLocation5319); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MANAGEDLOCATION.add(KW_MANAGEDLOCATION272);

					newLocation=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterDatabaseSuffixSetLocation5323); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(newLocation);

					// AST REWRITE
					// elements: newLocation, dbName
					// token labels: newLocation
					// rule labels: dbName, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_newLocation=new RewriteRuleTokenStream(adaptor,"token newLocation",newLocation);
					RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1309:5: -> ^( TOK_ALTERDATABASE_MANAGEDLOCATION $dbName $newLocation)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1309:8: ^( TOK_ALTERDATABASE_MANAGEDLOCATION $dbName $newLocation)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERDATABASE_MANAGEDLOCATION, "TOK_ALTERDATABASE_MANAGEDLOCATION"), root_1);
						adaptor.addChild(root_1, stream_dbName.nextTree());
						adaptor.addChild(root_1, stream_newLocation.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterDatabaseSuffixSetLocation"


	public static class alterDatabaseSuffixSetManagedLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterDatabaseSuffixSetManagedLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1312:1: alterDatabaseSuffixSetManagedLocation : dbName= identifier KW_SET KW_MANAGEDLOCATION newLocation= StringLiteral -> ^( TOK_ALTERDATABASE_MANAGEDLOCATION $dbName $newLocation) ;
	public final HiveParser.alterDatabaseSuffixSetManagedLocation_return alterDatabaseSuffixSetManagedLocation() throws RecognitionException {
		HiveParser.alterDatabaseSuffixSetManagedLocation_return retval = new HiveParser.alterDatabaseSuffixSetManagedLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token newLocation=null;
		Token KW_SET273=null;
		Token KW_MANAGEDLOCATION274=null;
		ParserRuleReturnScope dbName =null;

		ASTNode newLocation_tree=null;
		ASTNode KW_SET273_tree=null;
		ASTNode KW_MANAGEDLOCATION274_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_MANAGEDLOCATION=new RewriteRuleTokenStream(adaptor,"token KW_MANAGEDLOCATION");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("alter database set managed location", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1315:5: (dbName= identifier KW_SET KW_MANAGEDLOCATION newLocation= StringLiteral -> ^( TOK_ALTERDATABASE_MANAGEDLOCATION $dbName $newLocation) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1315:7: dbName= identifier KW_SET KW_MANAGEDLOCATION newLocation= StringLiteral
			{
			pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixSetManagedLocation5368);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			KW_SET273=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterDatabaseSuffixSetManagedLocation5370); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET273);

			KW_MANAGEDLOCATION274=(Token)match(input,KW_MANAGEDLOCATION,FOLLOW_KW_MANAGEDLOCATION_in_alterDatabaseSuffixSetManagedLocation5372); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MANAGEDLOCATION.add(KW_MANAGEDLOCATION274);

			newLocation=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterDatabaseSuffixSetManagedLocation5376); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(newLocation);

			// AST REWRITE
			// elements: dbName, newLocation
			// token labels: newLocation
			// rule labels: dbName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_newLocation=new RewriteRuleTokenStream(adaptor,"token newLocation",newLocation);
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1316:5: -> ^( TOK_ALTERDATABASE_MANAGEDLOCATION $dbName $newLocation)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:8: ^( TOK_ALTERDATABASE_MANAGEDLOCATION $dbName $newLocation)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERDATABASE_MANAGEDLOCATION, "TOK_ALTERDATABASE_MANAGEDLOCATION"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				adaptor.addChild(root_1, stream_newLocation.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterDatabaseSuffixSetManagedLocation"


	public static class alterStatementSuffixRename_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixRename"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:1: alterStatementSuffixRename[boolean table] : KW_RENAME KW_TO tableName -> { table }? ^( TOK_ALTERTABLE_RENAME tableName ) -> ^( TOK_ALTERVIEW_RENAME tableName ) ;
	public final HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename(boolean table) throws RecognitionException {
		HiveParser.alterStatementSuffixRename_return retval = new HiveParser.alterStatementSuffixRename_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RENAME275=null;
		Token KW_TO276=null;
		ParserRuleReturnScope tableName277 =null;

		ASTNode KW_RENAME275_tree=null;
		ASTNode KW_TO276_tree=null;
		RewriteRuleTokenStream stream_KW_RENAME=new RewriteRuleTokenStream(adaptor,"token KW_RENAME");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("rename statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1322:5: ( KW_RENAME KW_TO tableName -> { table }? ^( TOK_ALTERTABLE_RENAME tableName ) -> ^( TOK_ALTERVIEW_RENAME tableName ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1322:7: KW_RENAME KW_TO tableName
			{
			KW_RENAME275=(Token)match(input,KW_RENAME,FOLLOW_KW_RENAME_in_alterStatementSuffixRename5420); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_RENAME.add(KW_RENAME275);

			KW_TO276=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_alterStatementSuffixRename5422); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO276);

			pushFollow(FOLLOW_tableName_in_alterStatementSuffixRename5424);
			tableName277=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName277.getTree());
			// AST REWRITE
			// elements: tableName, tableName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1323:5: -> { table }? ^( TOK_ALTERTABLE_RENAME tableName )
			if ( table ) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:19: ^( TOK_ALTERTABLE_RENAME tableName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_RENAME, "TOK_ALTERTABLE_RENAME"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1324:5: -> ^( TOK_ALTERVIEW_RENAME tableName )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:19: ^( TOK_ALTERVIEW_RENAME tableName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW_RENAME, "TOK_ALTERVIEW_RENAME"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixRename"


	public static class alterStatementSuffixAddCol_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixAddCol"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:1: alterStatementSuffixAddCol : (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )? -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? ) -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? ) ;
	public final HiveParser.alterStatementSuffixAddCol_return alterStatementSuffixAddCol() throws RecognitionException {
		HiveParser.alterStatementSuffixAddCol_return retval = new HiveParser.alterStatementSuffixAddCol_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token add=null;
		Token replace=null;
		Token KW_COLUMNS278=null;
		Token LPAREN279=null;
		Token RPAREN281=null;
		ParserRuleReturnScope columnNameTypeList280 =null;
		ParserRuleReturnScope restrictOrCascade282 =null;

		ASTNode add_tree=null;
		ASTNode replace_tree=null;
		ASTNode KW_COLUMNS278_tree=null;
		ASTNode LPAREN279_tree=null;
		ASTNode RPAREN281_tree=null;
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
		RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
		RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");
		RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");

		 pushMsg("add column statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:5: ( (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )? -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? ) -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:7: (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:7: (add= KW_ADD |replace= KW_REPLACE )
			int alt75=2;
			int LA75_0 = input.LA(1);
			if ( (LA75_0==KW_ADD) ) {
				alt75=1;
			}
			else if ( (LA75_0==KW_REPLACE) ) {
				alt75=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 75, 0, input);
				throw nvae;
			}

			switch (alt75) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:8: add= KW_ADD
					{
					add=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_alterStatementSuffixAddCol5491); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ADD.add(add);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:21: replace= KW_REPLACE
					{
					replace=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol5497); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REPLACE.add(replace);

					}
					break;

			}

			KW_COLUMNS278=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol5500); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS278);

			LPAREN279=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_alterStatementSuffixAddCol5502); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN279);

			pushFollow(FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol5504);
			columnNameTypeList280=columnNameTypeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameTypeList.add(columnNameTypeList280.getTree());
			RPAREN281=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_alterStatementSuffixAddCol5506); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN281);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:85: ( restrictOrCascade )?
			int alt76=2;
			int LA76_0 = input.LA(1);
			if ( (LA76_0==KW_CASCADE||LA76_0==KW_RESTRICT) ) {
				alt76=1;
			}
			switch (alt76) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:85: restrictOrCascade
					{
					pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixAddCol5508);
					restrictOrCascade282=restrictOrCascade();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade282.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: restrictOrCascade, columnNameTypeList, columnNameTypeList, restrictOrCascade
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1331:5: -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? )
			if (add != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1331:24: ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_ADDCOLS, "TOK_ALTERTABLE_ADDCOLS"), root_1);
				adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1331:68: ( restrictOrCascade )?
				if ( stream_restrictOrCascade.hasNext() ) {
					adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
				}
				stream_restrictOrCascade.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1332:5: -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:24: ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_REPLACECOLS, "TOK_ALTERTABLE_REPLACECOLS"), root_1);
				adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:72: ( restrictOrCascade )?
				if ( stream_restrictOrCascade.hasNext() ) {
					adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
				}
				stream_restrictOrCascade.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixAddCol"


	public static class alterStatementSuffixAddConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixAddConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:1: alterStatementSuffixAddConstraint : KW_ADD (fk= alterForeignKeyWithName | alterConstraintWithName ) -> {fk != null}? ^( TOK_ALTERTABLE_ADDCONSTRAINT alterForeignKeyWithName ) -> ^( TOK_ALTERTABLE_ADDCONSTRAINT alterConstraintWithName ) ;
	public final HiveParser.alterStatementSuffixAddConstraint_return alterStatementSuffixAddConstraint() throws RecognitionException {
		HiveParser.alterStatementSuffixAddConstraint_return retval = new HiveParser.alterStatementSuffixAddConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ADD283=null;
		ParserRuleReturnScope fk =null;
		ParserRuleReturnScope alterConstraintWithName284 =null;

		ASTNode KW_ADD283_tree=null;
		RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
		RewriteRuleSubtreeStream stream_alterForeignKeyWithName=new RewriteRuleSubtreeStream(adaptor,"rule alterForeignKeyWithName");
		RewriteRuleSubtreeStream stream_alterConstraintWithName=new RewriteRuleSubtreeStream(adaptor,"rule alterConstraintWithName");

		 pushMsg("add constraint statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:4: ( KW_ADD (fk= alterForeignKeyWithName | alterConstraintWithName ) -> {fk != null}? ^( TOK_ALTERTABLE_ADDCONSTRAINT alterForeignKeyWithName ) -> ^( TOK_ALTERTABLE_ADDCONSTRAINT alterConstraintWithName ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:7: KW_ADD (fk= alterForeignKeyWithName | alterConstraintWithName )
			{
			KW_ADD283=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_alterStatementSuffixAddConstraint5584); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ADD.add(KW_ADD283);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:14: (fk= alterForeignKeyWithName | alterConstraintWithName )
			int alt77=2;
			int LA77_0 = input.LA(1);
			if ( (LA77_0==KW_CONSTRAINT) ) {
				int LA77_1 = input.LA(2);
				if ( (LA77_1==Identifier) ) {
					int LA77_2 = input.LA(3);
					if ( (LA77_2==KW_FOREIGN) ) {
						alt77=1;
					}
					else if ( (LA77_2==KW_CHECK||LA77_2==KW_PRIMARY||LA77_2==KW_UNIQUE) ) {
						alt77=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 77, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( ((LA77_1 >= KW_ABORT && LA77_1 <= KW_AFTER)||LA77_1==KW_ALLOC_FRACTION||LA77_1==KW_ANALYZE||LA77_1==KW_ARCHIVE||(LA77_1 >= KW_ASC && LA77_1 <= KW_AT)||(LA77_1 >= KW_AUTOCOMMIT && LA77_1 <= KW_BEFORE)||(LA77_1 >= KW_BUCKET && LA77_1 <= KW_BUCKETS)||(LA77_1 >= KW_CACHE && LA77_1 <= KW_CASCADE)||(LA77_1 >= KW_CBO && LA77_1 <= KW_CHANGE)||(LA77_1 >= KW_CHECK && LA77_1 <= KW_COLLECTION)||(LA77_1 >= KW_COLUMNS && LA77_1 <= KW_COMMENT)||(LA77_1 >= KW_COMPACT && LA77_1 <= KW_CONCATENATE)||(LA77_1 >= KW_CONTINUE && LA77_1 <= KW_COST)||LA77_1==KW_CRON||LA77_1==KW_DATA||LA77_1==KW_DATABASES||(LA77_1 >= KW_DATETIME && LA77_1 <= KW_DEBUG)||(LA77_1 >= KW_DEFAULT && LA77_1 <= KW_DEFINED)||(LA77_1 >= KW_DELIMITED && LA77_1 <= KW_DESC)||(LA77_1 >= KW_DETAIL && LA77_1 <= KW_DISABLE)||(LA77_1 >= KW_DISTRIBUTE && LA77_1 <= KW_DO)||LA77_1==KW_DOW||(LA77_1 >= KW_DUMP && LA77_1 <= KW_ELEM_TYPE)||LA77_1==KW_ENABLE||(LA77_1 >= KW_ENFORCED && LA77_1 <= KW_EVERY)||(LA77_1 >= KW_EXCLUSIVE && LA77_1 <= KW_EXECUTED)||(LA77_1 >= KW_EXPLAIN && LA77_1 <= KW_EXPRESSION)||(LA77_1 >= KW_FIELDS && LA77_1 <= KW_FIRST)||(LA77_1 >= KW_FORMAT && LA77_1 <= KW_FORMATTED)||LA77_1==KW_FUNCTIONS||(LA77_1 >= KW_HOUR && LA77_1 <= KW_IDXPROPERTIES)||(LA77_1 >= KW_INDEX && LA77_1 <= KW_INDEXES)||(LA77_1 >= KW_INPATH && LA77_1 <= KW_INPUTFORMAT)||(LA77_1 >= KW_ISOLATION && LA77_1 <= KW_JAR)||(LA77_1 >= KW_JOINCOST && LA77_1 <= KW_LAST)||LA77_1==KW_LEVEL||(LA77_1 >= KW_LIMIT && LA77_1 <= KW_LOAD)||(LA77_1 >= KW_LOCATION && LA77_1 <= KW_LONG)||(LA77_1 >= KW_MANAGEDLOCATION && LA77_1 <= KW_MANAGEMENT)||(LA77_1 >= KW_MAPJOIN && LA77_1 <= KW_MATERIALIZED)||LA77_1==KW_METADATA||(LA77_1 >= KW_MINUTE && LA77_1 <= KW_MONTH)||(LA77_1 >= KW_MOVE && LA77_1 <= KW_MSCK)||(LA77_1 >= KW_NORELY && LA77_1 <= KW_NOSCAN)||LA77_1==KW_NOVALIDATE||LA77_1==KW_NULLS||LA77_1==KW_OFFSET||(LA77_1 >= KW_OPERATOR && LA77_1 <= KW_OPTION)||(LA77_1 >= KW_OUTPUTDRIVER && LA77_1 <= KW_OUTPUTFORMAT)||(LA77_1 >= KW_OVERWRITE && LA77_1 <= KW_OWNER)||(LA77_1 >= KW_PARTITIONED && LA77_1 <= KW_PATH)||(LA77_1 >= KW_PLAN && LA77_1 <= KW_POOL)||LA77_1==KW_PRINCIPALS||(LA77_1 >= KW_PURGE && LA77_1 <= KW_QUERY_PARALLELISM)||LA77_1==KW_READ||(LA77_1 >= KW_REBUILD && LA77_1 <= KW_RECORDWRITER)||(LA77_1 >= KW_RELOAD && LA77_1 <= KW_RESTRICT)||LA77_1==KW_REWRITE||(LA77_1 >= KW_ROLE && LA77_1 <= KW_ROLES)||(LA77_1 >= KW_SCHEDULED && LA77_1 <= KW_SECOND)||(LA77_1 >= KW_SEMI && LA77_1 <= KW_SERVER)||(LA77_1 >= KW_SETS && LA77_1 <= KW_SKEWED)||(LA77_1 >= KW_SNAPSHOT && LA77_1 <= KW_SSL)||(LA77_1 >= KW_STATISTICS && LA77_1 <= KW_SUMMARY)||LA77_1==KW_TABLES||(LA77_1 >= KW_TBLPROPERTIES && LA77_1 <= KW_TERMINATED)||LA77_1==KW_TINYINT||(LA77_1 >= KW_TOUCH && LA77_1 <= KW_TRANSACTIONS)||LA77_1==KW_UNARCHIVE||LA77_1==KW_UNDO||LA77_1==KW_UNIONTYPE||(LA77_1 >= KW_UNLOCK && LA77_1 <= KW_UNSIGNED)||(LA77_1 >= KW_URI && LA77_1 <= KW_USE)||(LA77_1 >= KW_UTC && LA77_1 <= KW_VALIDATE)||LA77_1==KW_VALUE_TYPE||(LA77_1 >= KW_VECTORIZATION && LA77_1 <= KW_WEEK)||LA77_1==KW_WHILE||(LA77_1 >= KW_WORK && LA77_1 <= KW_ZONE)||LA77_1==KW_BATCH||LA77_1==KW_DAYOFWEEK||LA77_1==KW_HOLD_DDLTIME||LA77_1==KW_IGNORE||LA77_1==KW_NO_DROP||LA77_1==KW_OFFLINE||LA77_1==KW_PROTECTION||LA77_1==KW_READONLY||LA77_1==KW_TIMESTAMPTZ) ) {
					int LA77_3 = input.LA(3);
					if ( (LA77_3==KW_FOREIGN) ) {
						alt77=1;
					}
					else if ( (LA77_3==KW_CHECK||LA77_3==KW_PRIMARY||LA77_3==KW_UNIQUE) ) {
						alt77=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 77, 3, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 77, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 77, 0, input);
				throw nvae;
			}

			switch (alt77) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:15: fk= alterForeignKeyWithName
					{
					pushFollow(FOLLOW_alterForeignKeyWithName_in_alterStatementSuffixAddConstraint5589);
					fk=alterForeignKeyWithName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterForeignKeyWithName.add(fk.getTree());
					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:44: alterConstraintWithName
					{
					pushFollow(FOLLOW_alterConstraintWithName_in_alterStatementSuffixAddConstraint5593);
					alterConstraintWithName284=alterConstraintWithName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterConstraintWithName.add(alterConstraintWithName284.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: alterConstraintWithName, alterForeignKeyWithName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1339:4: -> {fk != null}? ^( TOK_ALTERTABLE_ADDCONSTRAINT alterForeignKeyWithName )
			if (fk != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1339:21: ^( TOK_ALTERTABLE_ADDCONSTRAINT alterForeignKeyWithName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_ADDCONSTRAINT, "TOK_ALTERTABLE_ADDCONSTRAINT"), root_1);
				adaptor.addChild(root_1, stream_alterForeignKeyWithName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1340:4: -> ^( TOK_ALTERTABLE_ADDCONSTRAINT alterConstraintWithName )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:21: ^( TOK_ALTERTABLE_ADDCONSTRAINT alterConstraintWithName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_ADDCONSTRAINT, "TOK_ALTERTABLE_ADDCONSTRAINT"), root_1);
				adaptor.addChild(root_1, stream_alterConstraintWithName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixAddConstraint"


	public static class alterStatementSuffixUpdateColumns_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixUpdateColumns"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:1: alterStatementSuffixUpdateColumns : KW_UPDATE KW_COLUMNS ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_UPDATECOLUMNS ( restrictOrCascade )? ) ;
	public final HiveParser.alterStatementSuffixUpdateColumns_return alterStatementSuffixUpdateColumns() throws RecognitionException {
		HiveParser.alterStatementSuffixUpdateColumns_return retval = new HiveParser.alterStatementSuffixUpdateColumns_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UPDATE285=null;
		Token KW_COLUMNS286=null;
		ParserRuleReturnScope restrictOrCascade287 =null;

		ASTNode KW_UPDATE285_tree=null;
		ASTNode KW_COLUMNS286_tree=null;
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");

		 pushMsg("update columns statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:5: ( KW_UPDATE KW_COLUMNS ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_UPDATECOLUMNS ( restrictOrCascade )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:7: KW_UPDATE KW_COLUMNS ( restrictOrCascade )?
			{
			KW_UPDATE285=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateColumns5658); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE285);

			KW_COLUMNS286=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_alterStatementSuffixUpdateColumns5660); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS286);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:28: ( restrictOrCascade )?
			int alt78=2;
			int LA78_0 = input.LA(1);
			if ( (LA78_0==KW_CASCADE||LA78_0==KW_RESTRICT) ) {
				alt78=1;
			}
			switch (alt78) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:28: restrictOrCascade
					{
					pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixUpdateColumns5662);
					restrictOrCascade287=restrictOrCascade();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade287.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: restrictOrCascade
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1347:5: -> ^( TOK_ALTERTABLE_UPDATECOLUMNS ( restrictOrCascade )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1347:8: ^( TOK_ALTERTABLE_UPDATECOLUMNS ( restrictOrCascade )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_UPDATECOLUMNS, "TOK_ALTERTABLE_UPDATECOLUMNS"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1347:39: ( restrictOrCascade )?
				if ( stream_restrictOrCascade.hasNext() ) {
					adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
				}
				stream_restrictOrCascade.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixUpdateColumns"


	public static class alterStatementSuffixDropConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixDropConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:1: alterStatementSuffixDropConstraint : KW_DROP KW_CONSTRAINT cName= identifier -> ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName) ;
	public final HiveParser.alterStatementSuffixDropConstraint_return alterStatementSuffixDropConstraint() throws RecognitionException {
		HiveParser.alterStatementSuffixDropConstraint_return retval = new HiveParser.alterStatementSuffixDropConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP288=null;
		Token KW_CONSTRAINT289=null;
		ParserRuleReturnScope cName =null;

		ASTNode KW_DROP288_tree=null;
		ASTNode KW_CONSTRAINT289_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("drop constraint statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:4: ( KW_DROP KW_CONSTRAINT cName= identifier -> ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:6: KW_DROP KW_CONSTRAINT cName= identifier
			{
			KW_DROP288=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_alterStatementSuffixDropConstraint5702); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP288);

			KW_CONSTRAINT289=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterStatementSuffixDropConstraint5704); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT289);

			pushFollow(FOLLOW_identifier_in_alterStatementSuffixDropConstraint5708);
			cName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(cName.getTree());
			// AST REWRITE
			// elements: cName
			// token labels: 
			// rule labels: cName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_cName=new RewriteRuleSubtreeStream(adaptor,"rule cName",cName!=null?cName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1354:4: -> ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1354:6: ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_DROPCONSTRAINT, "TOK_ALTERTABLE_DROPCONSTRAINT"), root_1);
				adaptor.addChild(root_1, stream_cName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixDropConstraint"


	public static class alterStatementSuffixRenameCol_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixRenameCol"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1357:1: alterStatementSuffixRenameCol : KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( alterColumnConstraint[$newName.tree] )? ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterColumnConstraint )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? ) ;
	public final HiveParser.alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol() throws RecognitionException {
		HiveParser.alterStatementSuffixRenameCol_return retval = new HiveParser.alterStatementSuffixRenameCol_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_CHANGE290=null;
		Token KW_COLUMN291=null;
		Token KW_COMMENT294=null;
		ParserRuleReturnScope oldName =null;
		ParserRuleReturnScope newName =null;
		ParserRuleReturnScope colType292 =null;
		ParserRuleReturnScope alterColumnConstraint293 =null;
		ParserRuleReturnScope alterStatementChangeColPosition295 =null;
		ParserRuleReturnScope restrictOrCascade296 =null;

		ASTNode comment_tree=null;
		ASTNode KW_CHANGE290_tree=null;
		ASTNode KW_COLUMN291_tree=null;
		ASTNode KW_COMMENT294_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
		RewriteRuleTokenStream stream_KW_CHANGE=new RewriteRuleTokenStream(adaptor,"token KW_CHANGE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");
		RewriteRuleSubtreeStream stream_alterStatementChangeColPosition=new RewriteRuleSubtreeStream(adaptor,"rule alterStatementChangeColPosition");
		RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");
		RewriteRuleSubtreeStream stream_alterColumnConstraint=new RewriteRuleSubtreeStream(adaptor,"rule alterColumnConstraint");

		 pushMsg("rename column name", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:5: ( KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( alterColumnConstraint[$newName.tree] )? ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterColumnConstraint )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:7: KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( alterColumnConstraint[$newName.tree] )? ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )?
			{
			KW_CHANGE290=(Token)match(input,KW_CHANGE,FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol5745); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CHANGE.add(KW_CHANGE290);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:17: ( KW_COLUMN )?
			int alt79=2;
			int LA79_0 = input.LA(1);
			if ( (LA79_0==KW_COLUMN) ) {
				alt79=1;
			}
			switch (alt79) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:17: KW_COLUMN
					{
					KW_COLUMN291=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol5747); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN291);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol5752);
			oldName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(oldName.getTree());
			pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol5756);
			newName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(newName.getTree());
			pushFollow(FOLLOW_colType_in_alterStatementSuffixRenameCol5758);
			colType292=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType292.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:74: ( alterColumnConstraint[$newName.tree] )?
			int alt80=2;
			int LA80_0 = input.LA(1);
			if ( (LA80_0==KW_CHECK||LA80_0==KW_CONSTRAINT||LA80_0==KW_DEFAULT||LA80_0==KW_NOT||LA80_0==KW_PRIMARY||LA80_0==KW_REFERENCES||LA80_0==KW_UNIQUE) ) {
				alt80=1;
			}
			switch (alt80) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:74: alterColumnConstraint[$newName.tree]
					{
					pushFollow(FOLLOW_alterColumnConstraint_in_alterStatementSuffixRenameCol5760);
					alterColumnConstraint293=alterColumnConstraint((newName!=null?((ASTNode)newName.getTree()):null));
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterColumnConstraint.add(alterColumnConstraint293.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:112: ( KW_COMMENT comment= StringLiteral )?
			int alt81=2;
			int LA81_0 = input.LA(1);
			if ( (LA81_0==KW_COMMENT) ) {
				alt81=1;
			}
			switch (alt81) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:113: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT294=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol5765); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT294);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol5769); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:148: ( alterStatementChangeColPosition )?
			int alt82=2;
			int LA82_0 = input.LA(1);
			if ( (LA82_0==KW_AFTER||LA82_0==KW_FIRST) ) {
				alt82=1;
			}
			switch (alt82) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:148: alterStatementChangeColPosition
					{
					pushFollow(FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol5773);
					alterStatementChangeColPosition295=alterStatementChangeColPosition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterStatementChangeColPosition.add(alterStatementChangeColPosition295.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:181: ( restrictOrCascade )?
			int alt83=2;
			int LA83_0 = input.LA(1);
			if ( (LA83_0==KW_CASCADE||LA83_0==KW_RESTRICT) ) {
				alt83=1;
			}
			switch (alt83) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:181: restrictOrCascade
					{
					pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixRenameCol5776);
					restrictOrCascade296=restrictOrCascade();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade296.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: comment, alterStatementChangeColPosition, oldName, restrictOrCascade, colType, alterColumnConstraint, newName
			// token labels: comment
			// rule labels: newName, oldName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_newName=new RewriteRuleSubtreeStream(adaptor,"rule newName",newName!=null?newName.getTree():null);
			RewriteRuleSubtreeStream stream_oldName=new RewriteRuleSubtreeStream(adaptor,"rule oldName",oldName!=null?oldName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1361:5: -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterColumnConstraint )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:7: ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterColumnConstraint )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_RENAMECOL, "TOK_ALTERTABLE_RENAMECOL"), root_1);
				adaptor.addChild(root_1, stream_oldName.nextTree());
				adaptor.addChild(root_1, stream_newName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:61: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:70: ( alterColumnConstraint )?
				if ( stream_alterColumnConstraint.hasNext() ) {
					adaptor.addChild(root_1, stream_alterColumnConstraint.nextTree());
				}
				stream_alterColumnConstraint.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:93: ( alterStatementChangeColPosition )?
				if ( stream_alterStatementChangeColPosition.hasNext() ) {
					adaptor.addChild(root_1, stream_alterStatementChangeColPosition.nextTree());
				}
				stream_alterStatementChangeColPosition.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:126: ( restrictOrCascade )?
				if ( stream_restrictOrCascade.hasNext() ) {
					adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
				}
				stream_restrictOrCascade.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixRenameCol"


	public static class alterStatementSuffixUpdateStatsCol_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixUpdateStatsCol"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1364:1: alterStatementSuffixUpdateStatsCol[boolean partition] : KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> {partition}? ^( TOK_ALTERPARTITION_UPDATECOLSTATS $colName tableProperties ( $comment)? ) -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) ;
	public final HiveParser.alterStatementSuffixUpdateStatsCol_return alterStatementSuffixUpdateStatsCol(boolean partition) throws RecognitionException {
		HiveParser.alterStatementSuffixUpdateStatsCol_return retval = new HiveParser.alterStatementSuffixUpdateStatsCol_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_UPDATE297=null;
		Token KW_STATISTICS298=null;
		Token KW_FOR299=null;
		Token KW_COLUMN300=null;
		Token KW_SET301=null;
		Token KW_COMMENT303=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope tableProperties302 =null;

		ASTNode comment_tree=null;
		ASTNode KW_UPDATE297_tree=null;
		ASTNode KW_STATISTICS298_tree=null;
		ASTNode KW_FOR299_tree=null;
		ASTNode KW_COLUMN300_tree=null;
		ASTNode KW_SET301_tree=null;
		ASTNode KW_COMMENT303_tree=null;
		RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("update column statistics", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:5: ( KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> {partition}? ^( TOK_ALTERPARTITION_UPDATECOLSTATS $colName tableProperties ( $comment)? ) -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:7: KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )?
			{
			KW_UPDATE297=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStatsCol5835); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE297);

			KW_STATISTICS298=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStatsCol5837); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS298);

			KW_FOR299=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_alterStatementSuffixUpdateStatsCol5839); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR299);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:38: ( KW_COLUMN )?
			int alt84=2;
			int LA84_0 = input.LA(1);
			if ( (LA84_0==KW_COLUMN) ) {
				alt84=1;
			}
			switch (alt84) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:38: KW_COLUMN
					{
					KW_COLUMN300=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementSuffixUpdateStatsCol5841); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN300);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_alterStatementSuffixUpdateStatsCol5846);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			KW_SET301=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixUpdateStatsCol5848); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET301);

			pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixUpdateStatsCol5850);
			tableProperties302=tableProperties();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties302.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:91: ( KW_COMMENT comment= StringLiteral )?
			int alt85=2;
			int LA85_0 = input.LA(1);
			if ( (LA85_0==KW_COMMENT) ) {
				alt85=1;
			}
			switch (alt85) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:92: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT303=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_alterStatementSuffixUpdateStatsCol5853); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT303);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixUpdateStatsCol5857); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: tableProperties, comment, colName, colName, comment, tableProperties
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1368:5: -> {partition}? ^( TOK_ALTERPARTITION_UPDATECOLSTATS $colName tableProperties ( $comment)? )
			if (partition) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:21: ^( TOK_ALTERPARTITION_UPDATECOLSTATS $colName tableProperties ( $comment)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERPARTITION_UPDATECOLSTATS, "TOK_ALTERPARTITION_UPDATECOLSTATS"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_tableProperties.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:83: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1369:5: -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:21: ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_UPDATECOLSTATS, "TOK_ALTERTABLE_UPDATECOLSTATS"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_tableProperties.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:79: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixUpdateStatsCol"


	public static class alterStatementSuffixUpdateStats_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixUpdateStats"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1372:1: alterStatementSuffixUpdateStats[boolean partition] : KW_UPDATE KW_STATISTICS KW_SET tableProperties -> {partition}? ^( TOK_ALTERPARTITION_UPDATESTATS tableProperties ) -> ^( TOK_ALTERTABLE_UPDATESTATS tableProperties ) ;
	public final HiveParser.alterStatementSuffixUpdateStats_return alterStatementSuffixUpdateStats(boolean partition) throws RecognitionException {
		HiveParser.alterStatementSuffixUpdateStats_return retval = new HiveParser.alterStatementSuffixUpdateStats_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UPDATE304=null;
		Token KW_STATISTICS305=null;
		Token KW_SET306=null;
		ParserRuleReturnScope tableProperties307 =null;

		ASTNode KW_UPDATE304_tree=null;
		ASTNode KW_STATISTICS305_tree=null;
		ASTNode KW_SET306_tree=null;
		RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("update basic statistics", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1375:5: ( KW_UPDATE KW_STATISTICS KW_SET tableProperties -> {partition}? ^( TOK_ALTERPARTITION_UPDATESTATS tableProperties ) -> ^( TOK_ALTERTABLE_UPDATESTATS tableProperties ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1375:7: KW_UPDATE KW_STATISTICS KW_SET tableProperties
			{
			KW_UPDATE304=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStats5940); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE304);

			KW_STATISTICS305=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStats5942); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS305);

			KW_SET306=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixUpdateStats5944); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET306);

			pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixUpdateStats5946);
			tableProperties307=tableProperties();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties307.getTree());
			// AST REWRITE
			// elements: tableProperties, tableProperties
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1376:5: -> {partition}? ^( TOK_ALTERPARTITION_UPDATESTATS tableProperties )
			if (partition) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1376:21: ^( TOK_ALTERPARTITION_UPDATESTATS tableProperties )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERPARTITION_UPDATESTATS, "TOK_ALTERPARTITION_UPDATESTATS"), root_1);
				adaptor.addChild(root_1, stream_tableProperties.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1377:5: -> ^( TOK_ALTERTABLE_UPDATESTATS tableProperties )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:21: ^( TOK_ALTERTABLE_UPDATESTATS tableProperties )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_UPDATESTATS, "TOK_ALTERTABLE_UPDATESTATS"), root_1);
				adaptor.addChild(root_1, stream_tableProperties.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixUpdateStats"


	public static class alterStatementChangeColPosition_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementChangeColPosition"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:1: alterStatementChangeColPosition : (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) );
	public final HiveParser.alterStatementChangeColPosition_return alterStatementChangeColPosition() throws RecognitionException {
		HiveParser.alterStatementChangeColPosition_return retval = new HiveParser.alterStatementChangeColPosition_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token first=null;
		Token KW_AFTER308=null;
		ParserRuleReturnScope afterCol =null;

		ASTNode first_tree=null;
		ASTNode KW_AFTER308_tree=null;
		RewriteRuleTokenStream stream_KW_AFTER=new RewriteRuleTokenStream(adaptor,"token KW_AFTER");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1381:5: (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) )
			int alt86=2;
			int LA86_0 = input.LA(1);
			if ( (LA86_0==KW_FIRST) ) {
				alt86=1;
			}
			else if ( (LA86_0==KW_AFTER) ) {
				alt86=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 86, 0, input);
				throw nvae;
			}

			switch (alt86) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1381:7: first= KW_FIRST
					{
					root_0 = (ASTNode)adaptor.nil();


					first=(Token)match(input,KW_FIRST,FOLLOW_KW_FIRST_in_alterStatementChangeColPosition6004); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					first_tree = (ASTNode)adaptor.create(first);
					adaptor.addChild(root_0, first_tree);
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1381:22: KW_AFTER afterCol= identifier
					{
					KW_AFTER308=(Token)match(input,KW_AFTER,FOLLOW_KW_AFTER_in_alterStatementChangeColPosition6006); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_AFTER.add(KW_AFTER308);

					pushFollow(FOLLOW_identifier_in_alterStatementChangeColPosition6010);
					afterCol=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(afterCol.getTree());
					// AST REWRITE
					// elements: afterCol
					// token labels: 
					// rule labels: afterCol, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_afterCol=new RewriteRuleSubtreeStream(adaptor,"rule afterCol",afterCol!=null?afterCol.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1382:5: -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
					if (first != null) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1382:25: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION, "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}

					else // 1383:5: -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:8: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION, "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION"), root_1);
						adaptor.addChild(root_1, stream_afterCol.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementChangeColPosition"


	public static class alterStatementSuffixAddPartitions_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixAddPartitions"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:1: alterStatementSuffixAddPartitions[boolean table] : KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) ;
	public final HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions(boolean table) throws RecognitionException {
		HiveParser.alterStatementSuffixAddPartitions_return retval = new HiveParser.alterStatementSuffixAddPartitions_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ADD309=null;
		ParserRuleReturnScope ifNotExists310 =null;
		ParserRuleReturnScope alterStatementSuffixAddPartitionsElement311 =null;

		ASTNode KW_ADD309_tree=null;
		RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_alterStatementSuffixAddPartitionsElement=new RewriteRuleSubtreeStream(adaptor,"rule alterStatementSuffixAddPartitionsElement");

		 pushMsg("add partition statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1389:5: ( KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1389:7: KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+
			{
			KW_ADD309=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions6063); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ADD.add(KW_ADD309);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1389:14: ( ifNotExists )?
			int alt87=2;
			int LA87_0 = input.LA(1);
			if ( (LA87_0==KW_IF) ) {
				alt87=1;
			}
			switch (alt87) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1389:14: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions6065);
					ifNotExists310=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists310.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1389:27: ( alterStatementSuffixAddPartitionsElement )+
			int cnt88=0;
			loop88:
			while (true) {
				int alt88=2;
				int LA88_0 = input.LA(1);
				if ( (LA88_0==KW_PARTITION) ) {
					alt88=1;
				}

				switch (alt88) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1389:27: alterStatementSuffixAddPartitionsElement
					{
					pushFollow(FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions6068);
					alterStatementSuffixAddPartitionsElement311=alterStatementSuffixAddPartitionsElement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_alterStatementSuffixAddPartitionsElement.add(alterStatementSuffixAddPartitionsElement311.getTree());
					}
					break;

				default :
					if ( cnt88 >= 1 ) break loop88;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(88, input);
					throw eee;
				}
				cnt88++;
			}

			// AST REWRITE
			// elements: alterStatementSuffixAddPartitionsElement, alterStatementSuffixAddPartitionsElement, ifNotExists, ifNotExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1390:5: -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
			if ( table ) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1390:19: ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_ADDPARTS, "TOK_ALTERTABLE_ADDPARTS"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1390:45: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				if ( !(stream_alterStatementSuffixAddPartitionsElement.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_alterStatementSuffixAddPartitionsElement.hasNext() ) {
					adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitionsElement.nextTree());
				}
				stream_alterStatementSuffixAddPartitionsElement.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1391:5: -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1391:19: ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW_ADDPARTS, "TOK_ALTERVIEW_ADDPARTS"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1391:44: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				if ( !(stream_alterStatementSuffixAddPartitionsElement.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_alterStatementSuffixAddPartitionsElement.hasNext() ) {
					adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitionsElement.nextTree());
				}
				stream_alterStatementSuffixAddPartitionsElement.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixAddPartitions"


	public static class alterStatementSuffixAddPartitionsElement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixAddPartitionsElement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1394:1: alterStatementSuffixAddPartitionsElement : partitionSpec ( partitionLocation )? ;
	public final HiveParser.alterStatementSuffixAddPartitionsElement_return alterStatementSuffixAddPartitionsElement() throws RecognitionException {
		HiveParser.alterStatementSuffixAddPartitionsElement_return retval = new HiveParser.alterStatementSuffixAddPartitionsElement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope partitionSpec312 =null;
		ParserRuleReturnScope partitionLocation313 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:5: ( partitionSpec ( partitionLocation )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:7: partitionSpec ( partitionLocation )?
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement6131);
			partitionSpec312=partitionSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, partitionSpec312.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:21: ( partitionLocation )?
			int alt89=2;
			int LA89_0 = input.LA(1);
			if ( (LA89_0==KW_LOCATION) ) {
				alt89=1;
			}
			switch (alt89) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:21: partitionLocation
					{
					pushFollow(FOLLOW_partitionLocation_in_alterStatementSuffixAddPartitionsElement6133);
					partitionLocation313=partitionLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, partitionLocation313.getTree());

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixAddPartitionsElement"


	public static class alterStatementSuffixTouch_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixTouch"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:1: alterStatementSuffixTouch : KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* ) ;
	public final HiveParser.alterStatementSuffixTouch_return alterStatementSuffixTouch() throws RecognitionException {
		HiveParser.alterStatementSuffixTouch_return retval = new HiveParser.alterStatementSuffixTouch_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_TOUCH314=null;
		ParserRuleReturnScope partitionSpec315 =null;

		ASTNode KW_TOUCH314_tree=null;
		RewriteRuleTokenStream stream_KW_TOUCH=new RewriteRuleTokenStream(adaptor,"token KW_TOUCH");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");

		 pushMsg("touch statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:5: ( KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:7: KW_TOUCH ( partitionSpec )*
			{
			KW_TOUCH314=(Token)match(input,KW_TOUCH,FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch6161); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TOUCH.add(KW_TOUCH314);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:16: ( partitionSpec )*
			loop90:
			while (true) {
				int alt90=2;
				int LA90_0 = input.LA(1);
				if ( (LA90_0==KW_PARTITION) ) {
					alt90=1;
				}

				switch (alt90) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:17: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixTouch6164);
					partitionSpec315=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec315.getTree());
					}
					break;

				default :
					break loop90;
				}
			}

			// AST REWRITE
			// elements: partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1402:5: -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1402:8: ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_TOUCH, "TOK_ALTERTABLE_TOUCH"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1402:31: ( partitionSpec )*
				while ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixTouch"


	public static class alterStatementSuffixArchive_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixArchive"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1405:1: alterStatementSuffixArchive : KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* ) ;
	public final HiveParser.alterStatementSuffixArchive_return alterStatementSuffixArchive() throws RecognitionException {
		HiveParser.alterStatementSuffixArchive_return retval = new HiveParser.alterStatementSuffixArchive_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ARCHIVE316=null;
		ParserRuleReturnScope partitionSpec317 =null;

		ASTNode KW_ARCHIVE316_tree=null;
		RewriteRuleTokenStream stream_KW_ARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_ARCHIVE");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");

		 pushMsg("archive statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1408:5: ( KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1408:7: KW_ARCHIVE ( partitionSpec )*
			{
			KW_ARCHIVE316=(Token)match(input,KW_ARCHIVE,FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive6208); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ARCHIVE.add(KW_ARCHIVE316);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1408:18: ( partitionSpec )*
			loop91:
			while (true) {
				int alt91=2;
				int LA91_0 = input.LA(1);
				if ( (LA91_0==KW_PARTITION) ) {
					alt91=1;
				}

				switch (alt91) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1408:19: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixArchive6211);
					partitionSpec317=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec317.getTree());
					}
					break;

				default :
					break loop91;
				}
			}

			// AST REWRITE
			// elements: partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1409:5: -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1409:8: ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_ARCHIVE, "TOK_ALTERTABLE_ARCHIVE"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1409:33: ( partitionSpec )*
				while ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixArchive"


	public static class alterStatementSuffixUnArchive_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixUnArchive"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1412:1: alterStatementSuffixUnArchive : KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* ) ;
	public final HiveParser.alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive() throws RecognitionException {
		HiveParser.alterStatementSuffixUnArchive_return retval = new HiveParser.alterStatementSuffixUnArchive_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNARCHIVE318=null;
		ParserRuleReturnScope partitionSpec319 =null;

		ASTNode KW_UNARCHIVE318_tree=null;
		RewriteRuleTokenStream stream_KW_UNARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_UNARCHIVE");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");

		 pushMsg("unarchive statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:5: ( KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:7: KW_UNARCHIVE ( partitionSpec )*
			{
			KW_UNARCHIVE318=(Token)match(input,KW_UNARCHIVE,FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive6255); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UNARCHIVE.add(KW_UNARCHIVE318);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:20: ( partitionSpec )*
			loop92:
			while (true) {
				int alt92=2;
				int LA92_0 = input.LA(1);
				if ( (LA92_0==KW_PARTITION) ) {
					alt92=1;
				}

				switch (alt92) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:21: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive6258);
					partitionSpec319=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec319.getTree());
					}
					break;

				default :
					break loop92;
				}
			}

			// AST REWRITE
			// elements: partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1416:5: -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1416:8: ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_UNARCHIVE, "TOK_ALTERTABLE_UNARCHIVE"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1416:35: ( partitionSpec )*
				while ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixUnArchive"


	public static class partitionLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "partitionLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1419:1: partitionLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_PARTITIONLOCATION $locn) ;
	public final HiveParser.partitionLocation_return partitionLocation() throws RecognitionException {
		HiveParser.partitionLocation_return retval = new HiveParser.partitionLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token locn=null;
		Token KW_LOCATION320=null;

		ASTNode locn_tree=null;
		ASTNode KW_LOCATION320_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

		 pushMsg("partition location", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1422:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_PARTITIONLOCATION $locn) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1423:7: KW_LOCATION locn= StringLiteral
			{
			KW_LOCATION320=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_partitionLocation6308); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION320);

			locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_partitionLocation6312); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(locn);

			// AST REWRITE
			// elements: locn
			// token labels: locn
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1423:38: -> ^( TOK_PARTITIONLOCATION $locn)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1423:41: ^( TOK_PARTITIONLOCATION $locn)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PARTITIONLOCATION, "TOK_PARTITIONLOCATION"), root_1);
				adaptor.addChild(root_1, stream_locn.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "partitionLocation"


	public static class alterStatementSuffixDropPartitions_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixDropPartitions"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1426:1: alterStatementSuffixDropPartitions[boolean table] : KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( KW_PURGE )? ( replicationClause )? -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? ) ;
	public final HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions(boolean table) throws RecognitionException {
		HiveParser.alterStatementSuffixDropPartitions_return retval = new HiveParser.alterStatementSuffixDropPartitions_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP321=null;
		Token COMMA324=null;
		Token KW_PURGE326=null;
		ParserRuleReturnScope ifExists322 =null;
		ParserRuleReturnScope dropPartitionSpec323 =null;
		ParserRuleReturnScope dropPartitionSpec325 =null;
		ParserRuleReturnScope replicationClause327 =null;

		ASTNode KW_DROP321_tree=null;
		ASTNode COMMA324_tree=null;
		ASTNode KW_PURGE326_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_PURGE=new RewriteRuleTokenStream(adaptor,"token KW_PURGE");
		RewriteRuleSubtreeStream stream_dropPartitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule dropPartitionSpec");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
		RewriteRuleSubtreeStream stream_replicationClause=new RewriteRuleSubtreeStream(adaptor,"rule replicationClause");

		 pushMsg("drop partition statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:5: ( KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( KW_PURGE )? ( replicationClause )? -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:7: KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( KW_PURGE )? ( replicationClause )?
			{
			KW_DROP321=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions6349); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP321);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:15: ( ifExists )?
			int alt93=2;
			int LA93_0 = input.LA(1);
			if ( (LA93_0==KW_IF) ) {
				alt93=1;
			}
			switch (alt93) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:15: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_alterStatementSuffixDropPartitions6351);
					ifExists322=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists322.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions6354);
			dropPartitionSpec323=dropPartitionSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_dropPartitionSpec.add(dropPartitionSpec323.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:43: ( COMMA dropPartitionSpec )*
			loop94:
			while (true) {
				int alt94=2;
				int LA94_0 = input.LA(1);
				if ( (LA94_0==COMMA) ) {
					alt94=1;
				}

				switch (alt94) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:44: COMMA dropPartitionSpec
					{
					COMMA324=(Token)match(input,COMMA,FOLLOW_COMMA_in_alterStatementSuffixDropPartitions6357); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA324);

					pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions6359);
					dropPartitionSpec325=dropPartitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_dropPartitionSpec.add(dropPartitionSpec325.getTree());
					}
					break;

				default :
					break loop94;
				}
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:70: ( KW_PURGE )?
			int alt95=2;
			int LA95_0 = input.LA(1);
			if ( (LA95_0==KW_PURGE) ) {
				alt95=1;
			}
			switch (alt95) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:70: KW_PURGE
					{
					KW_PURGE326=(Token)match(input,KW_PURGE,FOLLOW_KW_PURGE_in_alterStatementSuffixDropPartitions6363); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PURGE.add(KW_PURGE326);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:80: ( replicationClause )?
			int alt96=2;
			int LA96_0 = input.LA(1);
			if ( (LA96_0==KW_FOR) ) {
				alt96=1;
			}
			switch (alt96) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:80: replicationClause
					{
					pushFollow(FOLLOW_replicationClause_in_alterStatementSuffixDropPartitions6366);
					replicationClause327=replicationClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replicationClause.add(replicationClause327.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: ifExists, ifExists, replicationClause, replicationClause, dropPartitionSpec, KW_PURGE, dropPartitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1430:5: -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
			if ( table ) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1430:19: ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_DROPPARTS, "TOK_ALTERTABLE_DROPPARTS"), root_1);
				if ( !(stream_dropPartitionSpec.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_dropPartitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_dropPartitionSpec.nextTree());
				}
				stream_dropPartitionSpec.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1430:65: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1430:75: ( KW_PURGE )?
				if ( stream_KW_PURGE.hasNext() ) {
					adaptor.addChild(root_1, stream_KW_PURGE.nextNode());
				}
				stream_KW_PURGE.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1430:85: ( replicationClause )?
				if ( stream_replicationClause.hasNext() ) {
					adaptor.addChild(root_1, stream_replicationClause.nextTree());
				}
				stream_replicationClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1431:5: -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:19: ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW_DROPPARTS, "TOK_ALTERVIEW_DROPPARTS"), root_1);
				if ( !(stream_dropPartitionSpec.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_dropPartitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_dropPartitionSpec.nextTree());
				}
				stream_dropPartitionSpec.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:64: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:74: ( replicationClause )?
				if ( stream_replicationClause.hasNext() ) {
					adaptor.addChild(root_1, stream_replicationClause.nextTree());
				}
				stream_replicationClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixDropPartitions"


	public static class alterStatementSuffixProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:1: alterStatementSuffixProperties : ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? ) );
	public final HiveParser.alterStatementSuffixProperties_return alterStatementSuffixProperties() throws RecognitionException {
		HiveParser.alterStatementSuffixProperties_return retval = new HiveParser.alterStatementSuffixProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET328=null;
		Token KW_TBLPROPERTIES329=null;
		Token KW_UNSET331=null;
		Token KW_TBLPROPERTIES332=null;
		ParserRuleReturnScope tableProperties330 =null;
		ParserRuleReturnScope ifExists333 =null;
		ParserRuleReturnScope tableProperties334 =null;

		ASTNode KW_SET328_tree=null;
		ASTNode KW_TBLPROPERTIES329_tree=null;
		ASTNode KW_UNSET331_tree=null;
		ASTNode KW_TBLPROPERTIES332_tree=null;
		RewriteRuleTokenStream stream_KW_UNSET=new RewriteRuleTokenStream(adaptor,"token KW_UNSET");
		RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("alter properties statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1437:5: ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? ) )
			int alt98=2;
			int LA98_0 = input.LA(1);
			if ( (LA98_0==KW_SET) ) {
				alt98=1;
			}
			else if ( (LA98_0==KW_UNSET) ) {
				alt98=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 98, 0, input);
				throw nvae;
			}

			switch (alt98) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1437:7: KW_SET KW_TBLPROPERTIES tableProperties
					{
					KW_SET328=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixProperties6448); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET328);

					KW_TBLPROPERTIES329=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties6450); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES329);

					pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties6452);
					tableProperties330=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties330.getTree());
					// AST REWRITE
					// elements: tableProperties
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1438:5: -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:8: ^( TOK_ALTERTABLE_PROPERTIES tableProperties )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_PROPERTIES, "TOK_ALTERTABLE_PROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableProperties.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1439:7: KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
					{
					KW_UNSET331=(Token)match(input,KW_UNSET,FOLLOW_KW_UNSET_in_alterStatementSuffixProperties6472); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNSET.add(KW_UNSET331);

					KW_TBLPROPERTIES332=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties6474); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES332);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1439:33: ( ifExists )?
					int alt97=2;
					int LA97_0 = input.LA(1);
					if ( (LA97_0==KW_IF) ) {
						alt97=1;
					}
					switch (alt97) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1439:33: ifExists
							{
							pushFollow(FOLLOW_ifExists_in_alterStatementSuffixProperties6476);
							ifExists333=ifExists();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_ifExists.add(ifExists333.getTree());
							}
							break;

					}

					pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties6479);
					tableProperties334=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties334.getTree());
					// AST REWRITE
					// elements: tableProperties, ifExists
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1440:5: -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1440:8: ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_DROPPROPERTIES, "TOK_ALTERTABLE_DROPPROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableProperties.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1440:56: ( ifExists )?
						if ( stream_ifExists.hasNext() ) {
							adaptor.addChild(root_1, stream_ifExists.nextTree());
						}
						stream_ifExists.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixProperties"


	public static class alterViewSuffixProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterViewSuffixProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1443:1: alterViewSuffixProperties : ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? ) );
	public final HiveParser.alterViewSuffixProperties_return alterViewSuffixProperties() throws RecognitionException {
		HiveParser.alterViewSuffixProperties_return retval = new HiveParser.alterViewSuffixProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET335=null;
		Token KW_TBLPROPERTIES336=null;
		Token KW_UNSET338=null;
		Token KW_TBLPROPERTIES339=null;
		ParserRuleReturnScope tableProperties337 =null;
		ParserRuleReturnScope ifExists340 =null;
		ParserRuleReturnScope tableProperties341 =null;

		ASTNode KW_SET335_tree=null;
		ASTNode KW_TBLPROPERTIES336_tree=null;
		ASTNode KW_UNSET338_tree=null;
		ASTNode KW_TBLPROPERTIES339_tree=null;
		RewriteRuleTokenStream stream_KW_UNSET=new RewriteRuleTokenStream(adaptor,"token KW_UNSET");
		RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("alter view properties statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1446:5: ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? ) )
			int alt100=2;
			int LA100_0 = input.LA(1);
			if ( (LA100_0==KW_SET) ) {
				alt100=1;
			}
			else if ( (LA100_0==KW_UNSET) ) {
				alt100=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 100, 0, input);
				throw nvae;
			}

			switch (alt100) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1446:7: KW_SET KW_TBLPROPERTIES tableProperties
					{
					KW_SET335=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterViewSuffixProperties6521); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET335);

					KW_TBLPROPERTIES336=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties6523); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES336);

					pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties6525);
					tableProperties337=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties337.getTree());
					// AST REWRITE
					// elements: tableProperties
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1447:5: -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1447:8: ^( TOK_ALTERVIEW_PROPERTIES tableProperties )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW_PROPERTIES, "TOK_ALTERVIEW_PROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableProperties.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:7: KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
					{
					KW_UNSET338=(Token)match(input,KW_UNSET,FOLLOW_KW_UNSET_in_alterViewSuffixProperties6545); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNSET.add(KW_UNSET338);

					KW_TBLPROPERTIES339=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties6547); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES339);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:33: ( ifExists )?
					int alt99=2;
					int LA99_0 = input.LA(1);
					if ( (LA99_0==KW_IF) ) {
						alt99=1;
					}
					switch (alt99) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:33: ifExists
							{
							pushFollow(FOLLOW_ifExists_in_alterViewSuffixProperties6549);
							ifExists340=ifExists();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_ifExists.add(ifExists340.getTree());
							}
							break;

					}

					pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties6552);
					tableProperties341=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties341.getTree());
					// AST REWRITE
					// elements: tableProperties, ifExists
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1449:5: -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1449:8: ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERVIEW_DROPPROPERTIES, "TOK_ALTERVIEW_DROPPROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableProperties.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1449:55: ( ifExists )?
						if ( stream_ifExists.hasNext() ) {
							adaptor.addChild(root_1, stream_ifExists.nextTree());
						}
						stream_ifExists.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterViewSuffixProperties"


	public static class alterStatementSuffixSerdeProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixSerdeProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1452:1: alterStatementSuffixSerdeProperties[boolean partition] : ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> {partition}? ^( TOK_ALTERPARTITION_SERIALIZER $serdeName ( tableProperties )? ) -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> {partition}? ^( TOK_ALTERPARTITION_SERDEPROPERTIES tableProperties ) -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) );
	public final HiveParser.alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties(boolean partition) throws RecognitionException {
		HiveParser.alterStatementSuffixSerdeProperties_return retval = new HiveParser.alterStatementSuffixSerdeProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token serdeName=null;
		Token KW_SET342=null;
		Token KW_SERDE343=null;
		Token KW_WITH344=null;
		Token KW_SERDEPROPERTIES345=null;
		Token KW_SET347=null;
		Token KW_SERDEPROPERTIES348=null;
		ParserRuleReturnScope tableProperties346 =null;
		ParserRuleReturnScope tableProperties349 =null;

		ASTNode serdeName_tree=null;
		ASTNode KW_SET342_tree=null;
		ASTNode KW_SERDE343_tree=null;
		ASTNode KW_WITH344_tree=null;
		ASTNode KW_SERDEPROPERTIES345_tree=null;
		ASTNode KW_SET347_tree=null;
		ASTNode KW_SERDEPROPERTIES348_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
		RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("alter serdes statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1455:5: ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> {partition}? ^( TOK_ALTERPARTITION_SERIALIZER $serdeName ( tableProperties )? ) -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> {partition}? ^( TOK_ALTERPARTITION_SERDEPROPERTIES tableProperties ) -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) )
			int alt102=2;
			int LA102_0 = input.LA(1);
			if ( (LA102_0==KW_SET) ) {
				int LA102_1 = input.LA(2);
				if ( (LA102_1==KW_SERDE) ) {
					alt102=1;
				}
				else if ( (LA102_1==KW_SERDEPROPERTIES) ) {
					alt102=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 102, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 102, 0, input);
				throw nvae;
			}

			switch (alt102) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1455:7: KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
					{
					KW_SET342=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties6595); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET342);

					KW_SERDE343=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties6597); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE343);

					serdeName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties6601); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(serdeName);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1455:47: ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
					int alt101=2;
					int LA101_0 = input.LA(1);
					if ( (LA101_0==KW_WITH) ) {
						alt101=1;
					}
					switch (alt101) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1455:48: KW_WITH KW_SERDEPROPERTIES tableProperties
							{
							KW_WITH344=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties6604); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH344);

							KW_SERDEPROPERTIES345=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties6606); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES345);

							pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties6608);
							tableProperties346=tableProperties();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties346.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: tableProperties, serdeName, serdeName, tableProperties
					// token labels: serdeName
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_serdeName=new RewriteRuleTokenStream(adaptor,"token serdeName",serdeName);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1456:5: -> {partition}? ^( TOK_ALTERPARTITION_SERIALIZER $serdeName ( tableProperties )? )
					if (partition) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1456:21: ^( TOK_ALTERPARTITION_SERIALIZER $serdeName ( tableProperties )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERPARTITION_SERIALIZER, "TOK_ALTERPARTITION_SERIALIZER"), root_1);
						adaptor.addChild(root_1, stream_serdeName.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1456:64: ( tableProperties )?
						if ( stream_tableProperties.hasNext() ) {
							adaptor.addChild(root_1, stream_tableProperties.nextTree());
						}
						stream_tableProperties.reset();

						adaptor.addChild(root_0, root_1);
						}

					}

					else // 1457:5: -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1457:21: ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SERIALIZER, "TOK_ALTERTABLE_SERIALIZER"), root_1);
						adaptor.addChild(root_1, stream_serdeName.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1457:60: ( tableProperties )?
						if ( stream_tableProperties.hasNext() ) {
							adaptor.addChild(root_1, stream_tableProperties.nextTree());
						}
						stream_tableProperties.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1458:7: KW_SET KW_SERDEPROPERTIES tableProperties
					{
					KW_SET347=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties6665); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET347);

					KW_SERDEPROPERTIES348=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties6667); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES348);

					pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties6669);
					tableProperties349=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties349.getTree());
					// AST REWRITE
					// elements: tableProperties, tableProperties
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1459:5: -> {partition}? ^( TOK_ALTERPARTITION_SERDEPROPERTIES tableProperties )
					if (partition) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1459:21: ^( TOK_ALTERPARTITION_SERDEPROPERTIES tableProperties )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERPARTITION_SERDEPROPERTIES, "TOK_ALTERPARTITION_SERDEPROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableProperties.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}

					else // 1460:5: -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1460:21: ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SERDEPROPERTIES, "TOK_ALTERTABLE_SERDEPROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableProperties.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixSerdeProperties"


	public static class tablePartitionPrefix_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tablePartitionPrefix"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1463:1: tablePartitionPrefix : tableName ( partitionSpec )? -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? ) ;
	public final HiveParser.tablePartitionPrefix_return tablePartitionPrefix() throws RecognitionException {
		HiveParser.tablePartitionPrefix_return retval = new HiveParser.tablePartitionPrefix_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope tableName350 =null;
		ParserRuleReturnScope partitionSpec351 =null;

		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		pushMsg("table partition prefix", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:3: ( tableName ( partitionSpec )? -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:5: tableName ( partitionSpec )?
			{
			pushFollow(FOLLOW_tableName_in_tablePartitionPrefix6733);
			tableName350=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName350.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:15: ( partitionSpec )?
			int alt103=2;
			int LA103_0 = input.LA(1);
			if ( (LA103_0==KW_PARTITION) ) {
				alt103=1;
			}
			switch (alt103) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:15: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_tablePartitionPrefix6735);
					partitionSpec351=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec351.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: partitionSpec, tableName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1467:3: -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1467:5: ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLE_PARTITION, "TOK_TABLE_PARTITION"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1467:37: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tablePartitionPrefix"


	public static class alterStatementSuffixFileFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixFileFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1470:1: alterStatementSuffixFileFormat[boolean partition] : KW_SET KW_FILEFORMAT fileFormat -> {partition}? ^( TOK_ALTERPARTITION_FILEFORMAT fileFormat ) -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) ;
	public final HiveParser.alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat(boolean partition) throws RecognitionException {
		HiveParser.alterStatementSuffixFileFormat_return retval = new HiveParser.alterStatementSuffixFileFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET352=null;
		Token KW_FILEFORMAT353=null;
		ParserRuleReturnScope fileFormat354 =null;

		ASTNode KW_SET352_tree=null;
		ASTNode KW_FILEFORMAT353_tree=null;
		RewriteRuleTokenStream stream_KW_FILEFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FILEFORMAT");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_fileFormat=new RewriteRuleSubtreeStream(adaptor,"rule fileFormat");

		pushMsg("alter fileformat statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1473:3: ( KW_SET KW_FILEFORMAT fileFormat -> {partition}? ^( TOK_ALTERPARTITION_FILEFORMAT fileFormat ) -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1473:5: KW_SET KW_FILEFORMAT fileFormat
			{
			KW_SET352=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixFileFormat6772); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET352);

			KW_FILEFORMAT353=(Token)match(input,KW_FILEFORMAT,FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat6774); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FILEFORMAT.add(KW_FILEFORMAT353);

			pushFollow(FOLLOW_fileFormat_in_alterStatementSuffixFileFormat6776);
			fileFormat354=fileFormat();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_fileFormat.add(fileFormat354.getTree());
			// AST REWRITE
			// elements: fileFormat, fileFormat
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1474:3: -> {partition}? ^( TOK_ALTERPARTITION_FILEFORMAT fileFormat )
			if (partition) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1474:19: ^( TOK_ALTERPARTITION_FILEFORMAT fileFormat )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERPARTITION_FILEFORMAT, "TOK_ALTERPARTITION_FILEFORMAT"), root_1);
				adaptor.addChild(root_1, stream_fileFormat.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1475:3: -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1475:19: ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_FILEFORMAT, "TOK_ALTERTABLE_FILEFORMAT"), root_1);
				adaptor.addChild(root_1, stream_fileFormat.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixFileFormat"


	public static class alterStatementSuffixClusterbySortby_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixClusterbySortby"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:1: alterStatementSuffixClusterbySortby : ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) );
	public final HiveParser.alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby() throws RecognitionException {
		HiveParser.alterStatementSuffixClusterbySortby_return retval = new HiveParser.alterStatementSuffixClusterbySortby_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_NOT355=null;
		Token KW_CLUSTERED356=null;
		Token KW_NOT357=null;
		Token KW_SORTED358=null;
		ParserRuleReturnScope tableBuckets359 =null;

		ASTNode KW_NOT355_tree=null;
		ASTNode KW_CLUSTERED356_tree=null;
		ASTNode KW_NOT357_tree=null;
		ASTNode KW_SORTED358_tree=null;
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
		RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
		RewriteRuleSubtreeStream stream_tableBuckets=new RewriteRuleSubtreeStream(adaptor,"rule tableBuckets");

		pushMsg("alter partition cluster by sort by statement", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:3: ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) )
			int alt104=3;
			int LA104_0 = input.LA(1);
			if ( (LA104_0==KW_NOT) ) {
				int LA104_1 = input.LA(2);
				if ( (LA104_1==KW_CLUSTERED) ) {
					alt104=1;
				}
				else if ( (LA104_1==KW_SORTED) ) {
					alt104=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 104, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( (LA104_0==KW_CLUSTERED) ) {
				alt104=3;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 104, 0, input);
				throw nvae;
			}

			switch (alt104) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:5: KW_NOT KW_CLUSTERED
					{
					KW_NOT355=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6834); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT355);

					KW_CLUSTERED356=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby6836); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CLUSTERED.add(KW_CLUSTERED356);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1481:25: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:28: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);
						adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_NOT_CLUSTERED, "TOK_NOT_CLUSTERED"));
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1482:5: KW_NOT KW_SORTED
					{
					KW_NOT357=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6850); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT357);

					KW_SORTED358=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby6852); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SORTED.add(KW_SORTED358);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1482:22: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1482:25: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);
						adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_NOT_SORTED, "TOK_NOT_SORTED"));
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1483:5: tableBuckets
					{
					pushFollow(FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby6866);
					tableBuckets359=tableBuckets();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableBuckets.add(tableBuckets359.getTree());
					// AST REWRITE
					// elements: tableBuckets
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1483:18: -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1483:21: ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);
						adaptor.addChild(root_1, stream_tableBuckets.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixClusterbySortby"


	public static class alterTblPartitionStatementSuffixSkewedLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterTblPartitionStatementSuffixSkewedLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1486:1: alterTblPartitionStatementSuffixSkewedLocation : KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations ) ;
	public final HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return alterTblPartitionStatementSuffixSkewedLocation() throws RecognitionException {
		HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return retval = new HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET360=null;
		Token KW_SKEWED361=null;
		Token KW_LOCATION362=null;
		ParserRuleReturnScope skewedLocations363 =null;

		ASTNode KW_SET360_tree=null;
		ASTNode KW_SKEWED361_tree=null;
		ASTNode KW_LOCATION362_tree=null;
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");
		RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_skewedLocations=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocations");

		pushMsg("alter partition skewed location", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:3: ( KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:5: KW_SET KW_SKEWED KW_LOCATION skewedLocations
			{
			KW_SET360=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation6897); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET360);

			KW_SKEWED361=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation6899); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SKEWED.add(KW_SKEWED361);

			KW_LOCATION362=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation6901); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION362);

			pushFollow(FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation6903);
			skewedLocations363=skewedLocations();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedLocations.add(skewedLocations363.getTree());
			// AST REWRITE
			// elements: skewedLocations
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1490:3: -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:6: ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED_LOCATION, "TOK_ALTERTABLE_SKEWED_LOCATION"), root_1);
				adaptor.addChild(root_1, stream_skewedLocations.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterTblPartitionStatementSuffixSkewedLocation"


	public static class skewedLocations_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedLocations"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1493:1: skewedLocations : LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) ;
	public final HiveParser.skewedLocations_return skewedLocations() throws RecognitionException {
		HiveParser.skewedLocations_return retval = new HiveParser.skewedLocations_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN364=null;
		Token RPAREN366=null;
		ParserRuleReturnScope skewedLocationsList365 =null;

		ASTNode LPAREN364_tree=null;
		ASTNode RPAREN366_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_skewedLocationsList=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocationsList");

		 pushMsg("skewed locations", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1496:5: ( LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1497:7: LPAREN skewedLocationsList RPAREN
			{
			LPAREN364=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_skewedLocations6946); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN364);

			pushFollow(FOLLOW_skewedLocationsList_in_skewedLocations6948);
			skewedLocationsList365=skewedLocationsList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedLocationsList.add(skewedLocationsList365.getTree());
			RPAREN366=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_skewedLocations6950); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN366);

			// AST REWRITE
			// elements: skewedLocationsList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1497:41: -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1497:44: ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SKEWED_LOCATIONS, "TOK_SKEWED_LOCATIONS"), root_1);
				adaptor.addChild(root_1, stream_skewedLocationsList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedLocations"


	public static class skewedLocationsList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedLocationsList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:1: skewedLocationsList : skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) ;
	public final HiveParser.skewedLocationsList_return skewedLocationsList() throws RecognitionException {
		HiveParser.skewedLocationsList_return retval = new HiveParser.skewedLocationsList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA368=null;
		ParserRuleReturnScope skewedLocationMap367 =null;
		ParserRuleReturnScope skewedLocationMap369 =null;

		ASTNode COMMA368_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_skewedLocationMap=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocationMap");

		 pushMsg("skewed locations list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1503:5: ( skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:7: skewedLocationMap ( COMMA skewedLocationMap )*
			{
			pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList6991);
			skewedLocationMap367=skewedLocationMap();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedLocationMap.add(skewedLocationMap367.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:25: ( COMMA skewedLocationMap )*
			loop105:
			while (true) {
				int alt105=2;
				int LA105_0 = input.LA(1);
				if ( (LA105_0==COMMA) ) {
					alt105=1;
				}

				switch (alt105) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:26: COMMA skewedLocationMap
					{
					COMMA368=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedLocationsList6994); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA368);

					pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList6996);
					skewedLocationMap369=skewedLocationMap();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_skewedLocationMap.add(skewedLocationMap369.getTree());
					}
					break;

				default :
					break loop105;
				}
			}

			// AST REWRITE
			// elements: skewedLocationMap
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1504:52: -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:55: ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SKEWED_LOCATION_LIST, "TOK_SKEWED_LOCATION_LIST"), root_1);
				if ( !(stream_skewedLocationMap.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_skewedLocationMap.hasNext() ) {
					adaptor.addChild(root_1, stream_skewedLocationMap.nextTree());
				}
				stream_skewedLocationMap.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedLocationsList"


	public static class skewedLocationMap_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedLocationMap"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1507:1: skewedLocationMap : key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) ;
	public final HiveParser.skewedLocationMap_return skewedLocationMap() throws RecognitionException {
		HiveParser.skewedLocationMap_return retval = new HiveParser.skewedLocationMap_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token value=null;
		Token EQUAL370=null;
		ParserRuleReturnScope key =null;

		ASTNode value_tree=null;
		ASTNode EQUAL370_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");
		RewriteRuleSubtreeStream stream_skewedValueLocationElement=new RewriteRuleSubtreeStream(adaptor,"rule skewedValueLocationElement");

		 pushMsg("specifying skewed location map", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1510:5: (key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:7: key= skewedValueLocationElement EQUAL value= StringLiteral
			{
			pushFollow(FOLLOW_skewedValueLocationElement_in_skewedLocationMap7042);
			key=skewedValueLocationElement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedValueLocationElement.add(key.getTree());
			EQUAL370=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_skewedLocationMap7044); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_EQUAL.add(EQUAL370);

			value=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_skewedLocationMap7048); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(value);

			// AST REWRITE
			// elements: value, key
			// token labels: value
			// rule labels: key, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
			RewriteRuleSubtreeStream stream_key=new RewriteRuleSubtreeStream(adaptor,"rule key",key!=null?key.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1511:64: -> ^( TOK_SKEWED_LOCATION_MAP $key $value)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:67: ^( TOK_SKEWED_LOCATION_MAP $key $value)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SKEWED_LOCATION_MAP, "TOK_SKEWED_LOCATION_MAP"), root_1);
				adaptor.addChild(root_1, stream_key.nextTree());
				adaptor.addChild(root_1, stream_value.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedLocationMap"


	public static class alterStatementSuffixLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:1: alterStatementSuffixLocation[boolean partition] : KW_SET KW_LOCATION newLoc= StringLiteral -> {partition}? ^( TOK_ALTERPARTITION_LOCATION $newLoc) -> ^( TOK_ALTERTABLE_LOCATION $newLoc) ;
	public final HiveParser.alterStatementSuffixLocation_return alterStatementSuffixLocation(boolean partition) throws RecognitionException {
		HiveParser.alterStatementSuffixLocation_return retval = new HiveParser.alterStatementSuffixLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token newLoc=null;
		Token KW_SET371=null;
		Token KW_LOCATION372=null;

		ASTNode newLoc_tree=null;
		ASTNode KW_SET371_tree=null;
		ASTNode KW_LOCATION372_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");

		pushMsg("alter location", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1517:3: ( KW_SET KW_LOCATION newLoc= StringLiteral -> {partition}? ^( TOK_ALTERPARTITION_LOCATION $newLoc) -> ^( TOK_ALTERTABLE_LOCATION $newLoc) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1517:5: KW_SET KW_LOCATION newLoc= StringLiteral
			{
			KW_SET371=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixLocation7086); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET371);

			KW_LOCATION372=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_alterStatementSuffixLocation7088); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION372);

			newLoc=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixLocation7092); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(newLoc);

			// AST REWRITE
			// elements: newLoc, newLoc
			// token labels: newLoc
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_newLoc=new RewriteRuleTokenStream(adaptor,"token newLoc",newLoc);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1518:3: -> {partition}? ^( TOK_ALTERPARTITION_LOCATION $newLoc)
			if (partition) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:19: ^( TOK_ALTERPARTITION_LOCATION $newLoc)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERPARTITION_LOCATION, "TOK_ALTERPARTITION_LOCATION"), root_1);
				adaptor.addChild(root_1, stream_newLoc.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1519:3: -> ^( TOK_ALTERTABLE_LOCATION $newLoc)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:19: ^( TOK_ALTERTABLE_LOCATION $newLoc)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_LOCATION, "TOK_ALTERTABLE_LOCATION"), root_1);
				adaptor.addChild(root_1, stream_newLoc.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixLocation"


	public static class alterStatementSuffixSkewedby_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixSkewedby"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1523:1: alterStatementSuffixSkewedby : ( tableSkewed -> ^( TOK_ALTERTABLE_SKEWED tableSkewed ) | KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED ) | KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs ) );
	public final HiveParser.alterStatementSuffixSkewedby_return alterStatementSuffixSkewedby() throws RecognitionException {
		HiveParser.alterStatementSuffixSkewedby_return retval = new HiveParser.alterStatementSuffixSkewedby_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_NOT374=null;
		Token KW_SKEWED375=null;
		Token KW_NOT376=null;
		ParserRuleReturnScope tableSkewed373 =null;
		ParserRuleReturnScope storedAsDirs377 =null;

		ASTNode KW_NOT374_tree=null;
		ASTNode KW_SKEWED375_tree=null;
		ASTNode KW_NOT376_tree=null;
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
		RewriteRuleSubtreeStream stream_tableSkewed=new RewriteRuleSubtreeStream(adaptor,"rule tableSkewed");
		RewriteRuleSubtreeStream stream_storedAsDirs=new RewriteRuleSubtreeStream(adaptor,"rule storedAsDirs");

		pushMsg("alter skewed by statement", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1526:2: ( tableSkewed -> ^( TOK_ALTERTABLE_SKEWED tableSkewed ) | KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED ) | KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs ) )
			int alt106=3;
			int LA106_0 = input.LA(1);
			if ( (LA106_0==KW_SKEWED) ) {
				alt106=1;
			}
			else if ( (LA106_0==KW_NOT) ) {
				int LA106_2 = input.LA(2);
				if ( (LA106_2==KW_SKEWED) ) {
					alt106=2;
				}
				else if ( (LA106_2==KW_STORED) ) {
					alt106=3;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 106, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 106, 0, input);
				throw nvae;
			}

			switch (alt106) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1526:4: tableSkewed
					{
					pushFollow(FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby7152);
					tableSkewed373=tableSkewed();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableSkewed.add(tableSkewed373.getTree());
					// AST REWRITE
					// elements: tableSkewed
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1527:2: -> ^( TOK_ALTERTABLE_SKEWED tableSkewed )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:4: ^( TOK_ALTERTABLE_SKEWED tableSkewed )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);
						adaptor.addChild(root_1, stream_tableSkewed.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1529:3: KW_NOT KW_SKEWED
					{
					KW_NOT374=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby7167); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT374);

					KW_SKEWED375=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby7169); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SKEWED.add(KW_SKEWED375);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1530:2: -> ^( TOK_ALTERTABLE_SKEWED )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1530:4: ^( TOK_ALTERTABLE_SKEWED )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1532:3: KW_NOT storedAsDirs
					{
					KW_NOT376=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby7182); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT376);

					pushFollow(FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby7184);
					storedAsDirs377=storedAsDirs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_storedAsDirs.add(storedAsDirs377.getTree());
					// AST REWRITE
					// elements: storedAsDirs
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1533:2: -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1533:4: ^( TOK_ALTERTABLE_SKEWED storedAsDirs )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);
						adaptor.addChild(root_1, stream_storedAsDirs.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixSkewedby"


	public static class alterStatementSuffixExchangePartition_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixExchangePartition"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1536:1: alterStatementSuffixExchangePartition : KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename) ;
	public final HiveParser.alterStatementSuffixExchangePartition_return alterStatementSuffixExchangePartition() throws RecognitionException {
		HiveParser.alterStatementSuffixExchangePartition_return retval = new HiveParser.alterStatementSuffixExchangePartition_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_EXCHANGE378=null;
		Token KW_WITH380=null;
		Token KW_TABLE381=null;
		ParserRuleReturnScope exchangename =null;
		ParserRuleReturnScope partitionSpec379 =null;

		ASTNode KW_EXCHANGE378_tree=null;
		ASTNode KW_WITH380_tree=null;
		ASTNode KW_TABLE381_tree=null;
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_EXCHANGE=new RewriteRuleTokenStream(adaptor,"token KW_EXCHANGE");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		pushMsg("alter exchange partition", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1539:5: ( KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1539:7: KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName
			{
			KW_EXCHANGE378=(Token)match(input,KW_EXCHANGE,FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition7215); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXCHANGE.add(KW_EXCHANGE378);

			pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition7217);
			partitionSpec379=partitionSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec379.getTree());
			KW_WITH380=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition7219); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH380);

			KW_TABLE381=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition7221); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE381);

			pushFollow(FOLLOW_tableName_in_alterStatementSuffixExchangePartition7225);
			exchangename=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(exchangename.getTree());
			// AST REWRITE
			// elements: partitionSpec, exchangename
			// token labels: 
			// rule labels: exchangename, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_exchangename=new RewriteRuleSubtreeStream(adaptor,"rule exchangename",exchangename!=null?exchangename.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1540:5: -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1540:8: ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_EXCHANGEPARTITION, "TOK_ALTERTABLE_EXCHANGEPARTITION"), root_1);
				adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				adaptor.addChild(root_1, stream_exchangename.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixExchangePartition"


	public static class alterStatementSuffixRenamePart_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixRenamePart"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1543:1: alterStatementSuffixRenamePart : KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) ;
	public final HiveParser.alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart() throws RecognitionException {
		HiveParser.alterStatementSuffixRenamePart_return retval = new HiveParser.alterStatementSuffixRenamePart_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RENAME382=null;
		Token KW_TO383=null;
		ParserRuleReturnScope partitionSpec384 =null;

		ASTNode KW_RENAME382_tree=null;
		ASTNode KW_TO383_tree=null;
		RewriteRuleTokenStream stream_KW_RENAME=new RewriteRuleTokenStream(adaptor,"token KW_RENAME");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");

		 pushMsg("alter table rename partition statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1546:5: ( KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1546:7: KW_RENAME KW_TO partitionSpec
			{
			KW_RENAME382=(Token)match(input,KW_RENAME,FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart7267); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_RENAME.add(KW_RENAME382);

			KW_TO383=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_alterStatementSuffixRenamePart7269); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO383);

			pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart7271);
			partitionSpec384=partitionSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec384.getTree());
			// AST REWRITE
			// elements: partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1547:5: -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1547:7: ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_RENAMEPART, "TOK_ALTERTABLE_RENAMEPART"), root_1);
				adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixRenamePart"


	public static class alterStatementSuffixStatsPart_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixStatsPart"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1550:1: alterStatementSuffixStatsPart : KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) ;
	public final HiveParser.alterStatementSuffixStatsPart_return alterStatementSuffixStatsPart() throws RecognitionException {
		HiveParser.alterStatementSuffixStatsPart_return retval = new HiveParser.alterStatementSuffixStatsPart_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_UPDATE385=null;
		Token KW_STATISTICS386=null;
		Token KW_FOR387=null;
		Token KW_COLUMN388=null;
		Token KW_SET389=null;
		Token KW_COMMENT391=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope tableProperties390 =null;

		ASTNode comment_tree=null;
		ASTNode KW_UPDATE385_tree=null;
		ASTNode KW_STATISTICS386_tree=null;
		ASTNode KW_FOR387_tree=null;
		ASTNode KW_COLUMN388_tree=null;
		ASTNode KW_SET389_tree=null;
		ASTNode KW_COMMENT391_tree=null;
		RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("alter table stats partition statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1553:5: ( KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1553:7: KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )?
			{
			KW_UPDATE385=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_alterStatementSuffixStatsPart7309); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE385);

			KW_STATISTICS386=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_alterStatementSuffixStatsPart7311); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS386);

			KW_FOR387=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_alterStatementSuffixStatsPart7313); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR387);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1553:38: ( KW_COLUMN )?
			int alt107=2;
			int LA107_0 = input.LA(1);
			if ( (LA107_0==KW_COLUMN) ) {
				alt107=1;
			}
			switch (alt107) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1553:38: KW_COLUMN
					{
					KW_COLUMN388=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementSuffixStatsPart7315); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN388);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_alterStatementSuffixStatsPart7320);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			KW_SET389=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixStatsPart7322); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET389);

			pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixStatsPart7324);
			tableProperties390=tableProperties();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties390.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1553:91: ( KW_COMMENT comment= StringLiteral )?
			int alt108=2;
			int LA108_0 = input.LA(1);
			if ( (LA108_0==KW_COMMENT) ) {
				alt108=1;
			}
			switch (alt108) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1553:92: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT391=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_alterStatementSuffixStatsPart7327); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT391);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixStatsPart7331); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: colName, tableProperties, comment
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1554:5: -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1554:7: ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_UPDATECOLSTATS, "TOK_ALTERTABLE_UPDATECOLSTATS"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_tableProperties.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1554:65: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixStatsPart"


	public static class alterStatementSuffixMergeFiles_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixMergeFiles"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:1: alterStatementSuffixMergeFiles[boolean partition] : KW_CONCATENATE -> {partition}? ^( TOK_ALTERPARTITION_MERGEFILES ) -> ^( TOK_ALTERTABLE_MERGEFILES ) ;
	public final HiveParser.alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles(boolean partition) throws RecognitionException {
		HiveParser.alterStatementSuffixMergeFiles_return retval = new HiveParser.alterStatementSuffixMergeFiles_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONCATENATE392=null;

		ASTNode KW_CONCATENATE392_tree=null;
		RewriteRuleTokenStream stream_KW_CONCATENATE=new RewriteRuleTokenStream(adaptor,"token KW_CONCATENATE");

		 pushMsg("", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1560:5: ( KW_CONCATENATE -> {partition}? ^( TOK_ALTERPARTITION_MERGEFILES ) -> ^( TOK_ALTERTABLE_MERGEFILES ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1560:7: KW_CONCATENATE
			{
			KW_CONCATENATE392=(Token)match(input,KW_CONCATENATE,FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles7379); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CONCATENATE.add(KW_CONCATENATE392);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1561:5: -> {partition}? ^( TOK_ALTERPARTITION_MERGEFILES )
			if (partition) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1561:21: ^( TOK_ALTERPARTITION_MERGEFILES )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERPARTITION_MERGEFILES, "TOK_ALTERPARTITION_MERGEFILES"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1562:5: -> ^( TOK_ALTERTABLE_MERGEFILES )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1562:21: ^( TOK_ALTERTABLE_MERGEFILES )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_MERGEFILES, "TOK_ALTERTABLE_MERGEFILES"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixMergeFiles"


	public static class alterStatementSuffixBucketNum_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixBucketNum"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1565:1: alterStatementSuffixBucketNum[boolean partition] : KW_INTO num= Number KW_BUCKETS -> {partition}? ^( TOK_ALTERPARTITION_BUCKETS $num) -> ^( TOK_ALTERTABLE_BUCKETS $num) ;
	public final HiveParser.alterStatementSuffixBucketNum_return alterStatementSuffixBucketNum(boolean partition) throws RecognitionException {
		HiveParser.alterStatementSuffixBucketNum_return retval = new HiveParser.alterStatementSuffixBucketNum_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token num=null;
		Token KW_INTO393=null;
		Token KW_BUCKETS394=null;

		ASTNode num_tree=null;
		ASTNode KW_INTO393_tree=null;
		ASTNode KW_BUCKETS394_tree=null;
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_BUCKETS=new RewriteRuleTokenStream(adaptor,"token KW_BUCKETS");

		 pushMsg("", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1568:5: ( KW_INTO num= Number KW_BUCKETS -> {partition}? ^( TOK_ALTERPARTITION_BUCKETS $num) -> ^( TOK_ALTERTABLE_BUCKETS $num) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1568:7: KW_INTO num= Number KW_BUCKETS
			{
			KW_INTO393=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum7442); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO393);

			num=(Token)match(input,Number,FOLLOW_Number_in_alterStatementSuffixBucketNum7446); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Number.add(num);

			KW_BUCKETS394=(Token)match(input,KW_BUCKETS,FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum7448); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BUCKETS.add(KW_BUCKETS394);

			// AST REWRITE
			// elements: num, num
			// token labels: num
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1569:5: -> {partition}? ^( TOK_ALTERPARTITION_BUCKETS $num)
			if (partition) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1569:21: ^( TOK_ALTERPARTITION_BUCKETS $num)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERPARTITION_BUCKETS, "TOK_ALTERPARTITION_BUCKETS"), root_1);
				adaptor.addChild(root_1, stream_num.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1570:5: -> ^( TOK_ALTERTABLE_BUCKETS $num)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1570:21: ^( TOK_ALTERTABLE_BUCKETS $num)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_BUCKETS, "TOK_ALTERTABLE_BUCKETS"), root_1);
				adaptor.addChild(root_1, stream_num.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixBucketNum"


	public static class blocking_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "blocking"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1573:1: blocking : KW_AND KW_WAIT -> TOK_BLOCKING ;
	public final HiveParser.blocking_return blocking() throws RecognitionException {
		HiveParser.blocking_return retval = new HiveParser.blocking_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_AND395=null;
		Token KW_WAIT396=null;

		ASTNode KW_AND395_tree=null;
		ASTNode KW_WAIT396_tree=null;
		RewriteRuleTokenStream stream_KW_WAIT=new RewriteRuleTokenStream(adaptor,"token KW_WAIT");
		RewriteRuleTokenStream stream_KW_AND=new RewriteRuleTokenStream(adaptor,"token KW_AND");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1574:3: ( KW_AND KW_WAIT -> TOK_BLOCKING )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1574:5: KW_AND KW_WAIT
			{
			KW_AND395=(Token)match(input,KW_AND,FOLLOW_KW_AND_in_blocking7504); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AND.add(KW_AND395);

			KW_WAIT396=(Token)match(input,KW_WAIT,FOLLOW_KW_WAIT_in_blocking7506); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WAIT.add(KW_WAIT396);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1575:3: -> TOK_BLOCKING
			{
				adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_BLOCKING, "TOK_BLOCKING"));
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "blocking"


	public static class alterStatementSuffixCompact_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixCompact"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1578:1: alterStatementSuffixCompact : KW_COMPACT compactType= StringLiteral ( blocking )? ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_COMPACT $compactType ( blocking )? ( tableProperties )? ) ;
	public final HiveParser.alterStatementSuffixCompact_return alterStatementSuffixCompact() throws RecognitionException {
		HiveParser.alterStatementSuffixCompact_return retval = new HiveParser.alterStatementSuffixCompact_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token compactType=null;
		Token KW_COMPACT397=null;
		Token KW_WITH399=null;
		Token KW_OVERWRITE400=null;
		Token KW_TBLPROPERTIES401=null;
		ParserRuleReturnScope blocking398 =null;
		ParserRuleReturnScope tableProperties402 =null;

		ASTNode compactType_tree=null;
		ASTNode KW_COMPACT397_tree=null;
		ASTNode KW_WITH399_tree=null;
		ASTNode KW_OVERWRITE400_tree=null;
		ASTNode KW_TBLPROPERTIES401_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_COMPACT=new RewriteRuleTokenStream(adaptor,"token KW_COMPACT");
		RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
		RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
		RewriteRuleSubtreeStream stream_blocking=new RewriteRuleSubtreeStream(adaptor,"rule blocking");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 msgs.push("compaction request"); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1581:5: ( KW_COMPACT compactType= StringLiteral ( blocking )? ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_COMPACT $compactType ( blocking )? ( tableProperties )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1581:7: KW_COMPACT compactType= StringLiteral ( blocking )? ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )?
			{
			KW_COMPACT397=(Token)match(input,KW_COMPACT,FOLLOW_KW_COMPACT_in_alterStatementSuffixCompact7537); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COMPACT.add(KW_COMPACT397);

			compactType=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixCompact7541); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(compactType);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1581:44: ( blocking )?
			int alt109=2;
			int LA109_0 = input.LA(1);
			if ( (LA109_0==KW_AND) ) {
				alt109=1;
			}
			switch (alt109) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1581:44: blocking
					{
					pushFollow(FOLLOW_blocking_in_alterStatementSuffixCompact7543);
					blocking398=blocking();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_blocking.add(blocking398.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1581:54: ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )?
			int alt110=2;
			int LA110_0 = input.LA(1);
			if ( (LA110_0==KW_WITH) ) {
				alt110=1;
			}
			switch (alt110) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1581:55: KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties
					{
					KW_WITH399=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_alterStatementSuffixCompact7547); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH399);

					KW_OVERWRITE400=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_alterStatementSuffixCompact7549); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OVERWRITE.add(KW_OVERWRITE400);

					KW_TBLPROPERTIES401=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixCompact7551); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES401);

					pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixCompact7553);
					tableProperties402=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties402.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableProperties, blocking, compactType
			// token labels: compactType
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_compactType=new RewriteRuleTokenStream(adaptor,"token compactType",compactType);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1582:5: -> ^( TOK_ALTERTABLE_COMPACT $compactType ( blocking )? ( tableProperties )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1582:8: ^( TOK_ALTERTABLE_COMPACT $compactType ( blocking )? ( tableProperties )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_COMPACT, "TOK_ALTERTABLE_COMPACT"), root_1);
				adaptor.addChild(root_1, stream_compactType.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1582:46: ( blocking )?
				if ( stream_blocking.hasNext() ) {
					adaptor.addChild(root_1, stream_blocking.nextTree());
				}
				stream_blocking.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1582:56: ( tableProperties )?
				if ( stream_tableProperties.hasNext() ) {
					adaptor.addChild(root_1, stream_tableProperties.nextTree());
				}
				stream_tableProperties.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { msgs.pop(); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixCompact"


	public static class alterStatementSuffixSetOwner_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterStatementSuffixSetOwner"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1585:1: alterStatementSuffixSetOwner : KW_SET KW_OWNER principalName -> ^( TOK_ALTERTABLE_OWNER principalName ) ;
	public final HiveParser.alterStatementSuffixSetOwner_return alterStatementSuffixSetOwner() throws RecognitionException {
		HiveParser.alterStatementSuffixSetOwner_return retval = new HiveParser.alterStatementSuffixSetOwner_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET403=null;
		Token KW_OWNER404=null;
		ParserRuleReturnScope principalName405 =null;

		ASTNode KW_SET403_tree=null;
		ASTNode KW_OWNER404_tree=null;
		RewriteRuleTokenStream stream_KW_OWNER=new RewriteRuleTokenStream(adaptor,"token KW_OWNER");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		 pushMsg("alter table set owner", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:5: ( KW_SET KW_OWNER principalName -> ^( TOK_ALTERTABLE_OWNER principalName ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:7: KW_SET KW_OWNER principalName
			{
			KW_SET403=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixSetOwner7601); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET403);

			KW_OWNER404=(Token)match(input,KW_OWNER,FOLLOW_KW_OWNER_in_alterStatementSuffixSetOwner7603); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OWNER.add(KW_OWNER404);

			pushFollow(FOLLOW_principalName_in_alterStatementSuffixSetOwner7605);
			principalName405=principalName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalName.add(principalName405.getTree());
			// AST REWRITE
			// elements: principalName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1589:5: -> ^( TOK_ALTERTABLE_OWNER principalName )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1589:8: ^( TOK_ALTERTABLE_OWNER principalName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_OWNER, "TOK_ALTERTABLE_OWNER"), root_1);
				adaptor.addChild(root_1, stream_principalName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterStatementSuffixSetOwner"


	public static class fileFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "fileFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1592:1: fileFormat : ( KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
	public final HiveParser.fileFormat_return fileFormat() throws RecognitionException {
		HiveParser.fileFormat_return retval = new HiveParser.fileFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token inFmt=null;
		Token outFmt=null;
		Token serdeCls=null;
		Token inDriver=null;
		Token outDriver=null;
		Token KW_INPUTFORMAT406=null;
		Token KW_OUTPUTFORMAT407=null;
		Token KW_SERDE408=null;
		Token KW_INPUTDRIVER409=null;
		Token KW_OUTPUTDRIVER410=null;
		ParserRuleReturnScope genericSpec =null;

		ASTNode inFmt_tree=null;
		ASTNode outFmt_tree=null;
		ASTNode serdeCls_tree=null;
		ASTNode inDriver_tree=null;
		ASTNode outDriver_tree=null;
		ASTNode KW_INPUTFORMAT406_tree=null;
		ASTNode KW_OUTPUTFORMAT407_tree=null;
		ASTNode KW_SERDE408_tree=null;
		ASTNode KW_INPUTDRIVER409_tree=null;
		ASTNode KW_OUTPUTDRIVER410_tree=null;
		RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_INPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_INPUTDRIVER");
		RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
		RewriteRuleTokenStream stream_KW_OUTPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTFORMAT");
		RewriteRuleTokenStream stream_KW_OUTPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTDRIVER");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("file format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1595:5: ( KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
			int alt112=2;
			int LA112_0 = input.LA(1);
			if ( (LA112_0==KW_INPUTFORMAT) ) {
				int LA112_1 = input.LA(2);
				if ( (LA112_1==StringLiteral) ) {
					alt112=1;
				}
				else if ( (LA112_1==EOF) ) {
					alt112=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 112, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( (LA112_0==Identifier||(LA112_0 >= KW_ABORT && LA112_0 <= KW_AFTER)||LA112_0==KW_ALLOC_FRACTION||LA112_0==KW_ANALYZE||LA112_0==KW_ARCHIVE||(LA112_0 >= KW_ASC && LA112_0 <= KW_AT)||(LA112_0 >= KW_AUTOCOMMIT && LA112_0 <= KW_BEFORE)||(LA112_0 >= KW_BUCKET && LA112_0 <= KW_BUCKETS)||(LA112_0 >= KW_CACHE && LA112_0 <= KW_CASCADE)||(LA112_0 >= KW_CBO && LA112_0 <= KW_CHANGE)||(LA112_0 >= KW_CHECK && LA112_0 <= KW_COLLECTION)||(LA112_0 >= KW_COLUMNS && LA112_0 <= KW_COMMENT)||(LA112_0 >= KW_COMPACT && LA112_0 <= KW_CONCATENATE)||(LA112_0 >= KW_CONTINUE && LA112_0 <= KW_COST)||LA112_0==KW_CRON||LA112_0==KW_DATA||LA112_0==KW_DATABASES||(LA112_0 >= KW_DATETIME && LA112_0 <= KW_DEBUG)||(LA112_0 >= KW_DEFAULT && LA112_0 <= KW_DEFINED)||(LA112_0 >= KW_DELIMITED && LA112_0 <= KW_DESC)||(LA112_0 >= KW_DETAIL && LA112_0 <= KW_DISABLE)||(LA112_0 >= KW_DISTRIBUTE && LA112_0 <= KW_DO)||LA112_0==KW_DOW||(LA112_0 >= KW_DUMP && LA112_0 <= KW_ELEM_TYPE)||LA112_0==KW_ENABLE||(LA112_0 >= KW_ENFORCED && LA112_0 <= KW_EVERY)||(LA112_0 >= KW_EXCLUSIVE && LA112_0 <= KW_EXECUTED)||(LA112_0 >= KW_EXPLAIN && LA112_0 <= KW_EXPRESSION)||(LA112_0 >= KW_FIELDS && LA112_0 <= KW_FIRST)||(LA112_0 >= KW_FORMAT && LA112_0 <= KW_FORMATTED)||LA112_0==KW_FUNCTIONS||(LA112_0 >= KW_HOUR && LA112_0 <= KW_IDXPROPERTIES)||(LA112_0 >= KW_INDEX && LA112_0 <= KW_INDEXES)||(LA112_0 >= KW_INPATH && LA112_0 <= KW_INPUTDRIVER)||(LA112_0 >= KW_ISOLATION && LA112_0 <= KW_JAR)||(LA112_0 >= KW_JOINCOST && LA112_0 <= KW_LAST)||LA112_0==KW_LEVEL||(LA112_0 >= KW_LIMIT && LA112_0 <= KW_LOAD)||(LA112_0 >= KW_LOCATION && LA112_0 <= KW_LONG)||(LA112_0 >= KW_MANAGEDLOCATION && LA112_0 <= KW_MANAGEMENT)||(LA112_0 >= KW_MAPJOIN && LA112_0 <= KW_MATERIALIZED)||LA112_0==KW_METADATA||(LA112_0 >= KW_MINUTE && LA112_0 <= KW_MONTH)||(LA112_0 >= KW_MOVE && LA112_0 <= KW_MSCK)||(LA112_0 >= KW_NORELY && LA112_0 <= KW_NOSCAN)||LA112_0==KW_NOVALIDATE||LA112_0==KW_NULLS||LA112_0==KW_OFFSET||(LA112_0 >= KW_OPERATOR && LA112_0 <= KW_OPTION)||(LA112_0 >= KW_OUTPUTDRIVER && LA112_0 <= KW_OUTPUTFORMAT)||(LA112_0 >= KW_OVERWRITE && LA112_0 <= KW_OWNER)||(LA112_0 >= KW_PARTITIONED && LA112_0 <= KW_PATH)||(LA112_0 >= KW_PLAN && LA112_0 <= KW_POOL)||LA112_0==KW_PRINCIPALS||(LA112_0 >= KW_PURGE && LA112_0 <= KW_QUERY_PARALLELISM)||LA112_0==KW_READ||(LA112_0 >= KW_REBUILD && LA112_0 <= KW_RECORDWRITER)||(LA112_0 >= KW_RELOAD && LA112_0 <= KW_RESTRICT)||LA112_0==KW_REWRITE||(LA112_0 >= KW_ROLE && LA112_0 <= KW_ROLES)||(LA112_0 >= KW_SCHEDULED && LA112_0 <= KW_SECOND)||(LA112_0 >= KW_SEMI && LA112_0 <= KW_SERVER)||(LA112_0 >= KW_SETS && LA112_0 <= KW_SKEWED)||(LA112_0 >= KW_SNAPSHOT && LA112_0 <= KW_SSL)||(LA112_0 >= KW_STATISTICS && LA112_0 <= KW_SUMMARY)||LA112_0==KW_TABLES||(LA112_0 >= KW_TBLPROPERTIES && LA112_0 <= KW_TERMINATED)||LA112_0==KW_TINYINT||(LA112_0 >= KW_TOUCH && LA112_0 <= KW_TRANSACTIONS)||LA112_0==KW_UNARCHIVE||LA112_0==KW_UNDO||LA112_0==KW_UNIONTYPE||(LA112_0 >= KW_UNLOCK && LA112_0 <= KW_UNSIGNED)||(LA112_0 >= KW_URI && LA112_0 <= KW_USE)||(LA112_0 >= KW_UTC && LA112_0 <= KW_VALIDATE)||LA112_0==KW_VALUE_TYPE||(LA112_0 >= KW_VECTORIZATION && LA112_0 <= KW_WEEK)||LA112_0==KW_WHILE||(LA112_0 >= KW_WORK && LA112_0 <= KW_ZONE)||LA112_0==KW_BATCH||LA112_0==KW_DAYOFWEEK||LA112_0==KW_HOLD_DDLTIME||LA112_0==KW_IGNORE||LA112_0==KW_NO_DROP||LA112_0==KW_OFFLINE||LA112_0==KW_PROTECTION||LA112_0==KW_READONLY||LA112_0==KW_TIMESTAMPTZ) ) {
				alt112=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 112, 0, input);
				throw nvae;
			}

			switch (alt112) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1595:7: KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
					{
					KW_INPUTFORMAT406=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_fileFormat7644); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT406);

					inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat7648); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(inFmt);

					KW_OUTPUTFORMAT407=(Token)match(input,KW_OUTPUTFORMAT,FOLLOW_KW_OUTPUTFORMAT_in_fileFormat7650); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT407);

					outFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat7654); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(outFmt);

					KW_SERDE408=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_fileFormat7656); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE408);

					serdeCls=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat7660); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(serdeCls);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1595:111: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
					int alt111=2;
					int LA111_0 = input.LA(1);
					if ( (LA111_0==KW_INPUTDRIVER) ) {
						alt111=1;
					}
					switch (alt111) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1595:112: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
							{
							KW_INPUTDRIVER409=(Token)match(input,KW_INPUTDRIVER,FOLLOW_KW_INPUTDRIVER_in_fileFormat7663); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER409);

							inDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat7667); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(inDriver);

							KW_OUTPUTDRIVER410=(Token)match(input,KW_OUTPUTDRIVER,FOLLOW_KW_OUTPUTDRIVER_in_fileFormat7669); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER410);

							outDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat7673); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(outDriver);

							}
							break;

					}

					// AST REWRITE
					// elements: outFmt, outDriver, inFmt, inDriver, serdeCls
					// token labels: inFmt, inDriver, outDriver, serdeCls, outFmt
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
					RewriteRuleTokenStream stream_inDriver=new RewriteRuleTokenStream(adaptor,"token inDriver",inDriver);
					RewriteRuleTokenStream stream_outDriver=new RewriteRuleTokenStream(adaptor,"token outDriver",outDriver);
					RewriteRuleTokenStream stream_serdeCls=new RewriteRuleTokenStream(adaptor,"token serdeCls",serdeCls);
					RewriteRuleTokenStream stream_outFmt=new RewriteRuleTokenStream(adaptor,"token outFmt",outFmt);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1596:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1596:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT"), root_1);
						adaptor.addChild(root_1, stream_inFmt.nextNode());
						adaptor.addChild(root_1, stream_outFmt.nextNode());
						adaptor.addChild(root_1, stream_serdeCls.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1596:58: ( $inDriver)?
						if ( stream_inDriver.hasNext() ) {
							adaptor.addChild(root_1, stream_inDriver.nextNode());
						}
						stream_inDriver.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1596:69: ( $outDriver)?
						if ( stream_outDriver.hasNext() ) {
							adaptor.addChild(root_1, stream_outDriver.nextNode());
						}
						stream_outDriver.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1597:7: genericSpec= identifier
					{
					pushFollow(FOLLOW_identifier_in_fileFormat7714);
					genericSpec=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(genericSpec.getTree());
					// AST REWRITE
					// elements: genericSpec
					// token labels: 
					// rule labels: genericSpec, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_genericSpec=new RewriteRuleSubtreeStream(adaptor,"rule genericSpec",genericSpec!=null?genericSpec.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1597:30: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1597:33: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC"), root_1);
						adaptor.addChild(root_1, stream_genericSpec.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "fileFormat"


	public static class inputFileFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "inputFileFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:1: inputFileFormat : KW_INPUTFORMAT inFmt= StringLiteral KW_SERDE serdeCls= StringLiteral -> ^( TOK_INPUTFORMAT $inFmt $serdeCls) ;
	public final HiveParser.inputFileFormat_return inputFileFormat() throws RecognitionException {
		HiveParser.inputFileFormat_return retval = new HiveParser.inputFileFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token inFmt=null;
		Token serdeCls=null;
		Token KW_INPUTFORMAT411=null;
		Token KW_SERDE412=null;

		ASTNode inFmt_tree=null;
		ASTNode serdeCls_tree=null;
		ASTNode KW_INPUTFORMAT411_tree=null;
		ASTNode KW_SERDE412_tree=null;
		RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");

		 pushMsg("Load Data input file format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:5: ( KW_INPUTFORMAT inFmt= StringLiteral KW_SERDE serdeCls= StringLiteral -> ^( TOK_INPUTFORMAT $inFmt $serdeCls) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:7: KW_INPUTFORMAT inFmt= StringLiteral KW_SERDE serdeCls= StringLiteral
			{
			KW_INPUTFORMAT411=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_inputFileFormat7750); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT411);

			inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_inputFileFormat7754); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(inFmt);

			KW_SERDE412=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_inputFileFormat7756); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE412);

			serdeCls=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_inputFileFormat7760); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(serdeCls);

			// AST REWRITE
			// elements: inFmt, serdeCls
			// token labels: inFmt, serdeCls
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
			RewriteRuleTokenStream stream_serdeCls=new RewriteRuleTokenStream(adaptor,"token serdeCls",serdeCls);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1604:7: -> ^( TOK_INPUTFORMAT $inFmt $serdeCls)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1604:10: ^( TOK_INPUTFORMAT $inFmt $serdeCls)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INPUTFORMAT, "TOK_INPUTFORMAT"), root_1);
				adaptor.addChild(root_1, stream_inFmt.nextNode());
				adaptor.addChild(root_1, stream_serdeCls.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "inputFileFormat"


	public static class tabTypeExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tabTypeExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1607:1: tabTypeExpr : identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )? ;
	public final HiveParser.tabTypeExpr_return tabTypeExpr() throws RecognitionException {
		HiveParser.tabTypeExpr_return retval = new HiveParser.tabTypeExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token DOT414=null;
		Token DOT417=null;
		Token KW_ELEM_TYPE418=null;
		Token KW_KEY_TYPE419=null;
		Token KW_VALUE_TYPE420=null;
		ParserRuleReturnScope identifier413 =null;
		ParserRuleReturnScope identifier415 =null;
		ParserRuleReturnScope identifier416 =null;
		ParserRuleReturnScope identifier421 =null;

		ASTNode DOT414_tree=null;
		ASTNode DOT417_tree=null;
		ASTNode KW_ELEM_TYPE418_tree=null;
		ASTNode KW_KEY_TYPE419_tree=null;
		ASTNode KW_VALUE_TYPE420_tree=null;

		 pushMsg("specifying table types", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1610:4: ( identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1610:6: identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )?
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_identifier_in_tabTypeExpr7804);
			identifier413=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier413.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1610:17: ( DOT ^ identifier )?
			int alt113=2;
			int LA113_0 = input.LA(1);
			if ( (LA113_0==DOT) ) {
				alt113=1;
			}
			switch (alt113) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1610:18: DOT ^ identifier
					{
					DOT414=(Token)match(input,DOT,FOLLOW_DOT_in_tabTypeExpr7807); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					DOT414_tree = (ASTNode)adaptor.create(DOT414);
					root_0 = (ASTNode)adaptor.becomeRoot(DOT414_tree, root_0);
					}

					pushFollow(FOLLOW_identifier_in_tabTypeExpr7810);
					identifier415=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier415.getTree());

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:4: ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )?
			int alt116=2;
			int LA116_0 = input.LA(1);
			if ( (LA116_0==Identifier||(LA116_0 >= KW_ABORT && LA116_0 <= KW_AFTER)||LA116_0==KW_ALLOC_FRACTION||LA116_0==KW_ANALYZE||LA116_0==KW_ARCHIVE||(LA116_0 >= KW_ASC && LA116_0 <= KW_AT)||(LA116_0 >= KW_AUTOCOMMIT && LA116_0 <= KW_BEFORE)||(LA116_0 >= KW_BUCKET && LA116_0 <= KW_BUCKETS)||(LA116_0 >= KW_CACHE && LA116_0 <= KW_CASCADE)||(LA116_0 >= KW_CBO && LA116_0 <= KW_CHANGE)||(LA116_0 >= KW_CHECK && LA116_0 <= KW_COLLECTION)||(LA116_0 >= KW_COLUMNS && LA116_0 <= KW_COMMENT)||(LA116_0 >= KW_COMPACT && LA116_0 <= KW_CONCATENATE)||(LA116_0 >= KW_CONTINUE && LA116_0 <= KW_COST)||LA116_0==KW_CRON||LA116_0==KW_DATA||LA116_0==KW_DATABASES||(LA116_0 >= KW_DATETIME && LA116_0 <= KW_DEBUG)||(LA116_0 >= KW_DEFAULT && LA116_0 <= KW_DEFINED)||(LA116_0 >= KW_DELIMITED && LA116_0 <= KW_DESC)||(LA116_0 >= KW_DETAIL && LA116_0 <= KW_DISABLE)||(LA116_0 >= KW_DISTRIBUTE && LA116_0 <= KW_DO)||LA116_0==KW_DOW||(LA116_0 >= KW_DUMP && LA116_0 <= KW_ELEM_TYPE)||LA116_0==KW_ENABLE||(LA116_0 >= KW_ENFORCED && LA116_0 <= KW_EVERY)||(LA116_0 >= KW_EXCLUSIVE && LA116_0 <= KW_EXECUTED)||(LA116_0 >= KW_EXPLAIN && LA116_0 <= KW_EXPRESSION)||(LA116_0 >= KW_FIELDS && LA116_0 <= KW_FIRST)||(LA116_0 >= KW_FORMAT && LA116_0 <= KW_FORMATTED)||LA116_0==KW_FUNCTIONS||(LA116_0 >= KW_HOUR && LA116_0 <= KW_IDXPROPERTIES)||(LA116_0 >= KW_INDEX && LA116_0 <= KW_INDEXES)||(LA116_0 >= KW_INPATH && LA116_0 <= KW_INPUTFORMAT)||(LA116_0 >= KW_ISOLATION && LA116_0 <= KW_JAR)||(LA116_0 >= KW_JOINCOST && LA116_0 <= KW_LAST)||LA116_0==KW_LEVEL||(LA116_0 >= KW_LIMIT && LA116_0 <= KW_LOAD)||(LA116_0 >= KW_LOCATION && LA116_0 <= KW_LONG)||(LA116_0 >= KW_MANAGEDLOCATION && LA116_0 <= KW_MANAGEMENT)||(LA116_0 >= KW_MAPJOIN && LA116_0 <= KW_MATERIALIZED)||LA116_0==KW_METADATA||(LA116_0 >= KW_MINUTE && LA116_0 <= KW_MONTH)||(LA116_0 >= KW_MOVE && LA116_0 <= KW_MSCK)||(LA116_0 >= KW_NORELY && LA116_0 <= KW_NOSCAN)||LA116_0==KW_NOVALIDATE||LA116_0==KW_NULLS||LA116_0==KW_OFFSET||(LA116_0 >= KW_OPERATOR && LA116_0 <= KW_OPTION)||(LA116_0 >= KW_OUTPUTDRIVER && LA116_0 <= KW_OUTPUTFORMAT)||(LA116_0 >= KW_OVERWRITE && LA116_0 <= KW_OWNER)||(LA116_0 >= KW_PARTITIONED && LA116_0 <= KW_PATH)||(LA116_0 >= KW_PLAN && LA116_0 <= KW_POOL)||LA116_0==KW_PRINCIPALS||(LA116_0 >= KW_PURGE && LA116_0 <= KW_QUERY_PARALLELISM)||LA116_0==KW_READ||(LA116_0 >= KW_REBUILD && LA116_0 <= KW_RECORDWRITER)||(LA116_0 >= KW_RELOAD && LA116_0 <= KW_RESTRICT)||LA116_0==KW_REWRITE||(LA116_0 >= KW_ROLE && LA116_0 <= KW_ROLES)||(LA116_0 >= KW_SCHEDULED && LA116_0 <= KW_SECOND)||(LA116_0 >= KW_SEMI && LA116_0 <= KW_SERVER)||(LA116_0 >= KW_SETS && LA116_0 <= KW_SKEWED)||(LA116_0 >= KW_SNAPSHOT && LA116_0 <= KW_SSL)||(LA116_0 >= KW_STATISTICS && LA116_0 <= KW_SUMMARY)||LA116_0==KW_TABLES||(LA116_0 >= KW_TBLPROPERTIES && LA116_0 <= KW_TERMINATED)||LA116_0==KW_TINYINT||(LA116_0 >= KW_TOUCH && LA116_0 <= KW_TRANSACTIONS)||LA116_0==KW_UNARCHIVE||LA116_0==KW_UNDO||LA116_0==KW_UNIONTYPE||(LA116_0 >= KW_UNLOCK && LA116_0 <= KW_UNSIGNED)||(LA116_0 >= KW_URI && LA116_0 <= KW_USE)||(LA116_0 >= KW_UTC && LA116_0 <= KW_VALIDATE)||LA116_0==KW_VALUE_TYPE||(LA116_0 >= KW_VECTORIZATION && LA116_0 <= KW_WEEK)||LA116_0==KW_WHILE||(LA116_0 >= KW_WORK && LA116_0 <= KW_ZONE)||LA116_0==KW_BATCH||LA116_0==KW_DAYOFWEEK||LA116_0==KW_HOLD_DDLTIME||LA116_0==KW_IGNORE||LA116_0==KW_NO_DROP||LA116_0==KW_OFFLINE||LA116_0==KW_PROTECTION||LA116_0==KW_READONLY||LA116_0==KW_TIMESTAMPTZ) ) {
				alt116=1;
			}
			switch (alt116) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:5: identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
					{
					pushFollow(FOLLOW_identifier_in_tabTypeExpr7818);
					identifier416=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier416.getTree());

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:16: ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
					loop115:
					while (true) {
						int alt115=2;
						int LA115_0 = input.LA(1);
						if ( (LA115_0==DOT) ) {
							alt115=1;
						}

						switch (alt115) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:17: DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
							{
							DOT417=(Token)match(input,DOT,FOLLOW_DOT_in_tabTypeExpr7821); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							DOT417_tree = (ASTNode)adaptor.create(DOT417);
							root_0 = (ASTNode)adaptor.becomeRoot(DOT417_tree, root_0);
							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:4: ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
							int alt114=4;
							switch ( input.LA(1) ) {
							case KW_ELEM_TYPE:
								{
								int LA114_1 = input.LA(2);
								if ( (synpred4_HiveParser()) ) {
									alt114=1;
								}
								else if ( (true) ) {
									alt114=4;
								}

								}
								break;
							case KW_KEY_TYPE:
								{
								int LA114_2 = input.LA(2);
								if ( (synpred5_HiveParser()) ) {
									alt114=2;
								}
								else if ( (true) ) {
									alt114=4;
								}

								}
								break;
							case KW_VALUE_TYPE:
								{
								int LA114_3 = input.LA(2);
								if ( (synpred6_HiveParser()) ) {
									alt114=3;
								}
								else if ( (true) ) {
									alt114=4;
								}

								}
								break;
							case Identifier:
							case KW_ABORT:
							case KW_ACTIVATE:
							case KW_ACTIVE:
							case KW_ADD:
							case KW_ADMIN:
							case KW_AFTER:
							case KW_ALLOC_FRACTION:
							case KW_ANALYZE:
							case KW_ARCHIVE:
							case KW_ASC:
							case KW_AT:
							case KW_AUTOCOMMIT:
							case KW_BEFORE:
							case KW_BUCKET:
							case KW_BUCKETS:
							case KW_CACHE:
							case KW_CASCADE:
							case KW_CBO:
							case KW_CHANGE:
							case KW_CHECK:
							case KW_CLUSTER:
							case KW_CLUSTERED:
							case KW_CLUSTERSTATUS:
							case KW_COLLECTION:
							case KW_COLUMNS:
							case KW_COMMENT:
							case KW_COMPACT:
							case KW_COMPACTIONS:
							case KW_COMPUTE:
							case KW_CONCATENATE:
							case KW_CONTINUE:
							case KW_COST:
							case KW_CRON:
							case KW_DATA:
							case KW_DATABASES:
							case KW_DATETIME:
							case KW_DAY:
							case KW_DBPROPERTIES:
							case KW_DEBUG:
							case KW_DEFAULT:
							case KW_DEFERRED:
							case KW_DEFINED:
							case KW_DELIMITED:
							case KW_DEPENDENCY:
							case KW_DESC:
							case KW_DETAIL:
							case KW_DIRECTORIES:
							case KW_DIRECTORY:
							case KW_DISABLE:
							case KW_DISTRIBUTE:
							case KW_DISTRIBUTED:
							case KW_DO:
							case KW_DOW:
							case KW_DUMP:
							case KW_ENABLE:
							case KW_ENFORCED:
							case KW_ESCAPED:
							case KW_EVERY:
							case KW_EXCLUSIVE:
							case KW_EXECUTE:
							case KW_EXECUTED:
							case KW_EXPLAIN:
							case KW_EXPORT:
							case KW_EXPRESSION:
							case KW_FIELDS:
							case KW_FILE:
							case KW_FILEFORMAT:
							case KW_FIRST:
							case KW_FORMAT:
							case KW_FORMATTED:
							case KW_FUNCTIONS:
							case KW_HOUR:
							case KW_IDXPROPERTIES:
							case KW_INDEX:
							case KW_INDEXES:
							case KW_INPATH:
							case KW_INPUTDRIVER:
							case KW_INPUTFORMAT:
							case KW_ISOLATION:
							case KW_ITEMS:
							case KW_JAR:
							case KW_JOINCOST:
							case KW_KEY:
							case KW_KEYS:
							case KW_KILL:
							case KW_LAST:
							case KW_LEVEL:
							case KW_LIMIT:
							case KW_LINES:
							case KW_LOAD:
							case KW_LOCATION:
							case KW_LOCK:
							case KW_LOCKS:
							case KW_LOGICAL:
							case KW_LONG:
							case KW_MANAGEDLOCATION:
							case KW_MANAGEMENT:
							case KW_MAPJOIN:
							case KW_MAPPING:
							case KW_MATCHED:
							case KW_MATERIALIZED:
							case KW_METADATA:
							case KW_MINUTE:
							case KW_MONTH:
							case KW_MOVE:
							case KW_MSCK:
							case KW_NORELY:
							case KW_NOSCAN:
							case KW_NOVALIDATE:
							case KW_NULLS:
							case KW_OFFSET:
							case KW_OPERATOR:
							case KW_OPTION:
							case KW_OUTPUTDRIVER:
							case KW_OUTPUTFORMAT:
							case KW_OVERWRITE:
							case KW_OWNER:
							case KW_PARTITIONED:
							case KW_PARTITIONS:
							case KW_PATH:
							case KW_PLAN:
							case KW_PLANS:
							case KW_PLUS:
							case KW_POOL:
							case KW_PRINCIPALS:
							case KW_PURGE:
							case KW_QUARTER:
							case KW_QUERY:
							case KW_QUERY_PARALLELISM:
							case KW_READ:
							case KW_REBUILD:
							case KW_RECORDREADER:
							case KW_RECORDWRITER:
							case KW_RELOAD:
							case KW_RELY:
							case KW_RENAME:
							case KW_REOPTIMIZATION:
							case KW_REPAIR:
							case KW_REPL:
							case KW_REPLACE:
							case KW_REPLICATION:
							case KW_RESOURCE:
							case KW_RESTRICT:
							case KW_REWRITE:
							case KW_ROLE:
							case KW_ROLES:
							case KW_SCHEDULED:
							case KW_SCHEDULING_POLICY:
							case KW_SCHEMA:
							case KW_SCHEMAS:
							case KW_SECOND:
							case KW_SEMI:
							case KW_SERDE:
							case KW_SERDEPROPERTIES:
							case KW_SERVER:
							case KW_SETS:
							case KW_SHARED:
							case KW_SHOW:
							case KW_SHOW_DATABASE:
							case KW_SKEWED:
							case KW_SNAPSHOT:
							case KW_SORT:
							case KW_SORTED:
							case KW_SSL:
							case KW_STATISTICS:
							case KW_STATUS:
							case KW_STORED:
							case KW_STREAMTABLE:
							case KW_STRING:
							case KW_STRUCT:
							case KW_SUMMARY:
							case KW_TABLES:
							case KW_TBLPROPERTIES:
							case KW_TEMPORARY:
							case KW_TERMINATED:
							case KW_TINYINT:
							case KW_TOUCH:
							case KW_TRANSACTION:
							case KW_TRANSACTIONAL:
							case KW_TRANSACTIONS:
							case KW_UNARCHIVE:
							case KW_UNDO:
							case KW_UNIONTYPE:
							case KW_UNLOCK:
							case KW_UNMANAGED:
							case KW_UNSET:
							case KW_UNSIGNED:
							case KW_URI:
							case KW_USE:
							case KW_UTC:
							case KW_UTCTIMESTAMP:
							case KW_VALIDATE:
							case KW_VECTORIZATION:
							case KW_VIEW:
							case KW_VIEWS:
							case KW_WAIT:
							case KW_WEEK:
							case KW_WHILE:
							case KW_WORK:
							case KW_WORKLOAD:
							case KW_WRITE:
							case KW_YEAR:
							case KW_ZONE:
							case KW_BATCH:
							case KW_DAYOFWEEK:
							case KW_HOLD_DDLTIME:
							case KW_IGNORE:
							case KW_NO_DROP:
							case KW_OFFLINE:
							case KW_PROTECTION:
							case KW_READONLY:
							case KW_TIMESTAMPTZ:
								{
								alt114=4;
								}
								break;
							default:
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 114, 0, input);
								throw nvae;
							}
							switch (alt114) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:4: ( KW_ELEM_TYPE )=> KW_ELEM_TYPE
									{
									KW_ELEM_TYPE418=(Token)match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr7838); if (state.failed) return retval;
									if ( state.backtracking==0 ) {
									KW_ELEM_TYPE418_tree = (ASTNode)adaptor.create(KW_ELEM_TYPE418);
									adaptor.addChild(root_0, KW_ELEM_TYPE418_tree);
									}

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:4: ( KW_KEY_TYPE )=> KW_KEY_TYPE
									{
									KW_KEY_TYPE419=(Token)match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_tabTypeExpr7855); if (state.failed) return retval;
									if ( state.backtracking==0 ) {
									KW_KEY_TYPE419_tree = (ASTNode)adaptor.create(KW_KEY_TYPE419);
									adaptor.addChild(root_0, KW_KEY_TYPE419_tree);
									}

									}
									break;
								case 3 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:4: ( KW_VALUE_TYPE )=> KW_VALUE_TYPE
									{
									KW_VALUE_TYPE420=(Token)match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr7872); if (state.failed) return retval;
									if ( state.backtracking==0 ) {
									KW_VALUE_TYPE420_tree = (ASTNode)adaptor.create(KW_VALUE_TYPE420);
									adaptor.addChild(root_0, KW_VALUE_TYPE420_tree);
									}

									}
									break;
								case 4 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1618:6: identifier
									{
									pushFollow(FOLLOW_identifier_in_tabTypeExpr7880);
									identifier421=identifier();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier421.getTree());

									}
									break;

							}

							}
							break;

						default :
							break loop115;
						}
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tabTypeExpr"


	public static class partTypeExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "partTypeExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1623:1: partTypeExpr : tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) ;
	public final HiveParser.partTypeExpr_return partTypeExpr() throws RecognitionException {
		HiveParser.partTypeExpr_return retval = new HiveParser.partTypeExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope tabTypeExpr422 =null;
		ParserRuleReturnScope partitionSpec423 =null;

		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tabTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule tabTypeExpr");

		 pushMsg("specifying table partitions", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:5: ( tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:8: tabTypeExpr ( partitionSpec )?
			{
			pushFollow(FOLLOW_tabTypeExpr_in_partTypeExpr7920);
			tabTypeExpr422=tabTypeExpr();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tabTypeExpr.add(tabTypeExpr422.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:20: ( partitionSpec )?
			int alt117=2;
			int LA117_0 = input.LA(1);
			if ( (LA117_0==KW_PARTITION) ) {
				alt117=1;
			}
			switch (alt117) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:20: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_partTypeExpr7922);
					partitionSpec423=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec423.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: partitionSpec, tabTypeExpr
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1626:35: -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:38: ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABTYPE, "TOK_TABTYPE"), root_1);
				adaptor.addChild(root_1, stream_tabTypeExpr.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1626:64: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "partTypeExpr"


	public static class tabPartColTypeExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tabPartColTypeExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1629:1: tabPartColTypeExpr : tableName ( partitionSpec )? ( extColumnName )? -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? ) ;
	public final HiveParser.tabPartColTypeExpr_return tabPartColTypeExpr() throws RecognitionException {
		HiveParser.tabPartColTypeExpr_return retval = new HiveParser.tabPartColTypeExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope tableName424 =null;
		ParserRuleReturnScope partitionSpec425 =null;
		ParserRuleReturnScope extColumnName426 =null;

		RewriteRuleSubtreeStream stream_extColumnName=new RewriteRuleSubtreeStream(adaptor,"rule extColumnName");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("specifying table partitions columnName", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:5: ( tableName ( partitionSpec )? ( extColumnName )? -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:8: tableName ( partitionSpec )? ( extColumnName )?
			{
			pushFollow(FOLLOW_tableName_in_tabPartColTypeExpr7962);
			tableName424=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName424.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:18: ( partitionSpec )?
			int alt118=2;
			int LA118_0 = input.LA(1);
			if ( (LA118_0==KW_PARTITION) ) {
				alt118=1;
			}
			switch (alt118) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:18: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_tabPartColTypeExpr7964);
					partitionSpec425=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec425.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:33: ( extColumnName )?
			int alt119=2;
			int LA119_0 = input.LA(1);
			if ( (LA119_0==Identifier||(LA119_0 >= KW_ABORT && LA119_0 <= KW_AFTER)||LA119_0==KW_ALLOC_FRACTION||LA119_0==KW_ANALYZE||LA119_0==KW_ARCHIVE||(LA119_0 >= KW_ASC && LA119_0 <= KW_AT)||(LA119_0 >= KW_AUTOCOMMIT && LA119_0 <= KW_BEFORE)||(LA119_0 >= KW_BUCKET && LA119_0 <= KW_BUCKETS)||(LA119_0 >= KW_CACHE && LA119_0 <= KW_CASCADE)||(LA119_0 >= KW_CBO && LA119_0 <= KW_CHANGE)||(LA119_0 >= KW_CHECK && LA119_0 <= KW_COLLECTION)||(LA119_0 >= KW_COLUMNS && LA119_0 <= KW_COMMENT)||(LA119_0 >= KW_COMPACT && LA119_0 <= KW_CONCATENATE)||(LA119_0 >= KW_CONTINUE && LA119_0 <= KW_COST)||LA119_0==KW_CRON||LA119_0==KW_DATA||LA119_0==KW_DATABASES||(LA119_0 >= KW_DATETIME && LA119_0 <= KW_DEBUG)||(LA119_0 >= KW_DEFAULT && LA119_0 <= KW_DEFINED)||(LA119_0 >= KW_DELIMITED && LA119_0 <= KW_DESC)||(LA119_0 >= KW_DETAIL && LA119_0 <= KW_DISABLE)||(LA119_0 >= KW_DISTRIBUTE && LA119_0 <= KW_DO)||LA119_0==KW_DOW||(LA119_0 >= KW_DUMP && LA119_0 <= KW_ELEM_TYPE)||LA119_0==KW_ENABLE||(LA119_0 >= KW_ENFORCED && LA119_0 <= KW_EVERY)||(LA119_0 >= KW_EXCLUSIVE && LA119_0 <= KW_EXECUTED)||(LA119_0 >= KW_EXPLAIN && LA119_0 <= KW_EXPRESSION)||(LA119_0 >= KW_FIELDS && LA119_0 <= KW_FIRST)||(LA119_0 >= KW_FORMAT && LA119_0 <= KW_FORMATTED)||LA119_0==KW_FUNCTIONS||(LA119_0 >= KW_HOUR && LA119_0 <= KW_IDXPROPERTIES)||(LA119_0 >= KW_INDEX && LA119_0 <= KW_INDEXES)||(LA119_0 >= KW_INPATH && LA119_0 <= KW_INPUTFORMAT)||(LA119_0 >= KW_ISOLATION && LA119_0 <= KW_JAR)||(LA119_0 >= KW_JOINCOST && LA119_0 <= KW_LAST)||LA119_0==KW_LEVEL||(LA119_0 >= KW_LIMIT && LA119_0 <= KW_LOAD)||(LA119_0 >= KW_LOCATION && LA119_0 <= KW_LONG)||(LA119_0 >= KW_MANAGEDLOCATION && LA119_0 <= KW_MANAGEMENT)||(LA119_0 >= KW_MAPJOIN && LA119_0 <= KW_MATERIALIZED)||LA119_0==KW_METADATA||(LA119_0 >= KW_MINUTE && LA119_0 <= KW_MONTH)||(LA119_0 >= KW_MOVE && LA119_0 <= KW_MSCK)||(LA119_0 >= KW_NORELY && LA119_0 <= KW_NOSCAN)||LA119_0==KW_NOVALIDATE||LA119_0==KW_NULLS||LA119_0==KW_OFFSET||(LA119_0 >= KW_OPERATOR && LA119_0 <= KW_OPTION)||(LA119_0 >= KW_OUTPUTDRIVER && LA119_0 <= KW_OUTPUTFORMAT)||(LA119_0 >= KW_OVERWRITE && LA119_0 <= KW_OWNER)||(LA119_0 >= KW_PARTITIONED && LA119_0 <= KW_PATH)||(LA119_0 >= KW_PLAN && LA119_0 <= KW_POOL)||LA119_0==KW_PRINCIPALS||(LA119_0 >= KW_PURGE && LA119_0 <= KW_QUERY_PARALLELISM)||LA119_0==KW_READ||(LA119_0 >= KW_REBUILD && LA119_0 <= KW_RECORDWRITER)||(LA119_0 >= KW_RELOAD && LA119_0 <= KW_RESTRICT)||LA119_0==KW_REWRITE||(LA119_0 >= KW_ROLE && LA119_0 <= KW_ROLES)||(LA119_0 >= KW_SCHEDULED && LA119_0 <= KW_SECOND)||(LA119_0 >= KW_SEMI && LA119_0 <= KW_SERVER)||(LA119_0 >= KW_SETS && LA119_0 <= KW_SKEWED)||(LA119_0 >= KW_SNAPSHOT && LA119_0 <= KW_SSL)||(LA119_0 >= KW_STATISTICS && LA119_0 <= KW_SUMMARY)||LA119_0==KW_TABLES||(LA119_0 >= KW_TBLPROPERTIES && LA119_0 <= KW_TERMINATED)||LA119_0==KW_TINYINT||(LA119_0 >= KW_TOUCH && LA119_0 <= KW_TRANSACTIONS)||LA119_0==KW_UNARCHIVE||LA119_0==KW_UNDO||LA119_0==KW_UNIONTYPE||(LA119_0 >= KW_UNLOCK && LA119_0 <= KW_UNSIGNED)||(LA119_0 >= KW_URI && LA119_0 <= KW_USE)||(LA119_0 >= KW_UTC && LA119_0 <= KW_VALIDATE)||LA119_0==KW_VALUE_TYPE||(LA119_0 >= KW_VECTORIZATION && LA119_0 <= KW_WEEK)||LA119_0==KW_WHILE||(LA119_0 >= KW_WORK && LA119_0 <= KW_ZONE)||LA119_0==KW_BATCH||LA119_0==KW_DAYOFWEEK||LA119_0==KW_HOLD_DDLTIME||LA119_0==KW_IGNORE||LA119_0==KW_NO_DROP||LA119_0==KW_OFFLINE||LA119_0==KW_PROTECTION||LA119_0==KW_READONLY||LA119_0==KW_TIMESTAMPTZ) ) {
				alt119=1;
			}
			switch (alt119) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:33: extColumnName
					{
					pushFollow(FOLLOW_extColumnName_in_tabPartColTypeExpr7967);
					extColumnName426=extColumnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_extColumnName.add(extColumnName426.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableName, extColumnName, partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1632:48: -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:51: ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABTYPE, "TOK_TABTYPE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:75: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:90: ( extColumnName )?
				if ( stream_extColumnName.hasNext() ) {
					adaptor.addChild(root_1, stream_extColumnName.nextTree());
				}
				stream_extColumnName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tabPartColTypeExpr"


	public static class descStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "descStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1635:1: descStatement : ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) ) ;
	public final HiveParser.descStatement_return descStatement() throws RecognitionException {
		HiveParser.descStatement_return retval = new HiveParser.descStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token descOptions=null;
		Token KW_DESCRIBE427=null;
		Token KW_DESC428=null;
		Token KW_DATABASE429=null;
		Token KW_SCHEMA430=null;
		Token KW_EXTENDED431=null;
		Token KW_FUNCTION432=null;
		Token KW_EXTENDED433=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope parttype =null;

		ASTNode descOptions_tree=null;
		ASTNode KW_DESCRIBE427_tree=null;
		ASTNode KW_DESC428_tree=null;
		ASTNode KW_DATABASE429_tree=null;
		ASTNode KW_SCHEMA430_tree=null;
		ASTNode KW_EXTENDED431_tree=null;
		ASTNode KW_FUNCTION432_tree=null;
		ASTNode KW_EXTENDED433_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_EXTENDED=new RewriteRuleTokenStream(adaptor,"token KW_EXTENDED");
		RewriteRuleTokenStream stream_KW_DESC=new RewriteRuleTokenStream(adaptor,"token KW_DESC");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleTokenStream stream_KW_FORMATTED=new RewriteRuleTokenStream(adaptor,"token KW_FORMATTED");
		RewriteRuleTokenStream stream_KW_DESCRIBE=new RewriteRuleTokenStream(adaptor,"token KW_DESCRIBE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tabPartColTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule tabPartColTypeExpr");
		RewriteRuleSubtreeStream stream_descFuncNames=new RewriteRuleSubtreeStream(adaptor,"rule descFuncNames");

		 pushMsg("describe statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1638:5: ( ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1639:5: ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) )
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1639:5: ( KW_DESCRIBE | KW_DESC )
			int alt120=2;
			int LA120_0 = input.LA(1);
			if ( (LA120_0==KW_DESCRIBE) ) {
				alt120=1;
			}
			else if ( (LA120_0==KW_DESC) ) {
				alt120=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 120, 0, input);
				throw nvae;
			}

			switch (alt120) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1639:6: KW_DESCRIBE
					{
					KW_DESCRIBE427=(Token)match(input,KW_DESCRIBE,FOLLOW_KW_DESCRIBE_in_descStatement8014); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DESCRIBE.add(KW_DESCRIBE427);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1639:18: KW_DESC
					{
					KW_DESC428=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_descStatement8016); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DESC.add(KW_DESC428);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:5: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) )
			int alt125=4;
			int LA125_0 = input.LA(1);
			if ( (LA125_0==KW_DATABASE) && (synpred7_HiveParser())) {
				alt125=1;
			}
			else if ( (LA125_0==KW_SCHEMA) ) {
				int LA125_2 = input.LA(2);
				if ( (LA125_2==KW_EXTENDED) && (synpred7_HiveParser())) {
					alt125=1;
				}
				else if ( (LA125_2==Identifier) ) {
					int LA125_9 = input.LA(3);
					if ( (synpred7_HiveParser()) ) {
						alt125=1;
					}
					else if ( (true) ) {
						alt125=4;
					}

				}
				else if ( ((LA125_2 >= KW_ABORT && LA125_2 <= KW_AFTER)||LA125_2==KW_ALLOC_FRACTION||LA125_2==KW_ANALYZE||LA125_2==KW_ARCHIVE||(LA125_2 >= KW_ASC && LA125_2 <= KW_AT)||(LA125_2 >= KW_AUTOCOMMIT && LA125_2 <= KW_BEFORE)||(LA125_2 >= KW_BUCKET && LA125_2 <= KW_BUCKETS)||(LA125_2 >= KW_CACHE && LA125_2 <= KW_CASCADE)||(LA125_2 >= KW_CBO && LA125_2 <= KW_CHANGE)||(LA125_2 >= KW_CHECK && LA125_2 <= KW_COLLECTION)||(LA125_2 >= KW_COLUMNS && LA125_2 <= KW_COMMENT)||(LA125_2 >= KW_COMPACT && LA125_2 <= KW_CONCATENATE)||(LA125_2 >= KW_CONTINUE && LA125_2 <= KW_COST)||LA125_2==KW_CRON||LA125_2==KW_DATA||LA125_2==KW_DATABASES||(LA125_2 >= KW_DATETIME && LA125_2 <= KW_DEBUG)||(LA125_2 >= KW_DEFAULT && LA125_2 <= KW_DEFINED)||(LA125_2 >= KW_DELIMITED && LA125_2 <= KW_DESC)||(LA125_2 >= KW_DETAIL && LA125_2 <= KW_DISABLE)||(LA125_2 >= KW_DISTRIBUTE && LA125_2 <= KW_DO)||LA125_2==KW_DOW||(LA125_2 >= KW_DUMP && LA125_2 <= KW_ELEM_TYPE)||LA125_2==KW_ENABLE||(LA125_2 >= KW_ENFORCED && LA125_2 <= KW_EVERY)||(LA125_2 >= KW_EXCLUSIVE && LA125_2 <= KW_EXECUTED)||(LA125_2 >= KW_EXPLAIN && LA125_2 <= KW_EXPRESSION)||(LA125_2 >= KW_FIELDS && LA125_2 <= KW_FIRST)||(LA125_2 >= KW_FORMAT && LA125_2 <= KW_FORMATTED)||LA125_2==KW_FUNCTIONS||(LA125_2 >= KW_HOUR && LA125_2 <= KW_IDXPROPERTIES)||(LA125_2 >= KW_INDEX && LA125_2 <= KW_INDEXES)||(LA125_2 >= KW_INPATH && LA125_2 <= KW_INPUTFORMAT)||(LA125_2 >= KW_ISOLATION && LA125_2 <= KW_JAR)||(LA125_2 >= KW_JOINCOST && LA125_2 <= KW_LAST)||LA125_2==KW_LEVEL||(LA125_2 >= KW_LIMIT && LA125_2 <= KW_LOAD)||(LA125_2 >= KW_LOCATION && LA125_2 <= KW_LONG)||(LA125_2 >= KW_MANAGEDLOCATION && LA125_2 <= KW_MANAGEMENT)||(LA125_2 >= KW_MAPJOIN && LA125_2 <= KW_MATERIALIZED)||LA125_2==KW_METADATA||(LA125_2 >= KW_MINUTE && LA125_2 <= KW_MONTH)||(LA125_2 >= KW_MOVE && LA125_2 <= KW_MSCK)||(LA125_2 >= KW_NORELY && LA125_2 <= KW_NOSCAN)||LA125_2==KW_NOVALIDATE||LA125_2==KW_NULLS||LA125_2==KW_OFFSET||(LA125_2 >= KW_OPERATOR && LA125_2 <= KW_OPTION)||(LA125_2 >= KW_OUTPUTDRIVER && LA125_2 <= KW_OUTPUTFORMAT)||(LA125_2 >= KW_OVERWRITE && LA125_2 <= KW_OWNER)||(LA125_2 >= KW_PARTITIONED && LA125_2 <= KW_PATH)||(LA125_2 >= KW_PLAN && LA125_2 <= KW_POOL)||LA125_2==KW_PRINCIPALS||(LA125_2 >= KW_PURGE && LA125_2 <= KW_QUERY_PARALLELISM)||LA125_2==KW_READ||(LA125_2 >= KW_REBUILD && LA125_2 <= KW_RECORDWRITER)||(LA125_2 >= KW_RELOAD && LA125_2 <= KW_RESTRICT)||LA125_2==KW_REWRITE||(LA125_2 >= KW_ROLE && LA125_2 <= KW_ROLES)||(LA125_2 >= KW_SCHEDULED && LA125_2 <= KW_SECOND)||(LA125_2 >= KW_SEMI && LA125_2 <= KW_SERVER)||(LA125_2 >= KW_SETS && LA125_2 <= KW_SKEWED)||(LA125_2 >= KW_SNAPSHOT && LA125_2 <= KW_SSL)||(LA125_2 >= KW_STATISTICS && LA125_2 <= KW_SUMMARY)||LA125_2==KW_TABLES||(LA125_2 >= KW_TBLPROPERTIES && LA125_2 <= KW_TERMINATED)||LA125_2==KW_TINYINT||(LA125_2 >= KW_TOUCH && LA125_2 <= KW_TRANSACTIONS)||LA125_2==KW_UNARCHIVE||LA125_2==KW_UNDO||LA125_2==KW_UNIONTYPE||(LA125_2 >= KW_UNLOCK && LA125_2 <= KW_UNSIGNED)||(LA125_2 >= KW_URI && LA125_2 <= KW_USE)||(LA125_2 >= KW_UTC && LA125_2 <= KW_VALIDATE)||LA125_2==KW_VALUE_TYPE||(LA125_2 >= KW_VECTORIZATION && LA125_2 <= KW_WEEK)||LA125_2==KW_WHILE||(LA125_2 >= KW_WORK && LA125_2 <= KW_ZONE)||LA125_2==KW_BATCH||LA125_2==KW_DAYOFWEEK||LA125_2==KW_HOLD_DDLTIME||LA125_2==KW_IGNORE||LA125_2==KW_NO_DROP||LA125_2==KW_OFFLINE||LA125_2==KW_PROTECTION||LA125_2==KW_READONLY||LA125_2==KW_TIMESTAMPTZ) ) {
					int LA125_10 = input.LA(3);
					if ( (synpred7_HiveParser()) ) {
						alt125=1;
					}
					else if ( (true) ) {
						alt125=4;
					}

				}
				else if ( (LA125_2==EOF||LA125_2==DOT||LA125_2==KW_PARTITION) ) {
					alt125=4;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 125, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( (LA125_0==KW_FUNCTION) && (synpred8_HiveParser())) {
				alt125=2;
			}
			else if ( (LA125_0==KW_FORMATTED) ) {
				switch ( input.LA(2) ) {
				case Identifier:
					{
					int LA125_14 = input.LA(3);
					if ( (synpred9_HiveParser()) ) {
						alt125=3;
					}
					else if ( (true) ) {
						alt125=4;
					}

					}
					break;
				case KW_ABORT:
				case KW_ACTIVATE:
				case KW_ACTIVE:
				case KW_ADD:
				case KW_ADMIN:
				case KW_AFTER:
				case KW_ALLOC_FRACTION:
				case KW_ANALYZE:
				case KW_ARCHIVE:
				case KW_ASC:
				case KW_AT:
				case KW_AUTOCOMMIT:
				case KW_BEFORE:
				case KW_BUCKET:
				case KW_BUCKETS:
				case KW_CACHE:
				case KW_CASCADE:
				case KW_CBO:
				case KW_CHANGE:
				case KW_CHECK:
				case KW_CLUSTER:
				case KW_CLUSTERED:
				case KW_CLUSTERSTATUS:
				case KW_COLLECTION:
				case KW_COLUMNS:
				case KW_COMMENT:
				case KW_COMPACT:
				case KW_COMPACTIONS:
				case KW_COMPUTE:
				case KW_CONCATENATE:
				case KW_CONTINUE:
				case KW_COST:
				case KW_CRON:
				case KW_DATA:
				case KW_DATABASES:
				case KW_DATETIME:
				case KW_DAY:
				case KW_DBPROPERTIES:
				case KW_DEBUG:
				case KW_DEFAULT:
				case KW_DEFERRED:
				case KW_DEFINED:
				case KW_DELIMITED:
				case KW_DEPENDENCY:
				case KW_DESC:
				case KW_DETAIL:
				case KW_DIRECTORIES:
				case KW_DIRECTORY:
				case KW_DISABLE:
				case KW_DISTRIBUTE:
				case KW_DISTRIBUTED:
				case KW_DO:
				case KW_DOW:
				case KW_DUMP:
				case KW_ELEM_TYPE:
				case KW_ENABLE:
				case KW_ENFORCED:
				case KW_ESCAPED:
				case KW_EVERY:
				case KW_EXCLUSIVE:
				case KW_EXECUTE:
				case KW_EXECUTED:
				case KW_EXPLAIN:
				case KW_EXPORT:
				case KW_EXPRESSION:
				case KW_FIELDS:
				case KW_FILE:
				case KW_FILEFORMAT:
				case KW_FIRST:
				case KW_FORMAT:
				case KW_FORMATTED:
				case KW_FUNCTIONS:
				case KW_HOUR:
				case KW_IDXPROPERTIES:
				case KW_INDEX:
				case KW_INDEXES:
				case KW_INPATH:
				case KW_INPUTDRIVER:
				case KW_INPUTFORMAT:
				case KW_ISOLATION:
				case KW_ITEMS:
				case KW_JAR:
				case KW_JOINCOST:
				case KW_KEY:
				case KW_KEYS:
				case KW_KEY_TYPE:
				case KW_KILL:
				case KW_LAST:
				case KW_LEVEL:
				case KW_LIMIT:
				case KW_LINES:
				case KW_LOAD:
				case KW_LOCATION:
				case KW_LOCK:
				case KW_LOCKS:
				case KW_LOGICAL:
				case KW_LONG:
				case KW_MANAGEDLOCATION:
				case KW_MANAGEMENT:
				case KW_MAPJOIN:
				case KW_MAPPING:
				case KW_MATCHED:
				case KW_MATERIALIZED:
				case KW_METADATA:
				case KW_MINUTE:
				case KW_MONTH:
				case KW_MOVE:
				case KW_MSCK:
				case KW_NORELY:
				case KW_NOSCAN:
				case KW_NOVALIDATE:
				case KW_NULLS:
				case KW_OFFSET:
				case KW_OPERATOR:
				case KW_OPTION:
				case KW_OUTPUTDRIVER:
				case KW_OUTPUTFORMAT:
				case KW_OVERWRITE:
				case KW_OWNER:
				case KW_PARTITIONED:
				case KW_PARTITIONS:
				case KW_PATH:
				case KW_PLAN:
				case KW_PLANS:
				case KW_PLUS:
				case KW_POOL:
				case KW_PRINCIPALS:
				case KW_PURGE:
				case KW_QUARTER:
				case KW_QUERY:
				case KW_QUERY_PARALLELISM:
				case KW_READ:
				case KW_REBUILD:
				case KW_RECORDREADER:
				case KW_RECORDWRITER:
				case KW_RELOAD:
				case KW_RELY:
				case KW_RENAME:
				case KW_REOPTIMIZATION:
				case KW_REPAIR:
				case KW_REPL:
				case KW_REPLACE:
				case KW_REPLICATION:
				case KW_RESOURCE:
				case KW_RESTRICT:
				case KW_REWRITE:
				case KW_ROLE:
				case KW_ROLES:
				case KW_SCHEDULED:
				case KW_SCHEDULING_POLICY:
				case KW_SCHEMA:
				case KW_SCHEMAS:
				case KW_SECOND:
				case KW_SEMI:
				case KW_SERDE:
				case KW_SERDEPROPERTIES:
				case KW_SERVER:
				case KW_SETS:
				case KW_SHARED:
				case KW_SHOW:
				case KW_SHOW_DATABASE:
				case KW_SKEWED:
				case KW_SNAPSHOT:
				case KW_SORT:
				case KW_SORTED:
				case KW_SSL:
				case KW_STATISTICS:
				case KW_STATUS:
				case KW_STORED:
				case KW_STREAMTABLE:
				case KW_STRING:
				case KW_STRUCT:
				case KW_SUMMARY:
				case KW_TABLES:
				case KW_TBLPROPERTIES:
				case KW_TEMPORARY:
				case KW_TERMINATED:
				case KW_TINYINT:
				case KW_TOUCH:
				case KW_TRANSACTION:
				case KW_TRANSACTIONAL:
				case KW_TRANSACTIONS:
				case KW_UNARCHIVE:
				case KW_UNDO:
				case KW_UNIONTYPE:
				case KW_UNLOCK:
				case KW_UNMANAGED:
				case KW_UNSET:
				case KW_UNSIGNED:
				case KW_URI:
				case KW_USE:
				case KW_UTC:
				case KW_UTCTIMESTAMP:
				case KW_VALIDATE:
				case KW_VALUE_TYPE:
				case KW_VECTORIZATION:
				case KW_VIEW:
				case KW_VIEWS:
				case KW_WAIT:
				case KW_WEEK:
				case KW_WHILE:
				case KW_WORK:
				case KW_WORKLOAD:
				case KW_WRITE:
				case KW_YEAR:
				case KW_ZONE:
				case KW_BATCH:
				case KW_DAYOFWEEK:
				case KW_HOLD_DDLTIME:
				case KW_IGNORE:
				case KW_NO_DROP:
				case KW_OFFLINE:
				case KW_PROTECTION:
				case KW_READONLY:
				case KW_TIMESTAMPTZ:
					{
					int LA125_15 = input.LA(3);
					if ( (synpred9_HiveParser()) ) {
						alt125=3;
					}
					else if ( (true) ) {
						alt125=4;
					}

					}
					break;
				case EOF:
				case DOT:
				case KW_PARTITION:
					{
					alt125=4;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 125, 4, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
			}
			else if ( (LA125_0==KW_EXTENDED) && (synpred9_HiveParser())) {
				alt125=3;
			}
			else if ( (LA125_0==Identifier||(LA125_0 >= KW_ABORT && LA125_0 <= KW_AFTER)||LA125_0==KW_ALLOC_FRACTION||LA125_0==KW_ANALYZE||LA125_0==KW_ARCHIVE||(LA125_0 >= KW_ASC && LA125_0 <= KW_AT)||(LA125_0 >= KW_AUTOCOMMIT && LA125_0 <= KW_BEFORE)||(LA125_0 >= KW_BUCKET && LA125_0 <= KW_BUCKETS)||(LA125_0 >= KW_CACHE && LA125_0 <= KW_CASCADE)||(LA125_0 >= KW_CBO && LA125_0 <= KW_CHANGE)||(LA125_0 >= KW_CHECK && LA125_0 <= KW_COLLECTION)||(LA125_0 >= KW_COLUMNS && LA125_0 <= KW_COMMENT)||(LA125_0 >= KW_COMPACT && LA125_0 <= KW_CONCATENATE)||(LA125_0 >= KW_CONTINUE && LA125_0 <= KW_COST)||LA125_0==KW_CRON||LA125_0==KW_DATA||LA125_0==KW_DATABASES||(LA125_0 >= KW_DATETIME && LA125_0 <= KW_DEBUG)||(LA125_0 >= KW_DEFAULT && LA125_0 <= KW_DEFINED)||(LA125_0 >= KW_DELIMITED && LA125_0 <= KW_DESC)||(LA125_0 >= KW_DETAIL && LA125_0 <= KW_DISABLE)||(LA125_0 >= KW_DISTRIBUTE && LA125_0 <= KW_DO)||LA125_0==KW_DOW||(LA125_0 >= KW_DUMP && LA125_0 <= KW_ELEM_TYPE)||LA125_0==KW_ENABLE||(LA125_0 >= KW_ENFORCED && LA125_0 <= KW_EVERY)||(LA125_0 >= KW_EXCLUSIVE && LA125_0 <= KW_EXECUTED)||(LA125_0 >= KW_EXPLAIN && LA125_0 <= KW_EXPRESSION)||(LA125_0 >= KW_FIELDS && LA125_0 <= KW_FIRST)||LA125_0==KW_FORMAT||LA125_0==KW_FUNCTIONS||(LA125_0 >= KW_HOUR && LA125_0 <= KW_IDXPROPERTIES)||(LA125_0 >= KW_INDEX && LA125_0 <= KW_INDEXES)||(LA125_0 >= KW_INPATH && LA125_0 <= KW_INPUTFORMAT)||(LA125_0 >= KW_ISOLATION && LA125_0 <= KW_JAR)||(LA125_0 >= KW_JOINCOST && LA125_0 <= KW_LAST)||LA125_0==KW_LEVEL||(LA125_0 >= KW_LIMIT && LA125_0 <= KW_LOAD)||(LA125_0 >= KW_LOCATION && LA125_0 <= KW_LONG)||(LA125_0 >= KW_MANAGEDLOCATION && LA125_0 <= KW_MANAGEMENT)||(LA125_0 >= KW_MAPJOIN && LA125_0 <= KW_MATERIALIZED)||LA125_0==KW_METADATA||(LA125_0 >= KW_MINUTE && LA125_0 <= KW_MONTH)||(LA125_0 >= KW_MOVE && LA125_0 <= KW_MSCK)||(LA125_0 >= KW_NORELY && LA125_0 <= KW_NOSCAN)||LA125_0==KW_NOVALIDATE||LA125_0==KW_NULLS||LA125_0==KW_OFFSET||(LA125_0 >= KW_OPERATOR && LA125_0 <= KW_OPTION)||(LA125_0 >= KW_OUTPUTDRIVER && LA125_0 <= KW_OUTPUTFORMAT)||(LA125_0 >= KW_OVERWRITE && LA125_0 <= KW_OWNER)||(LA125_0 >= KW_PARTITIONED && LA125_0 <= KW_PATH)||(LA125_0 >= KW_PLAN && LA125_0 <= KW_POOL)||LA125_0==KW_PRINCIPALS||(LA125_0 >= KW_PURGE && LA125_0 <= KW_QUERY_PARALLELISM)||LA125_0==KW_READ||(LA125_0 >= KW_REBUILD && LA125_0 <= KW_RECORDWRITER)||(LA125_0 >= KW_RELOAD && LA125_0 <= KW_RESTRICT)||LA125_0==KW_REWRITE||(LA125_0 >= KW_ROLE && LA125_0 <= KW_ROLES)||(LA125_0 >= KW_SCHEDULED && LA125_0 <= KW_SCHEDULING_POLICY)||(LA125_0 >= KW_SCHEMAS && LA125_0 <= KW_SECOND)||(LA125_0 >= KW_SEMI && LA125_0 <= KW_SERVER)||(LA125_0 >= KW_SETS && LA125_0 <= KW_SKEWED)||(LA125_0 >= KW_SNAPSHOT && LA125_0 <= KW_SSL)||(LA125_0 >= KW_STATISTICS && LA125_0 <= KW_SUMMARY)||LA125_0==KW_TABLES||(LA125_0 >= KW_TBLPROPERTIES && LA125_0 <= KW_TERMINATED)||LA125_0==KW_TINYINT||(LA125_0 >= KW_TOUCH && LA125_0 <= KW_TRANSACTIONS)||LA125_0==KW_UNARCHIVE||LA125_0==KW_UNDO||LA125_0==KW_UNIONTYPE||(LA125_0 >= KW_UNLOCK && LA125_0 <= KW_UNSIGNED)||(LA125_0 >= KW_URI && LA125_0 <= KW_USE)||(LA125_0 >= KW_UTC && LA125_0 <= KW_VALIDATE)||LA125_0==KW_VALUE_TYPE||(LA125_0 >= KW_VECTORIZATION && LA125_0 <= KW_WEEK)||LA125_0==KW_WHILE||(LA125_0 >= KW_WORK && LA125_0 <= KW_ZONE)||LA125_0==KW_BATCH||LA125_0==KW_DAYOFWEEK||LA125_0==KW_HOLD_DDLTIME||LA125_0==KW_IGNORE||LA125_0==KW_NO_DROP||LA125_0==KW_OFFLINE||LA125_0==KW_PROTECTION||LA125_0==KW_READONLY||LA125_0==KW_TIMESTAMPTZ) ) {
				alt125=4;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 125, 0, input);
				throw nvae;
			}

			switch (alt125) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:5: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:32: ( KW_DATABASE | KW_SCHEMA )
					int alt121=2;
					int LA121_0 = input.LA(1);
					if ( (LA121_0==KW_DATABASE) ) {
						alt121=1;
					}
					else if ( (LA121_0==KW_SCHEMA) ) {
						alt121=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 121, 0, input);
						throw nvae;
					}

					switch (alt121) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:33: KW_DATABASE
							{
							KW_DATABASE429=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_descStatement8038); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE429);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:45: KW_SCHEMA
							{
							KW_SCHEMA430=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_descStatement8040); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA430);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:56: ( KW_EXTENDED )?
					int alt122=2;
					int LA122_0 = input.LA(1);
					if ( (LA122_0==KW_EXTENDED) ) {
						alt122=1;
					}
					switch (alt122) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:56: KW_EXTENDED
							{
							KW_EXTENDED431=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement8043); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED431);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:69: (dbName= identifier )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:70: dbName= identifier
					{
					pushFollow(FOLLOW_identifier_in_descStatement8049);
					dbName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
					}

					// AST REWRITE
					// elements: dbName, KW_EXTENDED
					// token labels: 
					// rule labels: dbName, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1641:89: -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:92: ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCDATABASE, "TOK_DESCDATABASE"), root_1);
						adaptor.addChild(root_1, stream_dbName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:119: ( KW_EXTENDED )?
						if ( stream_KW_EXTENDED.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_EXTENDED.nextNode());
						}
						stream_KW_EXTENDED.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:5: ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames )
					{
					KW_FUNCTION432=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_descStatement8080); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION432);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:34: ( KW_EXTENDED )?
					int alt123=2;
					int LA123_0 = input.LA(1);
					if ( (LA123_0==KW_EXTENDED) ) {
						alt123=1;
					}
					switch (alt123) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:34: KW_EXTENDED
							{
							KW_EXTENDED433=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement8082); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED433);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:47: (name= descFuncNames )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:48: name= descFuncNames
					{
					pushFollow(FOLLOW_descFuncNames_in_descStatement8088);
					name=descFuncNames();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_descFuncNames.add(name.getTree());
					}

					// AST REWRITE
					// elements: name, KW_EXTENDED
					// token labels: 
					// rule labels: name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1643:68: -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:71: ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCFUNCTION, "TOK_DESCFUNCTION"), root_1);
						adaptor.addChild(root_1, stream_name.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:96: ( KW_EXTENDED )?
						if ( stream_KW_EXTENDED.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_EXTENDED.nextNode());
						}
						stream_KW_EXTENDED.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:5: ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:35: ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:36: (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:36: (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED )
					int alt124=2;
					int LA124_0 = input.LA(1);
					if ( (LA124_0==KW_FORMATTED) ) {
						alt124=1;
					}
					else if ( (LA124_0==KW_EXTENDED) ) {
						alt124=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 124, 0, input);
						throw nvae;
					}

					switch (alt124) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:37: descOptions= KW_FORMATTED
							{
							descOptions=(Token)match(input,KW_FORMATTED,FOLLOW_KW_FORMATTED_in_descStatement8125); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_FORMATTED.add(descOptions);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:62: descOptions= KW_EXTENDED
							{
							descOptions=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement8129); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(descOptions);

							}
							break;

					}

					pushFollow(FOLLOW_tabPartColTypeExpr_in_descStatement8134);
					parttype=tabPartColTypeExpr();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tabPartColTypeExpr.add(parttype.getTree());
					}

					// AST REWRITE
					// elements: descOptions, parttype
					// token labels: descOptions
					// rule labels: parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_descOptions=new RewriteRuleTokenStream(adaptor,"token descOptions",descOptions);
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1645:116: -> ^( TOK_DESCTABLE $parttype $descOptions)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:119: ^( TOK_DESCTABLE $parttype $descOptions)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCTABLE, "TOK_DESCTABLE"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						adaptor.addChild(root_1, stream_descOptions.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1647:5: parttype= tabPartColTypeExpr
					{
					pushFollow(FOLLOW_tabPartColTypeExpr_in_descStatement8161);
					parttype=tabPartColTypeExpr();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tabPartColTypeExpr.add(parttype.getTree());
					// AST REWRITE
					// elements: parttype
					// token labels: 
					// rule labels: parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1647:33: -> ^( TOK_DESCTABLE $parttype)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1647:36: ^( TOK_DESCTABLE $parttype)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCTABLE, "TOK_DESCTABLE"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "descStatement"


	public static class analyzeStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "analyzeStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1651:1: analyzeStatement : KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) ) ;
	public final HiveParser.analyzeStatement_return analyzeStatement() throws RecognitionException {
		HiveParser.analyzeStatement_return retval = new HiveParser.analyzeStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token noscan=null;
		Token KW_ANALYZE434=null;
		Token KW_TABLE435=null;
		Token KW_COMPUTE436=null;
		Token KW_STATISTICS437=null;
		Token KW_FOR438=null;
		Token KW_COLUMNS439=null;
		Token KW_CACHE440=null;
		Token KW_METADATA441=null;
		ParserRuleReturnScope parttype =null;
		ParserRuleReturnScope statsColumnName =null;

		ASTNode noscan_tree=null;
		ASTNode KW_ANALYZE434_tree=null;
		ASTNode KW_TABLE435_tree=null;
		ASTNode KW_COMPUTE436_tree=null;
		ASTNode KW_STATISTICS437_tree=null;
		ASTNode KW_FOR438_tree=null;
		ASTNode KW_COLUMNS439_tree=null;
		ASTNode KW_CACHE440_tree=null;
		ASTNode KW_METADATA441_tree=null;
		RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
		RewriteRuleTokenStream stream_KW_ANALYZE=new RewriteRuleTokenStream(adaptor,"token KW_ANALYZE");
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_COMPUTE=new RewriteRuleTokenStream(adaptor,"token KW_COMPUTE");
		RewriteRuleTokenStream stream_KW_METADATA=new RewriteRuleTokenStream(adaptor,"token KW_METADATA");
		RewriteRuleTokenStream stream_KW_NOSCAN=new RewriteRuleTokenStream(adaptor,"token KW_NOSCAN");
		RewriteRuleTokenStream stream_KW_CACHE=new RewriteRuleTokenStream(adaptor,"token KW_CACHE");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("analyze statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1654:5: ( KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1654:7: KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) )
			{
			KW_ANALYZE434=(Token)match(input,KW_ANALYZE,FOLLOW_KW_ANALYZE_in_analyzeStatement8203); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ANALYZE.add(KW_ANALYZE434);

			KW_TABLE435=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_analyzeStatement8205); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE435);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1654:27: (parttype= tableOrPartition )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1654:28: parttype= tableOrPartition
			{
			pushFollow(FOLLOW_tableOrPartition_in_analyzeStatement8210);
			parttype=tableOrPartition();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableOrPartition.add(parttype.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1655:7: ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) )
			int alt128=2;
			int LA128_0 = input.LA(1);
			if ( (LA128_0==KW_COMPUTE) && (synpred10_HiveParser())) {
				alt128=1;
			}
			else if ( (LA128_0==KW_CACHE) && (synpred11_HiveParser())) {
				alt128=2;
			}

			switch (alt128) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:7: ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
					{
					KW_COMPUTE436=(Token)match(input,KW_COMPUTE,FOLLOW_KW_COMPUTE_in_analyzeStatement8233); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMPUTE.add(KW_COMPUTE436);

					KW_STATISTICS437=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_analyzeStatement8235); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS437);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:48: ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
					int alt127=3;
					int LA127_0 = input.LA(1);
					if ( (LA127_0==KW_NOSCAN) ) {
						alt127=1;
					}
					else if ( (LA127_0==KW_FOR) ) {
						alt127=2;
					}
					switch (alt127) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:49: (noscan= KW_NOSCAN )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:49: (noscan= KW_NOSCAN )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:50: noscan= KW_NOSCAN
							{
							noscan=(Token)match(input,KW_NOSCAN,FOLLOW_KW_NOSCAN_in_analyzeStatement8241); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_NOSCAN.add(noscan);

							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:58: KW_FOR KW_COLUMNS (statsColumnName= columnNameList )?
							{
							KW_FOR438=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_analyzeStatement8301); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR438);

							KW_COLUMNS439=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_analyzeStatement8303); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS439);

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:76: (statsColumnName= columnNameList )?
							int alt126=2;
							int LA126_0 = input.LA(1);
							if ( (LA126_0==Identifier||(LA126_0 >= KW_ABORT && LA126_0 <= KW_AFTER)||LA126_0==KW_ALLOC_FRACTION||LA126_0==KW_ANALYZE||LA126_0==KW_ARCHIVE||(LA126_0 >= KW_ASC && LA126_0 <= KW_AT)||(LA126_0 >= KW_AUTOCOMMIT && LA126_0 <= KW_BEFORE)||(LA126_0 >= KW_BUCKET && LA126_0 <= KW_BUCKETS)||(LA126_0 >= KW_CACHE && LA126_0 <= KW_CASCADE)||(LA126_0 >= KW_CBO && LA126_0 <= KW_CHANGE)||(LA126_0 >= KW_CHECK && LA126_0 <= KW_COLLECTION)||(LA126_0 >= KW_COLUMNS && LA126_0 <= KW_COMMENT)||(LA126_0 >= KW_COMPACT && LA126_0 <= KW_CONCATENATE)||(LA126_0 >= KW_CONTINUE && LA126_0 <= KW_COST)||LA126_0==KW_CRON||LA126_0==KW_DATA||LA126_0==KW_DATABASES||(LA126_0 >= KW_DATETIME && LA126_0 <= KW_DEBUG)||(LA126_0 >= KW_DEFAULT && LA126_0 <= KW_DEFINED)||(LA126_0 >= KW_DELIMITED && LA126_0 <= KW_DESC)||(LA126_0 >= KW_DETAIL && LA126_0 <= KW_DISABLE)||(LA126_0 >= KW_DISTRIBUTE && LA126_0 <= KW_DO)||LA126_0==KW_DOW||(LA126_0 >= KW_DUMP && LA126_0 <= KW_ELEM_TYPE)||LA126_0==KW_ENABLE||(LA126_0 >= KW_ENFORCED && LA126_0 <= KW_EVERY)||(LA126_0 >= KW_EXCLUSIVE && LA126_0 <= KW_EXECUTED)||(LA126_0 >= KW_EXPLAIN && LA126_0 <= KW_EXPRESSION)||(LA126_0 >= KW_FIELDS && LA126_0 <= KW_FIRST)||(LA126_0 >= KW_FORMAT && LA126_0 <= KW_FORMATTED)||LA126_0==KW_FUNCTIONS||(LA126_0 >= KW_HOUR && LA126_0 <= KW_IDXPROPERTIES)||(LA126_0 >= KW_INDEX && LA126_0 <= KW_INDEXES)||(LA126_0 >= KW_INPATH && LA126_0 <= KW_INPUTFORMAT)||(LA126_0 >= KW_ISOLATION && LA126_0 <= KW_JAR)||(LA126_0 >= KW_JOINCOST && LA126_0 <= KW_LAST)||LA126_0==KW_LEVEL||(LA126_0 >= KW_LIMIT && LA126_0 <= KW_LOAD)||(LA126_0 >= KW_LOCATION && LA126_0 <= KW_LONG)||(LA126_0 >= KW_MANAGEDLOCATION && LA126_0 <= KW_MANAGEMENT)||(LA126_0 >= KW_MAPJOIN && LA126_0 <= KW_MATERIALIZED)||LA126_0==KW_METADATA||(LA126_0 >= KW_MINUTE && LA126_0 <= KW_MONTH)||(LA126_0 >= KW_MOVE && LA126_0 <= KW_MSCK)||(LA126_0 >= KW_NORELY && LA126_0 <= KW_NOSCAN)||LA126_0==KW_NOVALIDATE||LA126_0==KW_NULLS||LA126_0==KW_OFFSET||(LA126_0 >= KW_OPERATOR && LA126_0 <= KW_OPTION)||(LA126_0 >= KW_OUTPUTDRIVER && LA126_0 <= KW_OUTPUTFORMAT)||(LA126_0 >= KW_OVERWRITE && LA126_0 <= KW_OWNER)||(LA126_0 >= KW_PARTITIONED && LA126_0 <= KW_PATH)||(LA126_0 >= KW_PLAN && LA126_0 <= KW_POOL)||LA126_0==KW_PRINCIPALS||(LA126_0 >= KW_PURGE && LA126_0 <= KW_QUERY_PARALLELISM)||LA126_0==KW_READ||(LA126_0 >= KW_REBUILD && LA126_0 <= KW_RECORDWRITER)||(LA126_0 >= KW_RELOAD && LA126_0 <= KW_RESTRICT)||LA126_0==KW_REWRITE||(LA126_0 >= KW_ROLE && LA126_0 <= KW_ROLES)||(LA126_0 >= KW_SCHEDULED && LA126_0 <= KW_SECOND)||(LA126_0 >= KW_SEMI && LA126_0 <= KW_SERVER)||(LA126_0 >= KW_SETS && LA126_0 <= KW_SKEWED)||(LA126_0 >= KW_SNAPSHOT && LA126_0 <= KW_SSL)||(LA126_0 >= KW_STATISTICS && LA126_0 <= KW_SUMMARY)||LA126_0==KW_TABLES||(LA126_0 >= KW_TBLPROPERTIES && LA126_0 <= KW_TERMINATED)||LA126_0==KW_TINYINT||(LA126_0 >= KW_TOUCH && LA126_0 <= KW_TRANSACTIONS)||LA126_0==KW_UNARCHIVE||LA126_0==KW_UNDO||LA126_0==KW_UNIONTYPE||(LA126_0 >= KW_UNLOCK && LA126_0 <= KW_UNSIGNED)||(LA126_0 >= KW_URI && LA126_0 <= KW_USE)||(LA126_0 >= KW_UTC && LA126_0 <= KW_VALIDATE)||LA126_0==KW_VALUE_TYPE||(LA126_0 >= KW_VECTORIZATION && LA126_0 <= KW_WEEK)||LA126_0==KW_WHILE||(LA126_0 >= KW_WORK && LA126_0 <= KW_ZONE)||LA126_0==KW_BATCH||LA126_0==KW_DAYOFWEEK||LA126_0==KW_HOLD_DDLTIME||LA126_0==KW_IGNORE||LA126_0==KW_NO_DROP||LA126_0==KW_OFFLINE||LA126_0==KW_PROTECTION||LA126_0==KW_READONLY||LA126_0==KW_TIMESTAMPTZ) ) {
								alt126=1;
							}
							switch (alt126) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:77: statsColumnName= columnNameList
									{
									pushFollow(FOLLOW_columnNameList_in_analyzeStatement8308);
									statsColumnName=columnNameList();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_columnNameList.add(statsColumnName.getTree());
									}
									break;

							}

							}

							}
							break;

					}

					// AST REWRITE
					// elements: statsColumnName, parttype, KW_COLUMNS, noscan
					// token labels: noscan
					// rule labels: statsColumnName, parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_noscan=new RewriteRuleTokenStream(adaptor,"token noscan",noscan);
					RewriteRuleSubtreeStream stream_statsColumnName=new RewriteRuleSubtreeStream(adaptor,"rule statsColumnName",statsColumnName!=null?statsColumnName.getTree():null);
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1658:7: -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1658:10: ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ANALYZE, "TOK_ANALYZE"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1658:35: ( $noscan)?
						if ( stream_noscan.hasNext() ) {
							adaptor.addChild(root_1, stream_noscan.nextNode());
						}
						stream_noscan.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1658:43: ( KW_COLUMNS )?
						if ( stream_KW_COLUMNS.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_COLUMNS.nextNode());
						}
						stream_KW_COLUMNS.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1658:56: ( $statsColumnName)?
						if ( stream_statsColumnName.hasNext() ) {
							adaptor.addChild(root_1, stream_statsColumnName.nextTree());
						}
						stream_statsColumnName.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1660:7: ( KW_CACHE )=> KW_CACHE KW_METADATA
					{
					KW_CACHE440=(Token)match(input,KW_CACHE,FOLLOW_KW_CACHE_in_analyzeStatement8361); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CACHE.add(KW_CACHE440);

					KW_METADATA441=(Token)match(input,KW_METADATA,FOLLOW_KW_METADATA_in_analyzeStatement8363); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_METADATA.add(KW_METADATA441);

					// AST REWRITE
					// elements: parttype
					// token labels: 
					// rule labels: parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1660:42: -> ^( TOK_CACHE_METADATA $parttype)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1660:45: ^( TOK_CACHE_METADATA $parttype)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CACHE_METADATA, "TOK_CACHE_METADATA"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "analyzeStatement"


	public static class showStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1664:1: showStatement : ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW (isExtended= KW_EXTENDED )? KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? (filter= showTablesFilterExpr )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? ) | KW_SHOW KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_MATERIALIZED KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ) | KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) ) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) ) | KW_SHOW KW_COMPACTIONS -> ^( TOK_SHOW_COMPACTIONS ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) | KW_SHOW KW_RESOURCE ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) ) );
	public final HiveParser.showStatement_return showStatement() throws RecognitionException {
		HiveParser.showStatement_return retval = new HiveParser.showStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token isExtended=null;
		Token prptyName=null;
		Token KW_SHOW442=null;
		Token KW_DATABASES443=null;
		Token KW_SCHEMAS444=null;
		Token KW_LIKE445=null;
		Token KW_SHOW447=null;
		Token KW_TABLES448=null;
		Token KW_FROM449=null;
		Token KW_IN450=null;
		Token KW_SHOW451=null;
		Token KW_VIEWS452=null;
		Token KW_FROM453=null;
		Token KW_IN454=null;
		Token KW_LIKE455=null;
		Token KW_SHOW458=null;
		Token KW_MATERIALIZED459=null;
		Token KW_VIEWS460=null;
		Token KW_FROM461=null;
		Token KW_IN462=null;
		Token KW_LIKE463=null;
		Token KW_SHOW466=null;
		Token KW_COLUMNS467=null;
		Token KW_FROM468=null;
		Token KW_IN469=null;
		Token KW_FROM471=null;
		Token KW_IN472=null;
		Token KW_LIKE473=null;
		Token KW_SHOW476=null;
		Token KW_FUNCTIONS477=null;
		Token KW_LIKE478=null;
		Token KW_SHOW480=null;
		Token KW_PARTITIONS481=null;
		Token KW_SHOW483=null;
		Token KW_CREATE484=null;
		Token KW_DATABASE485=null;
		Token KW_SCHEMA486=null;
		Token KW_TABLE487=null;
		Token KW_SHOW488=null;
		Token KW_TABLE489=null;
		Token KW_EXTENDED490=null;
		Token KW_FROM491=null;
		Token KW_IN492=null;
		Token KW_LIKE493=null;
		Token KW_SHOW496=null;
		Token KW_TBLPROPERTIES497=null;
		Token LPAREN499=null;
		Token RPAREN500=null;
		Token KW_SHOW501=null;
		Token KW_LOCKS502=null;
		Token KW_DATABASE503=null;
		Token KW_SCHEMA504=null;
		Token KW_SHOW505=null;
		Token KW_COMPACTIONS506=null;
		Token KW_SHOW507=null;
		Token KW_TRANSACTIONS508=null;
		Token KW_SHOW509=null;
		Token KW_CONF510=null;
		Token StringLiteral511=null;
		Token KW_SHOW512=null;
		Token KW_RESOURCE513=null;
		Token KW_PLAN514=null;
		Token KW_PLANS515=null;
		ParserRuleReturnScope db_name =null;
		ParserRuleReturnScope filter =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope parttype =null;
		ParserRuleReturnScope rp_name =null;
		ParserRuleReturnScope showStmtIdentifier446 =null;
		ParserRuleReturnScope showStmtIdentifier456 =null;
		ParserRuleReturnScope showStmtIdentifier457 =null;
		ParserRuleReturnScope showStmtIdentifier464 =null;
		ParserRuleReturnScope showStmtIdentifier465 =null;
		ParserRuleReturnScope tableName470 =null;
		ParserRuleReturnScope showStmtIdentifier474 =null;
		ParserRuleReturnScope showStmtIdentifier475 =null;
		ParserRuleReturnScope showFunctionIdentifier479 =null;
		ParserRuleReturnScope partitionSpec482 =null;
		ParserRuleReturnScope showStmtIdentifier494 =null;
		ParserRuleReturnScope partitionSpec495 =null;
		ParserRuleReturnScope tableName498 =null;

		ASTNode isExtended_tree=null;
		ASTNode prptyName_tree=null;
		ASTNode KW_SHOW442_tree=null;
		ASTNode KW_DATABASES443_tree=null;
		ASTNode KW_SCHEMAS444_tree=null;
		ASTNode KW_LIKE445_tree=null;
		ASTNode KW_SHOW447_tree=null;
		ASTNode KW_TABLES448_tree=null;
		ASTNode KW_FROM449_tree=null;
		ASTNode KW_IN450_tree=null;
		ASTNode KW_SHOW451_tree=null;
		ASTNode KW_VIEWS452_tree=null;
		ASTNode KW_FROM453_tree=null;
		ASTNode KW_IN454_tree=null;
		ASTNode KW_LIKE455_tree=null;
		ASTNode KW_SHOW458_tree=null;
		ASTNode KW_MATERIALIZED459_tree=null;
		ASTNode KW_VIEWS460_tree=null;
		ASTNode KW_FROM461_tree=null;
		ASTNode KW_IN462_tree=null;
		ASTNode KW_LIKE463_tree=null;
		ASTNode KW_SHOW466_tree=null;
		ASTNode KW_COLUMNS467_tree=null;
		ASTNode KW_FROM468_tree=null;
		ASTNode KW_IN469_tree=null;
		ASTNode KW_FROM471_tree=null;
		ASTNode KW_IN472_tree=null;
		ASTNode KW_LIKE473_tree=null;
		ASTNode KW_SHOW476_tree=null;
		ASTNode KW_FUNCTIONS477_tree=null;
		ASTNode KW_LIKE478_tree=null;
		ASTNode KW_SHOW480_tree=null;
		ASTNode KW_PARTITIONS481_tree=null;
		ASTNode KW_SHOW483_tree=null;
		ASTNode KW_CREATE484_tree=null;
		ASTNode KW_DATABASE485_tree=null;
		ASTNode KW_SCHEMA486_tree=null;
		ASTNode KW_TABLE487_tree=null;
		ASTNode KW_SHOW488_tree=null;
		ASTNode KW_TABLE489_tree=null;
		ASTNode KW_EXTENDED490_tree=null;
		ASTNode KW_FROM491_tree=null;
		ASTNode KW_IN492_tree=null;
		ASTNode KW_LIKE493_tree=null;
		ASTNode KW_SHOW496_tree=null;
		ASTNode KW_TBLPROPERTIES497_tree=null;
		ASTNode LPAREN499_tree=null;
		ASTNode RPAREN500_tree=null;
		ASTNode KW_SHOW501_tree=null;
		ASTNode KW_LOCKS502_tree=null;
		ASTNode KW_DATABASE503_tree=null;
		ASTNode KW_SCHEMA504_tree=null;
		ASTNode KW_SHOW505_tree=null;
		ASTNode KW_COMPACTIONS506_tree=null;
		ASTNode KW_SHOW507_tree=null;
		ASTNode KW_TRANSACTIONS508_tree=null;
		ASTNode KW_SHOW509_tree=null;
		ASTNode KW_CONF510_tree=null;
		ASTNode StringLiteral511_tree=null;
		ASTNode KW_SHOW512_tree=null;
		ASTNode KW_RESOURCE513_tree=null;
		ASTNode KW_PLAN514_tree=null;
		ASTNode KW_PLANS515_tree=null;
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_VIEWS=new RewriteRuleTokenStream(adaptor,"token KW_VIEWS");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_LIKE=new RewriteRuleTokenStream(adaptor,"token KW_LIKE");
		RewriteRuleTokenStream stream_KW_PARTITIONS=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONS");
		RewriteRuleTokenStream stream_KW_IN=new RewriteRuleTokenStream(adaptor,"token KW_IN");
		RewriteRuleTokenStream stream_KW_LOCKS=new RewriteRuleTokenStream(adaptor,"token KW_LOCKS");
		RewriteRuleTokenStream stream_KW_EXTENDED=new RewriteRuleTokenStream(adaptor,"token KW_EXTENDED");
		RewriteRuleTokenStream stream_KW_TABLES=new RewriteRuleTokenStream(adaptor,"token KW_TABLES");
		RewriteRuleTokenStream stream_KW_FUNCTIONS=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTIONS");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_CONF=new RewriteRuleTokenStream(adaptor,"token KW_CONF");
		RewriteRuleTokenStream stream_KW_PLAN=new RewriteRuleTokenStream(adaptor,"token KW_PLAN");
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_KW_TRANSACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTIONS");
		RewriteRuleTokenStream stream_KW_SCHEMAS=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMAS");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_COMPACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_COMPACTIONS");
		RewriteRuleTokenStream stream_KW_PLANS=new RewriteRuleTokenStream(adaptor,"token KW_PLANS");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_RESOURCE=new RewriteRuleTokenStream(adaptor,"token KW_RESOURCE");
		RewriteRuleTokenStream stream_KW_DATABASES=new RewriteRuleTokenStream(adaptor,"token KW_DATABASES");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleTokenStream stream_KW_MATERIALIZED=new RewriteRuleTokenStream(adaptor,"token KW_MATERIALIZED");
		RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
		RewriteRuleSubtreeStream stream_showStmtIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showStmtIdentifier");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_showTablesFilterExpr=new RewriteRuleSubtreeStream(adaptor,"rule showTablesFilterExpr");
		RewriteRuleSubtreeStream stream_showFunctionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showFunctionIdentifier");
		RewriteRuleSubtreeStream stream_partTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule partTypeExpr");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("show statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:5: ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW (isExtended= KW_EXTENDED )? KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? (filter= showTablesFilterExpr )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? ) | KW_SHOW KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_MATERIALIZED KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ) | KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) ) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) ) | KW_SHOW KW_COMPACTIONS -> ^( TOK_SHOW_COMPACTIONS ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) | KW_SHOW KW_RESOURCE ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) ) )
			int alt159=15;
			int LA159_0 = input.LA(1);
			if ( (LA159_0==KW_SHOW) ) {
				switch ( input.LA(2) ) {
				case KW_VIEWS:
					{
					alt159=3;
					}
					break;
				case KW_MATERIALIZED:
					{
					alt159=4;
					}
					break;
				case KW_COLUMNS:
					{
					alt159=5;
					}
					break;
				case KW_FUNCTIONS:
					{
					alt159=6;
					}
					break;
				case KW_PARTITIONS:
					{
					alt159=7;
					}
					break;
				case KW_CREATE:
					{
					alt159=8;
					}
					break;
				case KW_TABLE:
					{
					alt159=9;
					}
					break;
				case KW_TBLPROPERTIES:
					{
					alt159=10;
					}
					break;
				case KW_LOCKS:
					{
					alt159=11;
					}
					break;
				case KW_COMPACTIONS:
					{
					alt159=12;
					}
					break;
				case KW_TRANSACTIONS:
					{
					alt159=13;
					}
					break;
				case KW_CONF:
					{
					alt159=14;
					}
					break;
				case KW_RESOURCE:
					{
					alt159=15;
					}
					break;
				case KW_DATABASES:
				case KW_SCHEMAS:
					{
					alt159=1;
					}
					break;
				case KW_EXTENDED:
				case KW_TABLES:
					{
					alt159=2;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 159, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 159, 0, input);
				throw nvae;
			}

			switch (alt159) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:7: KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )?
					{
					KW_SHOW442=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8407); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW442);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:15: ( KW_DATABASES | KW_SCHEMAS )
					int alt129=2;
					int LA129_0 = input.LA(1);
					if ( (LA129_0==KW_DATABASES) ) {
						alt129=1;
					}
					else if ( (LA129_0==KW_SCHEMAS) ) {
						alt129=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 129, 0, input);
						throw nvae;
					}

					switch (alt129) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:16: KW_DATABASES
							{
							KW_DATABASES443=(Token)match(input,KW_DATABASES,FOLLOW_KW_DATABASES_in_showStatement8410); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASES.add(KW_DATABASES443);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:29: KW_SCHEMAS
							{
							KW_SCHEMAS444=(Token)match(input,KW_SCHEMAS,FOLLOW_KW_SCHEMAS_in_showStatement8412); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMAS.add(KW_SCHEMAS444);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:41: ( KW_LIKE showStmtIdentifier )?
					int alt130=2;
					int LA130_0 = input.LA(1);
					if ( (LA130_0==KW_LIKE) ) {
						alt130=1;
					}
					switch (alt130) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:42: KW_LIKE showStmtIdentifier
							{
							KW_LIKE445=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement8416); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE445);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8418);
							showStmtIdentifier446=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier446.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: showStmtIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1667:71: -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:74: ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWDATABASES, "TOK_SHOWDATABASES"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:94: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1668:7: KW_SHOW (isExtended= KW_EXTENDED )? KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? (filter= showTablesFilterExpr )?
					{
					KW_SHOW447=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8437); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW447);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1668:15: (isExtended= KW_EXTENDED )?
					int alt131=2;
					int LA131_0 = input.LA(1);
					if ( (LA131_0==KW_EXTENDED) ) {
						alt131=1;
					}
					switch (alt131) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1668:16: isExtended= KW_EXTENDED
							{
							isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement8442); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(isExtended);

							}
							break;

					}

					KW_TABLES448=(Token)match(input,KW_TABLES,FOLLOW_KW_TABLES_in_showStatement8446); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLES.add(KW_TABLES448);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1668:51: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt133=2;
					int LA133_0 = input.LA(1);
					if ( (LA133_0==KW_FROM||LA133_0==KW_IN) ) {
						alt133=1;
					}
					switch (alt133) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1668:52: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1668:52: ( KW_FROM | KW_IN )
							int alt132=2;
							int LA132_0 = input.LA(1);
							if ( (LA132_0==KW_FROM) ) {
								alt132=1;
							}
							else if ( (LA132_0==KW_IN) ) {
								alt132=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 132, 0, input);
								throw nvae;
							}

							switch (alt132) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1668:53: KW_FROM
									{
									KW_FROM449=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement8450); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM449);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1668:61: KW_IN
									{
									KW_IN450=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement8452); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN450);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement8457);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1668:89: (filter= showTablesFilterExpr )?
					int alt134=2;
					int LA134_0 = input.LA(1);
					if ( (LA134_0==Identifier||(LA134_0 >= KW_ABORT && LA134_0 <= KW_AFTER)||LA134_0==KW_ALLOC_FRACTION||LA134_0==KW_ANALYZE||LA134_0==KW_ARCHIVE||(LA134_0 >= KW_ASC && LA134_0 <= KW_AT)||(LA134_0 >= KW_AUTOCOMMIT && LA134_0 <= KW_BEFORE)||(LA134_0 >= KW_BUCKET && LA134_0 <= KW_BUCKETS)||(LA134_0 >= KW_CACHE && LA134_0 <= KW_CASCADE)||(LA134_0 >= KW_CBO && LA134_0 <= KW_CHANGE)||(LA134_0 >= KW_CHECK && LA134_0 <= KW_COLLECTION)||(LA134_0 >= KW_COLUMNS && LA134_0 <= KW_COMMENT)||(LA134_0 >= KW_COMPACT && LA134_0 <= KW_CONCATENATE)||(LA134_0 >= KW_CONTINUE && LA134_0 <= KW_COST)||LA134_0==KW_CRON||LA134_0==KW_DATA||LA134_0==KW_DATABASES||(LA134_0 >= KW_DATETIME && LA134_0 <= KW_DEBUG)||(LA134_0 >= KW_DEFAULT && LA134_0 <= KW_DEFINED)||(LA134_0 >= KW_DELIMITED && LA134_0 <= KW_DESC)||(LA134_0 >= KW_DETAIL && LA134_0 <= KW_DISABLE)||(LA134_0 >= KW_DISTRIBUTE && LA134_0 <= KW_DO)||LA134_0==KW_DOW||(LA134_0 >= KW_DUMP && LA134_0 <= KW_ELEM_TYPE)||LA134_0==KW_ENABLE||(LA134_0 >= KW_ENFORCED && LA134_0 <= KW_EVERY)||(LA134_0 >= KW_EXCLUSIVE && LA134_0 <= KW_EXECUTED)||(LA134_0 >= KW_EXPLAIN && LA134_0 <= KW_EXPRESSION)||(LA134_0 >= KW_FIELDS && LA134_0 <= KW_FIRST)||(LA134_0 >= KW_FORMAT && LA134_0 <= KW_FORMATTED)||LA134_0==KW_FUNCTIONS||(LA134_0 >= KW_HOUR && LA134_0 <= KW_IDXPROPERTIES)||(LA134_0 >= KW_INDEX && LA134_0 <= KW_INDEXES)||(LA134_0 >= KW_INPATH && LA134_0 <= KW_INPUTFORMAT)||(LA134_0 >= KW_ISOLATION && LA134_0 <= KW_JAR)||(LA134_0 >= KW_JOINCOST && LA134_0 <= KW_LAST)||(LA134_0 >= KW_LEVEL && LA134_0 <= KW_LOAD)||(LA134_0 >= KW_LOCATION && LA134_0 <= KW_LONG)||(LA134_0 >= KW_MANAGEDLOCATION && LA134_0 <= KW_MANAGEMENT)||(LA134_0 >= KW_MAPJOIN && LA134_0 <= KW_MATERIALIZED)||LA134_0==KW_METADATA||(LA134_0 >= KW_MINUTE && LA134_0 <= KW_MONTH)||(LA134_0 >= KW_MOVE && LA134_0 <= KW_MSCK)||(LA134_0 >= KW_NORELY && LA134_0 <= KW_NOSCAN)||LA134_0==KW_NOVALIDATE||LA134_0==KW_NULLS||LA134_0==KW_OFFSET||(LA134_0 >= KW_OPERATOR && LA134_0 <= KW_OPTION)||(LA134_0 >= KW_OUTPUTDRIVER && LA134_0 <= KW_OUTPUTFORMAT)||(LA134_0 >= KW_OVERWRITE && LA134_0 <= KW_OWNER)||(LA134_0 >= KW_PARTITIONED && LA134_0 <= KW_PATH)||(LA134_0 >= KW_PLAN && LA134_0 <= KW_POOL)||LA134_0==KW_PRINCIPALS||(LA134_0 >= KW_PURGE && LA134_0 <= KW_QUERY_PARALLELISM)||LA134_0==KW_READ||(LA134_0 >= KW_REBUILD && LA134_0 <= KW_RECORDWRITER)||(LA134_0 >= KW_RELOAD && LA134_0 <= KW_RESTRICT)||LA134_0==KW_REWRITE||(LA134_0 >= KW_ROLE && LA134_0 <= KW_ROLES)||(LA134_0 >= KW_SCHEDULED && LA134_0 <= KW_SECOND)||(LA134_0 >= KW_SEMI && LA134_0 <= KW_SERVER)||(LA134_0 >= KW_SETS && LA134_0 <= KW_SKEWED)||(LA134_0 >= KW_SNAPSHOT && LA134_0 <= KW_SSL)||(LA134_0 >= KW_STATISTICS && LA134_0 <= KW_SUMMARY)||LA134_0==KW_TABLES||(LA134_0 >= KW_TBLPROPERTIES && LA134_0 <= KW_TERMINATED)||LA134_0==KW_TINYINT||(LA134_0 >= KW_TOUCH && LA134_0 <= KW_TRANSACTIONS)||LA134_0==KW_UNARCHIVE||LA134_0==KW_UNDO||LA134_0==KW_UNIONTYPE||(LA134_0 >= KW_UNLOCK && LA134_0 <= KW_UNSIGNED)||(LA134_0 >= KW_URI && LA134_0 <= KW_USE)||(LA134_0 >= KW_UTC && LA134_0 <= KW_VALIDATE)||LA134_0==KW_VALUE_TYPE||(LA134_0 >= KW_VECTORIZATION && LA134_0 <= KW_WEEK)||(LA134_0 >= KW_WHERE && LA134_0 <= KW_WHILE)||(LA134_0 >= KW_WORK && LA134_0 <= KW_ZONE)||LA134_0==StringLiteral||LA134_0==KW_BATCH||LA134_0==KW_DAYOFWEEK||LA134_0==KW_HOLD_DDLTIME||LA134_0==KW_IGNORE||LA134_0==KW_NO_DROP||LA134_0==KW_OFFLINE||LA134_0==KW_PROTECTION||LA134_0==KW_READONLY||LA134_0==KW_TIMESTAMPTZ) ) {
						alt134=1;
					}
					switch (alt134) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1668:90: filter= showTablesFilterExpr
							{
							pushFollow(FOLLOW_showTablesFilterExpr_in_showStatement8464);
							filter=showTablesFilterExpr();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showTablesFilterExpr.add(filter.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: db_name, isExtended, filter
					// token labels: isExtended
					// rule labels: filter, db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
					RewriteRuleSubtreeStream stream_filter=new RewriteRuleSubtreeStream(adaptor,"rule filter",filter!=null?filter.getTree():null);
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1669:5: -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1669:8: ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWTABLES, "TOK_SHOWTABLES"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1669:25: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1669:47: ( $filter)?
						if ( stream_filter.hasNext() ) {
							adaptor.addChild(root_1, stream_filter.nextTree());
						}
						stream_filter.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1669:56: ( $isExtended)?
						if ( stream_isExtended.hasNext() ) {
							adaptor.addChild(root_1, stream_isExtended.nextNode());
						}
						stream_isExtended.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:7: KW_SHOW KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					{
					KW_SHOW451=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8500); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW451);

					KW_VIEWS452=(Token)match(input,KW_VIEWS,FOLLOW_KW_VIEWS_in_showStatement8502); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VIEWS.add(KW_VIEWS452);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:24: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt136=2;
					int LA136_0 = input.LA(1);
					if ( (LA136_0==KW_FROM||LA136_0==KW_IN) ) {
						alt136=1;
					}
					switch (alt136) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:25: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:25: ( KW_FROM | KW_IN )
							int alt135=2;
							int LA135_0 = input.LA(1);
							if ( (LA135_0==KW_FROM) ) {
								alt135=1;
							}
							else if ( (LA135_0==KW_IN) ) {
								alt135=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 135, 0, input);
								throw nvae;
							}

							switch (alt135) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:26: KW_FROM
									{
									KW_FROM453=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement8506); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM453);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:34: KW_IN
									{
									KW_IN454=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement8508); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN454);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement8513);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:62: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					int alt137=3;
					int LA137_0 = input.LA(1);
					if ( (LA137_0==KW_LIKE) ) {
						alt137=1;
					}
					else if ( (LA137_0==Identifier||(LA137_0 >= KW_ABORT && LA137_0 <= KW_AFTER)||LA137_0==KW_ALLOC_FRACTION||LA137_0==KW_ANALYZE||LA137_0==KW_ARCHIVE||(LA137_0 >= KW_ASC && LA137_0 <= KW_AT)||(LA137_0 >= KW_AUTOCOMMIT && LA137_0 <= KW_BEFORE)||(LA137_0 >= KW_BUCKET && LA137_0 <= KW_BUCKETS)||(LA137_0 >= KW_CACHE && LA137_0 <= KW_CASCADE)||(LA137_0 >= KW_CBO && LA137_0 <= KW_CHANGE)||(LA137_0 >= KW_CHECK && LA137_0 <= KW_COLLECTION)||(LA137_0 >= KW_COLUMNS && LA137_0 <= KW_COMMENT)||(LA137_0 >= KW_COMPACT && LA137_0 <= KW_CONCATENATE)||(LA137_0 >= KW_CONTINUE && LA137_0 <= KW_COST)||LA137_0==KW_CRON||LA137_0==KW_DATA||LA137_0==KW_DATABASES||(LA137_0 >= KW_DATETIME && LA137_0 <= KW_DEBUG)||(LA137_0 >= KW_DEFAULT && LA137_0 <= KW_DEFINED)||(LA137_0 >= KW_DELIMITED && LA137_0 <= KW_DESC)||(LA137_0 >= KW_DETAIL && LA137_0 <= KW_DISABLE)||(LA137_0 >= KW_DISTRIBUTE && LA137_0 <= KW_DO)||LA137_0==KW_DOW||(LA137_0 >= KW_DUMP && LA137_0 <= KW_ELEM_TYPE)||LA137_0==KW_ENABLE||(LA137_0 >= KW_ENFORCED && LA137_0 <= KW_EVERY)||(LA137_0 >= KW_EXCLUSIVE && LA137_0 <= KW_EXECUTED)||(LA137_0 >= KW_EXPLAIN && LA137_0 <= KW_EXPRESSION)||(LA137_0 >= KW_FIELDS && LA137_0 <= KW_FIRST)||(LA137_0 >= KW_FORMAT && LA137_0 <= KW_FORMATTED)||LA137_0==KW_FUNCTIONS||(LA137_0 >= KW_HOUR && LA137_0 <= KW_IDXPROPERTIES)||(LA137_0 >= KW_INDEX && LA137_0 <= KW_INDEXES)||(LA137_0 >= KW_INPATH && LA137_0 <= KW_INPUTFORMAT)||(LA137_0 >= KW_ISOLATION && LA137_0 <= KW_JAR)||(LA137_0 >= KW_JOINCOST && LA137_0 <= KW_LAST)||LA137_0==KW_LEVEL||(LA137_0 >= KW_LIMIT && LA137_0 <= KW_LOAD)||(LA137_0 >= KW_LOCATION && LA137_0 <= KW_LONG)||(LA137_0 >= KW_MANAGEDLOCATION && LA137_0 <= KW_MANAGEMENT)||(LA137_0 >= KW_MAPJOIN && LA137_0 <= KW_MATERIALIZED)||LA137_0==KW_METADATA||(LA137_0 >= KW_MINUTE && LA137_0 <= KW_MONTH)||(LA137_0 >= KW_MOVE && LA137_0 <= KW_MSCK)||(LA137_0 >= KW_NORELY && LA137_0 <= KW_NOSCAN)||LA137_0==KW_NOVALIDATE||LA137_0==KW_NULLS||LA137_0==KW_OFFSET||(LA137_0 >= KW_OPERATOR && LA137_0 <= KW_OPTION)||(LA137_0 >= KW_OUTPUTDRIVER && LA137_0 <= KW_OUTPUTFORMAT)||(LA137_0 >= KW_OVERWRITE && LA137_0 <= KW_OWNER)||(LA137_0 >= KW_PARTITIONED && LA137_0 <= KW_PATH)||(LA137_0 >= KW_PLAN && LA137_0 <= KW_POOL)||LA137_0==KW_PRINCIPALS||(LA137_0 >= KW_PURGE && LA137_0 <= KW_QUERY_PARALLELISM)||LA137_0==KW_READ||(LA137_0 >= KW_REBUILD && LA137_0 <= KW_RECORDWRITER)||(LA137_0 >= KW_RELOAD && LA137_0 <= KW_RESTRICT)||LA137_0==KW_REWRITE||(LA137_0 >= KW_ROLE && LA137_0 <= KW_ROLES)||(LA137_0 >= KW_SCHEDULED && LA137_0 <= KW_SECOND)||(LA137_0 >= KW_SEMI && LA137_0 <= KW_SERVER)||(LA137_0 >= KW_SETS && LA137_0 <= KW_SKEWED)||(LA137_0 >= KW_SNAPSHOT && LA137_0 <= KW_SSL)||(LA137_0 >= KW_STATISTICS && LA137_0 <= KW_SUMMARY)||LA137_0==KW_TABLES||(LA137_0 >= KW_TBLPROPERTIES && LA137_0 <= KW_TERMINATED)||LA137_0==KW_TINYINT||(LA137_0 >= KW_TOUCH && LA137_0 <= KW_TRANSACTIONS)||LA137_0==KW_UNARCHIVE||LA137_0==KW_UNDO||LA137_0==KW_UNIONTYPE||(LA137_0 >= KW_UNLOCK && LA137_0 <= KW_UNSIGNED)||(LA137_0 >= KW_URI && LA137_0 <= KW_USE)||(LA137_0 >= KW_UTC && LA137_0 <= KW_VALIDATE)||LA137_0==KW_VALUE_TYPE||(LA137_0 >= KW_VECTORIZATION && LA137_0 <= KW_WEEK)||LA137_0==KW_WHILE||(LA137_0 >= KW_WORK && LA137_0 <= KW_ZONE)||LA137_0==StringLiteral||LA137_0==KW_BATCH||LA137_0==KW_DAYOFWEEK||LA137_0==KW_HOLD_DDLTIME||LA137_0==KW_IGNORE||LA137_0==KW_NO_DROP||LA137_0==KW_OFFLINE||LA137_0==KW_PROTECTION||LA137_0==KW_READONLY||LA137_0==KW_TIMESTAMPTZ) ) {
						alt137=2;
					}
					switch (alt137) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:63: KW_LIKE showStmtIdentifier
							{
							KW_LIKE455=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement8518); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE455);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8520);
							showStmtIdentifier456=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier456.getTree());
							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:90: showStmtIdentifier
							{
							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8522);
							showStmtIdentifier457=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier457.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: db_name, showStmtIdentifier
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1670:112: -> ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:115: ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWVIEWS, "TOK_SHOWVIEWS"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:131: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:152: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:7: KW_SHOW KW_MATERIALIZED KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					{
					KW_SHOW458=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8550); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW458);

					KW_MATERIALIZED459=(Token)match(input,KW_MATERIALIZED,FOLLOW_KW_MATERIALIZED_in_showStatement8552); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MATERIALIZED.add(KW_MATERIALIZED459);

					KW_VIEWS460=(Token)match(input,KW_VIEWS,FOLLOW_KW_VIEWS_in_showStatement8554); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VIEWS.add(KW_VIEWS460);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:40: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt139=2;
					int LA139_0 = input.LA(1);
					if ( (LA139_0==KW_FROM||LA139_0==KW_IN) ) {
						alt139=1;
					}
					switch (alt139) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:41: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:41: ( KW_FROM | KW_IN )
							int alt138=2;
							int LA138_0 = input.LA(1);
							if ( (LA138_0==KW_FROM) ) {
								alt138=1;
							}
							else if ( (LA138_0==KW_IN) ) {
								alt138=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 138, 0, input);
								throw nvae;
							}

							switch (alt138) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:42: KW_FROM
									{
									KW_FROM461=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement8558); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM461);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:50: KW_IN
									{
									KW_IN462=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement8560); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN462);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement8565);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:78: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					int alt140=3;
					int LA140_0 = input.LA(1);
					if ( (LA140_0==KW_LIKE) ) {
						alt140=1;
					}
					else if ( (LA140_0==Identifier||(LA140_0 >= KW_ABORT && LA140_0 <= KW_AFTER)||LA140_0==KW_ALLOC_FRACTION||LA140_0==KW_ANALYZE||LA140_0==KW_ARCHIVE||(LA140_0 >= KW_ASC && LA140_0 <= KW_AT)||(LA140_0 >= KW_AUTOCOMMIT && LA140_0 <= KW_BEFORE)||(LA140_0 >= KW_BUCKET && LA140_0 <= KW_BUCKETS)||(LA140_0 >= KW_CACHE && LA140_0 <= KW_CASCADE)||(LA140_0 >= KW_CBO && LA140_0 <= KW_CHANGE)||(LA140_0 >= KW_CHECK && LA140_0 <= KW_COLLECTION)||(LA140_0 >= KW_COLUMNS && LA140_0 <= KW_COMMENT)||(LA140_0 >= KW_COMPACT && LA140_0 <= KW_CONCATENATE)||(LA140_0 >= KW_CONTINUE && LA140_0 <= KW_COST)||LA140_0==KW_CRON||LA140_0==KW_DATA||LA140_0==KW_DATABASES||(LA140_0 >= KW_DATETIME && LA140_0 <= KW_DEBUG)||(LA140_0 >= KW_DEFAULT && LA140_0 <= KW_DEFINED)||(LA140_0 >= KW_DELIMITED && LA140_0 <= KW_DESC)||(LA140_0 >= KW_DETAIL && LA140_0 <= KW_DISABLE)||(LA140_0 >= KW_DISTRIBUTE && LA140_0 <= KW_DO)||LA140_0==KW_DOW||(LA140_0 >= KW_DUMP && LA140_0 <= KW_ELEM_TYPE)||LA140_0==KW_ENABLE||(LA140_0 >= KW_ENFORCED && LA140_0 <= KW_EVERY)||(LA140_0 >= KW_EXCLUSIVE && LA140_0 <= KW_EXECUTED)||(LA140_0 >= KW_EXPLAIN && LA140_0 <= KW_EXPRESSION)||(LA140_0 >= KW_FIELDS && LA140_0 <= KW_FIRST)||(LA140_0 >= KW_FORMAT && LA140_0 <= KW_FORMATTED)||LA140_0==KW_FUNCTIONS||(LA140_0 >= KW_HOUR && LA140_0 <= KW_IDXPROPERTIES)||(LA140_0 >= KW_INDEX && LA140_0 <= KW_INDEXES)||(LA140_0 >= KW_INPATH && LA140_0 <= KW_INPUTFORMAT)||(LA140_0 >= KW_ISOLATION && LA140_0 <= KW_JAR)||(LA140_0 >= KW_JOINCOST && LA140_0 <= KW_LAST)||LA140_0==KW_LEVEL||(LA140_0 >= KW_LIMIT && LA140_0 <= KW_LOAD)||(LA140_0 >= KW_LOCATION && LA140_0 <= KW_LONG)||(LA140_0 >= KW_MANAGEDLOCATION && LA140_0 <= KW_MANAGEMENT)||(LA140_0 >= KW_MAPJOIN && LA140_0 <= KW_MATERIALIZED)||LA140_0==KW_METADATA||(LA140_0 >= KW_MINUTE && LA140_0 <= KW_MONTH)||(LA140_0 >= KW_MOVE && LA140_0 <= KW_MSCK)||(LA140_0 >= KW_NORELY && LA140_0 <= KW_NOSCAN)||LA140_0==KW_NOVALIDATE||LA140_0==KW_NULLS||LA140_0==KW_OFFSET||(LA140_0 >= KW_OPERATOR && LA140_0 <= KW_OPTION)||(LA140_0 >= KW_OUTPUTDRIVER && LA140_0 <= KW_OUTPUTFORMAT)||(LA140_0 >= KW_OVERWRITE && LA140_0 <= KW_OWNER)||(LA140_0 >= KW_PARTITIONED && LA140_0 <= KW_PATH)||(LA140_0 >= KW_PLAN && LA140_0 <= KW_POOL)||LA140_0==KW_PRINCIPALS||(LA140_0 >= KW_PURGE && LA140_0 <= KW_QUERY_PARALLELISM)||LA140_0==KW_READ||(LA140_0 >= KW_REBUILD && LA140_0 <= KW_RECORDWRITER)||(LA140_0 >= KW_RELOAD && LA140_0 <= KW_RESTRICT)||LA140_0==KW_REWRITE||(LA140_0 >= KW_ROLE && LA140_0 <= KW_ROLES)||(LA140_0 >= KW_SCHEDULED && LA140_0 <= KW_SECOND)||(LA140_0 >= KW_SEMI && LA140_0 <= KW_SERVER)||(LA140_0 >= KW_SETS && LA140_0 <= KW_SKEWED)||(LA140_0 >= KW_SNAPSHOT && LA140_0 <= KW_SSL)||(LA140_0 >= KW_STATISTICS && LA140_0 <= KW_SUMMARY)||LA140_0==KW_TABLES||(LA140_0 >= KW_TBLPROPERTIES && LA140_0 <= KW_TERMINATED)||LA140_0==KW_TINYINT||(LA140_0 >= KW_TOUCH && LA140_0 <= KW_TRANSACTIONS)||LA140_0==KW_UNARCHIVE||LA140_0==KW_UNDO||LA140_0==KW_UNIONTYPE||(LA140_0 >= KW_UNLOCK && LA140_0 <= KW_UNSIGNED)||(LA140_0 >= KW_URI && LA140_0 <= KW_USE)||(LA140_0 >= KW_UTC && LA140_0 <= KW_VALIDATE)||LA140_0==KW_VALUE_TYPE||(LA140_0 >= KW_VECTORIZATION && LA140_0 <= KW_WEEK)||LA140_0==KW_WHILE||(LA140_0 >= KW_WORK && LA140_0 <= KW_ZONE)||LA140_0==StringLiteral||LA140_0==KW_BATCH||LA140_0==KW_DAYOFWEEK||LA140_0==KW_HOLD_DDLTIME||LA140_0==KW_IGNORE||LA140_0==KW_NO_DROP||LA140_0==KW_OFFLINE||LA140_0==KW_PROTECTION||LA140_0==KW_READONLY||LA140_0==KW_TIMESTAMPTZ) ) {
						alt140=2;
					}
					switch (alt140) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:79: KW_LIKE showStmtIdentifier
							{
							KW_LIKE463=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement8570); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE463);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8572);
							showStmtIdentifier464=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier464.getTree());
							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:106: showStmtIdentifier
							{
							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8574);
							showStmtIdentifier465=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier465.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: db_name, showStmtIdentifier
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1671:128: -> ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:131: ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWMATERIALIZEDVIEWS, "TOK_SHOWMATERIALIZEDVIEWS"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:159: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:180: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:7: KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					{
					KW_SHOW466=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8602); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW466);

					KW_COLUMNS467=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_showStatement8604); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS467);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:26: ( KW_FROM | KW_IN )
					int alt141=2;
					int LA141_0 = input.LA(1);
					if ( (LA141_0==KW_FROM) ) {
						alt141=1;
					}
					else if ( (LA141_0==KW_IN) ) {
						alt141=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 141, 0, input);
						throw nvae;
					}

					switch (alt141) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:27: KW_FROM
							{
							KW_FROM468=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement8607); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM468);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:35: KW_IN
							{
							KW_IN469=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement8609); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN469);

							}
							break;

					}

					pushFollow(FOLLOW_tableName_in_showStatement8612);
					tableName470=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName470.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:52: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt143=2;
					int LA143_0 = input.LA(1);
					if ( (LA143_0==KW_FROM||LA143_0==KW_IN) ) {
						alt143=1;
					}
					switch (alt143) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:53: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:53: ( KW_FROM | KW_IN )
							int alt142=2;
							int LA142_0 = input.LA(1);
							if ( (LA142_0==KW_FROM) ) {
								alt142=1;
							}
							else if ( (LA142_0==KW_IN) ) {
								alt142=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 142, 0, input);
								throw nvae;
							}

							switch (alt142) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:54: KW_FROM
									{
									KW_FROM471=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement8616); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM471);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:62: KW_IN
									{
									KW_IN472=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement8618); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN472);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement8623);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:90: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					int alt144=3;
					int LA144_0 = input.LA(1);
					if ( (LA144_0==KW_LIKE) ) {
						alt144=1;
					}
					else if ( (LA144_0==Identifier||(LA144_0 >= KW_ABORT && LA144_0 <= KW_AFTER)||LA144_0==KW_ALLOC_FRACTION||LA144_0==KW_ANALYZE||LA144_0==KW_ARCHIVE||(LA144_0 >= KW_ASC && LA144_0 <= KW_AT)||(LA144_0 >= KW_AUTOCOMMIT && LA144_0 <= KW_BEFORE)||(LA144_0 >= KW_BUCKET && LA144_0 <= KW_BUCKETS)||(LA144_0 >= KW_CACHE && LA144_0 <= KW_CASCADE)||(LA144_0 >= KW_CBO && LA144_0 <= KW_CHANGE)||(LA144_0 >= KW_CHECK && LA144_0 <= KW_COLLECTION)||(LA144_0 >= KW_COLUMNS && LA144_0 <= KW_COMMENT)||(LA144_0 >= KW_COMPACT && LA144_0 <= KW_CONCATENATE)||(LA144_0 >= KW_CONTINUE && LA144_0 <= KW_COST)||LA144_0==KW_CRON||LA144_0==KW_DATA||LA144_0==KW_DATABASES||(LA144_0 >= KW_DATETIME && LA144_0 <= KW_DEBUG)||(LA144_0 >= KW_DEFAULT && LA144_0 <= KW_DEFINED)||(LA144_0 >= KW_DELIMITED && LA144_0 <= KW_DESC)||(LA144_0 >= KW_DETAIL && LA144_0 <= KW_DISABLE)||(LA144_0 >= KW_DISTRIBUTE && LA144_0 <= KW_DO)||LA144_0==KW_DOW||(LA144_0 >= KW_DUMP && LA144_0 <= KW_ELEM_TYPE)||LA144_0==KW_ENABLE||(LA144_0 >= KW_ENFORCED && LA144_0 <= KW_EVERY)||(LA144_0 >= KW_EXCLUSIVE && LA144_0 <= KW_EXECUTED)||(LA144_0 >= KW_EXPLAIN && LA144_0 <= KW_EXPRESSION)||(LA144_0 >= KW_FIELDS && LA144_0 <= KW_FIRST)||(LA144_0 >= KW_FORMAT && LA144_0 <= KW_FORMATTED)||LA144_0==KW_FUNCTIONS||(LA144_0 >= KW_HOUR && LA144_0 <= KW_IDXPROPERTIES)||(LA144_0 >= KW_INDEX && LA144_0 <= KW_INDEXES)||(LA144_0 >= KW_INPATH && LA144_0 <= KW_INPUTFORMAT)||(LA144_0 >= KW_ISOLATION && LA144_0 <= KW_JAR)||(LA144_0 >= KW_JOINCOST && LA144_0 <= KW_LAST)||LA144_0==KW_LEVEL||(LA144_0 >= KW_LIMIT && LA144_0 <= KW_LOAD)||(LA144_0 >= KW_LOCATION && LA144_0 <= KW_LONG)||(LA144_0 >= KW_MANAGEDLOCATION && LA144_0 <= KW_MANAGEMENT)||(LA144_0 >= KW_MAPJOIN && LA144_0 <= KW_MATERIALIZED)||LA144_0==KW_METADATA||(LA144_0 >= KW_MINUTE && LA144_0 <= KW_MONTH)||(LA144_0 >= KW_MOVE && LA144_0 <= KW_MSCK)||(LA144_0 >= KW_NORELY && LA144_0 <= KW_NOSCAN)||LA144_0==KW_NOVALIDATE||LA144_0==KW_NULLS||LA144_0==KW_OFFSET||(LA144_0 >= KW_OPERATOR && LA144_0 <= KW_OPTION)||(LA144_0 >= KW_OUTPUTDRIVER && LA144_0 <= KW_OUTPUTFORMAT)||(LA144_0 >= KW_OVERWRITE && LA144_0 <= KW_OWNER)||(LA144_0 >= KW_PARTITIONED && LA144_0 <= KW_PATH)||(LA144_0 >= KW_PLAN && LA144_0 <= KW_POOL)||LA144_0==KW_PRINCIPALS||(LA144_0 >= KW_PURGE && LA144_0 <= KW_QUERY_PARALLELISM)||LA144_0==KW_READ||(LA144_0 >= KW_REBUILD && LA144_0 <= KW_RECORDWRITER)||(LA144_0 >= KW_RELOAD && LA144_0 <= KW_RESTRICT)||LA144_0==KW_REWRITE||(LA144_0 >= KW_ROLE && LA144_0 <= KW_ROLES)||(LA144_0 >= KW_SCHEDULED && LA144_0 <= KW_SECOND)||(LA144_0 >= KW_SEMI && LA144_0 <= KW_SERVER)||(LA144_0 >= KW_SETS && LA144_0 <= KW_SKEWED)||(LA144_0 >= KW_SNAPSHOT && LA144_0 <= KW_SSL)||(LA144_0 >= KW_STATISTICS && LA144_0 <= KW_SUMMARY)||LA144_0==KW_TABLES||(LA144_0 >= KW_TBLPROPERTIES && LA144_0 <= KW_TERMINATED)||LA144_0==KW_TINYINT||(LA144_0 >= KW_TOUCH && LA144_0 <= KW_TRANSACTIONS)||LA144_0==KW_UNARCHIVE||LA144_0==KW_UNDO||LA144_0==KW_UNIONTYPE||(LA144_0 >= KW_UNLOCK && LA144_0 <= KW_UNSIGNED)||(LA144_0 >= KW_URI && LA144_0 <= KW_USE)||(LA144_0 >= KW_UTC && LA144_0 <= KW_VALIDATE)||LA144_0==KW_VALUE_TYPE||(LA144_0 >= KW_VECTORIZATION && LA144_0 <= KW_WEEK)||LA144_0==KW_WHILE||(LA144_0 >= KW_WORK && LA144_0 <= KW_ZONE)||LA144_0==StringLiteral||LA144_0==KW_BATCH||LA144_0==KW_DAYOFWEEK||LA144_0==KW_HOLD_DDLTIME||LA144_0==KW_IGNORE||LA144_0==KW_NO_DROP||LA144_0==KW_OFFLINE||LA144_0==KW_PROTECTION||LA144_0==KW_READONLY||LA144_0==KW_TIMESTAMPTZ) ) {
						alt144=2;
					}
					switch (alt144) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:91: KW_LIKE showStmtIdentifier
							{
							KW_LIKE473=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement8628); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE473);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8630);
							showStmtIdentifier474=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier474.getTree());
							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:118: showStmtIdentifier
							{
							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8632);
							showStmtIdentifier475=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier475.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: db_name, tableName, showStmtIdentifier
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1673:5: -> ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1673:8: ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWCOLUMNS, "TOK_SHOWCOLUMNS"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1673:36: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1673:57: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:7: KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier )?
					{
					KW_SHOW476=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8665); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW476);

					KW_FUNCTIONS477=(Token)match(input,KW_FUNCTIONS,FOLLOW_KW_FUNCTIONS_in_showStatement8667); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTIONS.add(KW_FUNCTIONS477);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:28: ( KW_LIKE showFunctionIdentifier )?
					int alt145=2;
					int LA145_0 = input.LA(1);
					if ( (LA145_0==KW_LIKE) ) {
						alt145=1;
					}
					switch (alt145) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:29: KW_LIKE showFunctionIdentifier
							{
							KW_LIKE478=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement8670); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE478);

							pushFollow(FOLLOW_showFunctionIdentifier_in_showStatement8672);
							showFunctionIdentifier479=showFunctionIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showFunctionIdentifier.add(showFunctionIdentifier479.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: KW_LIKE, showFunctionIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1674:63: -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:66: ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWFUNCTIONS, "TOK_SHOWFUNCTIONS"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:86: ( KW_LIKE )?
						if ( stream_KW_LIKE.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_LIKE.nextNode());
						}
						stream_KW_LIKE.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:95: ( showFunctionIdentifier )?
						if ( stream_showFunctionIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showFunctionIdentifier.nextTree());
						}
						stream_showFunctionIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:7: KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )?
					{
					KW_SHOW480=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8695); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW480);

					KW_PARTITIONS481=(Token)match(input,KW_PARTITIONS,FOLLOW_KW_PARTITIONS_in_showStatement8697); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PARTITIONS.add(KW_PARTITIONS481);

					pushFollow(FOLLOW_tableName_in_showStatement8701);
					tabName=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:47: ( partitionSpec )?
					int alt146=2;
					int LA146_0 = input.LA(1);
					if ( (LA146_0==KW_PARTITION) ) {
						alt146=1;
					}
					switch (alt146) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:47: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_showStatement8703);
							partitionSpec482=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec482.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: tabName, partitionSpec
					// token labels: 
					// rule labels: tabName, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1675:62: -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:65: ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWPARTITIONS, "TOK_SHOWPARTITIONS"), root_1);
						adaptor.addChild(root_1, stream_tabName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:95: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1676:7: KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) )
					{
					KW_SHOW483=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8725); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW483);

					KW_CREATE484=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_showStatement8727); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE484);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1676:25: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) )
					int alt148=2;
					int LA148_0 = input.LA(1);
					if ( (LA148_0==KW_DATABASE) && (synpred12_HiveParser())) {
						alt148=1;
					}
					else if ( (LA148_0==KW_SCHEMA) && (synpred12_HiveParser())) {
						alt148=1;
					}
					else if ( (LA148_0==KW_TABLE) ) {
						alt148=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 148, 0, input);
						throw nvae;
					}

					switch (alt148) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1677:9: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1677:36: ( KW_DATABASE | KW_SCHEMA )
							int alt147=2;
							int LA147_0 = input.LA(1);
							if ( (LA147_0==KW_DATABASE) ) {
								alt147=1;
							}
							else if ( (LA147_0==KW_SCHEMA) ) {
								alt147=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 147, 0, input);
								throw nvae;
							}

							switch (alt147) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1677:37: KW_DATABASE
									{
									KW_DATABASE485=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_showStatement8748); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE485);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1677:49: KW_SCHEMA
									{
									KW_SCHEMA486=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_showStatement8750); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA486);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement8755);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							// AST REWRITE
							// elements: db_name
							// token labels: 
							// rule labels: db_name, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1677:79: -> ^( TOK_SHOW_CREATEDATABASE $db_name)
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1677:82: ^( TOK_SHOW_CREATEDATABASE $db_name)
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_CREATEDATABASE, "TOK_SHOW_CREATEDATABASE"), root_1);
								adaptor.addChild(root_1, stream_db_name.nextTree());
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1679:9: KW_TABLE tabName= tableName
							{
							KW_TABLE487=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_showStatement8784); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE487);

							pushFollow(FOLLOW_tableName_in_showStatement8788);
							tabName=tableName();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
							// AST REWRITE
							// elements: tabName
							// token labels: 
							// rule labels: tabName, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1679:36: -> ^( TOK_SHOW_CREATETABLE $tabName)
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1679:39: ^( TOK_SHOW_CREATETABLE $tabName)
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_CREATETABLE, "TOK_SHOW_CREATETABLE"), root_1);
								adaptor.addChild(root_1, stream_tabName.nextTree());
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;

					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:7: KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )?
					{
					KW_SHOW488=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8813); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW488);

					KW_TABLE489=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_showStatement8815); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE489);

					KW_EXTENDED490=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement8817); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED490);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:36: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt150=2;
					int LA150_0 = input.LA(1);
					if ( (LA150_0==KW_FROM||LA150_0==KW_IN) ) {
						alt150=1;
					}
					switch (alt150) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:37: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:37: ( KW_FROM | KW_IN )
							int alt149=2;
							int LA149_0 = input.LA(1);
							if ( (LA149_0==KW_FROM) ) {
								alt149=1;
							}
							else if ( (LA149_0==KW_IN) ) {
								alt149=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 149, 0, input);
								throw nvae;
							}

							switch (alt149) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:38: KW_FROM
									{
									KW_FROM491=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement8821); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM491);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:46: KW_IN
									{
									KW_IN492=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement8823); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN492);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement8828);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					KW_LIKE493=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement8832); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE493);

					pushFollow(FOLLOW_showStmtIdentifier_in_showStatement8834);
					showStmtIdentifier494=showStmtIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier494.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:101: ( partitionSpec )?
					int alt151=2;
					int LA151_0 = input.LA(1);
					if ( (LA151_0==KW_PARTITION) ) {
						alt151=1;
					}
					switch (alt151) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:101: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_showStatement8836);
							partitionSpec495=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec495.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: db_name, partitionSpec, showStmtIdentifier
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1682:5: -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1682:8: ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_TABLESTATUS, "TOK_SHOW_TABLESTATUS"), root_1);
						adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1682:51: ( $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1682:60: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1683:7: KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )?
					{
					KW_SHOW496=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8864); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW496);

					KW_TBLPROPERTIES497=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_showStatement8866); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES497);

					pushFollow(FOLLOW_tableName_in_showStatement8868);
					tableName498=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName498.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1683:42: ( LPAREN prptyName= StringLiteral RPAREN )?
					int alt152=2;
					int LA152_0 = input.LA(1);
					if ( (LA152_0==LPAREN) ) {
						alt152=1;
					}
					switch (alt152) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1683:43: LPAREN prptyName= StringLiteral RPAREN
							{
							LPAREN499=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_showStatement8871); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN499);

							prptyName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStatement8875); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(prptyName);

							RPAREN500=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_showStatement8877); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN500);

							}
							break;

					}

					// AST REWRITE
					// elements: tableName, prptyName
					// token labels: prptyName
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_prptyName=new RewriteRuleTokenStream(adaptor,"token prptyName",prptyName);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1683:83: -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1683:86: ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_TBLPROPERTIES, "TOK_SHOW_TBLPROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1683:122: ( $prptyName)?
						if ( stream_prptyName.hasNext() ) {
							adaptor.addChild(root_1, stream_prptyName.nextNode());
						}
						stream_prptyName.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1684:7: KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) )
					{
					KW_SHOW501=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8899); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW501);

					KW_LOCKS502=(Token)match(input,KW_LOCKS,FOLLOW_KW_LOCKS_in_showStatement8901); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCKS.add(KW_LOCKS502);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1685:7: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) )
					int alt157=2;
					int LA157_0 = input.LA(1);
					if ( (LA157_0==KW_DATABASE) && (synpred13_HiveParser())) {
						alt157=1;
					}
					else if ( (LA157_0==KW_SCHEMA) ) {
						switch ( input.LA(2) ) {
						case Identifier:
							{
							int LA157_7 = input.LA(3);
							if ( (synpred13_HiveParser()) ) {
								alt157=1;
							}
							else if ( (true) ) {
								alt157=2;
							}

							}
							break;
						case KW_ABORT:
						case KW_ACTIVATE:
						case KW_ACTIVE:
						case KW_ADD:
						case KW_ADMIN:
						case KW_AFTER:
						case KW_ALLOC_FRACTION:
						case KW_ANALYZE:
						case KW_ARCHIVE:
						case KW_ASC:
						case KW_AT:
						case KW_AUTOCOMMIT:
						case KW_BEFORE:
						case KW_BUCKET:
						case KW_BUCKETS:
						case KW_CACHE:
						case KW_CASCADE:
						case KW_CBO:
						case KW_CHANGE:
						case KW_CHECK:
						case KW_CLUSTER:
						case KW_CLUSTERED:
						case KW_CLUSTERSTATUS:
						case KW_COLLECTION:
						case KW_COLUMNS:
						case KW_COMMENT:
						case KW_COMPACT:
						case KW_COMPACTIONS:
						case KW_COMPUTE:
						case KW_CONCATENATE:
						case KW_CONTINUE:
						case KW_COST:
						case KW_CRON:
						case KW_DATA:
						case KW_DATABASES:
						case KW_DATETIME:
						case KW_DAY:
						case KW_DBPROPERTIES:
						case KW_DEBUG:
						case KW_DEFAULT:
						case KW_DEFERRED:
						case KW_DEFINED:
						case KW_DELIMITED:
						case KW_DEPENDENCY:
						case KW_DESC:
						case KW_DETAIL:
						case KW_DIRECTORIES:
						case KW_DIRECTORY:
						case KW_DISABLE:
						case KW_DISTRIBUTE:
						case KW_DISTRIBUTED:
						case KW_DO:
						case KW_DOW:
						case KW_DUMP:
						case KW_ELEM_TYPE:
						case KW_ENABLE:
						case KW_ENFORCED:
						case KW_ESCAPED:
						case KW_EVERY:
						case KW_EXCLUSIVE:
						case KW_EXECUTE:
						case KW_EXECUTED:
						case KW_EXPLAIN:
						case KW_EXPORT:
						case KW_EXPRESSION:
						case KW_FIELDS:
						case KW_FILE:
						case KW_FILEFORMAT:
						case KW_FIRST:
						case KW_FORMAT:
						case KW_FORMATTED:
						case KW_FUNCTIONS:
						case KW_HOUR:
						case KW_IDXPROPERTIES:
						case KW_INDEX:
						case KW_INDEXES:
						case KW_INPATH:
						case KW_INPUTDRIVER:
						case KW_INPUTFORMAT:
						case KW_ISOLATION:
						case KW_ITEMS:
						case KW_JAR:
						case KW_JOINCOST:
						case KW_KEY:
						case KW_KEYS:
						case KW_KEY_TYPE:
						case KW_KILL:
						case KW_LAST:
						case KW_LEVEL:
						case KW_LIMIT:
						case KW_LINES:
						case KW_LOAD:
						case KW_LOCATION:
						case KW_LOCK:
						case KW_LOCKS:
						case KW_LOGICAL:
						case KW_LONG:
						case KW_MANAGEDLOCATION:
						case KW_MANAGEMENT:
						case KW_MAPJOIN:
						case KW_MAPPING:
						case KW_MATCHED:
						case KW_MATERIALIZED:
						case KW_METADATA:
						case KW_MINUTE:
						case KW_MONTH:
						case KW_MOVE:
						case KW_MSCK:
						case KW_NORELY:
						case KW_NOSCAN:
						case KW_NOVALIDATE:
						case KW_NULLS:
						case KW_OFFSET:
						case KW_OPERATOR:
						case KW_OPTION:
						case KW_OUTPUTDRIVER:
						case KW_OUTPUTFORMAT:
						case KW_OVERWRITE:
						case KW_OWNER:
						case KW_PARTITIONED:
						case KW_PARTITIONS:
						case KW_PATH:
						case KW_PLAN:
						case KW_PLANS:
						case KW_PLUS:
						case KW_POOL:
						case KW_PRINCIPALS:
						case KW_PURGE:
						case KW_QUARTER:
						case KW_QUERY:
						case KW_QUERY_PARALLELISM:
						case KW_READ:
						case KW_REBUILD:
						case KW_RECORDREADER:
						case KW_RECORDWRITER:
						case KW_RELOAD:
						case KW_RELY:
						case KW_RENAME:
						case KW_REOPTIMIZATION:
						case KW_REPAIR:
						case KW_REPL:
						case KW_REPLACE:
						case KW_REPLICATION:
						case KW_RESOURCE:
						case KW_RESTRICT:
						case KW_REWRITE:
						case KW_ROLE:
						case KW_ROLES:
						case KW_SCHEDULED:
						case KW_SCHEDULING_POLICY:
						case KW_SCHEMA:
						case KW_SCHEMAS:
						case KW_SECOND:
						case KW_SEMI:
						case KW_SERDE:
						case KW_SERDEPROPERTIES:
						case KW_SERVER:
						case KW_SETS:
						case KW_SHARED:
						case KW_SHOW:
						case KW_SHOW_DATABASE:
						case KW_SKEWED:
						case KW_SNAPSHOT:
						case KW_SORT:
						case KW_SORTED:
						case KW_SSL:
						case KW_STATISTICS:
						case KW_STATUS:
						case KW_STORED:
						case KW_STREAMTABLE:
						case KW_STRING:
						case KW_STRUCT:
						case KW_SUMMARY:
						case KW_TABLES:
						case KW_TBLPROPERTIES:
						case KW_TEMPORARY:
						case KW_TERMINATED:
						case KW_TINYINT:
						case KW_TOUCH:
						case KW_TRANSACTION:
						case KW_TRANSACTIONAL:
						case KW_TRANSACTIONS:
						case KW_UNARCHIVE:
						case KW_UNDO:
						case KW_UNIONTYPE:
						case KW_UNLOCK:
						case KW_UNMANAGED:
						case KW_UNSET:
						case KW_UNSIGNED:
						case KW_URI:
						case KW_USE:
						case KW_UTC:
						case KW_UTCTIMESTAMP:
						case KW_VALIDATE:
						case KW_VALUE_TYPE:
						case KW_VECTORIZATION:
						case KW_VIEW:
						case KW_VIEWS:
						case KW_WAIT:
						case KW_WEEK:
						case KW_WHILE:
						case KW_WORK:
						case KW_WORKLOAD:
						case KW_WRITE:
						case KW_YEAR:
						case KW_ZONE:
						case KW_BATCH:
						case KW_DAYOFWEEK:
						case KW_HOLD_DDLTIME:
						case KW_IGNORE:
						case KW_NO_DROP:
						case KW_OFFLINE:
						case KW_PROTECTION:
						case KW_READONLY:
						case KW_TIMESTAMPTZ:
							{
							int LA157_8 = input.LA(3);
							if ( (synpred13_HiveParser()) ) {
								alt157=1;
							}
							else if ( (true) ) {
								alt157=2;
							}

							}
							break;
						case EOF:
						case DOT:
						case KW_EXTENDED:
						case KW_PARTITION:
							{
							alt157=2;
							}
							break;
						default:
							if (state.backtracking>0) {state.failed=true; return retval;}
							int nvaeMark = input.mark();
							try {
								input.consume();
								NoViableAltException nvae =
									new NoViableAltException("", 157, 2, input);
								throw nvae;
							} finally {
								input.rewind(nvaeMark);
							}
						}
					}
					else if ( (LA157_0==EOF||LA157_0==Identifier||(LA157_0 >= KW_ABORT && LA157_0 <= KW_AFTER)||LA157_0==KW_ALLOC_FRACTION||LA157_0==KW_ANALYZE||LA157_0==KW_ARCHIVE||(LA157_0 >= KW_ASC && LA157_0 <= KW_AT)||(LA157_0 >= KW_AUTOCOMMIT && LA157_0 <= KW_BEFORE)||(LA157_0 >= KW_BUCKET && LA157_0 <= KW_BUCKETS)||(LA157_0 >= KW_CACHE && LA157_0 <= KW_CASCADE)||(LA157_0 >= KW_CBO && LA157_0 <= KW_CHANGE)||(LA157_0 >= KW_CHECK && LA157_0 <= KW_COLLECTION)||(LA157_0 >= KW_COLUMNS && LA157_0 <= KW_COMMENT)||(LA157_0 >= KW_COMPACT && LA157_0 <= KW_CONCATENATE)||(LA157_0 >= KW_CONTINUE && LA157_0 <= KW_COST)||LA157_0==KW_CRON||LA157_0==KW_DATA||LA157_0==KW_DATABASES||(LA157_0 >= KW_DATETIME && LA157_0 <= KW_DEBUG)||(LA157_0 >= KW_DEFAULT && LA157_0 <= KW_DEFINED)||(LA157_0 >= KW_DELIMITED && LA157_0 <= KW_DESC)||(LA157_0 >= KW_DETAIL && LA157_0 <= KW_DISABLE)||(LA157_0 >= KW_DISTRIBUTE && LA157_0 <= KW_DO)||LA157_0==KW_DOW||(LA157_0 >= KW_DUMP && LA157_0 <= KW_ELEM_TYPE)||LA157_0==KW_ENABLE||(LA157_0 >= KW_ENFORCED && LA157_0 <= KW_EVERY)||(LA157_0 >= KW_EXCLUSIVE && LA157_0 <= KW_EXECUTED)||(LA157_0 >= KW_EXPLAIN && LA157_0 <= KW_EXTENDED)||(LA157_0 >= KW_FIELDS && LA157_0 <= KW_FIRST)||(LA157_0 >= KW_FORMAT && LA157_0 <= KW_FORMATTED)||LA157_0==KW_FUNCTIONS||(LA157_0 >= KW_HOUR && LA157_0 <= KW_IDXPROPERTIES)||(LA157_0 >= KW_INDEX && LA157_0 <= KW_INDEXES)||(LA157_0 >= KW_INPATH && LA157_0 <= KW_INPUTFORMAT)||(LA157_0 >= KW_ISOLATION && LA157_0 <= KW_JAR)||(LA157_0 >= KW_JOINCOST && LA157_0 <= KW_LAST)||LA157_0==KW_LEVEL||(LA157_0 >= KW_LIMIT && LA157_0 <= KW_LOAD)||(LA157_0 >= KW_LOCATION && LA157_0 <= KW_LONG)||(LA157_0 >= KW_MANAGEDLOCATION && LA157_0 <= KW_MANAGEMENT)||(LA157_0 >= KW_MAPJOIN && LA157_0 <= KW_MATERIALIZED)||LA157_0==KW_METADATA||(LA157_0 >= KW_MINUTE && LA157_0 <= KW_MONTH)||(LA157_0 >= KW_MOVE && LA157_0 <= KW_MSCK)||(LA157_0 >= KW_NORELY && LA157_0 <= KW_NOSCAN)||LA157_0==KW_NOVALIDATE||LA157_0==KW_NULLS||LA157_0==KW_OFFSET||(LA157_0 >= KW_OPERATOR && LA157_0 <= KW_OPTION)||(LA157_0 >= KW_OUTPUTDRIVER && LA157_0 <= KW_OUTPUTFORMAT)||(LA157_0 >= KW_OVERWRITE && LA157_0 <= KW_OWNER)||(LA157_0 >= KW_PARTITIONED && LA157_0 <= KW_PATH)||(LA157_0 >= KW_PLAN && LA157_0 <= KW_POOL)||LA157_0==KW_PRINCIPALS||(LA157_0 >= KW_PURGE && LA157_0 <= KW_QUERY_PARALLELISM)||LA157_0==KW_READ||(LA157_0 >= KW_REBUILD && LA157_0 <= KW_RECORDWRITER)||(LA157_0 >= KW_RELOAD && LA157_0 <= KW_RESTRICT)||LA157_0==KW_REWRITE||(LA157_0 >= KW_ROLE && LA157_0 <= KW_ROLES)||(LA157_0 >= KW_SCHEDULED && LA157_0 <= KW_SCHEDULING_POLICY)||(LA157_0 >= KW_SCHEMAS && LA157_0 <= KW_SECOND)||(LA157_0 >= KW_SEMI && LA157_0 <= KW_SERVER)||(LA157_0 >= KW_SETS && LA157_0 <= KW_SKEWED)||(LA157_0 >= KW_SNAPSHOT && LA157_0 <= KW_SSL)||(LA157_0 >= KW_STATISTICS && LA157_0 <= KW_SUMMARY)||LA157_0==KW_TABLES||(LA157_0 >= KW_TBLPROPERTIES && LA157_0 <= KW_TERMINATED)||LA157_0==KW_TINYINT||(LA157_0 >= KW_TOUCH && LA157_0 <= KW_TRANSACTIONS)||LA157_0==KW_UNARCHIVE||LA157_0==KW_UNDO||LA157_0==KW_UNIONTYPE||(LA157_0 >= KW_UNLOCK && LA157_0 <= KW_UNSIGNED)||(LA157_0 >= KW_URI && LA157_0 <= KW_USE)||(LA157_0 >= KW_UTC && LA157_0 <= KW_VALIDATE)||LA157_0==KW_VALUE_TYPE||(LA157_0 >= KW_VECTORIZATION && LA157_0 <= KW_WEEK)||LA157_0==KW_WHILE||(LA157_0 >= KW_WORK && LA157_0 <= KW_ZONE)||LA157_0==KW_BATCH||LA157_0==KW_DAYOFWEEK||LA157_0==KW_HOLD_DDLTIME||LA157_0==KW_IGNORE||LA157_0==KW_NO_DROP||LA157_0==KW_OFFLINE||LA157_0==KW_PROTECTION||LA157_0==KW_READONLY||LA157_0==KW_TIMESTAMPTZ) ) {
						alt157=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 157, 0, input);
						throw nvae;
					}

					switch (alt157) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:7: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )?
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:34: ( KW_DATABASE | KW_SCHEMA )
							int alt153=2;
							int LA153_0 = input.LA(1);
							if ( (LA153_0==KW_DATABASE) ) {
								alt153=1;
							}
							else if ( (LA153_0==KW_SCHEMA) ) {
								alt153=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 153, 0, input);
								throw nvae;
							}

							switch (alt153) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:35: KW_DATABASE
									{
									KW_DATABASE503=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_showStatement8927); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE503);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:47: KW_SCHEMA
									{
									KW_SCHEMA504=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_showStatement8929); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA504);

									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:58: (dbName= identifier )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:59: dbName= identifier
							{
							pushFollow(FOLLOW_identifier_in_showStatement8935);
							dbName=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:78: (isExtended= KW_EXTENDED )?
							int alt154=2;
							int LA154_0 = input.LA(1);
							if ( (LA154_0==KW_EXTENDED) ) {
								alt154=1;
							}
							switch (alt154) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:79: isExtended= KW_EXTENDED
									{
									isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement8941); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_EXTENDED.add(isExtended);

									}
									break;

							}

							// AST REWRITE
							// elements: dbName, isExtended
							// token labels: isExtended
							// rule labels: dbName, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
							RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1686:104: -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:107: ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWDBLOCKS, "TOK_SHOWDBLOCKS"), root_1);
								adaptor.addChild(root_1, stream_dbName.nextTree());
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:134: ( $isExtended)?
								if ( stream_isExtended.hasNext() ) {
									adaptor.addChild(root_1, stream_isExtended.nextNode());
								}
								stream_isExtended.reset();

								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:7: (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )?
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:7: (parttype= partTypeExpr )?
							int alt155=2;
							int LA155_0 = input.LA(1);
							if ( (LA155_0==Identifier||(LA155_0 >= KW_ABORT && LA155_0 <= KW_AFTER)||LA155_0==KW_ALLOC_FRACTION||LA155_0==KW_ANALYZE||LA155_0==KW_ARCHIVE||(LA155_0 >= KW_ASC && LA155_0 <= KW_AT)||(LA155_0 >= KW_AUTOCOMMIT && LA155_0 <= KW_BEFORE)||(LA155_0 >= KW_BUCKET && LA155_0 <= KW_BUCKETS)||(LA155_0 >= KW_CACHE && LA155_0 <= KW_CASCADE)||(LA155_0 >= KW_CBO && LA155_0 <= KW_CHANGE)||(LA155_0 >= KW_CHECK && LA155_0 <= KW_COLLECTION)||(LA155_0 >= KW_COLUMNS && LA155_0 <= KW_COMMENT)||(LA155_0 >= KW_COMPACT && LA155_0 <= KW_CONCATENATE)||(LA155_0 >= KW_CONTINUE && LA155_0 <= KW_COST)||LA155_0==KW_CRON||LA155_0==KW_DATA||LA155_0==KW_DATABASES||(LA155_0 >= KW_DATETIME && LA155_0 <= KW_DEBUG)||(LA155_0 >= KW_DEFAULT && LA155_0 <= KW_DEFINED)||(LA155_0 >= KW_DELIMITED && LA155_0 <= KW_DESC)||(LA155_0 >= KW_DETAIL && LA155_0 <= KW_DISABLE)||(LA155_0 >= KW_DISTRIBUTE && LA155_0 <= KW_DO)||LA155_0==KW_DOW||(LA155_0 >= KW_DUMP && LA155_0 <= KW_ELEM_TYPE)||LA155_0==KW_ENABLE||(LA155_0 >= KW_ENFORCED && LA155_0 <= KW_EVERY)||(LA155_0 >= KW_EXCLUSIVE && LA155_0 <= KW_EXECUTED)||(LA155_0 >= KW_EXPLAIN && LA155_0 <= KW_EXPRESSION)||(LA155_0 >= KW_FIELDS && LA155_0 <= KW_FIRST)||(LA155_0 >= KW_FORMAT && LA155_0 <= KW_FORMATTED)||LA155_0==KW_FUNCTIONS||(LA155_0 >= KW_HOUR && LA155_0 <= KW_IDXPROPERTIES)||(LA155_0 >= KW_INDEX && LA155_0 <= KW_INDEXES)||(LA155_0 >= KW_INPATH && LA155_0 <= KW_INPUTFORMAT)||(LA155_0 >= KW_ISOLATION && LA155_0 <= KW_JAR)||(LA155_0 >= KW_JOINCOST && LA155_0 <= KW_LAST)||LA155_0==KW_LEVEL||(LA155_0 >= KW_LIMIT && LA155_0 <= KW_LOAD)||(LA155_0 >= KW_LOCATION && LA155_0 <= KW_LONG)||(LA155_0 >= KW_MANAGEDLOCATION && LA155_0 <= KW_MANAGEMENT)||(LA155_0 >= KW_MAPJOIN && LA155_0 <= KW_MATERIALIZED)||LA155_0==KW_METADATA||(LA155_0 >= KW_MINUTE && LA155_0 <= KW_MONTH)||(LA155_0 >= KW_MOVE && LA155_0 <= KW_MSCK)||(LA155_0 >= KW_NORELY && LA155_0 <= KW_NOSCAN)||LA155_0==KW_NOVALIDATE||LA155_0==KW_NULLS||LA155_0==KW_OFFSET||(LA155_0 >= KW_OPERATOR && LA155_0 <= KW_OPTION)||(LA155_0 >= KW_OUTPUTDRIVER && LA155_0 <= KW_OUTPUTFORMAT)||(LA155_0 >= KW_OVERWRITE && LA155_0 <= KW_OWNER)||(LA155_0 >= KW_PARTITIONED && LA155_0 <= KW_PATH)||(LA155_0 >= KW_PLAN && LA155_0 <= KW_POOL)||LA155_0==KW_PRINCIPALS||(LA155_0 >= KW_PURGE && LA155_0 <= KW_QUERY_PARALLELISM)||LA155_0==KW_READ||(LA155_0 >= KW_REBUILD && LA155_0 <= KW_RECORDWRITER)||(LA155_0 >= KW_RELOAD && LA155_0 <= KW_RESTRICT)||LA155_0==KW_REWRITE||(LA155_0 >= KW_ROLE && LA155_0 <= KW_ROLES)||(LA155_0 >= KW_SCHEDULED && LA155_0 <= KW_SECOND)||(LA155_0 >= KW_SEMI && LA155_0 <= KW_SERVER)||(LA155_0 >= KW_SETS && LA155_0 <= KW_SKEWED)||(LA155_0 >= KW_SNAPSHOT && LA155_0 <= KW_SSL)||(LA155_0 >= KW_STATISTICS && LA155_0 <= KW_SUMMARY)||LA155_0==KW_TABLES||(LA155_0 >= KW_TBLPROPERTIES && LA155_0 <= KW_TERMINATED)||LA155_0==KW_TINYINT||(LA155_0 >= KW_TOUCH && LA155_0 <= KW_TRANSACTIONS)||LA155_0==KW_UNARCHIVE||LA155_0==KW_UNDO||LA155_0==KW_UNIONTYPE||(LA155_0 >= KW_UNLOCK && LA155_0 <= KW_UNSIGNED)||(LA155_0 >= KW_URI && LA155_0 <= KW_USE)||(LA155_0 >= KW_UTC && LA155_0 <= KW_VALIDATE)||LA155_0==KW_VALUE_TYPE||(LA155_0 >= KW_VECTORIZATION && LA155_0 <= KW_WEEK)||LA155_0==KW_WHILE||(LA155_0 >= KW_WORK && LA155_0 <= KW_ZONE)||LA155_0==KW_BATCH||LA155_0==KW_DAYOFWEEK||LA155_0==KW_HOLD_DDLTIME||LA155_0==KW_IGNORE||LA155_0==KW_NO_DROP||LA155_0==KW_OFFLINE||LA155_0==KW_PROTECTION||LA155_0==KW_READONLY||LA155_0==KW_TIMESTAMPTZ) ) {
								alt155=1;
							}
							switch (alt155) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:8: parttype= partTypeExpr
									{
									pushFollow(FOLLOW_partTypeExpr_in_showStatement8975);
									parttype=partTypeExpr();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_partTypeExpr.add(parttype.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:32: (isExtended= KW_EXTENDED )?
							int alt156=2;
							int LA156_0 = input.LA(1);
							if ( (LA156_0==KW_EXTENDED) ) {
								alt156=1;
							}
							switch (alt156) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:33: isExtended= KW_EXTENDED
									{
									isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement8982); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_EXTENDED.add(isExtended);

									}
									break;

							}

							// AST REWRITE
							// elements: parttype, isExtended
							// token labels: isExtended
							// rule labels: parttype, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
							RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1688:58: -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:61: ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWLOCKS, "TOK_SHOWLOCKS"), root_1);
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:78: ( $parttype)?
								if ( stream_parttype.hasNext() ) {
									adaptor.addChild(root_1, stream_parttype.nextTree());
								}
								stream_parttype.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:89: ( $isExtended)?
								if ( stream_isExtended.hasNext() ) {
									adaptor.addChild(root_1, stream_isExtended.nextNode());
								}
								stream_isExtended.reset();

								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;

					}

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1690:7: KW_SHOW KW_COMPACTIONS
					{
					KW_SHOW505=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement9014); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW505);

					KW_COMPACTIONS506=(Token)match(input,KW_COMPACTIONS,FOLLOW_KW_COMPACTIONS_in_showStatement9016); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMPACTIONS.add(KW_COMPACTIONS506);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1690:30: -> ^( TOK_SHOW_COMPACTIONS )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1690:33: ^( TOK_SHOW_COMPACTIONS )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_COMPACTIONS, "TOK_SHOW_COMPACTIONS"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1691:7: KW_SHOW KW_TRANSACTIONS
					{
					KW_SHOW507=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement9030); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW507);

					KW_TRANSACTIONS508=(Token)match(input,KW_TRANSACTIONS,FOLLOW_KW_TRANSACTIONS_in_showStatement9032); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TRANSACTIONS.add(KW_TRANSACTIONS508);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1691:31: -> ^( TOK_SHOW_TRANSACTIONS )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1691:34: ^( TOK_SHOW_TRANSACTIONS )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_TRANSACTIONS, "TOK_SHOW_TRANSACTIONS"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1692:7: KW_SHOW KW_CONF StringLiteral
					{
					KW_SHOW509=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement9046); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW509);

					KW_CONF510=(Token)match(input,KW_CONF,FOLLOW_KW_CONF_in_showStatement9048); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONF.add(KW_CONF510);

					StringLiteral511=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStatement9050); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral511);

					// AST REWRITE
					// elements: StringLiteral
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1692:37: -> ^( TOK_SHOWCONF StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1692:40: ^( TOK_SHOWCONF StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWCONF, "TOK_SHOWCONF"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 15 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1693:7: KW_SHOW KW_RESOURCE ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) )
					{
					KW_SHOW512=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement9066); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW512);

					KW_RESOURCE513=(Token)match(input,KW_RESOURCE,FOLLOW_KW_RESOURCE_in_showStatement9068); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RESOURCE.add(KW_RESOURCE513);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1694:7: ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) )
					int alt158=2;
					int LA158_0 = input.LA(1);
					if ( (LA158_0==KW_PLAN) ) {
						alt158=1;
					}
					else if ( (LA158_0==KW_PLANS) ) {
						alt158=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 158, 0, input);
						throw nvae;
					}

					switch (alt158) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:9: ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:9: ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:10: KW_PLAN rp_name= identifier
							{
							KW_PLAN514=(Token)match(input,KW_PLAN,FOLLOW_KW_PLAN_in_showStatement9087); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_PLAN.add(KW_PLAN514);

							pushFollow(FOLLOW_identifier_in_showStatement9091);
							rp_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(rp_name.getTree());
							// AST REWRITE
							// elements: rp_name
							// token labels: 
							// rule labels: retval, rp_name
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
							RewriteRuleSubtreeStream stream_rp_name=new RewriteRuleSubtreeStream(adaptor,"rule rp_name",rp_name!=null?rp_name.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1695:37: -> ^( TOK_SHOW_RP $rp_name)
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:40: ^( TOK_SHOW_RP $rp_name)
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_RP, "TOK_SHOW_RP"), root_1);
								adaptor.addChild(root_1, stream_rp_name.nextTree());
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1696:11: ( KW_PLANS -> ^( TOK_SHOW_RP ) )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1696:11: ( KW_PLANS -> ^( TOK_SHOW_RP ) )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1696:12: KW_PLANS
							{
							KW_PLANS515=(Token)match(input,KW_PLANS,FOLLOW_KW_PLANS_in_showStatement9114); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_PLANS.add(KW_PLANS515);

							// AST REWRITE
							// elements: 
							// token labels: 
							// rule labels: retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1696:21: -> ^( TOK_SHOW_RP )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1696:24: ^( TOK_SHOW_RP )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_RP, "TOK_SHOW_RP"), root_1);
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}

							}
							break;

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showStatement"


	public static class showTablesFilterExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showTablesFilterExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1700:1: showTablesFilterExpr : ( KW_WHERE identifier EQUAL StringLiteral -> ^( TOK_TABLE_TYPE identifier StringLiteral ) | KW_LIKE showStmtIdentifier | showStmtIdentifier -> showStmtIdentifier );
	public final HiveParser.showTablesFilterExpr_return showTablesFilterExpr() throws RecognitionException {
		HiveParser.showTablesFilterExpr_return retval = new HiveParser.showTablesFilterExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHERE516=null;
		Token EQUAL518=null;
		Token StringLiteral519=null;
		Token KW_LIKE520=null;
		ParserRuleReturnScope identifier517 =null;
		ParserRuleReturnScope showStmtIdentifier521 =null;
		ParserRuleReturnScope showStmtIdentifier522 =null;

		ASTNode KW_WHERE516_tree=null;
		ASTNode EQUAL518_tree=null;
		ASTNode StringLiteral519_tree=null;
		ASTNode KW_LIKE520_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");
		RewriteRuleTokenStream stream_KW_WHERE=new RewriteRuleTokenStream(adaptor,"token KW_WHERE");
		RewriteRuleSubtreeStream stream_showStmtIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showStmtIdentifier");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("show tables filter expr", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1703:5: ( KW_WHERE identifier EQUAL StringLiteral -> ^( TOK_TABLE_TYPE identifier StringLiteral ) | KW_LIKE showStmtIdentifier | showStmtIdentifier -> showStmtIdentifier )
			int alt160=3;
			switch ( input.LA(1) ) {
			case KW_WHERE:
				{
				alt160=1;
				}
				break;
			case KW_LIKE:
				{
				alt160=2;
				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AT:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_CRON:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EVERY:
			case KW_EXCLUSIVE:
			case KW_EXECUTE:
			case KW_EXECUTED:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_IDXPROPERTIES:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGEDLOCATION:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULED:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMA:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SERVER:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URI:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case StringLiteral:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_IGNORE:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt160=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 160, 0, input);
				throw nvae;
			}
			switch (alt160) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1703:7: KW_WHERE identifier EQUAL StringLiteral
					{
					KW_WHERE516=(Token)match(input,KW_WHERE,FOLLOW_KW_WHERE_in_showTablesFilterExpr9156); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WHERE.add(KW_WHERE516);

					pushFollow(FOLLOW_identifier_in_showTablesFilterExpr9158);
					identifier517=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier517.getTree());
					EQUAL518=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_showTablesFilterExpr9160); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_EQUAL.add(EQUAL518);

					StringLiteral519=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showTablesFilterExpr9162); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral519);

					// AST REWRITE
					// elements: StringLiteral, identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1704:5: -> ^( TOK_TABLE_TYPE identifier StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1704:8: ^( TOK_TABLE_TYPE identifier StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1705:7: KW_LIKE showStmtIdentifier
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_LIKE520=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showTablesFilterExpr9184); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_LIKE520_tree = (ASTNode)adaptor.create(KW_LIKE520);
					adaptor.addChild(root_0, KW_LIKE520_tree);
					}

					pushFollow(FOLLOW_showStmtIdentifier_in_showTablesFilterExpr9186);
					showStmtIdentifier521=showStmtIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showStmtIdentifier521.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1705:34: showStmtIdentifier
					{
					pushFollow(FOLLOW_showStmtIdentifier_in_showTablesFilterExpr9188);
					showStmtIdentifier522=showStmtIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier522.getTree());
					// AST REWRITE
					// elements: showStmtIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1706:5: -> showStmtIdentifier
					{
						adaptor.addChild(root_0, stream_showStmtIdentifier.nextTree());
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showTablesFilterExpr"


	public static class lockStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "lockStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1709:1: lockStatement : KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) ;
	public final HiveParser.lockStatement_return lockStatement() throws RecognitionException {
		HiveParser.lockStatement_return retval = new HiveParser.lockStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_LOCK523=null;
		Token KW_TABLE524=null;
		ParserRuleReturnScope tableName525 =null;
		ParserRuleReturnScope partitionSpec526 =null;
		ParserRuleReturnScope lockMode527 =null;

		ASTNode KW_LOCK523_tree=null;
		ASTNode KW_TABLE524_tree=null;
		RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_lockMode=new RewriteRuleSubtreeStream(adaptor,"rule lockMode");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("lock statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:5: ( KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:7: KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode
			{
			KW_LOCK523=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_lockStatement9223); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK523);

			KW_TABLE524=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_lockStatement9225); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE524);

			pushFollow(FOLLOW_tableName_in_lockStatement9227);
			tableName525=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName525.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:34: ( partitionSpec )?
			int alt161=2;
			int LA161_0 = input.LA(1);
			if ( (LA161_0==KW_PARTITION) ) {
				alt161=1;
			}
			switch (alt161) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:34: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_lockStatement9229);
					partitionSpec526=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec526.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_lockMode_in_lockStatement9232);
			lockMode527=lockMode();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_lockMode.add(lockMode527.getTree());
			// AST REWRITE
			// elements: partitionSpec, lockMode, tableName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1712:58: -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:61: ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LOCKTABLE, "TOK_LOCKTABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				adaptor.addChild(root_1, stream_lockMode.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:96: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "lockStatement"


	public static class lockDatabase_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "lockDatabase"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1715:1: lockDatabase : KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) ;
	public final HiveParser.lockDatabase_return lockDatabase() throws RecognitionException {
		HiveParser.lockDatabase_return retval = new HiveParser.lockDatabase_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_LOCK528=null;
		Token KW_DATABASE529=null;
		Token KW_SCHEMA530=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope lockMode531 =null;

		ASTNode KW_LOCK528_tree=null;
		ASTNode KW_DATABASE529_tree=null;
		ASTNode KW_SCHEMA530_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_lockMode=new RewriteRuleSubtreeStream(adaptor,"rule lockMode");

		 pushMsg("lock database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:5: ( KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:7: KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) lockMode
			{
			KW_LOCK528=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_lockDatabase9272); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK528);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:15: ( KW_DATABASE | KW_SCHEMA )
			int alt162=2;
			int LA162_0 = input.LA(1);
			if ( (LA162_0==KW_DATABASE) ) {
				alt162=1;
			}
			else if ( (LA162_0==KW_SCHEMA) ) {
				alt162=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 162, 0, input);
				throw nvae;
			}

			switch (alt162) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:16: KW_DATABASE
					{
					KW_DATABASE529=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_lockDatabase9275); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE529);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:28: KW_SCHEMA
					{
					KW_SCHEMA530=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_lockDatabase9277); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA530);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:39: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:40: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_lockDatabase9283);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			pushFollow(FOLLOW_lockMode_in_lockDatabase9286);
			lockMode531=lockMode();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_lockMode.add(lockMode531.getTree());
			// AST REWRITE
			// elements: lockMode, dbName
			// token labels: 
			// rule labels: dbName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1718:68: -> ^( TOK_LOCKDB $dbName lockMode )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1718:71: ^( TOK_LOCKDB $dbName lockMode )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LOCKDB, "TOK_LOCKDB"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				adaptor.addChild(root_1, stream_lockMode.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "lockDatabase"


	public static class lockMode_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "lockMode"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1721:1: lockMode : ( KW_SHARED | KW_EXCLUSIVE );
	public final HiveParser.lockMode_return lockMode() throws RecognitionException {
		HiveParser.lockMode_return retval = new HiveParser.lockMode_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token set532=null;

		ASTNode set532_tree=null;

		 pushMsg("lock mode", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1724:5: ( KW_SHARED | KW_EXCLUSIVE )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:
			{
			root_0 = (ASTNode)adaptor.nil();


			set532=input.LT(1);
			if ( input.LA(1)==KW_EXCLUSIVE||input.LA(1)==KW_SHARED ) {
				input.consume();
				if ( state.backtracking==0 ) adaptor.addChild(root_0, (ASTNode)adaptor.create(set532));
				state.errorRecovery=false;
				state.failed=false;
			}
			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				MismatchedSetException mse = new MismatchedSetException(null,input);
				throw mse;
			}
			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "lockMode"


	public static class unlockStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "unlockStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1727:1: unlockStatement : KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) ;
	public final HiveParser.unlockStatement_return unlockStatement() throws RecognitionException {
		HiveParser.unlockStatement_return retval = new HiveParser.unlockStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNLOCK533=null;
		Token KW_TABLE534=null;
		ParserRuleReturnScope tableName535 =null;
		ParserRuleReturnScope partitionSpec536 =null;

		ASTNode KW_UNLOCK533_tree=null;
		ASTNode KW_TABLE534_tree=null;
		RewriteRuleTokenStream stream_KW_UNLOCK=new RewriteRuleTokenStream(adaptor,"token KW_UNLOCK");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("unlock statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:5: ( KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:7: KW_UNLOCK KW_TABLE tableName ( partitionSpec )?
			{
			KW_UNLOCK533=(Token)match(input,KW_UNLOCK,FOLLOW_KW_UNLOCK_in_unlockStatement9355); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UNLOCK.add(KW_UNLOCK533);

			KW_TABLE534=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_unlockStatement9357); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE534);

			pushFollow(FOLLOW_tableName_in_unlockStatement9359);
			tableName535=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName535.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:36: ( partitionSpec )?
			int alt163=2;
			int LA163_0 = input.LA(1);
			if ( (LA163_0==KW_PARTITION) ) {
				alt163=1;
			}
			switch (alt163) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:36: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_unlockStatement9361);
					partitionSpec536=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec536.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableName, partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1730:52: -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:55: ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNLOCKTABLE, "TOK_UNLOCKTABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:83: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "unlockStatement"


	public static class unlockDatabase_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "unlockDatabase"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1733:1: unlockDatabase : KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) -> ^( TOK_UNLOCKDB $dbName) ;
	public final HiveParser.unlockDatabase_return unlockDatabase() throws RecognitionException {
		HiveParser.unlockDatabase_return retval = new HiveParser.unlockDatabase_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNLOCK537=null;
		Token KW_DATABASE538=null;
		Token KW_SCHEMA539=null;
		ParserRuleReturnScope dbName =null;

		ASTNode KW_UNLOCK537_tree=null;
		ASTNode KW_DATABASE538_tree=null;
		ASTNode KW_SCHEMA539_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_UNLOCK=new RewriteRuleTokenStream(adaptor,"token KW_UNLOCK");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("unlock database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:5: ( KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) -> ^( TOK_UNLOCKDB $dbName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:7: KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier )
			{
			KW_UNLOCK537=(Token)match(input,KW_UNLOCK,FOLLOW_KW_UNLOCK_in_unlockDatabase9401); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UNLOCK.add(KW_UNLOCK537);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:17: ( KW_DATABASE | KW_SCHEMA )
			int alt164=2;
			int LA164_0 = input.LA(1);
			if ( (LA164_0==KW_DATABASE) ) {
				alt164=1;
			}
			else if ( (LA164_0==KW_SCHEMA) ) {
				alt164=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 164, 0, input);
				throw nvae;
			}

			switch (alt164) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:18: KW_DATABASE
					{
					KW_DATABASE538=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_unlockDatabase9404); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE538);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:30: KW_SCHEMA
					{
					KW_SCHEMA539=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_unlockDatabase9406); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA539);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:41: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:42: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_unlockDatabase9412);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			// AST REWRITE
			// elements: dbName
			// token labels: 
			// rule labels: dbName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1736:61: -> ^( TOK_UNLOCKDB $dbName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:64: ^( TOK_UNLOCKDB $dbName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNLOCKDB, "TOK_UNLOCKDB"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "unlockDatabase"


	public static class createRoleStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createRoleStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1739:1: createRoleStatement : KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) ;
	public final HiveParser.createRoleStatement_return createRoleStatement() throws RecognitionException {
		HiveParser.createRoleStatement_return retval = new HiveParser.createRoleStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE540=null;
		Token KW_ROLE541=null;
		ParserRuleReturnScope roleName =null;

		ASTNode KW_CREATE540_tree=null;
		ASTNode KW_ROLE541_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("create role", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:5: ( KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:7: KW_CREATE KW_ROLE roleName= identifier
			{
			KW_CREATE540=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createRoleStatement9449); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE540);

			KW_ROLE541=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_createRoleStatement9451); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE541);

			pushFollow(FOLLOW_identifier_in_createRoleStatement9455);
			roleName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());
			// AST REWRITE
			// elements: roleName
			// token labels: 
			// rule labels: roleName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1743:5: -> ^( TOK_CREATEROLE $roleName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:8: ^( TOK_CREATEROLE $roleName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEROLE, "TOK_CREATEROLE"), root_1);
				adaptor.addChild(root_1, stream_roleName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createRoleStatement"


	public static class dropRoleStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropRoleStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1746:1: dropRoleStatement : KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) ;
	public final HiveParser.dropRoleStatement_return dropRoleStatement() throws RecognitionException {
		HiveParser.dropRoleStatement_return retval = new HiveParser.dropRoleStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP542=null;
		Token KW_ROLE543=null;
		ParserRuleReturnScope roleName =null;

		ASTNode KW_DROP542_tree=null;
		ASTNode KW_ROLE543_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		pushMsg("drop role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1749:5: ( KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1749:7: KW_DROP KW_ROLE roleName= identifier
			{
			KW_DROP542=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropRoleStatement9495); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP542);

			KW_ROLE543=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_dropRoleStatement9497); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE543);

			pushFollow(FOLLOW_identifier_in_dropRoleStatement9501);
			roleName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());
			// AST REWRITE
			// elements: roleName
			// token labels: 
			// rule labels: roleName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1750:5: -> ^( TOK_DROPROLE $roleName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1750:8: ^( TOK_DROPROLE $roleName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPROLE, "TOK_DROPROLE"), root_1);
				adaptor.addChild(root_1, stream_roleName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropRoleStatement"


	public static class grantPrivileges_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "grantPrivileges"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:1: grantPrivileges : KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) ;
	public final HiveParser.grantPrivileges_return grantPrivileges() throws RecognitionException {
		HiveParser.grantPrivileges_return retval = new HiveParser.grantPrivileges_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_GRANT544=null;
		Token KW_TO546=null;
		ParserRuleReturnScope privList =null;
		ParserRuleReturnScope privilegeObject545 =null;
		ParserRuleReturnScope principalSpecification547 =null;
		ParserRuleReturnScope withGrantOption548 =null;

		ASTNode KW_GRANT544_tree=null;
		ASTNode KW_TO546_tree=null;
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleSubtreeStream stream_withGrantOption=new RewriteRuleSubtreeStream(adaptor,"rule withGrantOption");
		RewriteRuleSubtreeStream stream_privilegeList=new RewriteRuleSubtreeStream(adaptor,"rule privilegeList");
		RewriteRuleSubtreeStream stream_privilegeObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeObject");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("grant privileges", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1756:5: ( KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1756:7: KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )?
			{
			KW_GRANT544=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantPrivileges9541); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT544);

			pushFollow(FOLLOW_privilegeList_in_grantPrivileges9545);
			privList=privilegeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privilegeList.add(privList.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1757:7: ( privilegeObject )?
			int alt165=2;
			int LA165_0 = input.LA(1);
			if ( (LA165_0==KW_ON) ) {
				alt165=1;
			}
			switch (alt165) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1757:7: privilegeObject
					{
					pushFollow(FOLLOW_privilegeObject_in_grantPrivileges9553);
					privilegeObject545=privilegeObject();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privilegeObject.add(privilegeObject545.getTree());
					}
					break;

			}

			KW_TO546=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_grantPrivileges9562); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO546);

			pushFollow(FOLLOW_principalSpecification_in_grantPrivileges9564);
			principalSpecification547=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification547.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1759:7: ( withGrantOption )?
			int alt166=2;
			int LA166_0 = input.LA(1);
			if ( (LA166_0==KW_WITH) ) {
				alt166=1;
			}
			switch (alt166) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1759:7: withGrantOption
					{
					pushFollow(FOLLOW_withGrantOption_in_grantPrivileges9572);
					withGrantOption548=withGrantOption();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withGrantOption.add(withGrantOption548.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: privList, principalSpecification, withGrantOption, privilegeObject
			// token labels: 
			// rule labels: privList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_privList=new RewriteRuleSubtreeStream(adaptor,"rule privList",privList!=null?privList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1760:5: -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:8: ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT, "TOK_GRANT"), root_1);
				adaptor.addChild(root_1, stream_privList.nextTree());
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:53: ( privilegeObject )?
				if ( stream_privilegeObject.hasNext() ) {
					adaptor.addChild(root_1, stream_privilegeObject.nextTree());
				}
				stream_privilegeObject.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:70: ( withGrantOption )?
				if ( stream_withGrantOption.hasNext() ) {
					adaptor.addChild(root_1, stream_withGrantOption.nextTree());
				}
				stream_withGrantOption.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "grantPrivileges"


	public static class revokePrivileges_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "revokePrivileges"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1763:1: revokePrivileges : KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) ;
	public final HiveParser.revokePrivileges_return revokePrivileges() throws RecognitionException {
		HiveParser.revokePrivileges_return retval = new HiveParser.revokePrivileges_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REVOKE549=null;
		Token KW_FROM553=null;
		ParserRuleReturnScope grantOptionFor550 =null;
		ParserRuleReturnScope privilegeList551 =null;
		ParserRuleReturnScope privilegeObject552 =null;
		ParserRuleReturnScope principalSpecification554 =null;

		ASTNode KW_REVOKE549_tree=null;
		ASTNode KW_FROM553_tree=null;
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_REVOKE=new RewriteRuleTokenStream(adaptor,"token KW_REVOKE");
		RewriteRuleSubtreeStream stream_grantOptionFor=new RewriteRuleSubtreeStream(adaptor,"rule grantOptionFor");
		RewriteRuleSubtreeStream stream_privilegeList=new RewriteRuleSubtreeStream(adaptor,"rule privilegeList");
		RewriteRuleSubtreeStream stream_privilegeObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeObject");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("revoke privileges", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1766:5: ( KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1766:7: KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification
			{
			KW_REVOKE549=(Token)match(input,KW_REVOKE,FOLLOW_KW_REVOKE_in_revokePrivileges9621); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REVOKE.add(KW_REVOKE549);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1766:17: ( grantOptionFor )?
			int alt167=2;
			int LA167_0 = input.LA(1);
			if ( (LA167_0==KW_GRANT) ) {
				alt167=1;
			}
			switch (alt167) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1766:17: grantOptionFor
					{
					pushFollow(FOLLOW_grantOptionFor_in_revokePrivileges9623);
					grantOptionFor550=grantOptionFor();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_grantOptionFor.add(grantOptionFor550.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_privilegeList_in_revokePrivileges9626);
			privilegeList551=privilegeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privilegeList.add(privilegeList551.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1766:47: ( privilegeObject )?
			int alt168=2;
			int LA168_0 = input.LA(1);
			if ( (LA168_0==KW_ON) ) {
				alt168=1;
			}
			switch (alt168) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1766:47: privilegeObject
					{
					pushFollow(FOLLOW_privilegeObject_in_revokePrivileges9628);
					privilegeObject552=privilegeObject();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privilegeObject.add(privilegeObject552.getTree());
					}
					break;

			}

			KW_FROM553=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_revokePrivileges9631); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM553);

			pushFollow(FOLLOW_principalSpecification_in_revokePrivileges9633);
			principalSpecification554=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification554.getTree());
			// AST REWRITE
			// elements: grantOptionFor, principalSpecification, privilegeList, privilegeObject
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1767:5: -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:8: ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REVOKE, "TOK_REVOKE"), root_1);
				adaptor.addChild(root_1, stream_privilegeList.nextTree());
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:58: ( privilegeObject )?
				if ( stream_privilegeObject.hasNext() ) {
					adaptor.addChild(root_1, stream_privilegeObject.nextTree());
				}
				stream_privilegeObject.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:75: ( grantOptionFor )?
				if ( stream_grantOptionFor.hasNext() ) {
					adaptor.addChild(root_1, stream_grantOptionFor.nextTree());
				}
				stream_grantOptionFor.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "revokePrivileges"


	public static class grantRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "grantRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1770:1: grantRole : KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) ;
	public final HiveParser.grantRole_return grantRole() throws RecognitionException {
		HiveParser.grantRole_return retval = new HiveParser.grantRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_GRANT555=null;
		Token KW_ROLE556=null;
		Token COMMA558=null;
		Token KW_TO560=null;
		ParserRuleReturnScope identifier557 =null;
		ParserRuleReturnScope identifier559 =null;
		ParserRuleReturnScope principalSpecification561 =null;
		ParserRuleReturnScope withAdminOption562 =null;

		ASTNode KW_GRANT555_tree=null;
		ASTNode KW_ROLE556_tree=null;
		ASTNode COMMA558_tree=null;
		ASTNode KW_TO560_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_withAdminOption=new RewriteRuleSubtreeStream(adaptor,"rule withAdminOption");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("grant role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1773:5: ( KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1773:7: KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )?
			{
			KW_GRANT555=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantRole9680); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT555);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1773:16: ( KW_ROLE )?
			int alt169=2;
			int LA169_0 = input.LA(1);
			if ( (LA169_0==KW_ROLE) ) {
				int LA169_1 = input.LA(2);
				if ( (LA169_1==Identifier||(LA169_1 >= KW_ABORT && LA169_1 <= KW_AFTER)||LA169_1==KW_ALLOC_FRACTION||LA169_1==KW_ANALYZE||LA169_1==KW_ARCHIVE||(LA169_1 >= KW_ASC && LA169_1 <= KW_AT)||(LA169_1 >= KW_AUTOCOMMIT && LA169_1 <= KW_BEFORE)||(LA169_1 >= KW_BUCKET && LA169_1 <= KW_BUCKETS)||(LA169_1 >= KW_CACHE && LA169_1 <= KW_CASCADE)||(LA169_1 >= KW_CBO && LA169_1 <= KW_CHANGE)||(LA169_1 >= KW_CHECK && LA169_1 <= KW_COLLECTION)||(LA169_1 >= KW_COLUMNS && LA169_1 <= KW_COMMENT)||(LA169_1 >= KW_COMPACT && LA169_1 <= KW_CONCATENATE)||(LA169_1 >= KW_CONTINUE && LA169_1 <= KW_COST)||LA169_1==KW_CRON||LA169_1==KW_DATA||LA169_1==KW_DATABASES||(LA169_1 >= KW_DATETIME && LA169_1 <= KW_DEBUG)||(LA169_1 >= KW_DEFAULT && LA169_1 <= KW_DEFINED)||(LA169_1 >= KW_DELIMITED && LA169_1 <= KW_DESC)||(LA169_1 >= KW_DETAIL && LA169_1 <= KW_DISABLE)||(LA169_1 >= KW_DISTRIBUTE && LA169_1 <= KW_DO)||LA169_1==KW_DOW||(LA169_1 >= KW_DUMP && LA169_1 <= KW_ELEM_TYPE)||LA169_1==KW_ENABLE||(LA169_1 >= KW_ENFORCED && LA169_1 <= KW_EVERY)||(LA169_1 >= KW_EXCLUSIVE && LA169_1 <= KW_EXECUTED)||(LA169_1 >= KW_EXPLAIN && LA169_1 <= KW_EXPRESSION)||(LA169_1 >= KW_FIELDS && LA169_1 <= KW_FIRST)||(LA169_1 >= KW_FORMAT && LA169_1 <= KW_FORMATTED)||LA169_1==KW_FUNCTIONS||(LA169_1 >= KW_HOUR && LA169_1 <= KW_IDXPROPERTIES)||(LA169_1 >= KW_INDEX && LA169_1 <= KW_INDEXES)||(LA169_1 >= KW_INPATH && LA169_1 <= KW_INPUTFORMAT)||(LA169_1 >= KW_ISOLATION && LA169_1 <= KW_JAR)||(LA169_1 >= KW_JOINCOST && LA169_1 <= KW_LAST)||LA169_1==KW_LEVEL||(LA169_1 >= KW_LIMIT && LA169_1 <= KW_LOAD)||(LA169_1 >= KW_LOCATION && LA169_1 <= KW_LONG)||(LA169_1 >= KW_MANAGEDLOCATION && LA169_1 <= KW_MANAGEMENT)||(LA169_1 >= KW_MAPJOIN && LA169_1 <= KW_MATERIALIZED)||LA169_1==KW_METADATA||(LA169_1 >= KW_MINUTE && LA169_1 <= KW_MONTH)||(LA169_1 >= KW_MOVE && LA169_1 <= KW_MSCK)||(LA169_1 >= KW_NORELY && LA169_1 <= KW_NOSCAN)||LA169_1==KW_NOVALIDATE||LA169_1==KW_NULLS||LA169_1==KW_OFFSET||(LA169_1 >= KW_OPERATOR && LA169_1 <= KW_OPTION)||(LA169_1 >= KW_OUTPUTDRIVER && LA169_1 <= KW_OUTPUTFORMAT)||(LA169_1 >= KW_OVERWRITE && LA169_1 <= KW_OWNER)||(LA169_1 >= KW_PARTITIONED && LA169_1 <= KW_PATH)||(LA169_1 >= KW_PLAN && LA169_1 <= KW_POOL)||LA169_1==KW_PRINCIPALS||(LA169_1 >= KW_PURGE && LA169_1 <= KW_QUERY_PARALLELISM)||LA169_1==KW_READ||(LA169_1 >= KW_REBUILD && LA169_1 <= KW_RECORDWRITER)||(LA169_1 >= KW_RELOAD && LA169_1 <= KW_RESTRICT)||LA169_1==KW_REWRITE||(LA169_1 >= KW_ROLE && LA169_1 <= KW_ROLES)||(LA169_1 >= KW_SCHEDULED && LA169_1 <= KW_SECOND)||(LA169_1 >= KW_SEMI && LA169_1 <= KW_SERVER)||(LA169_1 >= KW_SETS && LA169_1 <= KW_SKEWED)||(LA169_1 >= KW_SNAPSHOT && LA169_1 <= KW_SSL)||(LA169_1 >= KW_STATISTICS && LA169_1 <= KW_SUMMARY)||LA169_1==KW_TABLES||(LA169_1 >= KW_TBLPROPERTIES && LA169_1 <= KW_TERMINATED)||LA169_1==KW_TINYINT||(LA169_1 >= KW_TOUCH && LA169_1 <= KW_TRANSACTIONS)||LA169_1==KW_UNARCHIVE||LA169_1==KW_UNDO||LA169_1==KW_UNIONTYPE||(LA169_1 >= KW_UNLOCK && LA169_1 <= KW_UNSIGNED)||(LA169_1 >= KW_URI && LA169_1 <= KW_USE)||(LA169_1 >= KW_UTC && LA169_1 <= KW_VALIDATE)||LA169_1==KW_VALUE_TYPE||(LA169_1 >= KW_VECTORIZATION && LA169_1 <= KW_WEEK)||LA169_1==KW_WHILE||(LA169_1 >= KW_WORK && LA169_1 <= KW_ZONE)||LA169_1==KW_BATCH||LA169_1==KW_DAYOFWEEK||LA169_1==KW_HOLD_DDLTIME||LA169_1==KW_IGNORE||LA169_1==KW_NO_DROP||LA169_1==KW_OFFLINE||LA169_1==KW_PROTECTION||LA169_1==KW_READONLY||LA169_1==KW_TIMESTAMPTZ) ) {
					alt169=1;
				}
			}
			switch (alt169) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1773:16: KW_ROLE
					{
					KW_ROLE556=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_grantRole9682); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE556);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_grantRole9685);
			identifier557=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier557.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1773:36: ( COMMA identifier )*
			loop170:
			while (true) {
				int alt170=2;
				int LA170_0 = input.LA(1);
				if ( (LA170_0==COMMA) ) {
					alt170=1;
				}

				switch (alt170) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1773:37: COMMA identifier
					{
					COMMA558=(Token)match(input,COMMA,FOLLOW_COMMA_in_grantRole9688); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA558);

					pushFollow(FOLLOW_identifier_in_grantRole9690);
					identifier559=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier559.getTree());
					}
					break;

				default :
					break loop170;
				}
			}

			KW_TO560=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_grantRole9694); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO560);

			pushFollow(FOLLOW_principalSpecification_in_grantRole9696);
			principalSpecification561=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification561.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1773:85: ( withAdminOption )?
			int alt171=2;
			int LA171_0 = input.LA(1);
			if ( (LA171_0==KW_WITH) ) {
				alt171=1;
			}
			switch (alt171) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1773:85: withAdminOption
					{
					pushFollow(FOLLOW_withAdminOption_in_grantRole9698);
					withAdminOption562=withAdminOption();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withAdminOption.add(withAdminOption562.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: withAdminOption, principalSpecification, identifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1774:5: -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1774:8: ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_ROLE, "TOK_GRANT_ROLE"), root_1);
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1774:48: ( withAdminOption )?
				if ( stream_withAdminOption.hasNext() ) {
					adaptor.addChild(root_1, stream_withAdminOption.nextTree());
				}
				stream_withAdminOption.reset();

				if ( !(stream_identifier.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_identifier.hasNext() ) {
					adaptor.addChild(root_1, stream_identifier.nextTree());
				}
				stream_identifier.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "grantRole"


	public static class revokeRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "revokeRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1777:1: revokeRole : KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) ;
	public final HiveParser.revokeRole_return revokeRole() throws RecognitionException {
		HiveParser.revokeRole_return retval = new HiveParser.revokeRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REVOKE563=null;
		Token KW_ROLE565=null;
		Token COMMA567=null;
		Token KW_FROM569=null;
		ParserRuleReturnScope adminOptionFor564 =null;
		ParserRuleReturnScope identifier566 =null;
		ParserRuleReturnScope identifier568 =null;
		ParserRuleReturnScope principalSpecification570 =null;

		ASTNode KW_REVOKE563_tree=null;
		ASTNode KW_ROLE565_tree=null;
		ASTNode COMMA567_tree=null;
		ASTNode KW_FROM569_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_REVOKE=new RewriteRuleTokenStream(adaptor,"token KW_REVOKE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_adminOptionFor=new RewriteRuleSubtreeStream(adaptor,"rule adminOptionFor");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("revoke role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1780:5: ( KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1780:7: KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification
			{
			KW_REVOKE563=(Token)match(input,KW_REVOKE,FOLLOW_KW_REVOKE_in_revokeRole9744); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REVOKE.add(KW_REVOKE563);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1780:17: ( adminOptionFor )?
			int alt172=2;
			int LA172_0 = input.LA(1);
			if ( (LA172_0==KW_ADMIN) ) {
				int LA172_1 = input.LA(2);
				if ( (LA172_1==KW_OPTION) ) {
					alt172=1;
				}
			}
			switch (alt172) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1780:17: adminOptionFor
					{
					pushFollow(FOLLOW_adminOptionFor_in_revokeRole9746);
					adminOptionFor564=adminOptionFor();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_adminOptionFor.add(adminOptionFor564.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1780:33: ( KW_ROLE )?
			int alt173=2;
			int LA173_0 = input.LA(1);
			if ( (LA173_0==KW_ROLE) ) {
				int LA173_1 = input.LA(2);
				if ( (LA173_1==Identifier||(LA173_1 >= KW_ABORT && LA173_1 <= KW_AFTER)||LA173_1==KW_ALLOC_FRACTION||LA173_1==KW_ANALYZE||LA173_1==KW_ARCHIVE||(LA173_1 >= KW_ASC && LA173_1 <= KW_AT)||(LA173_1 >= KW_AUTOCOMMIT && LA173_1 <= KW_BEFORE)||(LA173_1 >= KW_BUCKET && LA173_1 <= KW_BUCKETS)||(LA173_1 >= KW_CACHE && LA173_1 <= KW_CASCADE)||(LA173_1 >= KW_CBO && LA173_1 <= KW_CHANGE)||(LA173_1 >= KW_CHECK && LA173_1 <= KW_COLLECTION)||(LA173_1 >= KW_COLUMNS && LA173_1 <= KW_COMMENT)||(LA173_1 >= KW_COMPACT && LA173_1 <= KW_CONCATENATE)||(LA173_1 >= KW_CONTINUE && LA173_1 <= KW_COST)||LA173_1==KW_CRON||LA173_1==KW_DATA||LA173_1==KW_DATABASES||(LA173_1 >= KW_DATETIME && LA173_1 <= KW_DEBUG)||(LA173_1 >= KW_DEFAULT && LA173_1 <= KW_DEFINED)||(LA173_1 >= KW_DELIMITED && LA173_1 <= KW_DESC)||(LA173_1 >= KW_DETAIL && LA173_1 <= KW_DISABLE)||(LA173_1 >= KW_DISTRIBUTE && LA173_1 <= KW_DO)||LA173_1==KW_DOW||(LA173_1 >= KW_DUMP && LA173_1 <= KW_ELEM_TYPE)||LA173_1==KW_ENABLE||(LA173_1 >= KW_ENFORCED && LA173_1 <= KW_EVERY)||(LA173_1 >= KW_EXCLUSIVE && LA173_1 <= KW_EXECUTED)||(LA173_1 >= KW_EXPLAIN && LA173_1 <= KW_EXPRESSION)||(LA173_1 >= KW_FIELDS && LA173_1 <= KW_FIRST)||(LA173_1 >= KW_FORMAT && LA173_1 <= KW_FORMATTED)||LA173_1==KW_FUNCTIONS||(LA173_1 >= KW_HOUR && LA173_1 <= KW_IDXPROPERTIES)||(LA173_1 >= KW_INDEX && LA173_1 <= KW_INDEXES)||(LA173_1 >= KW_INPATH && LA173_1 <= KW_INPUTFORMAT)||(LA173_1 >= KW_ISOLATION && LA173_1 <= KW_JAR)||(LA173_1 >= KW_JOINCOST && LA173_1 <= KW_LAST)||LA173_1==KW_LEVEL||(LA173_1 >= KW_LIMIT && LA173_1 <= KW_LOAD)||(LA173_1 >= KW_LOCATION && LA173_1 <= KW_LONG)||(LA173_1 >= KW_MANAGEDLOCATION && LA173_1 <= KW_MANAGEMENT)||(LA173_1 >= KW_MAPJOIN && LA173_1 <= KW_MATERIALIZED)||LA173_1==KW_METADATA||(LA173_1 >= KW_MINUTE && LA173_1 <= KW_MONTH)||(LA173_1 >= KW_MOVE && LA173_1 <= KW_MSCK)||(LA173_1 >= KW_NORELY && LA173_1 <= KW_NOSCAN)||LA173_1==KW_NOVALIDATE||LA173_1==KW_NULLS||LA173_1==KW_OFFSET||(LA173_1 >= KW_OPERATOR && LA173_1 <= KW_OPTION)||(LA173_1 >= KW_OUTPUTDRIVER && LA173_1 <= KW_OUTPUTFORMAT)||(LA173_1 >= KW_OVERWRITE && LA173_1 <= KW_OWNER)||(LA173_1 >= KW_PARTITIONED && LA173_1 <= KW_PATH)||(LA173_1 >= KW_PLAN && LA173_1 <= KW_POOL)||LA173_1==KW_PRINCIPALS||(LA173_1 >= KW_PURGE && LA173_1 <= KW_QUERY_PARALLELISM)||LA173_1==KW_READ||(LA173_1 >= KW_REBUILD && LA173_1 <= KW_RECORDWRITER)||(LA173_1 >= KW_RELOAD && LA173_1 <= KW_RESTRICT)||LA173_1==KW_REWRITE||(LA173_1 >= KW_ROLE && LA173_1 <= KW_ROLES)||(LA173_1 >= KW_SCHEDULED && LA173_1 <= KW_SECOND)||(LA173_1 >= KW_SEMI && LA173_1 <= KW_SERVER)||(LA173_1 >= KW_SETS && LA173_1 <= KW_SKEWED)||(LA173_1 >= KW_SNAPSHOT && LA173_1 <= KW_SSL)||(LA173_1 >= KW_STATISTICS && LA173_1 <= KW_SUMMARY)||LA173_1==KW_TABLES||(LA173_1 >= KW_TBLPROPERTIES && LA173_1 <= KW_TERMINATED)||LA173_1==KW_TINYINT||(LA173_1 >= KW_TOUCH && LA173_1 <= KW_TRANSACTIONS)||LA173_1==KW_UNARCHIVE||LA173_1==KW_UNDO||LA173_1==KW_UNIONTYPE||(LA173_1 >= KW_UNLOCK && LA173_1 <= KW_UNSIGNED)||(LA173_1 >= KW_URI && LA173_1 <= KW_USE)||(LA173_1 >= KW_UTC && LA173_1 <= KW_VALIDATE)||LA173_1==KW_VALUE_TYPE||(LA173_1 >= KW_VECTORIZATION && LA173_1 <= KW_WEEK)||LA173_1==KW_WHILE||(LA173_1 >= KW_WORK && LA173_1 <= KW_ZONE)||LA173_1==KW_BATCH||LA173_1==KW_DAYOFWEEK||LA173_1==KW_HOLD_DDLTIME||LA173_1==KW_IGNORE||LA173_1==KW_NO_DROP||LA173_1==KW_OFFLINE||LA173_1==KW_PROTECTION||LA173_1==KW_READONLY||LA173_1==KW_TIMESTAMPTZ) ) {
					alt173=1;
				}
			}
			switch (alt173) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1780:33: KW_ROLE
					{
					KW_ROLE565=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_revokeRole9749); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE565);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_revokeRole9752);
			identifier566=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier566.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1780:53: ( COMMA identifier )*
			loop174:
			while (true) {
				int alt174=2;
				int LA174_0 = input.LA(1);
				if ( (LA174_0==COMMA) ) {
					alt174=1;
				}

				switch (alt174) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1780:54: COMMA identifier
					{
					COMMA567=(Token)match(input,COMMA,FOLLOW_COMMA_in_revokeRole9755); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA567);

					pushFollow(FOLLOW_identifier_in_revokeRole9757);
					identifier568=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier568.getTree());
					}
					break;

				default :
					break loop174;
				}
			}

			KW_FROM569=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_revokeRole9761); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM569);

			pushFollow(FOLLOW_principalSpecification_in_revokeRole9763);
			principalSpecification570=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification570.getTree());
			// AST REWRITE
			// elements: principalSpecification, adminOptionFor, identifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1781:5: -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1781:8: ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REVOKE_ROLE, "TOK_REVOKE_ROLE"), root_1);
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1781:49: ( adminOptionFor )?
				if ( stream_adminOptionFor.hasNext() ) {
					adaptor.addChild(root_1, stream_adminOptionFor.nextTree());
				}
				stream_adminOptionFor.reset();

				if ( !(stream_identifier.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_identifier.hasNext() ) {
					adaptor.addChild(root_1, stream_identifier.nextTree());
				}
				stream_identifier.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "revokeRole"


	public static class showRoleGrants_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showRoleGrants"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1784:1: showRoleGrants : KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) ;
	public final HiveParser.showRoleGrants_return showRoleGrants() throws RecognitionException {
		HiveParser.showRoleGrants_return retval = new HiveParser.showRoleGrants_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW571=null;
		Token KW_ROLE572=null;
		Token KW_GRANT573=null;
		ParserRuleReturnScope principalName574 =null;

		ASTNode KW_SHOW571_tree=null;
		ASTNode KW_ROLE572_tree=null;
		ASTNode KW_GRANT573_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		pushMsg("show role grants", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1787:5: ( KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1787:7: KW_SHOW KW_ROLE KW_GRANT principalName
			{
			KW_SHOW571=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRoleGrants9808); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW571);

			KW_ROLE572=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_showRoleGrants9810); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE572);

			KW_GRANT573=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_showRoleGrants9812); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT573);

			pushFollow(FOLLOW_principalName_in_showRoleGrants9814);
			principalName574=principalName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalName.add(principalName574.getTree());
			// AST REWRITE
			// elements: principalName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1788:5: -> ^( TOK_SHOW_ROLE_GRANT principalName )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1788:8: ^( TOK_SHOW_ROLE_GRANT principalName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_ROLE_GRANT, "TOK_SHOW_ROLE_GRANT"), root_1);
				adaptor.addChild(root_1, stream_principalName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showRoleGrants"


	public static class showRoles_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showRoles"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1792:1: showRoles : KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) ;
	public final HiveParser.showRoles_return showRoles() throws RecognitionException {
		HiveParser.showRoles_return retval = new HiveParser.showRoles_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW575=null;
		Token KW_ROLES576=null;

		ASTNode KW_SHOW575_tree=null;
		ASTNode KW_ROLES576_tree=null;
		RewriteRuleTokenStream stream_KW_ROLES=new RewriteRuleTokenStream(adaptor,"token KW_ROLES");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");

		pushMsg("show roles", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1795:5: ( KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1795:7: KW_SHOW KW_ROLES
			{
			KW_SHOW575=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRoles9854); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW575);

			KW_ROLES576=(Token)match(input,KW_ROLES,FOLLOW_KW_ROLES_in_showRoles9856); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLES.add(KW_ROLES576);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1796:5: -> ^( TOK_SHOW_ROLES )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1796:8: ^( TOK_SHOW_ROLES )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_ROLES, "TOK_SHOW_ROLES"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showRoles"


	public static class showCurrentRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showCurrentRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1799:1: showCurrentRole : KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_CURRENT_ROLE ) ;
	public final HiveParser.showCurrentRole_return showCurrentRole() throws RecognitionException {
		HiveParser.showCurrentRole_return retval = new HiveParser.showCurrentRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW577=null;
		Token KW_CURRENT578=null;
		Token KW_ROLES579=null;

		ASTNode KW_SHOW577_tree=null;
		ASTNode KW_CURRENT578_tree=null;
		ASTNode KW_ROLES579_tree=null;
		RewriteRuleTokenStream stream_KW_ROLES=new RewriteRuleTokenStream(adaptor,"token KW_ROLES");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleTokenStream stream_KW_CURRENT=new RewriteRuleTokenStream(adaptor,"token KW_CURRENT");

		pushMsg("show current role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:5: ( KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_CURRENT_ROLE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:7: KW_SHOW KW_CURRENT KW_ROLES
			{
			KW_SHOW577=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showCurrentRole9893); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW577);

			KW_CURRENT578=(Token)match(input,KW_CURRENT,FOLLOW_KW_CURRENT_in_showCurrentRole9895); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CURRENT.add(KW_CURRENT578);

			KW_ROLES579=(Token)match(input,KW_ROLES,FOLLOW_KW_ROLES_in_showCurrentRole9897); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLES.add(KW_ROLES579);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1803:5: -> ^( TOK_SHOW_CURRENT_ROLE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1803:8: ^( TOK_SHOW_CURRENT_ROLE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_CURRENT_ROLE, "TOK_SHOW_CURRENT_ROLE"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showCurrentRole"


	public static class setRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1806:1: setRole : KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SET_ROLE identifier ) ) ;
	public final HiveParser.setRole_return setRole() throws RecognitionException {
		HiveParser.setRole_return retval = new HiveParser.setRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token all=null;
		Token none=null;
		Token KW_SET580=null;
		Token KW_ROLE581=null;
		ParserRuleReturnScope identifier582 =null;

		ASTNode all_tree=null;
		ASTNode none_tree=null;
		ASTNode KW_SET580_tree=null;
		ASTNode KW_ROLE581_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_NONE=new RewriteRuleTokenStream(adaptor,"token KW_NONE");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		pushMsg("set role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:5: ( KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SET_ROLE identifier ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:7: KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SET_ROLE identifier ) )
			{
			KW_SET580=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setRole9934); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET580);

			KW_ROLE581=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_setRole9936); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE581);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1810:5: ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SET_ROLE identifier ) )
			int alt175=3;
			int LA175_0 = input.LA(1);
			if ( (LA175_0==KW_ALL) && (synpred14_HiveParser())) {
				alt175=1;
			}
			else if ( (LA175_0==KW_NONE) && (synpred15_HiveParser())) {
				alt175=2;
			}
			else if ( (LA175_0==Identifier||(LA175_0 >= KW_ABORT && LA175_0 <= KW_AFTER)||LA175_0==KW_ALLOC_FRACTION||LA175_0==KW_ANALYZE||LA175_0==KW_ARCHIVE||(LA175_0 >= KW_ASC && LA175_0 <= KW_AT)||(LA175_0 >= KW_AUTOCOMMIT && LA175_0 <= KW_BEFORE)||(LA175_0 >= KW_BUCKET && LA175_0 <= KW_BUCKETS)||(LA175_0 >= KW_CACHE && LA175_0 <= KW_CASCADE)||(LA175_0 >= KW_CBO && LA175_0 <= KW_CHANGE)||(LA175_0 >= KW_CHECK && LA175_0 <= KW_COLLECTION)||(LA175_0 >= KW_COLUMNS && LA175_0 <= KW_COMMENT)||(LA175_0 >= KW_COMPACT && LA175_0 <= KW_CONCATENATE)||(LA175_0 >= KW_CONTINUE && LA175_0 <= KW_COST)||LA175_0==KW_CRON||LA175_0==KW_DATA||LA175_0==KW_DATABASES||(LA175_0 >= KW_DATETIME && LA175_0 <= KW_DEBUG)||(LA175_0 >= KW_DEFAULT && LA175_0 <= KW_DEFINED)||(LA175_0 >= KW_DELIMITED && LA175_0 <= KW_DESC)||(LA175_0 >= KW_DETAIL && LA175_0 <= KW_DISABLE)||(LA175_0 >= KW_DISTRIBUTE && LA175_0 <= KW_DO)||LA175_0==KW_DOW||(LA175_0 >= KW_DUMP && LA175_0 <= KW_ELEM_TYPE)||LA175_0==KW_ENABLE||(LA175_0 >= KW_ENFORCED && LA175_0 <= KW_EVERY)||(LA175_0 >= KW_EXCLUSIVE && LA175_0 <= KW_EXECUTED)||(LA175_0 >= KW_EXPLAIN && LA175_0 <= KW_EXPRESSION)||(LA175_0 >= KW_FIELDS && LA175_0 <= KW_FIRST)||(LA175_0 >= KW_FORMAT && LA175_0 <= KW_FORMATTED)||LA175_0==KW_FUNCTIONS||(LA175_0 >= KW_HOUR && LA175_0 <= KW_IDXPROPERTIES)||(LA175_0 >= KW_INDEX && LA175_0 <= KW_INDEXES)||(LA175_0 >= KW_INPATH && LA175_0 <= KW_INPUTFORMAT)||(LA175_0 >= KW_ISOLATION && LA175_0 <= KW_JAR)||(LA175_0 >= KW_JOINCOST && LA175_0 <= KW_LAST)||LA175_0==KW_LEVEL||(LA175_0 >= KW_LIMIT && LA175_0 <= KW_LOAD)||(LA175_0 >= KW_LOCATION && LA175_0 <= KW_LONG)||(LA175_0 >= KW_MANAGEDLOCATION && LA175_0 <= KW_MANAGEMENT)||(LA175_0 >= KW_MAPJOIN && LA175_0 <= KW_MATERIALIZED)||LA175_0==KW_METADATA||(LA175_0 >= KW_MINUTE && LA175_0 <= KW_MONTH)||(LA175_0 >= KW_MOVE && LA175_0 <= KW_MSCK)||(LA175_0 >= KW_NORELY && LA175_0 <= KW_NOSCAN)||LA175_0==KW_NOVALIDATE||LA175_0==KW_NULLS||LA175_0==KW_OFFSET||(LA175_0 >= KW_OPERATOR && LA175_0 <= KW_OPTION)||(LA175_0 >= KW_OUTPUTDRIVER && LA175_0 <= KW_OUTPUTFORMAT)||(LA175_0 >= KW_OVERWRITE && LA175_0 <= KW_OWNER)||(LA175_0 >= KW_PARTITIONED && LA175_0 <= KW_PATH)||(LA175_0 >= KW_PLAN && LA175_0 <= KW_POOL)||LA175_0==KW_PRINCIPALS||(LA175_0 >= KW_PURGE && LA175_0 <= KW_QUERY_PARALLELISM)||LA175_0==KW_READ||(LA175_0 >= KW_REBUILD && LA175_0 <= KW_RECORDWRITER)||(LA175_0 >= KW_RELOAD && LA175_0 <= KW_RESTRICT)||LA175_0==KW_REWRITE||(LA175_0 >= KW_ROLE && LA175_0 <= KW_ROLES)||(LA175_0 >= KW_SCHEDULED && LA175_0 <= KW_SECOND)||(LA175_0 >= KW_SEMI && LA175_0 <= KW_SERVER)||(LA175_0 >= KW_SETS && LA175_0 <= KW_SKEWED)||(LA175_0 >= KW_SNAPSHOT && LA175_0 <= KW_SSL)||(LA175_0 >= KW_STATISTICS && LA175_0 <= KW_SUMMARY)||LA175_0==KW_TABLES||(LA175_0 >= KW_TBLPROPERTIES && LA175_0 <= KW_TERMINATED)||LA175_0==KW_TINYINT||(LA175_0 >= KW_TOUCH && LA175_0 <= KW_TRANSACTIONS)||LA175_0==KW_UNARCHIVE||LA175_0==KW_UNDO||LA175_0==KW_UNIONTYPE||(LA175_0 >= KW_UNLOCK && LA175_0 <= KW_UNSIGNED)||(LA175_0 >= KW_URI && LA175_0 <= KW_USE)||(LA175_0 >= KW_UTC && LA175_0 <= KW_VALIDATE)||LA175_0==KW_VALUE_TYPE||(LA175_0 >= KW_VECTORIZATION && LA175_0 <= KW_WEEK)||LA175_0==KW_WHILE||(LA175_0 >= KW_WORK && LA175_0 <= KW_ZONE)||LA175_0==KW_BATCH||LA175_0==KW_DAYOFWEEK||LA175_0==KW_HOLD_DDLTIME||LA175_0==KW_IGNORE||LA175_0==KW_NO_DROP||LA175_0==KW_OFFLINE||LA175_0==KW_PROTECTION||LA175_0==KW_READONLY||LA175_0==KW_TIMESTAMPTZ) ) {
				alt175=3;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 175, 0, input);
				throw nvae;
			}

			switch (alt175) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1811:5: ( KW_ALL )=> (all= KW_ALL )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1811:17: (all= KW_ALL )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1811:18: all= KW_ALL
					{
					all=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setRole9958); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(all);

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1811:30: -> ^( TOK_SET_ROLE Identifier[$all.text] )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1811:33: ^( TOK_SET_ROLE Identifier[$all.text] )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_ROLE, "TOK_SET_ROLE"), root_1);
						adaptor.addChild(root_1, (ASTNode)adaptor.create(Identifier, (all!=null?all.getText():null)));
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1813:5: ( KW_NONE )=> (none= KW_NONE )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1813:18: (none= KW_NONE )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1813:19: none= KW_NONE
					{
					none=(Token)match(input,KW_NONE,FOLLOW_KW_NONE_in_setRole9989); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NONE.add(none);

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1813:33: -> ^( TOK_SET_ROLE Identifier[$none.text] )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1813:36: ^( TOK_SET_ROLE Identifier[$none.text] )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_ROLE, "TOK_SET_ROLE"), root_1);
						adaptor.addChild(root_1, (ASTNode)adaptor.create(Identifier, (none!=null?none.getText():null)));
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:5: identifier
					{
					pushFollow(FOLLOW_identifier_in_setRole10011);
					identifier582=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier582.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1815:16: -> ^( TOK_SET_ROLE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:19: ^( TOK_SET_ROLE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_ROLE, "TOK_SET_ROLE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setRole"


	public static class showGrants_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showGrants"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1819:1: showGrants : KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) ;
	public final HiveParser.showGrants_return showGrants() throws RecognitionException {
		HiveParser.showGrants_return retval = new HiveParser.showGrants_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW583=null;
		Token KW_GRANT584=null;
		Token KW_ON586=null;
		ParserRuleReturnScope principalName585 =null;
		ParserRuleReturnScope privilegeIncludeColObject587 =null;

		ASTNode KW_SHOW583_tree=null;
		ASTNode KW_GRANT584_tree=null;
		ASTNode KW_ON586_tree=null;
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleSubtreeStream stream_privilegeIncludeColObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeIncludeColObject");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		pushMsg("show grants", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1822:5: ( KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1822:7: KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )?
			{
			KW_SHOW583=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showGrants10052); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW583);

			KW_GRANT584=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_showGrants10054); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT584);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1822:24: ( principalName )?
			int alt176=2;
			int LA176_0 = input.LA(1);
			if ( (LA176_0==KW_GROUP||LA176_0==KW_ROLE||LA176_0==KW_USER) ) {
				alt176=1;
			}
			switch (alt176) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1822:24: principalName
					{
					pushFollow(FOLLOW_principalName_in_showGrants10056);
					principalName585=principalName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalName.add(principalName585.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1822:39: ( KW_ON privilegeIncludeColObject )?
			int alt177=2;
			int LA177_0 = input.LA(1);
			if ( (LA177_0==KW_ON) ) {
				alt177=1;
			}
			switch (alt177) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1822:40: KW_ON privilegeIncludeColObject
					{
					KW_ON586=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_showGrants10060); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON586);

					pushFollow(FOLLOW_privilegeIncludeColObject_in_showGrants10062);
					privilegeIncludeColObject587=privilegeIncludeColObject();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privilegeIncludeColObject.add(privilegeIncludeColObject587.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: principalName, privilegeIncludeColObject
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1823:5: -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1823:8: ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_GRANT, "TOK_SHOW_GRANT"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1823:25: ( principalName )?
				if ( stream_principalName.hasNext() ) {
					adaptor.addChild(root_1, stream_principalName.nextTree());
				}
				stream_principalName.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1823:40: ( privilegeIncludeColObject )?
				if ( stream_privilegeIncludeColObject.hasNext() ) {
					adaptor.addChild(root_1, stream_privilegeIncludeColObject.nextTree());
				}
				stream_privilegeIncludeColObject.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showGrants"


	public static class showRolePrincipals_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showRolePrincipals"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1826:1: showRolePrincipals : KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) ;
	public final HiveParser.showRolePrincipals_return showRolePrincipals() throws RecognitionException {
		HiveParser.showRolePrincipals_return retval = new HiveParser.showRolePrincipals_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW588=null;
		Token KW_PRINCIPALS589=null;
		ParserRuleReturnScope roleName =null;

		ASTNode KW_SHOW588_tree=null;
		ASTNode KW_PRINCIPALS589_tree=null;
		RewriteRuleTokenStream stream_KW_PRINCIPALS=new RewriteRuleTokenStream(adaptor,"token KW_PRINCIPALS");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		pushMsg("show role principals", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1829:5: ( KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1829:7: KW_SHOW KW_PRINCIPALS roleName= identifier
			{
			KW_SHOW588=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRolePrincipals10107); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW588);

			KW_PRINCIPALS589=(Token)match(input,KW_PRINCIPALS,FOLLOW_KW_PRINCIPALS_in_showRolePrincipals10109); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_PRINCIPALS.add(KW_PRINCIPALS589);

			pushFollow(FOLLOW_identifier_in_showRolePrincipals10113);
			roleName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());
			// AST REWRITE
			// elements: roleName
			// token labels: 
			// rule labels: roleName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1830:5: -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:8: ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_ROLE_PRINCIPALS, "TOK_SHOW_ROLE_PRINCIPALS"), root_1);
				adaptor.addChild(root_1, stream_roleName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showRolePrincipals"


	public static class privilegeIncludeColObject_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeIncludeColObject"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1834:1: privilegeIncludeColObject : ( ( KW_ALL )=> KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) );
	public final HiveParser.privilegeIncludeColObject_return privilegeIncludeColObject() throws RecognitionException {
		HiveParser.privilegeIncludeColObject_return retval = new HiveParser.privilegeIncludeColObject_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ALL590=null;
		ParserRuleReturnScope privObjectCols591 =null;

		ASTNode KW_ALL590_tree=null;
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
		RewriteRuleSubtreeStream stream_privObjectCols=new RewriteRuleSubtreeStream(adaptor,"rule privObjectCols");

		pushMsg("privilege object including columns", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1837:5: ( ( KW_ALL )=> KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) )
			int alt178=2;
			int LA178_0 = input.LA(1);
			if ( (LA178_0==KW_ALL) && (synpred16_HiveParser())) {
				alt178=1;
			}
			else if ( (LA178_0==Identifier||(LA178_0 >= KW_ABORT && LA178_0 <= KW_AFTER)||LA178_0==KW_ALLOC_FRACTION||LA178_0==KW_ANALYZE||LA178_0==KW_ARCHIVE||(LA178_0 >= KW_ASC && LA178_0 <= KW_AT)||(LA178_0 >= KW_AUTOCOMMIT && LA178_0 <= KW_BEFORE)||(LA178_0 >= KW_BUCKET && LA178_0 <= KW_BUCKETS)||(LA178_0 >= KW_CACHE && LA178_0 <= KW_CASCADE)||(LA178_0 >= KW_CBO && LA178_0 <= KW_CHANGE)||(LA178_0 >= KW_CHECK && LA178_0 <= KW_COLLECTION)||(LA178_0 >= KW_COLUMNS && LA178_0 <= KW_COMMENT)||(LA178_0 >= KW_COMPACT && LA178_0 <= KW_CONCATENATE)||(LA178_0 >= KW_CONTINUE && LA178_0 <= KW_COST)||LA178_0==KW_CRON||(LA178_0 >= KW_DATA && LA178_0 <= KW_DATABASES)||(LA178_0 >= KW_DATETIME && LA178_0 <= KW_DEBUG)||(LA178_0 >= KW_DEFAULT && LA178_0 <= KW_DEFINED)||(LA178_0 >= KW_DELIMITED && LA178_0 <= KW_DESC)||(LA178_0 >= KW_DETAIL && LA178_0 <= KW_DISABLE)||(LA178_0 >= KW_DISTRIBUTE && LA178_0 <= KW_DO)||LA178_0==KW_DOW||(LA178_0 >= KW_DUMP && LA178_0 <= KW_ELEM_TYPE)||LA178_0==KW_ENABLE||(LA178_0 >= KW_ENFORCED && LA178_0 <= KW_EVERY)||(LA178_0 >= KW_EXCLUSIVE && LA178_0 <= KW_EXECUTED)||(LA178_0 >= KW_EXPLAIN && LA178_0 <= KW_EXPRESSION)||(LA178_0 >= KW_FIELDS && LA178_0 <= KW_FIRST)||(LA178_0 >= KW_FORMAT && LA178_0 <= KW_FORMATTED)||LA178_0==KW_FUNCTIONS||(LA178_0 >= KW_HOUR && LA178_0 <= KW_IDXPROPERTIES)||(LA178_0 >= KW_INDEX && LA178_0 <= KW_INDEXES)||(LA178_0 >= KW_INPATH && LA178_0 <= KW_INPUTFORMAT)||(LA178_0 >= KW_ISOLATION && LA178_0 <= KW_JAR)||(LA178_0 >= KW_JOINCOST && LA178_0 <= KW_LAST)||LA178_0==KW_LEVEL||(LA178_0 >= KW_LIMIT && LA178_0 <= KW_LOAD)||(LA178_0 >= KW_LOCATION && LA178_0 <= KW_LONG)||(LA178_0 >= KW_MANAGEDLOCATION && LA178_0 <= KW_MANAGEMENT)||(LA178_0 >= KW_MAPJOIN && LA178_0 <= KW_MATERIALIZED)||LA178_0==KW_METADATA||(LA178_0 >= KW_MINUTE && LA178_0 <= KW_MONTH)||(LA178_0 >= KW_MOVE && LA178_0 <= KW_MSCK)||(LA178_0 >= KW_NORELY && LA178_0 <= KW_NOSCAN)||LA178_0==KW_NOVALIDATE||LA178_0==KW_NULLS||LA178_0==KW_OFFSET||(LA178_0 >= KW_OPERATOR && LA178_0 <= KW_OPTION)||(LA178_0 >= KW_OUTPUTDRIVER && LA178_0 <= KW_OUTPUTFORMAT)||(LA178_0 >= KW_OVERWRITE && LA178_0 <= KW_OWNER)||(LA178_0 >= KW_PARTITIONED && LA178_0 <= KW_PATH)||(LA178_0 >= KW_PLAN && LA178_0 <= KW_POOL)||LA178_0==KW_PRINCIPALS||(LA178_0 >= KW_PURGE && LA178_0 <= KW_QUERY_PARALLELISM)||LA178_0==KW_READ||(LA178_0 >= KW_REBUILD && LA178_0 <= KW_RECORDWRITER)||(LA178_0 >= KW_RELOAD && LA178_0 <= KW_RESTRICT)||LA178_0==KW_REWRITE||(LA178_0 >= KW_ROLE && LA178_0 <= KW_ROLES)||(LA178_0 >= KW_SCHEDULED && LA178_0 <= KW_SECOND)||(LA178_0 >= KW_SEMI && LA178_0 <= KW_SERVER)||(LA178_0 >= KW_SETS && LA178_0 <= KW_SKEWED)||(LA178_0 >= KW_SNAPSHOT && LA178_0 <= KW_SSL)||(LA178_0 >= KW_STATISTICS && LA178_0 <= KW_SUMMARY)||(LA178_0 >= KW_TABLE && LA178_0 <= KW_TABLES)||(LA178_0 >= KW_TBLPROPERTIES && LA178_0 <= KW_TERMINATED)||LA178_0==KW_TINYINT||(LA178_0 >= KW_TOUCH && LA178_0 <= KW_TRANSACTIONS)||LA178_0==KW_UNARCHIVE||LA178_0==KW_UNDO||LA178_0==KW_UNIONTYPE||(LA178_0 >= KW_UNLOCK && LA178_0 <= KW_UNSIGNED)||(LA178_0 >= KW_URI && LA178_0 <= KW_USE)||(LA178_0 >= KW_UTC && LA178_0 <= KW_VALIDATE)||LA178_0==KW_VALUE_TYPE||(LA178_0 >= KW_VECTORIZATION && LA178_0 <= KW_WEEK)||LA178_0==KW_WHILE||(LA178_0 >= KW_WORK && LA178_0 <= KW_ZONE)||LA178_0==KW_BATCH||LA178_0==KW_DAYOFWEEK||LA178_0==KW_HOLD_DDLTIME||LA178_0==KW_IGNORE||LA178_0==KW_NO_DROP||LA178_0==KW_OFFLINE||LA178_0==KW_PROTECTION||LA178_0==KW_READONLY||LA178_0==KW_TIMESTAMPTZ) ) {
				alt178=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 178, 0, input);
				throw nvae;
			}

			switch (alt178) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1837:7: ( KW_ALL )=> KW_ALL
					{
					KW_ALL590=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_privilegeIncludeColObject10160); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL590);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1837:26: -> ^( TOK_RESOURCE_ALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1837:29: ^( TOK_RESOURCE_ALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESOURCE_ALL, "TOK_RESOURCE_ALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1838:7: privObjectCols
					{
					pushFollow(FOLLOW_privObjectCols_in_privilegeIncludeColObject10174);
					privObjectCols591=privObjectCols();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privObjectCols.add(privObjectCols591.getTree());
					// AST REWRITE
					// elements: privObjectCols
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1838:22: -> ^( TOK_PRIV_OBJECT_COL privObjectCols )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1838:25: ^( TOK_PRIV_OBJECT_COL privObjectCols )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_OBJECT_COL, "TOK_PRIV_OBJECT_COL"), root_1);
						adaptor.addChild(root_1, stream_privObjectCols.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeIncludeColObject"


	public static class privilegeObject_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeObject"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1841:1: privilegeObject : KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) ;
	public final HiveParser.privilegeObject_return privilegeObject() throws RecognitionException {
		HiveParser.privilegeObject_return retval = new HiveParser.privilegeObject_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ON592=null;
		ParserRuleReturnScope privObject593 =null;

		ASTNode KW_ON592_tree=null;
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleSubtreeStream stream_privObject=new RewriteRuleSubtreeStream(adaptor,"rule privObject");

		pushMsg("privilege object", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1844:5: ( KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1844:7: KW_ON privObject
			{
			KW_ON592=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_privilegeObject10209); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON592);

			pushFollow(FOLLOW_privObject_in_privilegeObject10211);
			privObject593=privObject();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privObject.add(privObject593.getTree());
			// AST REWRITE
			// elements: privObject
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1844:24: -> ^( TOK_PRIV_OBJECT privObject )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1844:27: ^( TOK_PRIV_OBJECT privObject )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_OBJECT, "TOK_PRIV_OBJECT"), root_1);
				adaptor.addChild(root_1, stream_privObject.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeObject"


	public static class privObject_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privObject"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1848:1: privObject : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
	public final HiveParser.privObject_return privObject() throws RecognitionException {
		HiveParser.privObject_return retval = new HiveParser.privObject_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token path=null;
		Token KW_DATABASE594=null;
		Token KW_SCHEMA595=null;
		Token KW_TABLE597=null;
		Token KW_URI600=null;
		Token KW_SERVER601=null;
		ParserRuleReturnScope identifier596 =null;
		ParserRuleReturnScope tableName598 =null;
		ParserRuleReturnScope partitionSpec599 =null;
		ParserRuleReturnScope identifier602 =null;

		ASTNode path_tree=null;
		ASTNode KW_DATABASE594_tree=null;
		ASTNode KW_SCHEMA595_tree=null;
		ASTNode KW_TABLE597_tree=null;
		ASTNode KW_URI600_tree=null;
		ASTNode KW_SERVER601_tree=null;
		RewriteRuleTokenStream stream_KW_SERVER=new RewriteRuleTokenStream(adaptor,"token KW_SERVER");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_URI=new RewriteRuleTokenStream(adaptor,"token KW_URI");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1849:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
			int alt182=4;
			switch ( input.LA(1) ) {
			case KW_DATABASE:
				{
				alt182=1;
				}
				break;
			case KW_SCHEMA:
				{
				int LA182_2 = input.LA(2);
				if ( (LA182_2==Identifier||(LA182_2 >= KW_ABORT && LA182_2 <= KW_AFTER)||LA182_2==KW_ALLOC_FRACTION||LA182_2==KW_ANALYZE||LA182_2==KW_ARCHIVE||(LA182_2 >= KW_ASC && LA182_2 <= KW_AT)||(LA182_2 >= KW_AUTOCOMMIT && LA182_2 <= KW_BEFORE)||(LA182_2 >= KW_BUCKET && LA182_2 <= KW_BUCKETS)||(LA182_2 >= KW_CACHE && LA182_2 <= KW_CASCADE)||(LA182_2 >= KW_CBO && LA182_2 <= KW_CHANGE)||(LA182_2 >= KW_CHECK && LA182_2 <= KW_COLLECTION)||(LA182_2 >= KW_COLUMNS && LA182_2 <= KW_COMMENT)||(LA182_2 >= KW_COMPACT && LA182_2 <= KW_CONCATENATE)||(LA182_2 >= KW_CONTINUE && LA182_2 <= KW_COST)||LA182_2==KW_CRON||LA182_2==KW_DATA||LA182_2==KW_DATABASES||(LA182_2 >= KW_DATETIME && LA182_2 <= KW_DEBUG)||(LA182_2 >= KW_DEFAULT && LA182_2 <= KW_DEFINED)||(LA182_2 >= KW_DELIMITED && LA182_2 <= KW_DESC)||(LA182_2 >= KW_DETAIL && LA182_2 <= KW_DISABLE)||(LA182_2 >= KW_DISTRIBUTE && LA182_2 <= KW_DO)||LA182_2==KW_DOW||(LA182_2 >= KW_DUMP && LA182_2 <= KW_ELEM_TYPE)||LA182_2==KW_ENABLE||(LA182_2 >= KW_ENFORCED && LA182_2 <= KW_EVERY)||(LA182_2 >= KW_EXCLUSIVE && LA182_2 <= KW_EXECUTED)||(LA182_2 >= KW_EXPLAIN && LA182_2 <= KW_EXPRESSION)||(LA182_2 >= KW_FIELDS && LA182_2 <= KW_FIRST)||(LA182_2 >= KW_FORMAT && LA182_2 <= KW_FORMATTED)||LA182_2==KW_FUNCTIONS||(LA182_2 >= KW_HOUR && LA182_2 <= KW_IDXPROPERTIES)||(LA182_2 >= KW_INDEX && LA182_2 <= KW_INDEXES)||(LA182_2 >= KW_INPATH && LA182_2 <= KW_INPUTFORMAT)||(LA182_2 >= KW_ISOLATION && LA182_2 <= KW_JAR)||(LA182_2 >= KW_JOINCOST && LA182_2 <= KW_LAST)||LA182_2==KW_LEVEL||(LA182_2 >= KW_LIMIT && LA182_2 <= KW_LOAD)||(LA182_2 >= KW_LOCATION && LA182_2 <= KW_LONG)||(LA182_2 >= KW_MANAGEDLOCATION && LA182_2 <= KW_MANAGEMENT)||(LA182_2 >= KW_MAPJOIN && LA182_2 <= KW_MATERIALIZED)||LA182_2==KW_METADATA||(LA182_2 >= KW_MINUTE && LA182_2 <= KW_MONTH)||(LA182_2 >= KW_MOVE && LA182_2 <= KW_MSCK)||(LA182_2 >= KW_NORELY && LA182_2 <= KW_NOSCAN)||LA182_2==KW_NOVALIDATE||LA182_2==KW_NULLS||LA182_2==KW_OFFSET||(LA182_2 >= KW_OPERATOR && LA182_2 <= KW_OPTION)||(LA182_2 >= KW_OUTPUTDRIVER && LA182_2 <= KW_OUTPUTFORMAT)||(LA182_2 >= KW_OVERWRITE && LA182_2 <= KW_OWNER)||(LA182_2 >= KW_PARTITIONED && LA182_2 <= KW_PATH)||(LA182_2 >= KW_PLAN && LA182_2 <= KW_POOL)||LA182_2==KW_PRINCIPALS||(LA182_2 >= KW_PURGE && LA182_2 <= KW_QUERY_PARALLELISM)||LA182_2==KW_READ||(LA182_2 >= KW_REBUILD && LA182_2 <= KW_RECORDWRITER)||(LA182_2 >= KW_RELOAD && LA182_2 <= KW_RESTRICT)||LA182_2==KW_REWRITE||(LA182_2 >= KW_ROLE && LA182_2 <= KW_ROLES)||(LA182_2 >= KW_SCHEDULED && LA182_2 <= KW_SECOND)||(LA182_2 >= KW_SEMI && LA182_2 <= KW_SERVER)||(LA182_2 >= KW_SETS && LA182_2 <= KW_SKEWED)||(LA182_2 >= KW_SNAPSHOT && LA182_2 <= KW_SSL)||(LA182_2 >= KW_STATISTICS && LA182_2 <= KW_SUMMARY)||LA182_2==KW_TABLES||(LA182_2 >= KW_TBLPROPERTIES && LA182_2 <= KW_TERMINATED)||LA182_2==KW_TINYINT||(LA182_2 >= KW_TOUCH && LA182_2 <= KW_TRANSACTIONS)||LA182_2==KW_UNARCHIVE||LA182_2==KW_UNDO||LA182_2==KW_UNIONTYPE||(LA182_2 >= KW_UNLOCK && LA182_2 <= KW_UNSIGNED)||(LA182_2 >= KW_URI && LA182_2 <= KW_USE)||(LA182_2 >= KW_UTC && LA182_2 <= KW_VALIDATE)||LA182_2==KW_VALUE_TYPE||(LA182_2 >= KW_VECTORIZATION && LA182_2 <= KW_WEEK)||LA182_2==KW_WHILE||(LA182_2 >= KW_WORK && LA182_2 <= KW_ZONE)||LA182_2==KW_BATCH||LA182_2==KW_DAYOFWEEK||LA182_2==KW_HOLD_DDLTIME||LA182_2==KW_IGNORE||LA182_2==KW_NO_DROP||LA182_2==KW_OFFLINE||LA182_2==KW_PROTECTION||LA182_2==KW_READONLY||LA182_2==KW_TIMESTAMPTZ) ) {
					alt182=1;
				}
				else if ( (LA182_2==DOT||LA182_2==KW_FROM||LA182_2==KW_PARTITION||LA182_2==KW_TO) ) {
					alt182=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 182, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AT:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_CRON:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EVERY:
			case KW_EXCLUSIVE:
			case KW_EXECUTE:
			case KW_EXECUTED:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_IDXPROPERTIES:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGEDLOCATION:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULED:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_TABLE:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_IGNORE:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt182=2;
				}
				break;
			case KW_URI:
				{
				int LA182_5 = input.LA(2);
				if ( (LA182_5==DOT||LA182_5==KW_FROM||LA182_5==KW_PARTITION||LA182_5==KW_TO) ) {
					alt182=2;
				}
				else if ( (LA182_5==StringLiteral) ) {
					alt182=3;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 182, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_SERVER:
				{
				int LA182_6 = input.LA(2);
				if ( (LA182_6==DOT||LA182_6==KW_FROM||LA182_6==KW_PARTITION||LA182_6==KW_TO) ) {
					alt182=2;
				}
				else if ( (LA182_6==Identifier||(LA182_6 >= KW_ABORT && LA182_6 <= KW_AFTER)||LA182_6==KW_ALLOC_FRACTION||LA182_6==KW_ANALYZE||LA182_6==KW_ARCHIVE||(LA182_6 >= KW_ASC && LA182_6 <= KW_AT)||(LA182_6 >= KW_AUTOCOMMIT && LA182_6 <= KW_BEFORE)||(LA182_6 >= KW_BUCKET && LA182_6 <= KW_BUCKETS)||(LA182_6 >= KW_CACHE && LA182_6 <= KW_CASCADE)||(LA182_6 >= KW_CBO && LA182_6 <= KW_CHANGE)||(LA182_6 >= KW_CHECK && LA182_6 <= KW_COLLECTION)||(LA182_6 >= KW_COLUMNS && LA182_6 <= KW_COMMENT)||(LA182_6 >= KW_COMPACT && LA182_6 <= KW_CONCATENATE)||(LA182_6 >= KW_CONTINUE && LA182_6 <= KW_COST)||LA182_6==KW_CRON||LA182_6==KW_DATA||LA182_6==KW_DATABASES||(LA182_6 >= KW_DATETIME && LA182_6 <= KW_DEBUG)||(LA182_6 >= KW_DEFAULT && LA182_6 <= KW_DEFINED)||(LA182_6 >= KW_DELIMITED && LA182_6 <= KW_DESC)||(LA182_6 >= KW_DETAIL && LA182_6 <= KW_DISABLE)||(LA182_6 >= KW_DISTRIBUTE && LA182_6 <= KW_DO)||LA182_6==KW_DOW||(LA182_6 >= KW_DUMP && LA182_6 <= KW_ELEM_TYPE)||LA182_6==KW_ENABLE||(LA182_6 >= KW_ENFORCED && LA182_6 <= KW_EVERY)||(LA182_6 >= KW_EXCLUSIVE && LA182_6 <= KW_EXECUTED)||(LA182_6 >= KW_EXPLAIN && LA182_6 <= KW_EXPRESSION)||(LA182_6 >= KW_FIELDS && LA182_6 <= KW_FIRST)||(LA182_6 >= KW_FORMAT && LA182_6 <= KW_FORMATTED)||LA182_6==KW_FUNCTIONS||(LA182_6 >= KW_HOUR && LA182_6 <= KW_IDXPROPERTIES)||(LA182_6 >= KW_INDEX && LA182_6 <= KW_INDEXES)||(LA182_6 >= KW_INPATH && LA182_6 <= KW_INPUTFORMAT)||(LA182_6 >= KW_ISOLATION && LA182_6 <= KW_JAR)||(LA182_6 >= KW_JOINCOST && LA182_6 <= KW_LAST)||LA182_6==KW_LEVEL||(LA182_6 >= KW_LIMIT && LA182_6 <= KW_LOAD)||(LA182_6 >= KW_LOCATION && LA182_6 <= KW_LONG)||(LA182_6 >= KW_MANAGEDLOCATION && LA182_6 <= KW_MANAGEMENT)||(LA182_6 >= KW_MAPJOIN && LA182_6 <= KW_MATERIALIZED)||LA182_6==KW_METADATA||(LA182_6 >= KW_MINUTE && LA182_6 <= KW_MONTH)||(LA182_6 >= KW_MOVE && LA182_6 <= KW_MSCK)||(LA182_6 >= KW_NORELY && LA182_6 <= KW_NOSCAN)||LA182_6==KW_NOVALIDATE||LA182_6==KW_NULLS||LA182_6==KW_OFFSET||(LA182_6 >= KW_OPERATOR && LA182_6 <= KW_OPTION)||(LA182_6 >= KW_OUTPUTDRIVER && LA182_6 <= KW_OUTPUTFORMAT)||(LA182_6 >= KW_OVERWRITE && LA182_6 <= KW_OWNER)||(LA182_6 >= KW_PARTITIONED && LA182_6 <= KW_PATH)||(LA182_6 >= KW_PLAN && LA182_6 <= KW_POOL)||LA182_6==KW_PRINCIPALS||(LA182_6 >= KW_PURGE && LA182_6 <= KW_QUERY_PARALLELISM)||LA182_6==KW_READ||(LA182_6 >= KW_REBUILD && LA182_6 <= KW_RECORDWRITER)||(LA182_6 >= KW_RELOAD && LA182_6 <= KW_RESTRICT)||LA182_6==KW_REWRITE||(LA182_6 >= KW_ROLE && LA182_6 <= KW_ROLES)||(LA182_6 >= KW_SCHEDULED && LA182_6 <= KW_SECOND)||(LA182_6 >= KW_SEMI && LA182_6 <= KW_SERVER)||(LA182_6 >= KW_SETS && LA182_6 <= KW_SKEWED)||(LA182_6 >= KW_SNAPSHOT && LA182_6 <= KW_SSL)||(LA182_6 >= KW_STATISTICS && LA182_6 <= KW_SUMMARY)||LA182_6==KW_TABLES||(LA182_6 >= KW_TBLPROPERTIES && LA182_6 <= KW_TERMINATED)||LA182_6==KW_TINYINT||(LA182_6 >= KW_TOUCH && LA182_6 <= KW_TRANSACTIONS)||LA182_6==KW_UNARCHIVE||LA182_6==KW_UNDO||LA182_6==KW_UNIONTYPE||(LA182_6 >= KW_UNLOCK && LA182_6 <= KW_UNSIGNED)||(LA182_6 >= KW_URI && LA182_6 <= KW_USE)||(LA182_6 >= KW_UTC && LA182_6 <= KW_VALIDATE)||LA182_6==KW_VALUE_TYPE||(LA182_6 >= KW_VECTORIZATION && LA182_6 <= KW_WEEK)||LA182_6==KW_WHILE||(LA182_6 >= KW_WORK && LA182_6 <= KW_ZONE)||LA182_6==KW_BATCH||LA182_6==KW_DAYOFWEEK||LA182_6==KW_HOLD_DDLTIME||LA182_6==KW_IGNORE||LA182_6==KW_NO_DROP||LA182_6==KW_OFFLINE||LA182_6==KW_PROTECTION||LA182_6==KW_READONLY||LA182_6==KW_TIMESTAMPTZ) ) {
					alt182=4;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 182, 6, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 182, 0, input);
				throw nvae;
			}
			switch (alt182) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1849:7: ( KW_DATABASE | KW_SCHEMA ) identifier
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1849:7: ( KW_DATABASE | KW_SCHEMA )
					int alt179=2;
					int LA179_0 = input.LA(1);
					if ( (LA179_0==KW_DATABASE) ) {
						alt179=1;
					}
					else if ( (LA179_0==KW_SCHEMA) ) {
						alt179=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 179, 0, input);
						throw nvae;
					}

					switch (alt179) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1849:8: KW_DATABASE
							{
							KW_DATABASE594=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_privObject10238); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE594);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1849:20: KW_SCHEMA
							{
							KW_SCHEMA595=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_privObject10240); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA595);

							}
							break;

					}

					pushFollow(FOLLOW_identifier_in_privObject10243);
					identifier596=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier596.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1849:42: -> ^( TOK_DB_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1849:45: ^( TOK_DB_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:7: ( KW_TABLE )? tableName ( partitionSpec )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:7: ( KW_TABLE )?
					int alt180=2;
					int LA180_0 = input.LA(1);
					if ( (LA180_0==KW_TABLE) ) {
						alt180=1;
					}
					switch (alt180) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:7: KW_TABLE
							{
							KW_TABLE597=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_privObject10259); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE597);

							}
							break;

					}

					pushFollow(FOLLOW_tableName_in_privObject10262);
					tableName598=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName598.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:27: ( partitionSpec )?
					int alt181=2;
					int LA181_0 = input.LA(1);
					if ( (LA181_0==KW_PARTITION) ) {
						alt181=1;
					}
					switch (alt181) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:27: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_privObject10264);
							partitionSpec599=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec599.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: partitionSpec, tableName
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1850:42: -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:45: ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:72: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1851:7: KW_URI (path= StringLiteral )
					{
					KW_URI600=(Token)match(input,KW_URI,FOLLOW_KW_URI_in_privObject10284); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_URI.add(KW_URI600);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1851:14: (path= StringLiteral )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1851:15: path= StringLiteral
					{
					path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_privObject10289); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(path);

					}

					// AST REWRITE
					// elements: path
					// token labels: path
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1851:35: -> ^( TOK_URI_TYPE $path)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1851:39: ^( TOK_URI_TYPE $path)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE"), root_1);
						adaptor.addChild(root_1, stream_path.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1852:7: KW_SERVER identifier
					{
					KW_SERVER601=(Token)match(input,KW_SERVER,FOLLOW_KW_SERVER_in_privObject10308); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERVER.add(KW_SERVER601);

					pushFollow(FOLLOW_identifier_in_privObject10310);
					identifier602=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier602.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1852:28: -> ^( TOK_SERVER_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1852:31: ^( TOK_SERVER_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privObject"


	public static class privObjectCols_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privObjectCols"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1855:1: privObjectCols : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
	public final HiveParser.privObjectCols_return privObjectCols() throws RecognitionException {
		HiveParser.privObjectCols_return retval = new HiveParser.privObjectCols_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token path=null;
		Token KW_DATABASE603=null;
		Token KW_SCHEMA604=null;
		Token KW_TABLE606=null;
		Token LPAREN608=null;
		Token RPAREN609=null;
		Token KW_URI611=null;
		Token KW_SERVER612=null;
		ParserRuleReturnScope cols =null;
		ParserRuleReturnScope identifier605 =null;
		ParserRuleReturnScope tableName607 =null;
		ParserRuleReturnScope partitionSpec610 =null;
		ParserRuleReturnScope identifier613 =null;

		ASTNode path_tree=null;
		ASTNode KW_DATABASE603_tree=null;
		ASTNode KW_SCHEMA604_tree=null;
		ASTNode KW_TABLE606_tree=null;
		ASTNode LPAREN608_tree=null;
		ASTNode RPAREN609_tree=null;
		ASTNode KW_URI611_tree=null;
		ASTNode KW_SERVER612_tree=null;
		RewriteRuleTokenStream stream_KW_SERVER=new RewriteRuleTokenStream(adaptor,"token KW_SERVER");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_URI=new RewriteRuleTokenStream(adaptor,"token KW_URI");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1856:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
			int alt187=4;
			switch ( input.LA(1) ) {
			case KW_DATABASE:
				{
				alt187=1;
				}
				break;
			case KW_SCHEMA:
				{
				int LA187_2 = input.LA(2);
				if ( (LA187_2==Identifier||(LA187_2 >= KW_ABORT && LA187_2 <= KW_AFTER)||LA187_2==KW_ALLOC_FRACTION||LA187_2==KW_ANALYZE||LA187_2==KW_ARCHIVE||(LA187_2 >= KW_ASC && LA187_2 <= KW_AT)||(LA187_2 >= KW_AUTOCOMMIT && LA187_2 <= KW_BEFORE)||(LA187_2 >= KW_BUCKET && LA187_2 <= KW_BUCKETS)||(LA187_2 >= KW_CACHE && LA187_2 <= KW_CASCADE)||(LA187_2 >= KW_CBO && LA187_2 <= KW_CHANGE)||(LA187_2 >= KW_CHECK && LA187_2 <= KW_COLLECTION)||(LA187_2 >= KW_COLUMNS && LA187_2 <= KW_COMMENT)||(LA187_2 >= KW_COMPACT && LA187_2 <= KW_CONCATENATE)||(LA187_2 >= KW_CONTINUE && LA187_2 <= KW_COST)||LA187_2==KW_CRON||LA187_2==KW_DATA||LA187_2==KW_DATABASES||(LA187_2 >= KW_DATETIME && LA187_2 <= KW_DEBUG)||(LA187_2 >= KW_DEFAULT && LA187_2 <= KW_DEFINED)||(LA187_2 >= KW_DELIMITED && LA187_2 <= KW_DESC)||(LA187_2 >= KW_DETAIL && LA187_2 <= KW_DISABLE)||(LA187_2 >= KW_DISTRIBUTE && LA187_2 <= KW_DO)||LA187_2==KW_DOW||(LA187_2 >= KW_DUMP && LA187_2 <= KW_ELEM_TYPE)||LA187_2==KW_ENABLE||(LA187_2 >= KW_ENFORCED && LA187_2 <= KW_EVERY)||(LA187_2 >= KW_EXCLUSIVE && LA187_2 <= KW_EXECUTED)||(LA187_2 >= KW_EXPLAIN && LA187_2 <= KW_EXPRESSION)||(LA187_2 >= KW_FIELDS && LA187_2 <= KW_FIRST)||(LA187_2 >= KW_FORMAT && LA187_2 <= KW_FORMATTED)||LA187_2==KW_FUNCTIONS||(LA187_2 >= KW_HOUR && LA187_2 <= KW_IDXPROPERTIES)||(LA187_2 >= KW_INDEX && LA187_2 <= KW_INDEXES)||(LA187_2 >= KW_INPATH && LA187_2 <= KW_INPUTFORMAT)||(LA187_2 >= KW_ISOLATION && LA187_2 <= KW_JAR)||(LA187_2 >= KW_JOINCOST && LA187_2 <= KW_LAST)||LA187_2==KW_LEVEL||(LA187_2 >= KW_LIMIT && LA187_2 <= KW_LOAD)||(LA187_2 >= KW_LOCATION && LA187_2 <= KW_LONG)||(LA187_2 >= KW_MANAGEDLOCATION && LA187_2 <= KW_MANAGEMENT)||(LA187_2 >= KW_MAPJOIN && LA187_2 <= KW_MATERIALIZED)||LA187_2==KW_METADATA||(LA187_2 >= KW_MINUTE && LA187_2 <= KW_MONTH)||(LA187_2 >= KW_MOVE && LA187_2 <= KW_MSCK)||(LA187_2 >= KW_NORELY && LA187_2 <= KW_NOSCAN)||LA187_2==KW_NOVALIDATE||LA187_2==KW_NULLS||LA187_2==KW_OFFSET||(LA187_2 >= KW_OPERATOR && LA187_2 <= KW_OPTION)||(LA187_2 >= KW_OUTPUTDRIVER && LA187_2 <= KW_OUTPUTFORMAT)||(LA187_2 >= KW_OVERWRITE && LA187_2 <= KW_OWNER)||(LA187_2 >= KW_PARTITIONED && LA187_2 <= KW_PATH)||(LA187_2 >= KW_PLAN && LA187_2 <= KW_POOL)||LA187_2==KW_PRINCIPALS||(LA187_2 >= KW_PURGE && LA187_2 <= KW_QUERY_PARALLELISM)||LA187_2==KW_READ||(LA187_2 >= KW_REBUILD && LA187_2 <= KW_RECORDWRITER)||(LA187_2 >= KW_RELOAD && LA187_2 <= KW_RESTRICT)||LA187_2==KW_REWRITE||(LA187_2 >= KW_ROLE && LA187_2 <= KW_ROLES)||(LA187_2 >= KW_SCHEDULED && LA187_2 <= KW_SECOND)||(LA187_2 >= KW_SEMI && LA187_2 <= KW_SERVER)||(LA187_2 >= KW_SETS && LA187_2 <= KW_SKEWED)||(LA187_2 >= KW_SNAPSHOT && LA187_2 <= KW_SSL)||(LA187_2 >= KW_STATISTICS && LA187_2 <= KW_SUMMARY)||LA187_2==KW_TABLES||(LA187_2 >= KW_TBLPROPERTIES && LA187_2 <= KW_TERMINATED)||LA187_2==KW_TINYINT||(LA187_2 >= KW_TOUCH && LA187_2 <= KW_TRANSACTIONS)||LA187_2==KW_UNARCHIVE||LA187_2==KW_UNDO||LA187_2==KW_UNIONTYPE||(LA187_2 >= KW_UNLOCK && LA187_2 <= KW_UNSIGNED)||(LA187_2 >= KW_URI && LA187_2 <= KW_USE)||(LA187_2 >= KW_UTC && LA187_2 <= KW_VALIDATE)||LA187_2==KW_VALUE_TYPE||(LA187_2 >= KW_VECTORIZATION && LA187_2 <= KW_WEEK)||LA187_2==KW_WHILE||(LA187_2 >= KW_WORK && LA187_2 <= KW_ZONE)||LA187_2==KW_BATCH||LA187_2==KW_DAYOFWEEK||LA187_2==KW_HOLD_DDLTIME||LA187_2==KW_IGNORE||LA187_2==KW_NO_DROP||LA187_2==KW_OFFLINE||LA187_2==KW_PROTECTION||LA187_2==KW_READONLY||LA187_2==KW_TIMESTAMPTZ) ) {
					alt187=1;
				}
				else if ( (LA187_2==EOF||LA187_2==DOT||LA187_2==KW_PARTITION||LA187_2==LPAREN) ) {
					alt187=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 187, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AT:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_CRON:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EVERY:
			case KW_EXCLUSIVE:
			case KW_EXECUTE:
			case KW_EXECUTED:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_IDXPROPERTIES:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGEDLOCATION:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULED:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_TABLE:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_IGNORE:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt187=2;
				}
				break;
			case KW_URI:
				{
				int LA187_5 = input.LA(2);
				if ( (LA187_5==EOF||LA187_5==DOT||LA187_5==KW_PARTITION||LA187_5==LPAREN) ) {
					alt187=2;
				}
				else if ( (LA187_5==StringLiteral) ) {
					alt187=3;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 187, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_SERVER:
				{
				int LA187_6 = input.LA(2);
				if ( (LA187_6==EOF||LA187_6==DOT||LA187_6==KW_PARTITION||LA187_6==LPAREN) ) {
					alt187=2;
				}
				else if ( (LA187_6==Identifier||(LA187_6 >= KW_ABORT && LA187_6 <= KW_AFTER)||LA187_6==KW_ALLOC_FRACTION||LA187_6==KW_ANALYZE||LA187_6==KW_ARCHIVE||(LA187_6 >= KW_ASC && LA187_6 <= KW_AT)||(LA187_6 >= KW_AUTOCOMMIT && LA187_6 <= KW_BEFORE)||(LA187_6 >= KW_BUCKET && LA187_6 <= KW_BUCKETS)||(LA187_6 >= KW_CACHE && LA187_6 <= KW_CASCADE)||(LA187_6 >= KW_CBO && LA187_6 <= KW_CHANGE)||(LA187_6 >= KW_CHECK && LA187_6 <= KW_COLLECTION)||(LA187_6 >= KW_COLUMNS && LA187_6 <= KW_COMMENT)||(LA187_6 >= KW_COMPACT && LA187_6 <= KW_CONCATENATE)||(LA187_6 >= KW_CONTINUE && LA187_6 <= KW_COST)||LA187_6==KW_CRON||LA187_6==KW_DATA||LA187_6==KW_DATABASES||(LA187_6 >= KW_DATETIME && LA187_6 <= KW_DEBUG)||(LA187_6 >= KW_DEFAULT && LA187_6 <= KW_DEFINED)||(LA187_6 >= KW_DELIMITED && LA187_6 <= KW_DESC)||(LA187_6 >= KW_DETAIL && LA187_6 <= KW_DISABLE)||(LA187_6 >= KW_DISTRIBUTE && LA187_6 <= KW_DO)||LA187_6==KW_DOW||(LA187_6 >= KW_DUMP && LA187_6 <= KW_ELEM_TYPE)||LA187_6==KW_ENABLE||(LA187_6 >= KW_ENFORCED && LA187_6 <= KW_EVERY)||(LA187_6 >= KW_EXCLUSIVE && LA187_6 <= KW_EXECUTED)||(LA187_6 >= KW_EXPLAIN && LA187_6 <= KW_EXPRESSION)||(LA187_6 >= KW_FIELDS && LA187_6 <= KW_FIRST)||(LA187_6 >= KW_FORMAT && LA187_6 <= KW_FORMATTED)||LA187_6==KW_FUNCTIONS||(LA187_6 >= KW_HOUR && LA187_6 <= KW_IDXPROPERTIES)||(LA187_6 >= KW_INDEX && LA187_6 <= KW_INDEXES)||(LA187_6 >= KW_INPATH && LA187_6 <= KW_INPUTFORMAT)||(LA187_6 >= KW_ISOLATION && LA187_6 <= KW_JAR)||(LA187_6 >= KW_JOINCOST && LA187_6 <= KW_LAST)||LA187_6==KW_LEVEL||(LA187_6 >= KW_LIMIT && LA187_6 <= KW_LOAD)||(LA187_6 >= KW_LOCATION && LA187_6 <= KW_LONG)||(LA187_6 >= KW_MANAGEDLOCATION && LA187_6 <= KW_MANAGEMENT)||(LA187_6 >= KW_MAPJOIN && LA187_6 <= KW_MATERIALIZED)||LA187_6==KW_METADATA||(LA187_6 >= KW_MINUTE && LA187_6 <= KW_MONTH)||(LA187_6 >= KW_MOVE && LA187_6 <= KW_MSCK)||(LA187_6 >= KW_NORELY && LA187_6 <= KW_NOSCAN)||LA187_6==KW_NOVALIDATE||LA187_6==KW_NULLS||LA187_6==KW_OFFSET||(LA187_6 >= KW_OPERATOR && LA187_6 <= KW_OPTION)||(LA187_6 >= KW_OUTPUTDRIVER && LA187_6 <= KW_OUTPUTFORMAT)||(LA187_6 >= KW_OVERWRITE && LA187_6 <= KW_OWNER)||(LA187_6 >= KW_PARTITIONED && LA187_6 <= KW_PATH)||(LA187_6 >= KW_PLAN && LA187_6 <= KW_POOL)||LA187_6==KW_PRINCIPALS||(LA187_6 >= KW_PURGE && LA187_6 <= KW_QUERY_PARALLELISM)||LA187_6==KW_READ||(LA187_6 >= KW_REBUILD && LA187_6 <= KW_RECORDWRITER)||(LA187_6 >= KW_RELOAD && LA187_6 <= KW_RESTRICT)||LA187_6==KW_REWRITE||(LA187_6 >= KW_ROLE && LA187_6 <= KW_ROLES)||(LA187_6 >= KW_SCHEDULED && LA187_6 <= KW_SECOND)||(LA187_6 >= KW_SEMI && LA187_6 <= KW_SERVER)||(LA187_6 >= KW_SETS && LA187_6 <= KW_SKEWED)||(LA187_6 >= KW_SNAPSHOT && LA187_6 <= KW_SSL)||(LA187_6 >= KW_STATISTICS && LA187_6 <= KW_SUMMARY)||LA187_6==KW_TABLES||(LA187_6 >= KW_TBLPROPERTIES && LA187_6 <= KW_TERMINATED)||LA187_6==KW_TINYINT||(LA187_6 >= KW_TOUCH && LA187_6 <= KW_TRANSACTIONS)||LA187_6==KW_UNARCHIVE||LA187_6==KW_UNDO||LA187_6==KW_UNIONTYPE||(LA187_6 >= KW_UNLOCK && LA187_6 <= KW_UNSIGNED)||(LA187_6 >= KW_URI && LA187_6 <= KW_USE)||(LA187_6 >= KW_UTC && LA187_6 <= KW_VALIDATE)||LA187_6==KW_VALUE_TYPE||(LA187_6 >= KW_VECTORIZATION && LA187_6 <= KW_WEEK)||LA187_6==KW_WHILE||(LA187_6 >= KW_WORK && LA187_6 <= KW_ZONE)||LA187_6==KW_BATCH||LA187_6==KW_DAYOFWEEK||LA187_6==KW_HOLD_DDLTIME||LA187_6==KW_IGNORE||LA187_6==KW_NO_DROP||LA187_6==KW_OFFLINE||LA187_6==KW_PROTECTION||LA187_6==KW_READONLY||LA187_6==KW_TIMESTAMPTZ) ) {
					alt187=4;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 187, 6, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 187, 0, input);
				throw nvae;
			}
			switch (alt187) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1856:7: ( KW_DATABASE | KW_SCHEMA ) identifier
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1856:7: ( KW_DATABASE | KW_SCHEMA )
					int alt183=2;
					int LA183_0 = input.LA(1);
					if ( (LA183_0==KW_DATABASE) ) {
						alt183=1;
					}
					else if ( (LA183_0==KW_SCHEMA) ) {
						alt183=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 183, 0, input);
						throw nvae;
					}

					switch (alt183) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1856:8: KW_DATABASE
							{
							KW_DATABASE603=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_privObjectCols10336); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE603);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1856:20: KW_SCHEMA
							{
							KW_SCHEMA604=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_privObjectCols10338); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA604);

							}
							break;

					}

					pushFollow(FOLLOW_identifier_in_privObjectCols10341);
					identifier605=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier605.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1856:42: -> ^( TOK_DB_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1856:45: ^( TOK_DB_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:7: ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:7: ( KW_TABLE )?
					int alt184=2;
					int LA184_0 = input.LA(1);
					if ( (LA184_0==KW_TABLE) ) {
						alt184=1;
					}
					switch (alt184) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:7: KW_TABLE
							{
							KW_TABLE606=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_privObjectCols10357); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE606);

							}
							break;

					}

					pushFollow(FOLLOW_tableName_in_privObjectCols10360);
					tableName607=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName607.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:27: ( LPAREN cols= columnNameList RPAREN )?
					int alt185=2;
					int LA185_0 = input.LA(1);
					if ( (LA185_0==LPAREN) ) {
						alt185=1;
					}
					switch (alt185) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:28: LPAREN cols= columnNameList RPAREN
							{
							LPAREN608=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_privObjectCols10363); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN608);

							pushFollow(FOLLOW_columnNameList_in_privObjectCols10367);
							cols=columnNameList();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_columnNameList.add(cols.getTree());
							RPAREN609=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_privObjectCols10369); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN609);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:64: ( partitionSpec )?
					int alt186=2;
					int LA186_0 = input.LA(1);
					if ( (LA186_0==KW_PARTITION) ) {
						alt186=1;
					}
					switch (alt186) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:64: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_privObjectCols10373);
							partitionSpec610=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec610.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: cols, partitionSpec, tableName
					// token labels: 
					// rule labels: cols, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_cols=new RewriteRuleSubtreeStream(adaptor,"rule cols",cols!=null?cols.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1857:79: -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:82: ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:110: ( $cols)?
						if ( stream_cols.hasNext() ) {
							adaptor.addChild(root_1, stream_cols.nextTree());
						}
						stream_cols.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:116: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1858:7: KW_URI (path= StringLiteral )
					{
					KW_URI611=(Token)match(input,KW_URI,FOLLOW_KW_URI_in_privObjectCols10397); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_URI.add(KW_URI611);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1858:14: (path= StringLiteral )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1858:15: path= StringLiteral
					{
					path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_privObjectCols10402); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(path);

					}

					// AST REWRITE
					// elements: path
					// token labels: path
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1858:35: -> ^( TOK_URI_TYPE $path)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1858:39: ^( TOK_URI_TYPE $path)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE"), root_1);
						adaptor.addChild(root_1, stream_path.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1859:7: KW_SERVER identifier
					{
					KW_SERVER612=(Token)match(input,KW_SERVER,FOLLOW_KW_SERVER_in_privObjectCols10421); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERVER.add(KW_SERVER612);

					pushFollow(FOLLOW_identifier_in_privObjectCols10423);
					identifier613=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier613.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1859:28: -> ^( TOK_SERVER_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1859:31: ^( TOK_SERVER_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privObjectCols"


	public static class privilegeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1862:1: privilegeList : privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) ;
	public final HiveParser.privilegeList_return privilegeList() throws RecognitionException {
		HiveParser.privilegeList_return retval = new HiveParser.privilegeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA615=null;
		ParserRuleReturnScope privlegeDef614 =null;
		ParserRuleReturnScope privlegeDef616 =null;

		ASTNode COMMA615_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_privlegeDef=new RewriteRuleSubtreeStream(adaptor,"rule privlegeDef");

		pushMsg("grant privilege list", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1865:5: ( privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1865:7: privlegeDef ( COMMA privlegeDef )*
			{
			pushFollow(FOLLOW_privlegeDef_in_privilegeList10458);
			privlegeDef614=privlegeDef();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privlegeDef.add(privlegeDef614.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1865:19: ( COMMA privlegeDef )*
			loop188:
			while (true) {
				int alt188=2;
				int LA188_0 = input.LA(1);
				if ( (LA188_0==COMMA) ) {
					alt188=1;
				}

				switch (alt188) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1865:20: COMMA privlegeDef
					{
					COMMA615=(Token)match(input,COMMA,FOLLOW_COMMA_in_privilegeList10461); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA615);

					pushFollow(FOLLOW_privlegeDef_in_privilegeList10463);
					privlegeDef616=privlegeDef();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privlegeDef.add(privlegeDef616.getTree());
					}
					break;

				default :
					break loop188;
				}
			}

			// AST REWRITE
			// elements: privlegeDef
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1866:5: -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1866:8: ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIVILEGE_LIST, "TOK_PRIVILEGE_LIST"), root_1);
				if ( !(stream_privlegeDef.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_privlegeDef.hasNext() ) {
					adaptor.addChild(root_1, stream_privlegeDef.nextTree());
				}
				stream_privlegeDef.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeList"


	public static class privlegeDef_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privlegeDef"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1869:1: privlegeDef : privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) ;
	public final HiveParser.privlegeDef_return privlegeDef() throws RecognitionException {
		HiveParser.privlegeDef_return retval = new HiveParser.privlegeDef_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN618=null;
		Token RPAREN619=null;
		ParserRuleReturnScope cols =null;
		ParserRuleReturnScope privilegeType617 =null;

		ASTNode LPAREN618_tree=null;
		ASTNode RPAREN619_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
		RewriteRuleSubtreeStream stream_privilegeType=new RewriteRuleSubtreeStream(adaptor,"rule privilegeType");

		pushMsg("grant privilege", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1872:5: ( privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1872:7: privilegeType ( LPAREN cols= columnNameList RPAREN )?
			{
			pushFollow(FOLLOW_privilegeType_in_privlegeDef10505);
			privilegeType617=privilegeType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privilegeType.add(privilegeType617.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1872:21: ( LPAREN cols= columnNameList RPAREN )?
			int alt189=2;
			int LA189_0 = input.LA(1);
			if ( (LA189_0==LPAREN) ) {
				alt189=1;
			}
			switch (alt189) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1872:22: LPAREN cols= columnNameList RPAREN
					{
					LPAREN618=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_privlegeDef10508); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN618);

					pushFollow(FOLLOW_columnNameList_in_privlegeDef10512);
					cols=columnNameList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameList.add(cols.getTree());
					RPAREN619=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_privlegeDef10514); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN619);

					}
					break;

			}

			// AST REWRITE
			// elements: privilegeType, cols
			// token labels: 
			// rule labels: cols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_cols=new RewriteRuleSubtreeStream(adaptor,"rule cols",cols!=null?cols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1873:5: -> ^( TOK_PRIVILEGE privilegeType ( $cols)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1873:8: ^( TOK_PRIVILEGE privilegeType ( $cols)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIVILEGE, "TOK_PRIVILEGE"), root_1);
				adaptor.addChild(root_1, stream_privilegeType.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1873:39: ( $cols)?
				if ( stream_cols.hasNext() ) {
					adaptor.addChild(root_1, stream_cols.nextTree());
				}
				stream_cols.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privlegeDef"


	public static class privilegeType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1876:1: privilegeType : ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) );
	public final HiveParser.privilegeType_return privilegeType() throws RecognitionException {
		HiveParser.privilegeType_return retval = new HiveParser.privilegeType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ALL620=null;
		Token KW_ALTER621=null;
		Token KW_UPDATE622=null;
		Token KW_CREATE623=null;
		Token KW_DROP624=null;
		Token KW_LOCK625=null;
		Token KW_SELECT626=null;
		Token KW_SHOW_DATABASE627=null;
		Token KW_INSERT628=null;
		Token KW_DELETE629=null;

		ASTNode KW_ALL620_tree=null;
		ASTNode KW_ALTER621_tree=null;
		ASTNode KW_UPDATE622_tree=null;
		ASTNode KW_CREATE623_tree=null;
		ASTNode KW_DROP624_tree=null;
		ASTNode KW_LOCK625_tree=null;
		ASTNode KW_SELECT626_tree=null;
		ASTNode KW_SHOW_DATABASE627_tree=null;
		ASTNode KW_INSERT628_tree=null;
		ASTNode KW_DELETE629_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
		RewriteRuleTokenStream stream_KW_SHOW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_SHOW_DATABASE");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_ALTER=new RewriteRuleTokenStream(adaptor,"token KW_ALTER");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
		RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
		RewriteRuleTokenStream stream_KW_SELECT=new RewriteRuleTokenStream(adaptor,"token KW_SELECT");
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");

		pushMsg("privilege type", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1879:5: ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) )
			int alt190=10;
			switch ( input.LA(1) ) {
			case KW_ALL:
				{
				alt190=1;
				}
				break;
			case KW_ALTER:
				{
				alt190=2;
				}
				break;
			case KW_UPDATE:
				{
				alt190=3;
				}
				break;
			case KW_CREATE:
				{
				alt190=4;
				}
				break;
			case KW_DROP:
				{
				alt190=5;
				}
				break;
			case KW_LOCK:
				{
				alt190=6;
				}
				break;
			case KW_SELECT:
				{
				alt190=7;
				}
				break;
			case KW_SHOW_DATABASE:
				{
				alt190=8;
				}
				break;
			case KW_INSERT:
				{
				alt190=9;
				}
				break;
			case KW_DELETE:
				{
				alt190=10;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 190, 0, input);
				throw nvae;
			}
			switch (alt190) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1879:7: KW_ALL
					{
					KW_ALL620=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_privilegeType10559); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL620);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1879:14: -> ^( TOK_PRIV_ALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1879:17: ^( TOK_PRIV_ALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_ALL, "TOK_PRIV_ALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1880:7: KW_ALTER
					{
					KW_ALTER621=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_privilegeType10573); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER621);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1880:16: -> ^( TOK_PRIV_ALTER_METADATA )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1880:19: ^( TOK_PRIV_ALTER_METADATA )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_ALTER_METADATA, "TOK_PRIV_ALTER_METADATA"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:7: KW_UPDATE
					{
					KW_UPDATE622=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_privilegeType10587); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE622);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1881:17: -> ^( TOK_PRIV_ALTER_DATA )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:20: ^( TOK_PRIV_ALTER_DATA )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_ALTER_DATA, "TOK_PRIV_ALTER_DATA"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:7: KW_CREATE
					{
					KW_CREATE623=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_privilegeType10601); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE623);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1882:17: -> ^( TOK_PRIV_CREATE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:20: ^( TOK_PRIV_CREATE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_CREATE, "TOK_PRIV_CREATE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:7: KW_DROP
					{
					KW_DROP624=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_privilegeType10615); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP624);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1883:15: -> ^( TOK_PRIV_DROP )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:18: ^( TOK_PRIV_DROP )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_DROP, "TOK_PRIV_DROP"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1884:7: KW_LOCK
					{
					KW_LOCK625=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_privilegeType10629); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK625);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1884:15: -> ^( TOK_PRIV_LOCK )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1884:18: ^( TOK_PRIV_LOCK )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_LOCK, "TOK_PRIV_LOCK"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:7: KW_SELECT
					{
					KW_SELECT626=(Token)match(input,KW_SELECT,FOLLOW_KW_SELECT_in_privilegeType10643); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SELECT.add(KW_SELECT626);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1885:17: -> ^( TOK_PRIV_SELECT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:20: ^( TOK_PRIV_SELECT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_SELECT, "TOK_PRIV_SELECT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1886:7: KW_SHOW_DATABASE
					{
					KW_SHOW_DATABASE627=(Token)match(input,KW_SHOW_DATABASE,FOLLOW_KW_SHOW_DATABASE_in_privilegeType10657); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW_DATABASE.add(KW_SHOW_DATABASE627);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1886:24: -> ^( TOK_PRIV_SHOW_DATABASE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1886:27: ^( TOK_PRIV_SHOW_DATABASE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_SHOW_DATABASE, "TOK_PRIV_SHOW_DATABASE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:7: KW_INSERT
					{
					KW_INSERT628=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_privilegeType10671); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT628);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1887:17: -> ^( TOK_PRIV_INSERT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:20: ^( TOK_PRIV_INSERT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_INSERT, "TOK_PRIV_INSERT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1888:7: KW_DELETE
					{
					KW_DELETE629=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_privilegeType10685); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE629);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1888:17: -> ^( TOK_PRIV_DELETE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1888:20: ^( TOK_PRIV_DELETE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_DELETE, "TOK_PRIV_DELETE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeType"


	public static class principalSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "principalSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1891:1: principalSpecification : principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) ;
	public final HiveParser.principalSpecification_return principalSpecification() throws RecognitionException {
		HiveParser.principalSpecification_return retval = new HiveParser.principalSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA631=null;
		ParserRuleReturnScope principalName630 =null;
		ParserRuleReturnScope principalName632 =null;

		ASTNode COMMA631_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		 pushMsg("user/group/role name list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1894:5: ( principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1894:7: principalName ( COMMA principalName )*
			{
			pushFollow(FOLLOW_principalName_in_principalSpecification10718);
			principalName630=principalName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalName.add(principalName630.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1894:21: ( COMMA principalName )*
			loop191:
			while (true) {
				int alt191=2;
				int LA191_0 = input.LA(1);
				if ( (LA191_0==COMMA) ) {
					alt191=1;
				}

				switch (alt191) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1894:22: COMMA principalName
					{
					COMMA631=(Token)match(input,COMMA,FOLLOW_COMMA_in_principalSpecification10721); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA631);

					pushFollow(FOLLOW_principalName_in_principalSpecification10723);
					principalName632=principalName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalName.add(principalName632.getTree());
					}
					break;

				default :
					break loop191;
				}
			}

			// AST REWRITE
			// elements: principalName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1894:44: -> ^( TOK_PRINCIPAL_NAME ( principalName )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1894:47: ^( TOK_PRINCIPAL_NAME ( principalName )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRINCIPAL_NAME, "TOK_PRINCIPAL_NAME"), root_1);
				if ( !(stream_principalName.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_principalName.hasNext() ) {
					adaptor.addChild(root_1, stream_principalName.nextTree());
				}
				stream_principalName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "principalSpecification"


	public static class principalName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "principalName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1897:1: principalName : ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) );
	public final HiveParser.principalName_return principalName() throws RecognitionException {
		HiveParser.principalName_return retval = new HiveParser.principalName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_USER633=null;
		Token KW_GROUP635=null;
		Token KW_ROLE637=null;
		ParserRuleReturnScope principalIdentifier634 =null;
		ParserRuleReturnScope principalIdentifier636 =null;
		ParserRuleReturnScope identifier638 =null;

		ASTNode KW_USER633_tree=null;
		ASTNode KW_GROUP635_tree=null;
		ASTNode KW_ROLE637_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_USER=new RewriteRuleTokenStream(adaptor,"token KW_USER");
		RewriteRuleTokenStream stream_KW_GROUP=new RewriteRuleTokenStream(adaptor,"token KW_GROUP");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_principalIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule principalIdentifier");

		pushMsg("user|group|role name", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1900:5: ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) )
			int alt192=3;
			switch ( input.LA(1) ) {
			case KW_USER:
				{
				alt192=1;
				}
				break;
			case KW_GROUP:
				{
				alt192=2;
				}
				break;
			case KW_ROLE:
				{
				alt192=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 192, 0, input);
				throw nvae;
			}
			switch (alt192) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1900:7: KW_USER principalIdentifier
					{
					KW_USER633=(Token)match(input,KW_USER,FOLLOW_KW_USER_in_principalName10761); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_USER.add(KW_USER633);

					pushFollow(FOLLOW_principalIdentifier_in_principalName10763);
					principalIdentifier634=principalIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalIdentifier.add(principalIdentifier634.getTree());
					// AST REWRITE
					// elements: principalIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1900:35: -> ^( TOK_USER principalIdentifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1900:38: ^( TOK_USER principalIdentifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_USER, "TOK_USER"), root_1);
						adaptor.addChild(root_1, stream_principalIdentifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1901:7: KW_GROUP principalIdentifier
					{
					KW_GROUP635=(Token)match(input,KW_GROUP,FOLLOW_KW_GROUP_in_principalName10779); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_GROUP.add(KW_GROUP635);

					pushFollow(FOLLOW_principalIdentifier_in_principalName10781);
					principalIdentifier636=principalIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalIdentifier.add(principalIdentifier636.getTree());
					// AST REWRITE
					// elements: principalIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1901:36: -> ^( TOK_GROUP principalIdentifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1901:39: ^( TOK_GROUP principalIdentifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GROUP, "TOK_GROUP"), root_1);
						adaptor.addChild(root_1, stream_principalIdentifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1902:7: KW_ROLE identifier
					{
					KW_ROLE637=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_principalName10797); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE637);

					pushFollow(FOLLOW_identifier_in_principalName10799);
					identifier638=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier638.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1902:26: -> ^( TOK_ROLE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1902:29: ^( TOK_ROLE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ROLE, "TOK_ROLE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "principalName"


	public static class withGrantOption_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "withGrantOption"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1905:1: withGrantOption : KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) ;
	public final HiveParser.withGrantOption_return withGrantOption() throws RecognitionException {
		HiveParser.withGrantOption_return retval = new HiveParser.withGrantOption_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WITH639=null;
		Token KW_GRANT640=null;
		Token KW_OPTION641=null;

		ASTNode KW_WITH639_tree=null;
		ASTNode KW_GRANT640_tree=null;
		ASTNode KW_OPTION641_tree=null;
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");

		pushMsg("with grant option", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:5: ( KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:7: KW_WITH KW_GRANT KW_OPTION
			{
			KW_WITH639=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withGrantOption10834); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH639);

			KW_GRANT640=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_withGrantOption10836); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT640);

			KW_OPTION641=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_withGrantOption10838); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION641);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1909:5: -> ^( TOK_GRANT_WITH_OPTION )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1909:8: ^( TOK_GRANT_WITH_OPTION )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_WITH_OPTION, "TOK_GRANT_WITH_OPTION"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "withGrantOption"


	public static class grantOptionFor_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "grantOptionFor"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1912:1: grantOptionFor : KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) ;
	public final HiveParser.grantOptionFor_return grantOptionFor() throws RecognitionException {
		HiveParser.grantOptionFor_return retval = new HiveParser.grantOptionFor_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_GRANT642=null;
		Token KW_OPTION643=null;
		Token KW_FOR644=null;

		ASTNode KW_GRANT642_tree=null;
		ASTNode KW_OPTION643_tree=null;
		ASTNode KW_FOR644_tree=null;
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");

		pushMsg("grant option for", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1915:5: ( KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1915:7: KW_GRANT KW_OPTION KW_FOR
			{
			KW_GRANT642=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantOptionFor10875); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT642);

			KW_OPTION643=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_grantOptionFor10877); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION643);

			KW_FOR644=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_grantOptionFor10879); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR644);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1916:5: -> ^( TOK_GRANT_OPTION_FOR )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1916:8: ^( TOK_GRANT_OPTION_FOR )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_OPTION_FOR, "TOK_GRANT_OPTION_FOR"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "grantOptionFor"


	public static class adminOptionFor_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "adminOptionFor"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:1: adminOptionFor : KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) ;
	public final HiveParser.adminOptionFor_return adminOptionFor() throws RecognitionException {
		HiveParser.adminOptionFor_return retval = new HiveParser.adminOptionFor_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ADMIN645=null;
		Token KW_OPTION646=null;
		Token KW_FOR647=null;

		ASTNode KW_ADMIN645_tree=null;
		ASTNode KW_OPTION646_tree=null;
		ASTNode KW_FOR647_tree=null;
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");
		RewriteRuleTokenStream stream_KW_ADMIN=new RewriteRuleTokenStream(adaptor,"token KW_ADMIN");

		pushMsg("admin option for", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1922:5: ( KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1922:7: KW_ADMIN KW_OPTION KW_FOR
			{
			KW_ADMIN645=(Token)match(input,KW_ADMIN,FOLLOW_KW_ADMIN_in_adminOptionFor10912); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ADMIN.add(KW_ADMIN645);

			KW_OPTION646=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_adminOptionFor10914); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION646);

			KW_FOR647=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_adminOptionFor10916); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR647);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1923:5: -> ^( TOK_ADMIN_OPTION_FOR )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1923:8: ^( TOK_ADMIN_OPTION_FOR )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ADMIN_OPTION_FOR, "TOK_ADMIN_OPTION_FOR"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "adminOptionFor"


	public static class withAdminOption_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "withAdminOption"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1926:1: withAdminOption : KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) ;
	public final HiveParser.withAdminOption_return withAdminOption() throws RecognitionException {
		HiveParser.withAdminOption_return retval = new HiveParser.withAdminOption_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WITH648=null;
		Token KW_ADMIN649=null;
		Token KW_OPTION650=null;

		ASTNode KW_WITH648_tree=null;
		ASTNode KW_ADMIN649_tree=null;
		ASTNode KW_OPTION650_tree=null;
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");
		RewriteRuleTokenStream stream_KW_ADMIN=new RewriteRuleTokenStream(adaptor,"token KW_ADMIN");

		pushMsg("with admin option", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1929:5: ( KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1929:7: KW_WITH KW_ADMIN KW_OPTION
			{
			KW_WITH648=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withAdminOption10949); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH648);

			KW_ADMIN649=(Token)match(input,KW_ADMIN,FOLLOW_KW_ADMIN_in_withAdminOption10951); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ADMIN.add(KW_ADMIN649);

			KW_OPTION650=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_withAdminOption10953); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION650);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1930:5: -> ^( TOK_GRANT_WITH_ADMIN_OPTION )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1930:8: ^( TOK_GRANT_WITH_ADMIN_OPTION )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_WITH_ADMIN_OPTION, "TOK_GRANT_WITH_ADMIN_OPTION"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "withAdminOption"


	public static class metastoreCheck_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "metastoreCheck"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1933:1: metastoreCheck : KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )? | ( partitionSpec )? ) -> ^( TOK_MSCK ( $repair)? ( tableName )? ( $add)? ( $drop)? ( $sync)? ( ( partitionSpec )* )? ) ;
	public final HiveParser.metastoreCheck_return metastoreCheck() throws RecognitionException {
		HiveParser.metastoreCheck_return retval = new HiveParser.metastoreCheck_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token repair=null;
		Token add=null;
		Token drop=null;
		Token sync=null;
		Token parts=null;
		Token KW_MSCK651=null;
		Token KW_TABLE652=null;
		ParserRuleReturnScope tableName653 =null;
		ParserRuleReturnScope partitionSpec654 =null;

		ASTNode repair_tree=null;
		ASTNode add_tree=null;
		ASTNode drop_tree=null;
		ASTNode sync_tree=null;
		ASTNode parts_tree=null;
		ASTNode KW_MSCK651_tree=null;
		ASTNode KW_TABLE652_tree=null;
		RewriteRuleTokenStream stream_KW_REPAIR=new RewriteRuleTokenStream(adaptor,"token KW_REPAIR");
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_SYNC=new RewriteRuleTokenStream(adaptor,"token KW_SYNC");
		RewriteRuleTokenStream stream_KW_MSCK=new RewriteRuleTokenStream(adaptor,"token KW_MSCK");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
		RewriteRuleTokenStream stream_KW_PARTITIONS=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONS");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("metastore check statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1936:5: ( KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )? | ( partitionSpec )? ) -> ^( TOK_MSCK ( $repair)? ( tableName )? ( $add)? ( $drop)? ( $sync)? ( ( partitionSpec )* )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1936:7: KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )? | ( partitionSpec )? )
			{
			KW_MSCK651=(Token)match(input,KW_MSCK,FOLLOW_KW_MSCK_in_metastoreCheck10990); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MSCK.add(KW_MSCK651);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1936:15: (repair= KW_REPAIR )?
			int alt193=2;
			int LA193_0 = input.LA(1);
			if ( (LA193_0==KW_REPAIR) ) {
				alt193=1;
			}
			switch (alt193) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1936:16: repair= KW_REPAIR
					{
					repair=(Token)match(input,KW_REPAIR,FOLLOW_KW_REPAIR_in_metastoreCheck10995); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REPAIR.add(repair);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1937:7: ( KW_TABLE tableName ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )? | ( partitionSpec )? )
			int alt197=2;
			int LA197_0 = input.LA(1);
			if ( (LA197_0==KW_TABLE) ) {
				alt197=1;
			}
			else if ( (LA197_0==EOF||LA197_0==KW_PARTITION) ) {
				alt197=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 197, 0, input);
				throw nvae;
			}

			switch (alt197) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1937:8: KW_TABLE tableName ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )?
					{
					KW_TABLE652=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_metastoreCheck11006); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE652);

					pushFollow(FOLLOW_tableName_in_metastoreCheck11008);
					tableName653=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName653.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:9: ( (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS ) )?
					int alt195=2;
					int LA195_0 = input.LA(1);
					if ( (LA195_0==KW_ADD||LA195_0==KW_DROP||LA195_0==KW_SYNC) ) {
						alt195=1;
					}
					switch (alt195) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:10: (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC ) (parts= KW_PARTITIONS )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:10: (add= KW_ADD |drop= KW_DROP |sync= KW_SYNC )
							int alt194=3;
							switch ( input.LA(1) ) {
							case KW_ADD:
								{
								alt194=1;
								}
								break;
							case KW_DROP:
								{
								alt194=2;
								}
								break;
							case KW_SYNC:
								{
								alt194=3;
								}
								break;
							default:
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 194, 0, input);
								throw nvae;
							}
							switch (alt194) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:11: add= KW_ADD
									{
									add=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_metastoreCheck11022); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_ADD.add(add);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:24: drop= KW_DROP
									{
									drop=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_metastoreCheck11028); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_DROP.add(drop);

									}
									break;
								case 3 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:39: sync= KW_SYNC
									{
									sync=(Token)match(input,KW_SYNC,FOLLOW_KW_SYNC_in_metastoreCheck11034); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_SYNC.add(sync);

									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:53: (parts= KW_PARTITIONS )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:54: parts= KW_PARTITIONS
							{
							parts=(Token)match(input,KW_PARTITIONS,FOLLOW_KW_PARTITIONS_in_metastoreCheck11040); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_PARTITIONS.add(parts);

							}

							}
							break;

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1939:9: ( partitionSpec )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1939:9: ( partitionSpec )?
					int alt196=2;
					int LA196_0 = input.LA(1);
					if ( (LA196_0==KW_PARTITION) ) {
						alt196=1;
					}
					switch (alt196) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1939:10: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_metastoreCheck11056);
							partitionSpec654=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec654.getTree());
							}
							break;

					}

					}
					break;

			}

			// AST REWRITE
			// elements: tableName, drop, sync, partitionSpec, repair, add
			// token labels: drop, add, repair, sync
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_drop=new RewriteRuleTokenStream(adaptor,"token drop",drop);
			RewriteRuleTokenStream stream_add=new RewriteRuleTokenStream(adaptor,"token add",add);
			RewriteRuleTokenStream stream_repair=new RewriteRuleTokenStream(adaptor,"token repair",repair);
			RewriteRuleTokenStream stream_sync=new RewriteRuleTokenStream(adaptor,"token sync",sync);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1940:5: -> ^( TOK_MSCK ( $repair)? ( tableName )? ( $add)? ( $drop)? ( $sync)? ( ( partitionSpec )* )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:8: ^( TOK_MSCK ( $repair)? ( tableName )? ( $add)? ( $drop)? ( $sync)? ( ( partitionSpec )* )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MSCK, "TOK_MSCK"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:20: ( $repair)?
				if ( stream_repair.hasNext() ) {
					adaptor.addChild(root_1, stream_repair.nextNode());
				}
				stream_repair.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:28: ( tableName )?
				if ( stream_tableName.hasNext() ) {
					adaptor.addChild(root_1, stream_tableName.nextTree());
				}
				stream_tableName.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:40: ( $add)?
				if ( stream_add.hasNext() ) {
					adaptor.addChild(root_1, stream_add.nextNode());
				}
				stream_add.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:46: ( $drop)?
				if ( stream_drop.hasNext() ) {
					adaptor.addChild(root_1, stream_drop.nextNode());
				}
				stream_drop.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:53: ( $sync)?
				if ( stream_sync.hasNext() ) {
					adaptor.addChild(root_1, stream_sync.nextNode());
				}
				stream_sync.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:59: ( ( partitionSpec )* )?
				if ( stream_partitionSpec.hasNext() ) {
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:60: ( partitionSpec )*
					while ( stream_partitionSpec.hasNext() ) {
						adaptor.addChild(root_1, stream_partitionSpec.nextTree());
					}
					stream_partitionSpec.reset();

				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "metastoreCheck"


	public static class resourceList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "resourceList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1943:1: resourceList : resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) ;
	public final HiveParser.resourceList_return resourceList() throws RecognitionException {
		HiveParser.resourceList_return retval = new HiveParser.resourceList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA656=null;
		ParserRuleReturnScope resource655 =null;
		ParserRuleReturnScope resource657 =null;

		ASTNode COMMA656_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_resource=new RewriteRuleSubtreeStream(adaptor,"rule resource");

		 pushMsg("resource list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1946:3: ( resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1947:3: resource ( COMMA resource )*
			{
			pushFollow(FOLLOW_resource_in_resourceList11121);
			resource655=resource();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_resource.add(resource655.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1947:12: ( COMMA resource )*
			loop198:
			while (true) {
				int alt198=2;
				int LA198_0 = input.LA(1);
				if ( (LA198_0==COMMA) ) {
					alt198=1;
				}

				switch (alt198) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1947:13: COMMA resource
					{
					COMMA656=(Token)match(input,COMMA,FOLLOW_COMMA_in_resourceList11124); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA656);

					pushFollow(FOLLOW_resource_in_resourceList11126);
					resource657=resource();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_resource.add(resource657.getTree());
					}
					break;

				default :
					break loop198;
				}
			}

			// AST REWRITE
			// elements: resource
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1947:30: -> ^( TOK_RESOURCE_LIST ( resource )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1947:33: ^( TOK_RESOURCE_LIST ( resource )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESOURCE_LIST, "TOK_RESOURCE_LIST"), root_1);
				if ( !(stream_resource.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_resource.hasNext() ) {
					adaptor.addChild(root_1, stream_resource.nextTree());
				}
				stream_resource.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "resourceList"


	public static class resource_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "resource"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1950:1: resource : resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) ;
	public final HiveParser.resource_return resource() throws RecognitionException {
		HiveParser.resource_return retval = new HiveParser.resource_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token resPath=null;
		ParserRuleReturnScope resType =null;

		ASTNode resPath_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleSubtreeStream stream_resourceType=new RewriteRuleSubtreeStream(adaptor,"rule resourceType");

		 pushMsg("resource", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1953:3: (resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1954:3: resType= resourceType resPath= StringLiteral
			{
			pushFollow(FOLLOW_resourceType_in_resource11164);
			resType=resourceType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_resourceType.add(resType.getTree());
			resPath=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_resource11168); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(resPath);

			// AST REWRITE
			// elements: resType, resPath
			// token labels: resPath
			// rule labels: resType, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_resPath=new RewriteRuleTokenStream(adaptor,"token resPath",resPath);
			RewriteRuleSubtreeStream stream_resType=new RewriteRuleSubtreeStream(adaptor,"rule resType",resType!=null?resType.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1954:46: -> ^( TOK_RESOURCE_URI $resType $resPath)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1954:49: ^( TOK_RESOURCE_URI $resType $resPath)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESOURCE_URI, "TOK_RESOURCE_URI"), root_1);
				adaptor.addChild(root_1, stream_resType.nextTree());
				adaptor.addChild(root_1, stream_resPath.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "resource"


	public static class resourceType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "resourceType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1957:1: resourceType : ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) );
	public final HiveParser.resourceType_return resourceType() throws RecognitionException {
		HiveParser.resourceType_return retval = new HiveParser.resourceType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_JAR658=null;
		Token KW_FILE659=null;
		Token KW_ARCHIVE660=null;

		ASTNode KW_JAR658_tree=null;
		ASTNode KW_FILE659_tree=null;
		ASTNode KW_ARCHIVE660_tree=null;
		RewriteRuleTokenStream stream_KW_ARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_ARCHIVE");
		RewriteRuleTokenStream stream_KW_JAR=new RewriteRuleTokenStream(adaptor,"token KW_JAR");
		RewriteRuleTokenStream stream_KW_FILE=new RewriteRuleTokenStream(adaptor,"token KW_FILE");

		 pushMsg("resource type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1960:3: ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) )
			int alt199=3;
			switch ( input.LA(1) ) {
			case KW_JAR:
				{
				alt199=1;
				}
				break;
			case KW_FILE:
				{
				alt199=2;
				}
				break;
			case KW_ARCHIVE:
				{
				alt199=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 199, 0, input);
				throw nvae;
			}
			switch (alt199) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1961:3: KW_JAR
					{
					KW_JAR658=(Token)match(input,KW_JAR,FOLLOW_KW_JAR_in_resourceType11205); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_JAR.add(KW_JAR658);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1961:10: -> ^( TOK_JAR )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1961:13: ^( TOK_JAR )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_JAR, "TOK_JAR"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:3: KW_FILE
					{
					KW_FILE659=(Token)match(input,KW_FILE,FOLLOW_KW_FILE_in_resourceType11219); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FILE.add(KW_FILE659);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1963:11: -> ^( TOK_FILE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:14: ^( TOK_FILE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FILE, "TOK_FILE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1965:3: KW_ARCHIVE
					{
					KW_ARCHIVE660=(Token)match(input,KW_ARCHIVE,FOLLOW_KW_ARCHIVE_in_resourceType11233); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ARCHIVE.add(KW_ARCHIVE660);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1965:14: -> ^( TOK_ARCHIVE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1965:17: ^( TOK_ARCHIVE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ARCHIVE, "TOK_ARCHIVE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "resourceType"


	public static class createFunctionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createFunctionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1968:1: createFunctionStatement : KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) ;
	public final HiveParser.createFunctionStatement_return createFunctionStatement() throws RecognitionException {
		HiveParser.createFunctionStatement_return retval = new HiveParser.createFunctionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token temp=null;
		Token KW_CREATE661=null;
		Token KW_FUNCTION662=null;
		Token KW_AS664=null;
		Token StringLiteral665=null;
		Token KW_USING666=null;
		ParserRuleReturnScope rList =null;
		ParserRuleReturnScope functionIdentifier663 =null;

		ASTNode temp_tree=null;
		ASTNode KW_CREATE661_tree=null;
		ASTNode KW_FUNCTION662_tree=null;
		ASTNode KW_AS664_tree=null;
		ASTNode StringLiteral665_tree=null;
		ASTNode KW_USING666_tree=null;
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_USING=new RewriteRuleTokenStream(adaptor,"token KW_USING");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_functionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule functionIdentifier");
		RewriteRuleSubtreeStream stream_resourceList=new RewriteRuleSubtreeStream(adaptor,"rule resourceList");

		 pushMsg("create function statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1971:5: ( KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1971:7: KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )?
			{
			KW_CREATE661=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createFunctionStatement11264); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE661);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1971:17: (temp= KW_TEMPORARY )?
			int alt200=2;
			int LA200_0 = input.LA(1);
			if ( (LA200_0==KW_TEMPORARY) ) {
				alt200=1;
			}
			switch (alt200) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1971:18: temp= KW_TEMPORARY
					{
					temp=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createFunctionStatement11269); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(temp);

					}
					break;

			}

			KW_FUNCTION662=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_createFunctionStatement11273); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION662);

			pushFollow(FOLLOW_functionIdentifier_in_createFunctionStatement11275);
			functionIdentifier663=functionIdentifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_functionIdentifier.add(functionIdentifier663.getTree());
			KW_AS664=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createFunctionStatement11277); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS664);

			StringLiteral665=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_createFunctionStatement11279); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral665);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1972:7: ( KW_USING rList= resourceList )?
			int alt201=2;
			int LA201_0 = input.LA(1);
			if ( (LA201_0==KW_USING) ) {
				alt201=1;
			}
			switch (alt201) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1972:8: KW_USING rList= resourceList
					{
					KW_USING666=(Token)match(input,KW_USING,FOLLOW_KW_USING_in_createFunctionStatement11288); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_USING.add(KW_USING666);

					pushFollow(FOLLOW_resourceList_in_createFunctionStatement11292);
					rList=resourceList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_resourceList.add(rList.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: functionIdentifier, StringLiteral, rList, StringLiteral, rList, functionIdentifier
			// token labels: 
			// rule labels: rList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_rList=new RewriteRuleSubtreeStream(adaptor,"rule rList",rList!=null?rList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1973:5: -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
			if (temp != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1973:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				adaptor.addChild(root_1, stream_StringLiteral.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1973:80: ( $rList)?
				if ( stream_rList.hasNext() ) {
					adaptor.addChild(root_1, stream_rList.nextTree());
				}
				stream_rList.reset();

				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY"));
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1974:5: -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1974:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				adaptor.addChild(root_1, stream_StringLiteral.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1974:80: ( $rList)?
				if ( stream_rList.hasNext() ) {
					adaptor.addChild(root_1, stream_rList.nextTree());
				}
				stream_rList.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createFunctionStatement"


	public static class dropFunctionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropFunctionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1977:1: dropFunctionStatement : KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) ;
	public final HiveParser.dropFunctionStatement_return dropFunctionStatement() throws RecognitionException {
		HiveParser.dropFunctionStatement_return retval = new HiveParser.dropFunctionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token temp=null;
		Token KW_DROP667=null;
		Token KW_FUNCTION668=null;
		ParserRuleReturnScope ifExists669 =null;
		ParserRuleReturnScope functionIdentifier670 =null;

		ASTNode temp_tree=null;
		ASTNode KW_DROP667_tree=null;
		ASTNode KW_FUNCTION668_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
		RewriteRuleSubtreeStream stream_functionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule functionIdentifier");

		 pushMsg("drop function statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1980:5: ( KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1980:7: KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier
			{
			KW_DROP667=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropFunctionStatement11378); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP667);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1980:15: (temp= KW_TEMPORARY )?
			int alt202=2;
			int LA202_0 = input.LA(1);
			if ( (LA202_0==KW_TEMPORARY) ) {
				alt202=1;
			}
			switch (alt202) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1980:16: temp= KW_TEMPORARY
					{
					temp=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_dropFunctionStatement11383); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(temp);

					}
					break;

			}

			KW_FUNCTION668=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_dropFunctionStatement11387); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION668);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1980:48: ( ifExists )?
			int alt203=2;
			int LA203_0 = input.LA(1);
			if ( (LA203_0==KW_IF) ) {
				alt203=1;
			}
			switch (alt203) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1980:48: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropFunctionStatement11389);
					ifExists669=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists669.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_functionIdentifier_in_dropFunctionStatement11392);
			functionIdentifier670=functionIdentifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_functionIdentifier.add(functionIdentifier670.getTree());
			// AST REWRITE
			// elements: functionIdentifier, ifExists, ifExists, functionIdentifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1981:5: -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
			if (temp != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1981:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1981:63: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY"));
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1982:5: -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1982:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1982:63: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropFunctionStatement"


	public static class reloadFunctionsStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "reloadFunctionsStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1985:1: reloadFunctionsStatement : KW_RELOAD ( KW_FUNCTIONS | KW_FUNCTION ) -> ^( TOK_RELOADFUNCTIONS ) ;
	public final HiveParser.reloadFunctionsStatement_return reloadFunctionsStatement() throws RecognitionException {
		HiveParser.reloadFunctionsStatement_return retval = new HiveParser.reloadFunctionsStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RELOAD671=null;
		Token KW_FUNCTIONS672=null;
		Token KW_FUNCTION673=null;

		ASTNode KW_RELOAD671_tree=null;
		ASTNode KW_FUNCTIONS672_tree=null;
		ASTNode KW_FUNCTION673_tree=null;
		RewriteRuleTokenStream stream_KW_FUNCTIONS=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTIONS");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleTokenStream stream_KW_RELOAD=new RewriteRuleTokenStream(adaptor,"token KW_RELOAD");

		 pushMsg("reload functions statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1988:5: ( KW_RELOAD ( KW_FUNCTIONS | KW_FUNCTION ) -> ^( TOK_RELOADFUNCTIONS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1988:7: KW_RELOAD ( KW_FUNCTIONS | KW_FUNCTION )
			{
			KW_RELOAD671=(Token)match(input,KW_RELOAD,FOLLOW_KW_RELOAD_in_reloadFunctionsStatement11470); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_RELOAD.add(KW_RELOAD671);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1988:17: ( KW_FUNCTIONS | KW_FUNCTION )
			int alt204=2;
			int LA204_0 = input.LA(1);
			if ( (LA204_0==KW_FUNCTIONS) ) {
				alt204=1;
			}
			else if ( (LA204_0==KW_FUNCTION) ) {
				alt204=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 204, 0, input);
				throw nvae;
			}

			switch (alt204) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1988:18: KW_FUNCTIONS
					{
					KW_FUNCTIONS672=(Token)match(input,KW_FUNCTIONS,FOLLOW_KW_FUNCTIONS_in_reloadFunctionsStatement11473); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTIONS.add(KW_FUNCTIONS672);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1988:31: KW_FUNCTION
					{
					KW_FUNCTION673=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_reloadFunctionsStatement11475); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION673);

					}
					break;

			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1988:44: -> ^( TOK_RELOADFUNCTIONS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1988:47: ^( TOK_RELOADFUNCTIONS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RELOADFUNCTIONS, "TOK_RELOADFUNCTIONS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "reloadFunctionsStatement"


	public static class createMacroStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createMacroStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1990:1: createMacroStatement : KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) ;
	public final HiveParser.createMacroStatement_return createMacroStatement() throws RecognitionException {
		HiveParser.createMacroStatement_return retval = new HiveParser.createMacroStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE674=null;
		Token KW_TEMPORARY675=null;
		Token KW_MACRO676=null;
		Token Identifier677=null;
		Token LPAREN678=null;
		Token RPAREN680=null;
		ParserRuleReturnScope columnNameTypeList679 =null;
		ParserRuleReturnScope expression681 =null;

		ASTNode KW_CREATE674_tree=null;
		ASTNode KW_TEMPORARY675_tree=null;
		ASTNode KW_MACRO676_tree=null;
		ASTNode Identifier677_tree=null;
		ASTNode LPAREN678_tree=null;
		ASTNode RPAREN680_tree=null;
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_MACRO=new RewriteRuleTokenStream(adaptor,"token KW_MACRO");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");

		 pushMsg("create macro statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1993:5: ( KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1993:7: KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression
			{
			KW_CREATE674=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createMacroStatement11504); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE674);

			KW_TEMPORARY675=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createMacroStatement11506); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(KW_TEMPORARY675);

			KW_MACRO676=(Token)match(input,KW_MACRO,FOLLOW_KW_MACRO_in_createMacroStatement11508); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MACRO.add(KW_MACRO676);

			Identifier677=(Token)match(input,Identifier,FOLLOW_Identifier_in_createMacroStatement11510); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Identifier.add(Identifier677);

			LPAREN678=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createMacroStatement11518); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN678);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1994:14: ( columnNameTypeList )?
			int alt205=2;
			int LA205_0 = input.LA(1);
			if ( (LA205_0==Identifier||(LA205_0 >= KW_ABORT && LA205_0 <= KW_AFTER)||LA205_0==KW_ALLOC_FRACTION||LA205_0==KW_ANALYZE||LA205_0==KW_ARCHIVE||(LA205_0 >= KW_ASC && LA205_0 <= KW_AT)||(LA205_0 >= KW_AUTOCOMMIT && LA205_0 <= KW_BEFORE)||(LA205_0 >= KW_BUCKET && LA205_0 <= KW_BUCKETS)||(LA205_0 >= KW_CACHE && LA205_0 <= KW_CASCADE)||(LA205_0 >= KW_CBO && LA205_0 <= KW_CHANGE)||(LA205_0 >= KW_CHECK && LA205_0 <= KW_COLLECTION)||(LA205_0 >= KW_COLUMNS && LA205_0 <= KW_COMMENT)||(LA205_0 >= KW_COMPACT && LA205_0 <= KW_CONCATENATE)||(LA205_0 >= KW_CONTINUE && LA205_0 <= KW_COST)||LA205_0==KW_CRON||LA205_0==KW_DATA||LA205_0==KW_DATABASES||(LA205_0 >= KW_DATETIME && LA205_0 <= KW_DEBUG)||(LA205_0 >= KW_DEFAULT && LA205_0 <= KW_DEFINED)||(LA205_0 >= KW_DELIMITED && LA205_0 <= KW_DESC)||(LA205_0 >= KW_DETAIL && LA205_0 <= KW_DISABLE)||(LA205_0 >= KW_DISTRIBUTE && LA205_0 <= KW_DO)||LA205_0==KW_DOW||(LA205_0 >= KW_DUMP && LA205_0 <= KW_ELEM_TYPE)||LA205_0==KW_ENABLE||(LA205_0 >= KW_ENFORCED && LA205_0 <= KW_EVERY)||(LA205_0 >= KW_EXCLUSIVE && LA205_0 <= KW_EXECUTED)||(LA205_0 >= KW_EXPLAIN && LA205_0 <= KW_EXPRESSION)||(LA205_0 >= KW_FIELDS && LA205_0 <= KW_FIRST)||(LA205_0 >= KW_FORMAT && LA205_0 <= KW_FORMATTED)||LA205_0==KW_FUNCTIONS||(LA205_0 >= KW_HOUR && LA205_0 <= KW_IDXPROPERTIES)||(LA205_0 >= KW_INDEX && LA205_0 <= KW_INDEXES)||(LA205_0 >= KW_INPATH && LA205_0 <= KW_INPUTFORMAT)||(LA205_0 >= KW_ISOLATION && LA205_0 <= KW_JAR)||(LA205_0 >= KW_JOINCOST && LA205_0 <= KW_LAST)||LA205_0==KW_LEVEL||(LA205_0 >= KW_LIMIT && LA205_0 <= KW_LOAD)||(LA205_0 >= KW_LOCATION && LA205_0 <= KW_LONG)||(LA205_0 >= KW_MANAGEDLOCATION && LA205_0 <= KW_MANAGEMENT)||(LA205_0 >= KW_MAPJOIN && LA205_0 <= KW_MATERIALIZED)||LA205_0==KW_METADATA||(LA205_0 >= KW_MINUTE && LA205_0 <= KW_MONTH)||(LA205_0 >= KW_MOVE && LA205_0 <= KW_MSCK)||(LA205_0 >= KW_NORELY && LA205_0 <= KW_NOSCAN)||LA205_0==KW_NOVALIDATE||LA205_0==KW_NULLS||LA205_0==KW_OFFSET||(LA205_0 >= KW_OPERATOR && LA205_0 <= KW_OPTION)||(LA205_0 >= KW_OUTPUTDRIVER && LA205_0 <= KW_OUTPUTFORMAT)||(LA205_0 >= KW_OVERWRITE && LA205_0 <= KW_OWNER)||(LA205_0 >= KW_PARTITIONED && LA205_0 <= KW_PATH)||(LA205_0 >= KW_PLAN && LA205_0 <= KW_POOL)||LA205_0==KW_PRINCIPALS||(LA205_0 >= KW_PURGE && LA205_0 <= KW_QUERY_PARALLELISM)||LA205_0==KW_READ||(LA205_0 >= KW_REBUILD && LA205_0 <= KW_RECORDWRITER)||(LA205_0 >= KW_RELOAD && LA205_0 <= KW_RESTRICT)||LA205_0==KW_REWRITE||(LA205_0 >= KW_ROLE && LA205_0 <= KW_ROLES)||(LA205_0 >= KW_SCHEDULED && LA205_0 <= KW_SECOND)||(LA205_0 >= KW_SEMI && LA205_0 <= KW_SERVER)||(LA205_0 >= KW_SETS && LA205_0 <= KW_SKEWED)||(LA205_0 >= KW_SNAPSHOT && LA205_0 <= KW_SSL)||(LA205_0 >= KW_STATISTICS && LA205_0 <= KW_SUMMARY)||LA205_0==KW_TABLES||(LA205_0 >= KW_TBLPROPERTIES && LA205_0 <= KW_TERMINATED)||LA205_0==KW_TINYINT||(LA205_0 >= KW_TOUCH && LA205_0 <= KW_TRANSACTIONS)||LA205_0==KW_UNARCHIVE||LA205_0==KW_UNDO||LA205_0==KW_UNIONTYPE||(LA205_0 >= KW_UNLOCK && LA205_0 <= KW_UNSIGNED)||(LA205_0 >= KW_URI && LA205_0 <= KW_USE)||(LA205_0 >= KW_UTC && LA205_0 <= KW_VALIDATE)||LA205_0==KW_VALUE_TYPE||(LA205_0 >= KW_VECTORIZATION && LA205_0 <= KW_WEEK)||LA205_0==KW_WHILE||(LA205_0 >= KW_WORK && LA205_0 <= KW_ZONE)||LA205_0==KW_BATCH||LA205_0==KW_DAYOFWEEK||LA205_0==KW_HOLD_DDLTIME||LA205_0==KW_IGNORE||LA205_0==KW_NO_DROP||LA205_0==KW_OFFLINE||LA205_0==KW_PROTECTION||LA205_0==KW_READONLY||LA205_0==KW_TIMESTAMPTZ) ) {
				alt205=1;
			}
			switch (alt205) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1994:14: columnNameTypeList
					{
					pushFollow(FOLLOW_columnNameTypeList_in_createMacroStatement11520);
					columnNameTypeList679=columnNameTypeList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameTypeList.add(columnNameTypeList679.getTree());
					}
					break;

			}

			RPAREN680=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createMacroStatement11523); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN680);

			pushFollow(FOLLOW_expression_in_createMacroStatement11525);
			expression681=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression681.getTree());
			// AST REWRITE
			// elements: Identifier, columnNameTypeList, expression
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1995:5: -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1995:8: ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEMACRO, "TOK_CREATEMACRO"), root_1);
				adaptor.addChild(root_1, stream_Identifier.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1995:37: ( columnNameTypeList )?
				if ( stream_columnNameTypeList.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());
				}
				stream_columnNameTypeList.reset();

				adaptor.addChild(root_1, stream_expression.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createMacroStatement"


	public static class dropMacroStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropMacroStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1998:1: dropMacroStatement : KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) ;
	public final HiveParser.dropMacroStatement_return dropMacroStatement() throws RecognitionException {
		HiveParser.dropMacroStatement_return retval = new HiveParser.dropMacroStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP682=null;
		Token KW_TEMPORARY683=null;
		Token KW_MACRO684=null;
		Token Identifier686=null;
		ParserRuleReturnScope ifExists685 =null;

		ASTNode KW_DROP682_tree=null;
		ASTNode KW_TEMPORARY683_tree=null;
		ASTNode KW_MACRO684_tree=null;
		ASTNode Identifier686_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
		RewriteRuleTokenStream stream_KW_MACRO=new RewriteRuleTokenStream(adaptor,"token KW_MACRO");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("drop macro statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2001:5: ( KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2001:7: KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier
			{
			KW_DROP682=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropMacroStatement11569); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP682);

			KW_TEMPORARY683=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_dropMacroStatement11571); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(KW_TEMPORARY683);

			KW_MACRO684=(Token)match(input,KW_MACRO,FOLLOW_KW_MACRO_in_dropMacroStatement11573); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MACRO.add(KW_MACRO684);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2001:37: ( ifExists )?
			int alt206=2;
			int LA206_0 = input.LA(1);
			if ( (LA206_0==KW_IF) ) {
				alt206=1;
			}
			switch (alt206) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2001:37: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropMacroStatement11575);
					ifExists685=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists685.getTree());
					}
					break;

			}

			Identifier686=(Token)match(input,Identifier,FOLLOW_Identifier_in_dropMacroStatement11578); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Identifier.add(Identifier686);

			// AST REWRITE
			// elements: Identifier, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2002:5: -> ^( TOK_DROPMACRO Identifier ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2002:8: ^( TOK_DROPMACRO Identifier ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPMACRO, "TOK_DROPMACRO"), root_1);
				adaptor.addChild(root_1, stream_Identifier.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2002:35: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropMacroStatement"


	public static class createViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2005:1: createViewStatement : KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) ;
	public final HiveParser.createViewStatement_return createViewStatement() throws RecognitionException {
		HiveParser.createViewStatement_return retval = new HiveParser.createViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE687=null;
		Token KW_VIEW689=null;
		Token LPAREN691=null;
		Token RPAREN693=null;
		Token KW_AS697=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope orReplace688 =null;
		ParserRuleReturnScope ifNotExists690 =null;
		ParserRuleReturnScope columnNameCommentList692 =null;
		ParserRuleReturnScope tableComment694 =null;
		ParserRuleReturnScope viewPartition695 =null;
		ParserRuleReturnScope tablePropertiesPrefixed696 =null;
		ParserRuleReturnScope selectStatementWithCTE698 =null;

		ASTNode KW_CREATE687_tree=null;
		ASTNode KW_VIEW689_tree=null;
		ASTNode LPAREN691_tree=null;
		ASTNode RPAREN693_tree=null;
		ASTNode KW_AS697_tree=null;
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_columnNameCommentList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameCommentList");
		RewriteRuleSubtreeStream stream_selectStatementWithCTE=new RewriteRuleSubtreeStream(adaptor,"rule selectStatementWithCTE");
		RewriteRuleSubtreeStream stream_orReplace=new RewriteRuleSubtreeStream(adaptor,"rule orReplace");
		RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
		RewriteRuleSubtreeStream stream_viewPartition=new RewriteRuleSubtreeStream(adaptor,"rule viewPartition");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");


		    pushMsg("create view statement", state);

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2010:5: ( KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2010:7: KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE
			{
			KW_CREATE687=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createViewStatement11620); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE687);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2010:17: ( orReplace )?
			int alt207=2;
			int LA207_0 = input.LA(1);
			if ( (LA207_0==KW_OR) ) {
				alt207=1;
			}
			switch (alt207) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2010:18: orReplace
					{
					pushFollow(FOLLOW_orReplace_in_createViewStatement11623);
					orReplace688=orReplace();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orReplace.add(orReplace688.getTree());
					}
					break;

			}

			KW_VIEW689=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_createViewStatement11627); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW689);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2010:38: ( ifNotExists )?
			int alt208=2;
			int LA208_0 = input.LA(1);
			if ( (LA208_0==KW_IF) ) {
				alt208=1;
			}
			switch (alt208) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2010:39: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_createViewStatement11630);
					ifNotExists690=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists690.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableName_in_createViewStatement11636);
			name=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(name.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2011:9: ( LPAREN columnNameCommentList RPAREN )?
			int alt209=2;
			int LA209_0 = input.LA(1);
			if ( (LA209_0==LPAREN) ) {
				alt209=1;
			}
			switch (alt209) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2011:10: LPAREN columnNameCommentList RPAREN
					{
					LPAREN691=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createViewStatement11647); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN691);

					pushFollow(FOLLOW_columnNameCommentList_in_createViewStatement11649);
					columnNameCommentList692=columnNameCommentList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameCommentList.add(columnNameCommentList692.getTree());
					RPAREN693=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createViewStatement11651); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN693);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2011:48: ( tableComment )?
			int alt210=2;
			int LA210_0 = input.LA(1);
			if ( (LA210_0==KW_COMMENT) ) {
				alt210=1;
			}
			switch (alt210) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2011:48: tableComment
					{
					pushFollow(FOLLOW_tableComment_in_createViewStatement11655);
					tableComment694=tableComment();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableComment.add(tableComment694.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2011:62: ( viewPartition )?
			int alt211=2;
			int LA211_0 = input.LA(1);
			if ( (LA211_0==KW_PARTITIONED) ) {
				alt211=1;
			}
			switch (alt211) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2011:62: viewPartition
					{
					pushFollow(FOLLOW_viewPartition_in_createViewStatement11658);
					viewPartition695=viewPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_viewPartition.add(viewPartition695.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2012:9: ( tablePropertiesPrefixed )?
			int alt212=2;
			int LA212_0 = input.LA(1);
			if ( (LA212_0==KW_TBLPROPERTIES) ) {
				alt212=1;
			}
			switch (alt212) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2012:9: tablePropertiesPrefixed
					{
					pushFollow(FOLLOW_tablePropertiesPrefixed_in_createViewStatement11669);
					tablePropertiesPrefixed696=tablePropertiesPrefixed();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed696.getTree());
					}
					break;

			}

			KW_AS697=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createViewStatement11680); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS697);

			pushFollow(FOLLOW_selectStatementWithCTE_in_createViewStatement11690);
			selectStatementWithCTE698=selectStatementWithCTE();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_selectStatementWithCTE.add(selectStatementWithCTE698.getTree());
			// AST REWRITE
			// elements: name, tableComment, selectStatementWithCTE, orReplace, ifNotExists, columnNameCommentList, viewPartition, tablePropertiesPrefixed
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2015:5: -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2015:8: ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEVIEW, "TOK_CREATEVIEW"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2015:31: ( orReplace )?
				if ( stream_orReplace.hasNext() ) {
					adaptor.addChild(root_1, stream_orReplace.nextTree());
				}
				stream_orReplace.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2016:10: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2017:10: ( columnNameCommentList )?
				if ( stream_columnNameCommentList.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameCommentList.nextTree());
				}
				stream_columnNameCommentList.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2018:10: ( tableComment )?
				if ( stream_tableComment.hasNext() ) {
					adaptor.addChild(root_1, stream_tableComment.nextTree());
				}
				stream_tableComment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2019:10: ( viewPartition )?
				if ( stream_viewPartition.hasNext() ) {
					adaptor.addChild(root_1, stream_viewPartition.nextTree());
				}
				stream_viewPartition.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2020:10: ( tablePropertiesPrefixed )?
				if ( stream_tablePropertiesPrefixed.hasNext() ) {
					adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
				}
				stream_tablePropertiesPrefixed.reset();

				adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createViewStatement"


	public static class viewPartition_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewPartition"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2025:1: viewPartition : KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) ;
	public final HiveParser.viewPartition_return viewPartition() throws RecognitionException {
		HiveParser.viewPartition_return retval = new HiveParser.viewPartition_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_PARTITIONED699=null;
		Token KW_ON700=null;
		Token LPAREN701=null;
		Token RPAREN703=null;
		ParserRuleReturnScope columnNameList702 =null;

		ASTNode KW_PARTITIONED699_tree=null;
		ASTNode KW_ON700_tree=null;
		ASTNode LPAREN701_tree=null;
		ASTNode RPAREN703_tree=null;
		RewriteRuleTokenStream stream_KW_PARTITIONED=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONED");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2028:5: ( KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2028:7: KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN
			{
			KW_PARTITIONED699=(Token)match(input,KW_PARTITIONED,FOLLOW_KW_PARTITIONED_in_viewPartition11813); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_PARTITIONED.add(KW_PARTITIONED699);

			KW_ON700=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewPartition11815); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON700);

			LPAREN701=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewPartition11817); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN701);

			pushFollow(FOLLOW_columnNameList_in_viewPartition11819);
			columnNameList702=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(columnNameList702.getTree());
			RPAREN703=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewPartition11821); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN703);

			// AST REWRITE
			// elements: columnNameList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2029:5: -> ^( TOK_VIEWPARTCOLS columnNameList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2029:8: ^( TOK_VIEWPARTCOLS columnNameList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWPARTCOLS, "TOK_VIEWPARTCOLS"), root_1);
				adaptor.addChild(root_1, stream_columnNameList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewPartition"


	public static class viewOrganization_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewOrganization"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2032:1: viewOrganization : ( viewClusterSpec | viewComplexSpec );
	public final HiveParser.viewOrganization_return viewOrganization() throws RecognitionException {
		HiveParser.viewOrganization_return retval = new HiveParser.viewOrganization_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope viewClusterSpec704 =null;
		ParserRuleReturnScope viewComplexSpec705 =null;


		 pushMsg("view organization specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2035:5: ( viewClusterSpec | viewComplexSpec )
			int alt213=2;
			int LA213_0 = input.LA(1);
			if ( (LA213_0==KW_CLUSTERED) ) {
				alt213=1;
			}
			else if ( (LA213_0==KW_DISTRIBUTED) ) {
				alt213=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 213, 0, input);
				throw nvae;
			}

			switch (alt213) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2035:7: viewClusterSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_viewClusterSpec_in_viewOrganization11860);
					viewClusterSpec704=viewClusterSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, viewClusterSpec704.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2036:7: viewComplexSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_viewComplexSpec_in_viewOrganization11868);
					viewComplexSpec705=viewComplexSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, viewComplexSpec705.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewOrganization"


	public static class viewClusterSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewClusterSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2039:1: viewClusterSpec : KW_CLUSTERED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWCLUSTERCOLS columnNameList ) ;
	public final HiveParser.viewClusterSpec_return viewClusterSpec() throws RecognitionException {
		HiveParser.viewClusterSpec_return retval = new HiveParser.viewClusterSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CLUSTERED706=null;
		Token KW_ON707=null;
		Token LPAREN708=null;
		Token RPAREN710=null;
		ParserRuleReturnScope columnNameList709 =null;

		ASTNode KW_CLUSTERED706_tree=null;
		ASTNode KW_ON707_tree=null;
		ASTNode LPAREN708_tree=null;
		ASTNode RPAREN710_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view cluster specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2042:5: ( KW_CLUSTERED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWCLUSTERCOLS columnNameList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2042:7: KW_CLUSTERED KW_ON LPAREN columnNameList RPAREN
			{
			KW_CLUSTERED706=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_viewClusterSpec11895); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CLUSTERED.add(KW_CLUSTERED706);

			KW_ON707=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewClusterSpec11897); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON707);

			LPAREN708=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewClusterSpec11899); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN708);

			pushFollow(FOLLOW_columnNameList_in_viewClusterSpec11901);
			columnNameList709=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(columnNameList709.getTree());
			RPAREN710=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewClusterSpec11903); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN710);

			// AST REWRITE
			// elements: columnNameList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2043:5: -> ^( TOK_VIEWCLUSTERCOLS columnNameList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:8: ^( TOK_VIEWCLUSTERCOLS columnNameList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWCLUSTERCOLS, "TOK_VIEWCLUSTERCOLS"), root_1);
				adaptor.addChild(root_1, stream_columnNameList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewClusterSpec"


	public static class viewComplexSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewComplexSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2046:1: viewComplexSpec : viewDistSpec viewSortSpec ;
	public final HiveParser.viewComplexSpec_return viewComplexSpec() throws RecognitionException {
		HiveParser.viewComplexSpec_return retval = new HiveParser.viewComplexSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope viewDistSpec711 =null;
		ParserRuleReturnScope viewSortSpec712 =null;


		 pushMsg("view complex specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2049:5: ( viewDistSpec viewSortSpec )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2049:7: viewDistSpec viewSortSpec
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_viewDistSpec_in_viewComplexSpec11942);
			viewDistSpec711=viewDistSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, viewDistSpec711.getTree());

			pushFollow(FOLLOW_viewSortSpec_in_viewComplexSpec11944);
			viewSortSpec712=viewSortSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, viewSortSpec712.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewComplexSpec"


	public static class viewDistSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewDistSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2052:1: viewDistSpec : KW_DISTRIBUTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWDISTRIBUTECOLS $colList) ;
	public final HiveParser.viewDistSpec_return viewDistSpec() throws RecognitionException {
		HiveParser.viewDistSpec_return retval = new HiveParser.viewDistSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DISTRIBUTED713=null;
		Token KW_ON714=null;
		Token LPAREN715=null;
		Token RPAREN716=null;
		ParserRuleReturnScope colList =null;

		ASTNode KW_DISTRIBUTED713_tree=null;
		ASTNode KW_ON714_tree=null;
		ASTNode LPAREN715_tree=null;
		ASTNode RPAREN716_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_DISTRIBUTED=new RewriteRuleTokenStream(adaptor,"token KW_DISTRIBUTED");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view distribute specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2055:5: ( KW_DISTRIBUTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWDISTRIBUTECOLS $colList) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2055:7: KW_DISTRIBUTED KW_ON LPAREN colList= columnNameList RPAREN
			{
			KW_DISTRIBUTED713=(Token)match(input,KW_DISTRIBUTED,FOLLOW_KW_DISTRIBUTED_in_viewDistSpec11971); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DISTRIBUTED.add(KW_DISTRIBUTED713);

			KW_ON714=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewDistSpec11973); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON714);

			LPAREN715=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewDistSpec11975); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN715);

			pushFollow(FOLLOW_columnNameList_in_viewDistSpec11979);
			colList=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(colList.getTree());
			RPAREN716=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewDistSpec11981); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN716);

			// AST REWRITE
			// elements: colList
			// token labels: 
			// rule labels: colList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colList=new RewriteRuleSubtreeStream(adaptor,"rule colList",colList!=null?colList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2056:5: -> ^( TOK_VIEWDISTRIBUTECOLS $colList)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2056:8: ^( TOK_VIEWDISTRIBUTECOLS $colList)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWDISTRIBUTECOLS, "TOK_VIEWDISTRIBUTECOLS"), root_1);
				adaptor.addChild(root_1, stream_colList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewDistSpec"


	public static class viewSortSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewSortSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2059:1: viewSortSpec : KW_SORTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWSORTCOLS $colList) ;
	public final HiveParser.viewSortSpec_return viewSortSpec() throws RecognitionException {
		HiveParser.viewSortSpec_return retval = new HiveParser.viewSortSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SORTED717=null;
		Token KW_ON718=null;
		Token LPAREN719=null;
		Token RPAREN720=null;
		ParserRuleReturnScope colList =null;

		ASTNode KW_SORTED717_tree=null;
		ASTNode KW_ON718_tree=null;
		ASTNode LPAREN719_tree=null;
		ASTNode RPAREN720_tree=null;
		RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view sort specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2062:5: ( KW_SORTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWSORTCOLS $colList) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2062:7: KW_SORTED KW_ON LPAREN colList= columnNameList RPAREN
			{
			KW_SORTED717=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_viewSortSpec12021); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SORTED.add(KW_SORTED717);

			KW_ON718=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewSortSpec12023); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON718);

			LPAREN719=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewSortSpec12025); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN719);

			pushFollow(FOLLOW_columnNameList_in_viewSortSpec12029);
			colList=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(colList.getTree());
			RPAREN720=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewSortSpec12031); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN720);

			// AST REWRITE
			// elements: colList
			// token labels: 
			// rule labels: colList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colList=new RewriteRuleSubtreeStream(adaptor,"rule colList",colList!=null?colList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2063:5: -> ^( TOK_VIEWSORTCOLS $colList)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:8: ^( TOK_VIEWSORTCOLS $colList)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWSORTCOLS, "TOK_VIEWSORTCOLS"), root_1);
				adaptor.addChild(root_1, stream_colList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewSortSpec"


	public static class dropViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2066:1: dropViewStatement : KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) ;
	public final HiveParser.dropViewStatement_return dropViewStatement() throws RecognitionException {
		HiveParser.dropViewStatement_return retval = new HiveParser.dropViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP721=null;
		Token KW_VIEW722=null;
		ParserRuleReturnScope ifExists723 =null;
		ParserRuleReturnScope viewName724 =null;

		ASTNode KW_DROP721_tree=null;
		ASTNode KW_VIEW722_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleSubtreeStream stream_viewName=new RewriteRuleSubtreeStream(adaptor,"rule viewName");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("drop view statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:5: ( KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:7: KW_DROP KW_VIEW ( ifExists )? viewName
			{
			KW_DROP721=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropViewStatement12071); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP721);

			KW_VIEW722=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_dropViewStatement12073); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW722);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:23: ( ifExists )?
			int alt214=2;
			int LA214_0 = input.LA(1);
			if ( (LA214_0==KW_IF) ) {
				alt214=1;
			}
			switch (alt214) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:23: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropViewStatement12075);
					ifExists723=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists723.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_viewName_in_dropViewStatement12078);
			viewName724=viewName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_viewName.add(viewName724.getTree());
			// AST REWRITE
			// elements: ifExists, viewName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2069:42: -> ^( TOK_DROPVIEW viewName ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:45: ^( TOK_DROPVIEW viewName ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPVIEW, "TOK_DROPVIEW"), root_1);
				adaptor.addChild(root_1, stream_viewName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:69: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropViewStatement"


	public static class createMaterializedViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createMaterializedViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2072:1: createMaterializedViewStatement : KW_CREATE KW_MATERIALIZED KW_VIEW ( ifNotExists )? name= tableName ( rewriteDisabled )? ( tableComment )? ( viewPartition )? ( viewOrganization )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) ;
	public final HiveParser.createMaterializedViewStatement_return createMaterializedViewStatement() throws RecognitionException {
		HiveParser.createMaterializedViewStatement_return retval = new HiveParser.createMaterializedViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE725=null;
		Token KW_MATERIALIZED726=null;
		Token KW_VIEW727=null;
		Token KW_AS737=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope ifNotExists728 =null;
		ParserRuleReturnScope rewriteDisabled729 =null;
		ParserRuleReturnScope tableComment730 =null;
		ParserRuleReturnScope viewPartition731 =null;
		ParserRuleReturnScope viewOrganization732 =null;
		ParserRuleReturnScope tableRowFormat733 =null;
		ParserRuleReturnScope tableFileFormat734 =null;
		ParserRuleReturnScope tableLocation735 =null;
		ParserRuleReturnScope tablePropertiesPrefixed736 =null;
		ParserRuleReturnScope selectStatementWithCTE738 =null;

		ASTNode KW_CREATE725_tree=null;
		ASTNode KW_MATERIALIZED726_tree=null;
		ASTNode KW_VIEW727_tree=null;
		ASTNode KW_AS737_tree=null;
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_MATERIALIZED=new RewriteRuleTokenStream(adaptor,"token KW_MATERIALIZED");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
		RewriteRuleSubtreeStream stream_selectStatementWithCTE=new RewriteRuleSubtreeStream(adaptor,"rule selectStatementWithCTE");
		RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
		RewriteRuleSubtreeStream stream_rewriteDisabled=new RewriteRuleSubtreeStream(adaptor,"rule rewriteDisabled");
		RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
		RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
		RewriteRuleSubtreeStream stream_viewOrganization=new RewriteRuleSubtreeStream(adaptor,"rule viewOrganization");
		RewriteRuleSubtreeStream stream_viewPartition=new RewriteRuleSubtreeStream(adaptor,"rule viewPartition");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");


		    pushMsg("create materialized view statement", state);

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2077:5: ( KW_CREATE KW_MATERIALIZED KW_VIEW ( ifNotExists )? name= tableName ( rewriteDisabled )? ( tableComment )? ( viewPartition )? ( viewOrganization )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2077:7: KW_CREATE KW_MATERIALIZED KW_VIEW ( ifNotExists )? name= tableName ( rewriteDisabled )? ( tableComment )? ( viewPartition )? ( viewOrganization )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE
			{
			KW_CREATE725=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createMaterializedViewStatement12116); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE725);

			KW_MATERIALIZED726=(Token)match(input,KW_MATERIALIZED,FOLLOW_KW_MATERIALIZED_in_createMaterializedViewStatement12118); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATERIALIZED.add(KW_MATERIALIZED726);

			KW_VIEW727=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_createMaterializedViewStatement12120); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW727);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2077:41: ( ifNotExists )?
			int alt215=2;
			int LA215_0 = input.LA(1);
			if ( (LA215_0==KW_IF) ) {
				alt215=1;
			}
			switch (alt215) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2077:42: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_createMaterializedViewStatement12123);
					ifNotExists728=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists728.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableName_in_createMaterializedViewStatement12129);
			name=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(name.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:9: ( rewriteDisabled )?
			int alt216=2;
			int LA216_0 = input.LA(1);
			if ( (LA216_0==KW_DISABLE) ) {
				alt216=1;
			}
			switch (alt216) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:9: rewriteDisabled
					{
					pushFollow(FOLLOW_rewriteDisabled_in_createMaterializedViewStatement12139);
					rewriteDisabled729=rewriteDisabled();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rewriteDisabled.add(rewriteDisabled729.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:26: ( tableComment )?
			int alt217=2;
			int LA217_0 = input.LA(1);
			if ( (LA217_0==KW_COMMENT) ) {
				alt217=1;
			}
			switch (alt217) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:26: tableComment
					{
					pushFollow(FOLLOW_tableComment_in_createMaterializedViewStatement12142);
					tableComment730=tableComment();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableComment.add(tableComment730.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:40: ( viewPartition )?
			int alt218=2;
			int LA218_0 = input.LA(1);
			if ( (LA218_0==KW_PARTITIONED) ) {
				alt218=1;
			}
			switch (alt218) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:40: viewPartition
					{
					pushFollow(FOLLOW_viewPartition_in_createMaterializedViewStatement12145);
					viewPartition731=viewPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_viewPartition.add(viewPartition731.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:55: ( viewOrganization )?
			int alt219=2;
			int LA219_0 = input.LA(1);
			if ( (LA219_0==KW_CLUSTERED||LA219_0==KW_DISTRIBUTED) ) {
				alt219=1;
			}
			switch (alt219) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:55: viewOrganization
					{
					pushFollow(FOLLOW_viewOrganization_in_createMaterializedViewStatement12148);
					viewOrganization732=viewOrganization();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_viewOrganization.add(viewOrganization732.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2079:9: ( tableRowFormat )?
			int alt220=2;
			int LA220_0 = input.LA(1);
			if ( (LA220_0==KW_ROW) ) {
				alt220=1;
			}
			switch (alt220) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2079:9: tableRowFormat
					{
					pushFollow(FOLLOW_tableRowFormat_in_createMaterializedViewStatement12159);
					tableRowFormat733=tableRowFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat733.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2079:25: ( tableFileFormat )?
			int alt221=2;
			int LA221_0 = input.LA(1);
			if ( (LA221_0==KW_STORED) ) {
				alt221=1;
			}
			switch (alt221) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2079:25: tableFileFormat
					{
					pushFollow(FOLLOW_tableFileFormat_in_createMaterializedViewStatement12162);
					tableFileFormat734=tableFileFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat734.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2079:42: ( tableLocation )?
			int alt222=2;
			int LA222_0 = input.LA(1);
			if ( (LA222_0==KW_LOCATION) ) {
				alt222=1;
			}
			switch (alt222) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2079:42: tableLocation
					{
					pushFollow(FOLLOW_tableLocation_in_createMaterializedViewStatement12165);
					tableLocation735=tableLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation735.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2080:9: ( tablePropertiesPrefixed )?
			int alt223=2;
			int LA223_0 = input.LA(1);
			if ( (LA223_0==KW_TBLPROPERTIES) ) {
				alt223=1;
			}
			switch (alt223) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2080:9: tablePropertiesPrefixed
					{
					pushFollow(FOLLOW_tablePropertiesPrefixed_in_createMaterializedViewStatement12176);
					tablePropertiesPrefixed736=tablePropertiesPrefixed();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed736.getTree());
					}
					break;

			}

			KW_AS737=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createMaterializedViewStatement12179); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS737);

			pushFollow(FOLLOW_selectStatementWithCTE_in_createMaterializedViewStatement12181);
			selectStatementWithCTE738=selectStatementWithCTE();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_selectStatementWithCTE.add(selectStatementWithCTE738.getTree());
			// AST REWRITE
			// elements: tableComment, tableRowFormat, ifNotExists, tableLocation, rewriteDisabled, viewOrganization, viewPartition, selectStatementWithCTE, tableFileFormat, tablePropertiesPrefixed, name
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2081:5: -> ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2081:8: ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATE_MATERIALIZED_VIEW, "TOK_CREATE_MATERIALIZED_VIEW"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2082:10: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2083:10: ( rewriteDisabled )?
				if ( stream_rewriteDisabled.hasNext() ) {
					adaptor.addChild(root_1, stream_rewriteDisabled.nextTree());
				}
				stream_rewriteDisabled.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2084:10: ( tableComment )?
				if ( stream_tableComment.hasNext() ) {
					adaptor.addChild(root_1, stream_tableComment.nextTree());
				}
				stream_tableComment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:10: ( tableRowFormat )?
				if ( stream_tableRowFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
				}
				stream_tableRowFormat.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2086:10: ( tableFileFormat )?
				if ( stream_tableFileFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
				}
				stream_tableFileFormat.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2087:10: ( tableLocation )?
				if ( stream_tableLocation.hasNext() ) {
					adaptor.addChild(root_1, stream_tableLocation.nextTree());
				}
				stream_tableLocation.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2088:10: ( viewPartition )?
				if ( stream_viewPartition.hasNext() ) {
					adaptor.addChild(root_1, stream_viewPartition.nextTree());
				}
				stream_viewPartition.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2089:10: ( viewOrganization )?
				if ( stream_viewOrganization.hasNext() ) {
					adaptor.addChild(root_1, stream_viewOrganization.nextTree());
				}
				stream_viewOrganization.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2090:10: ( tablePropertiesPrefixed )?
				if ( stream_tablePropertiesPrefixed.hasNext() ) {
					adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
				}
				stream_tablePropertiesPrefixed.reset();

				adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createMaterializedViewStatement"


	public static class dropMaterializedViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropMaterializedViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2095:1: dropMaterializedViewStatement : KW_DROP KW_MATERIALIZED KW_VIEW ( ifExists )? viewName -> ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? ) ;
	public final HiveParser.dropMaterializedViewStatement_return dropMaterializedViewStatement() throws RecognitionException {
		HiveParser.dropMaterializedViewStatement_return retval = new HiveParser.dropMaterializedViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP739=null;
		Token KW_MATERIALIZED740=null;
		Token KW_VIEW741=null;
		ParserRuleReturnScope ifExists742 =null;
		ParserRuleReturnScope viewName743 =null;

		ASTNode KW_DROP739_tree=null;
		ASTNode KW_MATERIALIZED740_tree=null;
		ASTNode KW_VIEW741_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleTokenStream stream_KW_MATERIALIZED=new RewriteRuleTokenStream(adaptor,"token KW_MATERIALIZED");
		RewriteRuleSubtreeStream stream_viewName=new RewriteRuleSubtreeStream(adaptor,"rule viewName");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("drop materialized view statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2098:5: ( KW_DROP KW_MATERIALIZED KW_VIEW ( ifExists )? viewName -> ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2098:7: KW_DROP KW_MATERIALIZED KW_VIEW ( ifExists )? viewName
			{
			KW_DROP739=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropMaterializedViewStatement12349); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP739);

			KW_MATERIALIZED740=(Token)match(input,KW_MATERIALIZED,FOLLOW_KW_MATERIALIZED_in_dropMaterializedViewStatement12351); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATERIALIZED.add(KW_MATERIALIZED740);

			KW_VIEW741=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_dropMaterializedViewStatement12353); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW741);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2098:39: ( ifExists )?
			int alt224=2;
			int LA224_0 = input.LA(1);
			if ( (LA224_0==KW_IF) ) {
				alt224=1;
			}
			switch (alt224) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2098:39: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropMaterializedViewStatement12355);
					ifExists742=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists742.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_viewName_in_dropMaterializedViewStatement12358);
			viewName743=viewName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_viewName.add(viewName743.getTree());
			// AST REWRITE
			// elements: viewName, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2098:58: -> ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2098:61: ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROP_MATERIALIZED_VIEW, "TOK_DROP_MATERIALIZED_VIEW"), root_1);
				adaptor.addChild(root_1, stream_viewName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2098:99: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropMaterializedViewStatement"


	public static class createScheduledQueryStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createScheduledQueryStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:1: createScheduledQueryStatement : KW_CREATE KW_SCHEDULED KW_QUERY name= identifier scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec -> ^( TOK_CREATE_SCHEDULED_QUERY $name scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec ) ;
	public final HiveParser.createScheduledQueryStatement_return createScheduledQueryStatement() throws RecognitionException {
		HiveParser.createScheduledQueryStatement_return retval = new HiveParser.createScheduledQueryStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE744=null;
		Token KW_SCHEDULED745=null;
		Token KW_QUERY746=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope scheduleSpec747 =null;
		ParserRuleReturnScope executedAsSpec748 =null;
		ParserRuleReturnScope enableSpecification749 =null;
		ParserRuleReturnScope definedAsSpec750 =null;

		ASTNode KW_CREATE744_tree=null;
		ASTNode KW_SCHEDULED745_tree=null;
		ASTNode KW_QUERY746_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEDULED=new RewriteRuleTokenStream(adaptor,"token KW_SCHEDULED");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_QUERY=new RewriteRuleTokenStream(adaptor,"token KW_QUERY");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_definedAsSpec=new RewriteRuleSubtreeStream(adaptor,"rule definedAsSpec");
		RewriteRuleSubtreeStream stream_scheduleSpec=new RewriteRuleSubtreeStream(adaptor,"rule scheduleSpec");
		RewriteRuleSubtreeStream stream_enableSpecification=new RewriteRuleSubtreeStream(adaptor,"rule enableSpecification");
		RewriteRuleSubtreeStream stream_executedAsSpec=new RewriteRuleSubtreeStream(adaptor,"rule executedAsSpec");

		 pushMsg("create scheduled query statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2104:5: ( KW_CREATE KW_SCHEDULED KW_QUERY name= identifier scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec -> ^( TOK_CREATE_SCHEDULED_QUERY $name scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2104:7: KW_CREATE KW_SCHEDULED KW_QUERY name= identifier scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec
			{
			KW_CREATE744=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createScheduledQueryStatement12396); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE744);

			KW_SCHEDULED745=(Token)match(input,KW_SCHEDULED,FOLLOW_KW_SCHEDULED_in_createScheduledQueryStatement12398); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SCHEDULED.add(KW_SCHEDULED745);

			KW_QUERY746=(Token)match(input,KW_QUERY,FOLLOW_KW_QUERY_in_createScheduledQueryStatement12400); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_QUERY.add(KW_QUERY746);

			pushFollow(FOLLOW_identifier_in_createScheduledQueryStatement12404);
			name=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
			pushFollow(FOLLOW_scheduleSpec_in_createScheduledQueryStatement12414);
			scheduleSpec747=scheduleSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_scheduleSpec.add(scheduleSpec747.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2106:9: ( executedAsSpec )?
			int alt225=2;
			int LA225_0 = input.LA(1);
			if ( (LA225_0==KW_EXECUTED) ) {
				alt225=1;
			}
			switch (alt225) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2106:9: executedAsSpec
					{
					pushFollow(FOLLOW_executedAsSpec_in_createScheduledQueryStatement12424);
					executedAsSpec748=executedAsSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_executedAsSpec.add(executedAsSpec748.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2107:9: ( enableSpecification )?
			int alt226=2;
			int LA226_0 = input.LA(1);
			if ( (LA226_0==KW_DISABLE||LA226_0==KW_ENABLE) ) {
				alt226=1;
			}
			switch (alt226) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2107:9: enableSpecification
					{
					pushFollow(FOLLOW_enableSpecification_in_createScheduledQueryStatement12435);
					enableSpecification749=enableSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_enableSpecification.add(enableSpecification749.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_definedAsSpec_in_createScheduledQueryStatement12446);
			definedAsSpec750=definedAsSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_definedAsSpec.add(definedAsSpec750.getTree());
			// AST REWRITE
			// elements: enableSpecification, definedAsSpec, scheduleSpec, executedAsSpec, name
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2109:5: -> ^( TOK_CREATE_SCHEDULED_QUERY $name scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2109:8: ^( TOK_CREATE_SCHEDULED_QUERY $name scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATE_SCHEDULED_QUERY, "TOK_CREATE_SCHEDULED_QUERY"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				adaptor.addChild(root_1, stream_scheduleSpec.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2112:13: ( executedAsSpec )?
				if ( stream_executedAsSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_executedAsSpec.nextTree());
				}
				stream_executedAsSpec.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2113:13: ( enableSpecification )?
				if ( stream_enableSpecification.hasNext() ) {
					adaptor.addChild(root_1, stream_enableSpecification.nextTree());
				}
				stream_enableSpecification.reset();

				adaptor.addChild(root_1, stream_definedAsSpec.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createScheduledQueryStatement"


	public static class dropScheduledQueryStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropScheduledQueryStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2118:1: dropScheduledQueryStatement : KW_DROP KW_SCHEDULED KW_QUERY name= identifier -> ^( TOK_DROP_SCHEDULED_QUERY $name) ;
	public final HiveParser.dropScheduledQueryStatement_return dropScheduledQueryStatement() throws RecognitionException {
		HiveParser.dropScheduledQueryStatement_return retval = new HiveParser.dropScheduledQueryStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP751=null;
		Token KW_SCHEDULED752=null;
		Token KW_QUERY753=null;
		ParserRuleReturnScope name =null;

		ASTNode KW_DROP751_tree=null;
		ASTNode KW_SCHEDULED752_tree=null;
		ASTNode KW_QUERY753_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_SCHEDULED=new RewriteRuleTokenStream(adaptor,"token KW_SCHEDULED");
		RewriteRuleTokenStream stream_KW_QUERY=new RewriteRuleTokenStream(adaptor,"token KW_QUERY");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("drop scheduled query statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2121:5: ( KW_DROP KW_SCHEDULED KW_QUERY name= identifier -> ^( TOK_DROP_SCHEDULED_QUERY $name) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2121:7: KW_DROP KW_SCHEDULED KW_QUERY name= identifier
			{
			KW_DROP751=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropScheduledQueryStatement12569); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP751);

			KW_SCHEDULED752=(Token)match(input,KW_SCHEDULED,FOLLOW_KW_SCHEDULED_in_dropScheduledQueryStatement12571); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SCHEDULED.add(KW_SCHEDULED752);

			KW_QUERY753=(Token)match(input,KW_QUERY,FOLLOW_KW_QUERY_in_dropScheduledQueryStatement12573); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_QUERY.add(KW_QUERY753);

			pushFollow(FOLLOW_identifier_in_dropScheduledQueryStatement12577);
			name=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
			// AST REWRITE
			// elements: name
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2122:5: -> ^( TOK_DROP_SCHEDULED_QUERY $name)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2122:8: ^( TOK_DROP_SCHEDULED_QUERY $name)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROP_SCHEDULED_QUERY, "TOK_DROP_SCHEDULED_QUERY"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropScheduledQueryStatement"


	public static class alterScheduledQueryStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterScheduledQueryStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2128:1: alterScheduledQueryStatement : KW_ALTER KW_SCHEDULED KW_QUERY name= identifier mod= alterScheduledQueryChange -> ^( TOK_ALTER_SCHEDULED_QUERY $name $mod) ;
	public final HiveParser.alterScheduledQueryStatement_return alterScheduledQueryStatement() throws RecognitionException {
		HiveParser.alterScheduledQueryStatement_return retval = new HiveParser.alterScheduledQueryStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ALTER754=null;
		Token KW_SCHEDULED755=null;
		Token KW_QUERY756=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope mod =null;

		ASTNode KW_ALTER754_tree=null;
		ASTNode KW_SCHEDULED755_tree=null;
		ASTNode KW_QUERY756_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEDULED=new RewriteRuleTokenStream(adaptor,"token KW_SCHEDULED");
		RewriteRuleTokenStream stream_KW_ALTER=new RewriteRuleTokenStream(adaptor,"token KW_ALTER");
		RewriteRuleTokenStream stream_KW_QUERY=new RewriteRuleTokenStream(adaptor,"token KW_QUERY");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_alterScheduledQueryChange=new RewriteRuleSubtreeStream(adaptor,"rule alterScheduledQueryChange");

		 pushMsg("alter scheduled query statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2131:5: ( KW_ALTER KW_SCHEDULED KW_QUERY name= identifier mod= alterScheduledQueryChange -> ^( TOK_ALTER_SCHEDULED_QUERY $name $mod) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2131:7: KW_ALTER KW_SCHEDULED KW_QUERY name= identifier mod= alterScheduledQueryChange
			{
			KW_ALTER754=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterScheduledQueryStatement12643); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER754);

			KW_SCHEDULED755=(Token)match(input,KW_SCHEDULED,FOLLOW_KW_SCHEDULED_in_alterScheduledQueryStatement12645); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SCHEDULED.add(KW_SCHEDULED755);

			KW_QUERY756=(Token)match(input,KW_QUERY,FOLLOW_KW_QUERY_in_alterScheduledQueryStatement12647); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_QUERY.add(KW_QUERY756);

			pushFollow(FOLLOW_identifier_in_alterScheduledQueryStatement12651);
			name=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
			pushFollow(FOLLOW_alterScheduledQueryChange_in_alterScheduledQueryStatement12667);
			mod=alterScheduledQueryChange();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_alterScheduledQueryChange.add(mod.getTree());
			// AST REWRITE
			// elements: name, mod
			// token labels: 
			// rule labels: mod, name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_mod=new RewriteRuleSubtreeStream(adaptor,"rule mod",mod!=null?mod.getTree():null);
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2133:5: -> ^( TOK_ALTER_SCHEDULED_QUERY $name $mod)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2133:8: ^( TOK_ALTER_SCHEDULED_QUERY $name $mod)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTER_SCHEDULED_QUERY, "TOK_ALTER_SCHEDULED_QUERY"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				adaptor.addChild(root_1, stream_mod.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterScheduledQueryStatement"


	public static class alterScheduledQueryChange_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterScheduledQueryChange"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2139:1: alterScheduledQueryChange : ( scheduleSpec | executedAsSpec | enableSpecification | definedAsSpec | KW_EXECUTE -> ^( TOK_EXECUTE ) );
	public final HiveParser.alterScheduledQueryChange_return alterScheduledQueryChange() throws RecognitionException {
		HiveParser.alterScheduledQueryChange_return retval = new HiveParser.alterScheduledQueryChange_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_EXECUTE761=null;
		ParserRuleReturnScope scheduleSpec757 =null;
		ParserRuleReturnScope executedAsSpec758 =null;
		ParserRuleReturnScope enableSpecification759 =null;
		ParserRuleReturnScope definedAsSpec760 =null;

		ASTNode KW_EXECUTE761_tree=null;
		RewriteRuleTokenStream stream_KW_EXECUTE=new RewriteRuleTokenStream(adaptor,"token KW_EXECUTE");

		 pushMsg("alter scheduled query change", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2142:5: ( scheduleSpec | executedAsSpec | enableSpecification | definedAsSpec | KW_EXECUTE -> ^( TOK_EXECUTE ) )
			int alt227=5;
			switch ( input.LA(1) ) {
			case KW_CRON:
			case KW_EVERY:
				{
				alt227=1;
				}
				break;
			case KW_EXECUTED:
				{
				alt227=2;
				}
				break;
			case KW_DISABLE:
			case KW_ENABLE:
				{
				alt227=3;
				}
				break;
			case KW_AS:
			case KW_DEFINED:
				{
				alt227=4;
				}
				break;
			case KW_EXECUTE:
				{
				alt227=5;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 227, 0, input);
				throw nvae;
			}
			switch (alt227) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2142:7: scheduleSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_scheduleSpec_in_alterScheduledQueryChange12747);
					scheduleSpec757=scheduleSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, scheduleSpec757.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2143:7: executedAsSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_executedAsSpec_in_alterScheduledQueryChange12755);
					executedAsSpec758=executedAsSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, executedAsSpec758.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2144:7: enableSpecification
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_enableSpecification_in_alterScheduledQueryChange12763);
					enableSpecification759=enableSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, enableSpecification759.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2145:7: definedAsSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_definedAsSpec_in_alterScheduledQueryChange12771);
					definedAsSpec760=definedAsSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, definedAsSpec760.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2146:7: KW_EXECUTE
					{
					KW_EXECUTE761=(Token)match(input,KW_EXECUTE,FOLLOW_KW_EXECUTE_in_alterScheduledQueryChange12779); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXECUTE.add(KW_EXECUTE761);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2146:18: -> ^( TOK_EXECUTE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2146:21: ^( TOK_EXECUTE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXECUTE, "TOK_EXECUTE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterScheduledQueryChange"


	public static class scheduleSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "scheduleSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2149:1: scheduleSpec : ( KW_CRON cronString= StringLiteral -> ^( TOK_CRON $cronString) | KW_EVERY (value= Number )? qualifier= intervalQualifiers ( ( KW_AT | KW_OFFSET KW_BY ) offsetTs= StringLiteral )? -> ^( TOK_SCHEDULE ^( TOK_EVERY ( $value)? ) $qualifier ( $offsetTs)? ) );
	public final HiveParser.scheduleSpec_return scheduleSpec() throws RecognitionException {
		HiveParser.scheduleSpec_return retval = new HiveParser.scheduleSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token cronString=null;
		Token value=null;
		Token offsetTs=null;
		Token KW_CRON762=null;
		Token KW_EVERY763=null;
		Token KW_AT764=null;
		Token KW_OFFSET765=null;
		Token KW_BY766=null;
		ParserRuleReturnScope qualifier =null;

		ASTNode cronString_tree=null;
		ASTNode value_tree=null;
		ASTNode offsetTs_tree=null;
		ASTNode KW_CRON762_tree=null;
		ASTNode KW_EVERY763_tree=null;
		ASTNode KW_AT764_tree=null;
		ASTNode KW_OFFSET765_tree=null;
		ASTNode KW_BY766_tree=null;
		RewriteRuleTokenStream stream_KW_CRON=new RewriteRuleTokenStream(adaptor,"token KW_CRON");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_OFFSET=new RewriteRuleTokenStream(adaptor,"token KW_OFFSET");
		RewriteRuleTokenStream stream_KW_EVERY=new RewriteRuleTokenStream(adaptor,"token KW_EVERY");
		RewriteRuleTokenStream stream_KW_AT=new RewriteRuleTokenStream(adaptor,"token KW_AT");
		RewriteRuleSubtreeStream stream_intervalQualifiers=new RewriteRuleSubtreeStream(adaptor,"rule intervalQualifiers");

		 pushMsg("schedule specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2152:9: ( KW_CRON cronString= StringLiteral -> ^( TOK_CRON $cronString) | KW_EVERY (value= Number )? qualifier= intervalQualifiers ( ( KW_AT | KW_OFFSET KW_BY ) offsetTs= StringLiteral )? -> ^( TOK_SCHEDULE ^( TOK_EVERY ( $value)? ) $qualifier ( $offsetTs)? ) )
			int alt231=2;
			int LA231_0 = input.LA(1);
			if ( (LA231_0==KW_CRON) ) {
				alt231=1;
			}
			else if ( (LA231_0==KW_EVERY) ) {
				alt231=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 231, 0, input);
				throw nvae;
			}

			switch (alt231) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2152:11: KW_CRON cronString= StringLiteral
					{
					KW_CRON762=(Token)match(input,KW_CRON,FOLLOW_KW_CRON_in_scheduleSpec12816); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CRON.add(KW_CRON762);

					cronString=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_scheduleSpec12820); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(cronString);

					// AST REWRITE
					// elements: cronString
					// token labels: cronString
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_cronString=new RewriteRuleTokenStream(adaptor,"token cronString",cronString);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2152:44: -> ^( TOK_CRON $cronString)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2152:47: ^( TOK_CRON $cronString)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CRON, "TOK_CRON"), root_1);
						adaptor.addChild(root_1, stream_cronString.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:11: KW_EVERY (value= Number )? qualifier= intervalQualifiers ( ( KW_AT | KW_OFFSET KW_BY ) offsetTs= StringLiteral )?
					{
					KW_EVERY763=(Token)match(input,KW_EVERY,FOLLOW_KW_EVERY_in_scheduleSpec12841); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EVERY.add(KW_EVERY763);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:25: (value= Number )?
					int alt228=2;
					int LA228_0 = input.LA(1);
					if ( (LA228_0==Number) ) {
						alt228=1;
					}
					switch (alt228) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:25: value= Number
							{
							value=(Token)match(input,Number,FOLLOW_Number_in_scheduleSpec12845); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(value);

							}
							break;

					}

					pushFollow(FOLLOW_intervalQualifiers_in_scheduleSpec12850);
					qualifier=intervalQualifiers();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_intervalQualifiers.add(qualifier.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:9: ( ( KW_AT | KW_OFFSET KW_BY ) offsetTs= StringLiteral )?
					int alt230=2;
					int LA230_0 = input.LA(1);
					if ( (LA230_0==KW_AT||LA230_0==KW_OFFSET) ) {
						alt230=1;
					}
					switch (alt230) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:10: ( KW_AT | KW_OFFSET KW_BY ) offsetTs= StringLiteral
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:10: ( KW_AT | KW_OFFSET KW_BY )
							int alt229=2;
							int LA229_0 = input.LA(1);
							if ( (LA229_0==KW_AT) ) {
								alt229=1;
							}
							else if ( (LA229_0==KW_OFFSET) ) {
								alt229=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 229, 0, input);
								throw nvae;
							}

							switch (alt229) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:11: KW_AT
									{
									KW_AT764=(Token)match(input,KW_AT,FOLLOW_KW_AT_in_scheduleSpec12862); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_AT.add(KW_AT764);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:17: KW_OFFSET KW_BY
									{
									KW_OFFSET765=(Token)match(input,KW_OFFSET,FOLLOW_KW_OFFSET_in_scheduleSpec12864); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_OFFSET.add(KW_OFFSET765);

									KW_BY766=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_scheduleSpec12866); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY766);

									}
									break;

							}

							offsetTs=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_scheduleSpec12871); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(offsetTs);

							}
							break;

					}

					// AST REWRITE
					// elements: value, qualifier, offsetTs
					// token labels: offsetTs, value
					// rule labels: qualifier, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_offsetTs=new RewriteRuleTokenStream(adaptor,"token offsetTs",offsetTs);
					RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
					RewriteRuleSubtreeStream stream_qualifier=new RewriteRuleSubtreeStream(adaptor,"rule qualifier",qualifier!=null?qualifier.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2154:59: -> ^( TOK_SCHEDULE ^( TOK_EVERY ( $value)? ) $qualifier ( $offsetTs)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:62: ^( TOK_SCHEDULE ^( TOK_EVERY ( $value)? ) $qualifier ( $offsetTs)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SCHEDULE, "TOK_SCHEDULE"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:77: ^( TOK_EVERY ( $value)? )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EVERY, "TOK_EVERY"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:90: ( $value)?
						if ( stream_value.hasNext() ) {
							adaptor.addChild(root_2, stream_value.nextNode());
						}
						stream_value.reset();

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_1, stream_qualifier.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:110: ( $offsetTs)?
						if ( stream_offsetTs.hasNext() ) {
							adaptor.addChild(root_1, stream_offsetTs.nextNode());
						}
						stream_offsetTs.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "scheduleSpec"


	public static class executedAsSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "executedAsSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2157:1: executedAsSpec : KW_EXECUTED KW_AS executedAs= StringLiteral -> ^( TOK_EXECUTED_AS $executedAs) ;
	public final HiveParser.executedAsSpec_return executedAsSpec() throws RecognitionException {
		HiveParser.executedAsSpec_return retval = new HiveParser.executedAsSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token executedAs=null;
		Token KW_EXECUTED767=null;
		Token KW_AS768=null;

		ASTNode executedAs_tree=null;
		ASTNode KW_EXECUTED767_tree=null;
		ASTNode KW_AS768_tree=null;
		RewriteRuleTokenStream stream_KW_EXECUTED=new RewriteRuleTokenStream(adaptor,"token KW_EXECUTED");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");

		 pushMsg("executedAs specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2160:9: ( KW_EXECUTED KW_AS executedAs= StringLiteral -> ^( TOK_EXECUTED_AS $executedAs) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2160:11: KW_EXECUTED KW_AS executedAs= StringLiteral
			{
			KW_EXECUTED767=(Token)match(input,KW_EXECUTED,FOLLOW_KW_EXECUTED_in_executedAsSpec12930); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXECUTED.add(KW_EXECUTED767);

			KW_AS768=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_executedAsSpec12932); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS768);

			executedAs=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_executedAsSpec12936); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(executedAs);

			// AST REWRITE
			// elements: executedAs
			// token labels: executedAs
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_executedAs=new RewriteRuleTokenStream(adaptor,"token executedAs",executedAs);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2160:54: -> ^( TOK_EXECUTED_AS $executedAs)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2160:57: ^( TOK_EXECUTED_AS $executedAs)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXECUTED_AS, "TOK_EXECUTED_AS"), root_1);
				adaptor.addChild(root_1, stream_executedAs.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "executedAsSpec"


	public static class definedAsSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "definedAsSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2163:1: definedAsSpec : ( KW_DEFINED )? KW_AS statement -> ^( TOK_QUERY statement ) ;
	public final HiveParser.definedAsSpec_return definedAsSpec() throws RecognitionException {
		HiveParser.definedAsSpec_return retval = new HiveParser.definedAsSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DEFINED769=null;
		Token KW_AS770=null;
		ParserRuleReturnScope statement771 =null;

		ASTNode KW_DEFINED769_tree=null;
		ASTNode KW_AS770_tree=null;
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_DEFINED=new RewriteRuleTokenStream(adaptor,"token KW_DEFINED");
		RewriteRuleSubtreeStream stream_statement=new RewriteRuleSubtreeStream(adaptor,"rule statement");

		 pushMsg("definedAs specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2166:9: ( ( KW_DEFINED )? KW_AS statement -> ^( TOK_QUERY statement ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2166:11: ( KW_DEFINED )? KW_AS statement
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2166:11: ( KW_DEFINED )?
			int alt232=2;
			int LA232_0 = input.LA(1);
			if ( (LA232_0==KW_DEFINED) ) {
				alt232=1;
			}
			switch (alt232) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2166:11: KW_DEFINED
					{
					KW_DEFINED769=(Token)match(input,KW_DEFINED,FOLLOW_KW_DEFINED_in_definedAsSpec12980); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DEFINED.add(KW_DEFINED769);

					}
					break;

			}

			KW_AS770=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_definedAsSpec12983); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS770);

			pushFollow(FOLLOW_statement_in_definedAsSpec12985);
			statement771=statement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_statement.add(statement771.getTree());
			// AST REWRITE
			// elements: statement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2166:39: -> ^( TOK_QUERY statement )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2166:42: ^( TOK_QUERY statement )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				adaptor.addChild(root_1, stream_statement.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "definedAsSpec"


	public static class showFunctionIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showFunctionIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2169:1: showFunctionIdentifier : ( functionIdentifier | StringLiteral );
	public final HiveParser.showFunctionIdentifier_return showFunctionIdentifier() throws RecognitionException {
		HiveParser.showFunctionIdentifier_return retval = new HiveParser.showFunctionIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token StringLiteral773=null;
		ParserRuleReturnScope functionIdentifier772 =null;

		ASTNode StringLiteral773_tree=null;

		 pushMsg("identifier for show function statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2172:5: ( functionIdentifier | StringLiteral )
			int alt233=2;
			int LA233_0 = input.LA(1);
			if ( (LA233_0==Identifier||(LA233_0 >= KW_ABORT && LA233_0 <= KW_AFTER)||LA233_0==KW_ALLOC_FRACTION||LA233_0==KW_ANALYZE||LA233_0==KW_ARCHIVE||(LA233_0 >= KW_ASC && LA233_0 <= KW_AT)||(LA233_0 >= KW_AUTOCOMMIT && LA233_0 <= KW_BEFORE)||(LA233_0 >= KW_BUCKET && LA233_0 <= KW_BUCKETS)||(LA233_0 >= KW_CACHE && LA233_0 <= KW_CASCADE)||(LA233_0 >= KW_CBO && LA233_0 <= KW_CHANGE)||(LA233_0 >= KW_CHECK && LA233_0 <= KW_COLLECTION)||(LA233_0 >= KW_COLUMNS && LA233_0 <= KW_COMMENT)||(LA233_0 >= KW_COMPACT && LA233_0 <= KW_CONCATENATE)||(LA233_0 >= KW_CONTINUE && LA233_0 <= KW_COST)||LA233_0==KW_CRON||LA233_0==KW_DATA||LA233_0==KW_DATABASES||(LA233_0 >= KW_DATETIME && LA233_0 <= KW_DEBUG)||(LA233_0 >= KW_DEFAULT && LA233_0 <= KW_DEFINED)||(LA233_0 >= KW_DELIMITED && LA233_0 <= KW_DESC)||(LA233_0 >= KW_DETAIL && LA233_0 <= KW_DISABLE)||(LA233_0 >= KW_DISTRIBUTE && LA233_0 <= KW_DO)||LA233_0==KW_DOW||(LA233_0 >= KW_DUMP && LA233_0 <= KW_ELEM_TYPE)||LA233_0==KW_ENABLE||(LA233_0 >= KW_ENFORCED && LA233_0 <= KW_EVERY)||(LA233_0 >= KW_EXCLUSIVE && LA233_0 <= KW_EXECUTED)||(LA233_0 >= KW_EXPLAIN && LA233_0 <= KW_EXPRESSION)||(LA233_0 >= KW_FIELDS && LA233_0 <= KW_FIRST)||(LA233_0 >= KW_FORMAT && LA233_0 <= KW_FORMATTED)||LA233_0==KW_FUNCTIONS||(LA233_0 >= KW_HOUR && LA233_0 <= KW_IDXPROPERTIES)||(LA233_0 >= KW_INDEX && LA233_0 <= KW_INDEXES)||(LA233_0 >= KW_INPATH && LA233_0 <= KW_INPUTFORMAT)||(LA233_0 >= KW_ISOLATION && LA233_0 <= KW_JAR)||(LA233_0 >= KW_JOINCOST && LA233_0 <= KW_LAST)||LA233_0==KW_LEVEL||(LA233_0 >= KW_LIMIT && LA233_0 <= KW_LOAD)||(LA233_0 >= KW_LOCATION && LA233_0 <= KW_LONG)||(LA233_0 >= KW_MANAGEDLOCATION && LA233_0 <= KW_MANAGEMENT)||(LA233_0 >= KW_MAPJOIN && LA233_0 <= KW_MATERIALIZED)||LA233_0==KW_METADATA||(LA233_0 >= KW_MINUTE && LA233_0 <= KW_MONTH)||(LA233_0 >= KW_MOVE && LA233_0 <= KW_MSCK)||(LA233_0 >= KW_NORELY && LA233_0 <= KW_NOSCAN)||LA233_0==KW_NOVALIDATE||LA233_0==KW_NULLS||LA233_0==KW_OFFSET||(LA233_0 >= KW_OPERATOR && LA233_0 <= KW_OPTION)||(LA233_0 >= KW_OUTPUTDRIVER && LA233_0 <= KW_OUTPUTFORMAT)||(LA233_0 >= KW_OVERWRITE && LA233_0 <= KW_OWNER)||(LA233_0 >= KW_PARTITIONED && LA233_0 <= KW_PATH)||(LA233_0 >= KW_PLAN && LA233_0 <= KW_POOL)||LA233_0==KW_PRINCIPALS||(LA233_0 >= KW_PURGE && LA233_0 <= KW_QUERY_PARALLELISM)||LA233_0==KW_READ||(LA233_0 >= KW_REBUILD && LA233_0 <= KW_RECORDWRITER)||(LA233_0 >= KW_RELOAD && LA233_0 <= KW_RESTRICT)||LA233_0==KW_REWRITE||(LA233_0 >= KW_ROLE && LA233_0 <= KW_ROLES)||(LA233_0 >= KW_SCHEDULED && LA233_0 <= KW_SECOND)||(LA233_0 >= KW_SEMI && LA233_0 <= KW_SERVER)||(LA233_0 >= KW_SETS && LA233_0 <= KW_SKEWED)||(LA233_0 >= KW_SNAPSHOT && LA233_0 <= KW_SSL)||(LA233_0 >= KW_STATISTICS && LA233_0 <= KW_SUMMARY)||LA233_0==KW_TABLES||(LA233_0 >= KW_TBLPROPERTIES && LA233_0 <= KW_TERMINATED)||LA233_0==KW_TINYINT||(LA233_0 >= KW_TOUCH && LA233_0 <= KW_TRANSACTIONS)||LA233_0==KW_UNARCHIVE||LA233_0==KW_UNDO||LA233_0==KW_UNIONTYPE||(LA233_0 >= KW_UNLOCK && LA233_0 <= KW_UNSIGNED)||(LA233_0 >= KW_URI && LA233_0 <= KW_USE)||(LA233_0 >= KW_UTC && LA233_0 <= KW_VALIDATE)||LA233_0==KW_VALUE_TYPE||(LA233_0 >= KW_VECTORIZATION && LA233_0 <= KW_WEEK)||LA233_0==KW_WHILE||(LA233_0 >= KW_WORK && LA233_0 <= KW_ZONE)||LA233_0==KW_BATCH||LA233_0==KW_DAYOFWEEK||LA233_0==KW_HOLD_DDLTIME||LA233_0==KW_IGNORE||LA233_0==KW_NO_DROP||LA233_0==KW_OFFLINE||LA233_0==KW_PROTECTION||LA233_0==KW_READONLY||LA233_0==KW_TIMESTAMPTZ) ) {
				alt233=1;
			}
			else if ( (LA233_0==StringLiteral) ) {
				alt233=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 233, 0, input);
				throw nvae;
			}

			switch (alt233) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2172:7: functionIdentifier
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_functionIdentifier_in_showFunctionIdentifier13024);
					functionIdentifier772=functionIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, functionIdentifier772.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2173:7: StringLiteral
					{
					root_0 = (ASTNode)adaptor.nil();


					StringLiteral773=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showFunctionIdentifier13032); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					StringLiteral773_tree = (ASTNode)adaptor.create(StringLiteral773);
					adaptor.addChild(root_0, StringLiteral773_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showFunctionIdentifier"


	public static class showStmtIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showStmtIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2176:1: showStmtIdentifier : ( identifier | StringLiteral );
	public final HiveParser.showStmtIdentifier_return showStmtIdentifier() throws RecognitionException {
		HiveParser.showStmtIdentifier_return retval = new HiveParser.showStmtIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token StringLiteral775=null;
		ParserRuleReturnScope identifier774 =null;

		ASTNode StringLiteral775_tree=null;

		 pushMsg("identifier for show statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:5: ( identifier | StringLiteral )
			int alt234=2;
			int LA234_0 = input.LA(1);
			if ( (LA234_0==Identifier||(LA234_0 >= KW_ABORT && LA234_0 <= KW_AFTER)||LA234_0==KW_ALLOC_FRACTION||LA234_0==KW_ANALYZE||LA234_0==KW_ARCHIVE||(LA234_0 >= KW_ASC && LA234_0 <= KW_AT)||(LA234_0 >= KW_AUTOCOMMIT && LA234_0 <= KW_BEFORE)||(LA234_0 >= KW_BUCKET && LA234_0 <= KW_BUCKETS)||(LA234_0 >= KW_CACHE && LA234_0 <= KW_CASCADE)||(LA234_0 >= KW_CBO && LA234_0 <= KW_CHANGE)||(LA234_0 >= KW_CHECK && LA234_0 <= KW_COLLECTION)||(LA234_0 >= KW_COLUMNS && LA234_0 <= KW_COMMENT)||(LA234_0 >= KW_COMPACT && LA234_0 <= KW_CONCATENATE)||(LA234_0 >= KW_CONTINUE && LA234_0 <= KW_COST)||LA234_0==KW_CRON||LA234_0==KW_DATA||LA234_0==KW_DATABASES||(LA234_0 >= KW_DATETIME && LA234_0 <= KW_DEBUG)||(LA234_0 >= KW_DEFAULT && LA234_0 <= KW_DEFINED)||(LA234_0 >= KW_DELIMITED && LA234_0 <= KW_DESC)||(LA234_0 >= KW_DETAIL && LA234_0 <= KW_DISABLE)||(LA234_0 >= KW_DISTRIBUTE && LA234_0 <= KW_DO)||LA234_0==KW_DOW||(LA234_0 >= KW_DUMP && LA234_0 <= KW_ELEM_TYPE)||LA234_0==KW_ENABLE||(LA234_0 >= KW_ENFORCED && LA234_0 <= KW_EVERY)||(LA234_0 >= KW_EXCLUSIVE && LA234_0 <= KW_EXECUTED)||(LA234_0 >= KW_EXPLAIN && LA234_0 <= KW_EXPRESSION)||(LA234_0 >= KW_FIELDS && LA234_0 <= KW_FIRST)||(LA234_0 >= KW_FORMAT && LA234_0 <= KW_FORMATTED)||LA234_0==KW_FUNCTIONS||(LA234_0 >= KW_HOUR && LA234_0 <= KW_IDXPROPERTIES)||(LA234_0 >= KW_INDEX && LA234_0 <= KW_INDEXES)||(LA234_0 >= KW_INPATH && LA234_0 <= KW_INPUTFORMAT)||(LA234_0 >= KW_ISOLATION && LA234_0 <= KW_JAR)||(LA234_0 >= KW_JOINCOST && LA234_0 <= KW_LAST)||LA234_0==KW_LEVEL||(LA234_0 >= KW_LIMIT && LA234_0 <= KW_LOAD)||(LA234_0 >= KW_LOCATION && LA234_0 <= KW_LONG)||(LA234_0 >= KW_MANAGEDLOCATION && LA234_0 <= KW_MANAGEMENT)||(LA234_0 >= KW_MAPJOIN && LA234_0 <= KW_MATERIALIZED)||LA234_0==KW_METADATA||(LA234_0 >= KW_MINUTE && LA234_0 <= KW_MONTH)||(LA234_0 >= KW_MOVE && LA234_0 <= KW_MSCK)||(LA234_0 >= KW_NORELY && LA234_0 <= KW_NOSCAN)||LA234_0==KW_NOVALIDATE||LA234_0==KW_NULLS||LA234_0==KW_OFFSET||(LA234_0 >= KW_OPERATOR && LA234_0 <= KW_OPTION)||(LA234_0 >= KW_OUTPUTDRIVER && LA234_0 <= KW_OUTPUTFORMAT)||(LA234_0 >= KW_OVERWRITE && LA234_0 <= KW_OWNER)||(LA234_0 >= KW_PARTITIONED && LA234_0 <= KW_PATH)||(LA234_0 >= KW_PLAN && LA234_0 <= KW_POOL)||LA234_0==KW_PRINCIPALS||(LA234_0 >= KW_PURGE && LA234_0 <= KW_QUERY_PARALLELISM)||LA234_0==KW_READ||(LA234_0 >= KW_REBUILD && LA234_0 <= KW_RECORDWRITER)||(LA234_0 >= KW_RELOAD && LA234_0 <= KW_RESTRICT)||LA234_0==KW_REWRITE||(LA234_0 >= KW_ROLE && LA234_0 <= KW_ROLES)||(LA234_0 >= KW_SCHEDULED && LA234_0 <= KW_SECOND)||(LA234_0 >= KW_SEMI && LA234_0 <= KW_SERVER)||(LA234_0 >= KW_SETS && LA234_0 <= KW_SKEWED)||(LA234_0 >= KW_SNAPSHOT && LA234_0 <= KW_SSL)||(LA234_0 >= KW_STATISTICS && LA234_0 <= KW_SUMMARY)||LA234_0==KW_TABLES||(LA234_0 >= KW_TBLPROPERTIES && LA234_0 <= KW_TERMINATED)||LA234_0==KW_TINYINT||(LA234_0 >= KW_TOUCH && LA234_0 <= KW_TRANSACTIONS)||LA234_0==KW_UNARCHIVE||LA234_0==KW_UNDO||LA234_0==KW_UNIONTYPE||(LA234_0 >= KW_UNLOCK && LA234_0 <= KW_UNSIGNED)||(LA234_0 >= KW_URI && LA234_0 <= KW_USE)||(LA234_0 >= KW_UTC && LA234_0 <= KW_VALIDATE)||LA234_0==KW_VALUE_TYPE||(LA234_0 >= KW_VECTORIZATION && LA234_0 <= KW_WEEK)||LA234_0==KW_WHILE||(LA234_0 >= KW_WORK && LA234_0 <= KW_ZONE)||LA234_0==KW_BATCH||LA234_0==KW_DAYOFWEEK||LA234_0==KW_HOLD_DDLTIME||LA234_0==KW_IGNORE||LA234_0==KW_NO_DROP||LA234_0==KW_OFFLINE||LA234_0==KW_PROTECTION||LA234_0==KW_READONLY||LA234_0==KW_TIMESTAMPTZ) ) {
				alt234=1;
			}
			else if ( (LA234_0==StringLiteral) ) {
				alt234=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 234, 0, input);
				throw nvae;
			}

			switch (alt234) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:7: identifier
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_identifier_in_showStmtIdentifier13059);
					identifier774=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier774.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2180:7: StringLiteral
					{
					root_0 = (ASTNode)adaptor.nil();


					StringLiteral775=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStmtIdentifier13067); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					StringLiteral775_tree = (ASTNode)adaptor.create(StringLiteral775);
					adaptor.addChild(root_0, StringLiteral775_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showStmtIdentifier"


	public static class tableComment_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableComment"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2183:1: tableComment : KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) ;
	public final HiveParser.tableComment_return tableComment() throws RecognitionException {
		HiveParser.tableComment_return retval = new HiveParser.tableComment_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT776=null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT776_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

		 pushMsg("table's comment", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2186:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2187:7: KW_COMMENT comment= StringLiteral
			{
			KW_COMMENT776=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_tableComment13100); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT776);

			comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableComment13104); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

			// AST REWRITE
			// elements: comment
			// token labels: comment
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2187:41: -> ^( TOK_TABLECOMMENT $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2187:44: ^( TOK_TABLECOMMENT $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLECOMMENT, "TOK_TABLECOMMENT"), root_1);
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableComment"


	public static class createTablePartitionSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createTablePartitionSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2190:1: createTablePartitionSpec : KW_PARTITIONED KW_BY LPAREN (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec ) RPAREN -> {$opt1.tree != null}? $opt1 -> $opt2;
	public final HiveParser.createTablePartitionSpec_return createTablePartitionSpec() throws RecognitionException {
		HiveParser.createTablePartitionSpec_return retval = new HiveParser.createTablePartitionSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_PARTITIONED777=null;
		Token KW_BY778=null;
		Token LPAREN779=null;
		Token RPAREN780=null;
		ParserRuleReturnScope opt1 =null;
		ParserRuleReturnScope opt2 =null;

		ASTNode KW_PARTITIONED777_tree=null;
		ASTNode KW_BY778_tree=null;
		ASTNode LPAREN779_tree=null;
		ASTNode RPAREN780_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_KW_PARTITIONED=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONED");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_createTablePartitionColumnSpec=new RewriteRuleSubtreeStream(adaptor,"rule createTablePartitionColumnSpec");
		RewriteRuleSubtreeStream stream_createTablePartitionColumnTypeSpec=new RewriteRuleSubtreeStream(adaptor,"rule createTablePartitionColumnTypeSpec");

		 pushMsg("create table partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2193:5: ( KW_PARTITIONED KW_BY LPAREN (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec ) RPAREN -> {$opt1.tree != null}? $opt1 -> $opt2)
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2193:7: KW_PARTITIONED KW_BY LPAREN (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec ) RPAREN
			{
			KW_PARTITIONED777=(Token)match(input,KW_PARTITIONED,FOLLOW_KW_PARTITIONED_in_createTablePartitionSpec13141); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_PARTITIONED.add(KW_PARTITIONED777);

			KW_BY778=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_createTablePartitionSpec13143); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY778);

			LPAREN779=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createTablePartitionSpec13145); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN779);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2193:35: (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec )
			int alt235=2;
			int LA235_0 = input.LA(1);
			if ( (LA235_0==Identifier) ) {
				int LA235_1 = input.LA(2);
				if ( (LA235_1==KW_ARRAY||(LA235_1 >= KW_BIGINT && LA235_1 <= KW_BOOLEAN)||LA235_1==KW_CHAR||(LA235_1 >= KW_DATE && LA235_1 <= KW_DATETIME)||LA235_1==KW_DECIMAL||LA235_1==KW_DOUBLE||LA235_1==KW_FLOAT||LA235_1==KW_INT||LA235_1==KW_MAP||LA235_1==KW_SMALLINT||(LA235_1 >= KW_STRING && LA235_1 <= KW_STRUCT)||(LA235_1 >= KW_TIMESTAMP && LA235_1 <= KW_TINYINT)||LA235_1==KW_UNIONTYPE||LA235_1==KW_VARCHAR) ) {
					alt235=1;
				}
				else if ( (LA235_1==COMMA||LA235_1==RPAREN) ) {
					alt235=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 235, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( ((LA235_0 >= KW_ABORT && LA235_0 <= KW_AFTER)||LA235_0==KW_ALLOC_FRACTION||LA235_0==KW_ANALYZE||LA235_0==KW_ARCHIVE||(LA235_0 >= KW_ASC && LA235_0 <= KW_AT)||(LA235_0 >= KW_AUTOCOMMIT && LA235_0 <= KW_BEFORE)||(LA235_0 >= KW_BUCKET && LA235_0 <= KW_BUCKETS)||(LA235_0 >= KW_CACHE && LA235_0 <= KW_CASCADE)||(LA235_0 >= KW_CBO && LA235_0 <= KW_CHANGE)||(LA235_0 >= KW_CHECK && LA235_0 <= KW_COLLECTION)||(LA235_0 >= KW_COLUMNS && LA235_0 <= KW_COMMENT)||(LA235_0 >= KW_COMPACT && LA235_0 <= KW_CONCATENATE)||(LA235_0 >= KW_CONTINUE && LA235_0 <= KW_COST)||LA235_0==KW_CRON||LA235_0==KW_DATA||LA235_0==KW_DATABASES||(LA235_0 >= KW_DATETIME && LA235_0 <= KW_DEBUG)||(LA235_0 >= KW_DEFAULT && LA235_0 <= KW_DEFINED)||(LA235_0 >= KW_DELIMITED && LA235_0 <= KW_DESC)||(LA235_0 >= KW_DETAIL && LA235_0 <= KW_DISABLE)||(LA235_0 >= KW_DISTRIBUTE && LA235_0 <= KW_DO)||LA235_0==KW_DOW||(LA235_0 >= KW_DUMP && LA235_0 <= KW_ELEM_TYPE)||LA235_0==KW_ENABLE||(LA235_0 >= KW_ENFORCED && LA235_0 <= KW_EVERY)||(LA235_0 >= KW_EXCLUSIVE && LA235_0 <= KW_EXECUTED)||(LA235_0 >= KW_EXPLAIN && LA235_0 <= KW_EXPRESSION)||(LA235_0 >= KW_FIELDS && LA235_0 <= KW_FIRST)||(LA235_0 >= KW_FORMAT && LA235_0 <= KW_FORMATTED)||LA235_0==KW_FUNCTIONS||(LA235_0 >= KW_HOUR && LA235_0 <= KW_IDXPROPERTIES)||(LA235_0 >= KW_INDEX && LA235_0 <= KW_INDEXES)||(LA235_0 >= KW_INPATH && LA235_0 <= KW_INPUTFORMAT)||(LA235_0 >= KW_ISOLATION && LA235_0 <= KW_JAR)||(LA235_0 >= KW_JOINCOST && LA235_0 <= KW_LAST)||LA235_0==KW_LEVEL||(LA235_0 >= KW_LIMIT && LA235_0 <= KW_LOAD)||(LA235_0 >= KW_LOCATION && LA235_0 <= KW_LONG)||(LA235_0 >= KW_MANAGEDLOCATION && LA235_0 <= KW_MANAGEMENT)||(LA235_0 >= KW_MAPJOIN && LA235_0 <= KW_MATERIALIZED)||LA235_0==KW_METADATA||(LA235_0 >= KW_MINUTE && LA235_0 <= KW_MONTH)||(LA235_0 >= KW_MOVE && LA235_0 <= KW_MSCK)||(LA235_0 >= KW_NORELY && LA235_0 <= KW_NOSCAN)||LA235_0==KW_NOVALIDATE||LA235_0==KW_NULLS||LA235_0==KW_OFFSET||(LA235_0 >= KW_OPERATOR && LA235_0 <= KW_OPTION)||(LA235_0 >= KW_OUTPUTDRIVER && LA235_0 <= KW_OUTPUTFORMAT)||(LA235_0 >= KW_OVERWRITE && LA235_0 <= KW_OWNER)||(LA235_0 >= KW_PARTITIONED && LA235_0 <= KW_PATH)||(LA235_0 >= KW_PLAN && LA235_0 <= KW_POOL)||LA235_0==KW_PRINCIPALS||(LA235_0 >= KW_PURGE && LA235_0 <= KW_QUERY_PARALLELISM)||LA235_0==KW_READ||(LA235_0 >= KW_REBUILD && LA235_0 <= KW_RECORDWRITER)||(LA235_0 >= KW_RELOAD && LA235_0 <= KW_RESTRICT)||LA235_0==KW_REWRITE||(LA235_0 >= KW_ROLE && LA235_0 <= KW_ROLES)||(LA235_0 >= KW_SCHEDULED && LA235_0 <= KW_SECOND)||(LA235_0 >= KW_SEMI && LA235_0 <= KW_SERVER)||(LA235_0 >= KW_SETS && LA235_0 <= KW_SKEWED)||(LA235_0 >= KW_SNAPSHOT && LA235_0 <= KW_SSL)||(LA235_0 >= KW_STATISTICS && LA235_0 <= KW_SUMMARY)||LA235_0==KW_TABLES||(LA235_0 >= KW_TBLPROPERTIES && LA235_0 <= KW_TERMINATED)||LA235_0==KW_TINYINT||(LA235_0 >= KW_TOUCH && LA235_0 <= KW_TRANSACTIONS)||LA235_0==KW_UNARCHIVE||LA235_0==KW_UNDO||LA235_0==KW_UNIONTYPE||(LA235_0 >= KW_UNLOCK && LA235_0 <= KW_UNSIGNED)||(LA235_0 >= KW_URI && LA235_0 <= KW_USE)||(LA235_0 >= KW_UTC && LA235_0 <= KW_VALIDATE)||LA235_0==KW_VALUE_TYPE||(LA235_0 >= KW_VECTORIZATION && LA235_0 <= KW_WEEK)||LA235_0==KW_WHILE||(LA235_0 >= KW_WORK && LA235_0 <= KW_ZONE)||LA235_0==KW_BATCH||LA235_0==KW_DAYOFWEEK||LA235_0==KW_HOLD_DDLTIME||LA235_0==KW_IGNORE||LA235_0==KW_NO_DROP||LA235_0==KW_OFFLINE||LA235_0==KW_PROTECTION||LA235_0==KW_READONLY||LA235_0==KW_TIMESTAMPTZ) ) {
				int LA235_2 = input.LA(2);
				if ( (LA235_2==KW_ARRAY||(LA235_2 >= KW_BIGINT && LA235_2 <= KW_BOOLEAN)||LA235_2==KW_CHAR||(LA235_2 >= KW_DATE && LA235_2 <= KW_DATETIME)||LA235_2==KW_DECIMAL||LA235_2==KW_DOUBLE||LA235_2==KW_FLOAT||LA235_2==KW_INT||LA235_2==KW_MAP||LA235_2==KW_SMALLINT||(LA235_2 >= KW_STRING && LA235_2 <= KW_STRUCT)||(LA235_2 >= KW_TIMESTAMP && LA235_2 <= KW_TINYINT)||LA235_2==KW_UNIONTYPE||LA235_2==KW_VARCHAR) ) {
					alt235=1;
				}
				else if ( (LA235_2==COMMA||LA235_2==RPAREN) ) {
					alt235=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 235, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 235, 0, input);
				throw nvae;
			}

			switch (alt235) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2193:36: opt1= createTablePartitionColumnTypeSpec
					{
					pushFollow(FOLLOW_createTablePartitionColumnTypeSpec_in_createTablePartitionSpec13152);
					opt1=createTablePartitionColumnTypeSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_createTablePartitionColumnTypeSpec.add(opt1.getTree());
					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2193:80: opt2= createTablePartitionColumnSpec
					{
					pushFollow(FOLLOW_createTablePartitionColumnSpec_in_createTablePartitionSpec13160);
					opt2=createTablePartitionColumnSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_createTablePartitionColumnSpec.add(opt2.getTree());
					}
					break;

			}

			RPAREN780=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createTablePartitionSpec13163); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN780);

			// AST REWRITE
			// elements: opt1, opt2
			// token labels: 
			// rule labels: opt1, opt2, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_opt1=new RewriteRuleSubtreeStream(adaptor,"rule opt1",opt1!=null?opt1.getTree():null);
			RewriteRuleSubtreeStream stream_opt2=new RewriteRuleSubtreeStream(adaptor,"rule opt2",opt2!=null?opt2.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2194:5: -> {$opt1.tree != null}? $opt1
			if ((opt1!=null?((ASTNode)opt1.getTree()):null) != null) {
				adaptor.addChild(root_0, stream_opt1.nextTree());
			}

			else // 2195:5: -> $opt2
			{
				adaptor.addChild(root_0, stream_opt2.nextTree());
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createTablePartitionSpec"


	public static class createTablePartitionColumnTypeSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createTablePartitionColumnTypeSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2198:1: createTablePartitionColumnTypeSpec : columnNameTypeConstraint ( COMMA columnNameTypeConstraint )* -> ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ ) ;
	public final HiveParser.createTablePartitionColumnTypeSpec_return createTablePartitionColumnTypeSpec() throws RecognitionException {
		HiveParser.createTablePartitionColumnTypeSpec_return retval = new HiveParser.createTablePartitionColumnTypeSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA782=null;
		ParserRuleReturnScope columnNameTypeConstraint781 =null;
		ParserRuleReturnScope columnNameTypeConstraint783 =null;

		ASTNode COMMA782_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameTypeConstraint=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeConstraint");

		 pushMsg("create table partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2201:5: ( columnNameTypeConstraint ( COMMA columnNameTypeConstraint )* -> ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2201:7: columnNameTypeConstraint ( COMMA columnNameTypeConstraint )*
			{
			pushFollow(FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec13210);
			columnNameTypeConstraint781=columnNameTypeConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameTypeConstraint.add(columnNameTypeConstraint781.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2201:32: ( COMMA columnNameTypeConstraint )*
			loop236:
			while (true) {
				int alt236=2;
				int LA236_0 = input.LA(1);
				if ( (LA236_0==COMMA) ) {
					alt236=1;
				}

				switch (alt236) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2201:33: COMMA columnNameTypeConstraint
					{
					COMMA782=(Token)match(input,COMMA,FOLLOW_COMMA_in_createTablePartitionColumnTypeSpec13213); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA782);

					pushFollow(FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec13215);
					columnNameTypeConstraint783=columnNameTypeConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameTypeConstraint.add(columnNameTypeConstraint783.getTree());
					}
					break;

				default :
					break loop236;
				}
			}

			// AST REWRITE
			// elements: columnNameTypeConstraint
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2202:5: -> ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2202:8: ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPARTCOLS, "TOK_TABLEPARTCOLS"), root_1);
				if ( !(stream_columnNameTypeConstraint.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameTypeConstraint.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameTypeConstraint.nextTree());
				}
				stream_columnNameTypeConstraint.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createTablePartitionColumnTypeSpec"


	public static class createTablePartitionColumnSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createTablePartitionColumnSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:1: createTablePartitionColumnSpec : columnName ( COMMA columnName )* -> ^( TOK_TABLEPARTCOLNAMES ( columnName )+ ) ;
	public final HiveParser.createTablePartitionColumnSpec_return createTablePartitionColumnSpec() throws RecognitionException {
		HiveParser.createTablePartitionColumnSpec_return retval = new HiveParser.createTablePartitionColumnSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA785=null;
		ParserRuleReturnScope columnName784 =null;
		ParserRuleReturnScope columnName786 =null;

		ASTNode COMMA785_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("create table partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:5: ( columnName ( COMMA columnName )* -> ^( TOK_TABLEPARTCOLNAMES ( columnName )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:7: columnName ( COMMA columnName )*
			{
			pushFollow(FOLLOW_columnName_in_createTablePartitionColumnSpec13257);
			columnName784=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(columnName784.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:18: ( COMMA columnName )*
			loop237:
			while (true) {
				int alt237=2;
				int LA237_0 = input.LA(1);
				if ( (LA237_0==COMMA) ) {
					alt237=1;
				}

				switch (alt237) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:19: COMMA columnName
					{
					COMMA785=(Token)match(input,COMMA,FOLLOW_COMMA_in_createTablePartitionColumnSpec13260); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA785);

					pushFollow(FOLLOW_columnName_in_createTablePartitionColumnSpec13262);
					columnName786=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName786.getTree());
					}
					break;

				default :
					break loop237;
				}
			}

			// AST REWRITE
			// elements: columnName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2209:5: -> ^( TOK_TABLEPARTCOLNAMES ( columnName )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2209:8: ^( TOK_TABLEPARTCOLNAMES ( columnName )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPARTCOLNAMES, "TOK_TABLEPARTCOLNAMES"), root_1);
				if ( !(stream_columnName.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnName.hasNext() ) {
					adaptor.addChild(root_1, stream_columnName.nextTree());
				}
				stream_columnName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createTablePartitionColumnSpec"


	public static class tableBuckets_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableBuckets"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2212:1: tableBuckets : KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) ;
	public final HiveParser.tableBuckets_return tableBuckets() throws RecognitionException {
		HiveParser.tableBuckets_return retval = new HiveParser.tableBuckets_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token num=null;
		Token KW_CLUSTERED787=null;
		Token KW_BY788=null;
		Token LPAREN789=null;
		Token RPAREN790=null;
		Token KW_SORTED791=null;
		Token KW_BY792=null;
		Token LPAREN793=null;
		Token RPAREN794=null;
		Token KW_INTO795=null;
		Token KW_BUCKETS796=null;
		ParserRuleReturnScope bucketCols =null;
		ParserRuleReturnScope sortCols =null;

		ASTNode num_tree=null;
		ASTNode KW_CLUSTERED787_tree=null;
		ASTNode KW_BY788_tree=null;
		ASTNode LPAREN789_tree=null;
		ASTNode RPAREN790_tree=null;
		ASTNode KW_SORTED791_tree=null;
		ASTNode KW_BY792_tree=null;
		ASTNode LPAREN793_tree=null;
		ASTNode RPAREN794_tree=null;
		ASTNode KW_INTO795_tree=null;
		ASTNode KW_BUCKETS796_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_BUCKETS=new RewriteRuleTokenStream(adaptor,"token KW_BUCKETS");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
		RewriteRuleSubtreeStream stream_columnNameOrderList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameOrderList");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("table buckets specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:5: ( KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2216:7: KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS
			{
			KW_CLUSTERED787=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_tableBuckets13310); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CLUSTERED.add(KW_CLUSTERED787);

			KW_BY788=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableBuckets13312); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY788);

			LPAREN789=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableBuckets13314); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN789);

			pushFollow(FOLLOW_columnNameList_in_tableBuckets13318);
			bucketCols=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(bucketCols.getTree());
			RPAREN790=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableBuckets13320); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN790);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2216:66: ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )?
			int alt238=2;
			int LA238_0 = input.LA(1);
			if ( (LA238_0==KW_SORTED) ) {
				alt238=1;
			}
			switch (alt238) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2216:67: KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN
					{
					KW_SORTED791=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_tableBuckets13323); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SORTED.add(KW_SORTED791);

					KW_BY792=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableBuckets13325); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY792);

					LPAREN793=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableBuckets13327); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN793);

					pushFollow(FOLLOW_columnNameOrderList_in_tableBuckets13331);
					sortCols=columnNameOrderList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameOrderList.add(sortCols.getTree());
					RPAREN794=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableBuckets13333); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN794);

					}
					break;

			}

			KW_INTO795=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_tableBuckets13337); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO795);

			num=(Token)match(input,Number,FOLLOW_Number_in_tableBuckets13341); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Number.add(num);

			KW_BUCKETS796=(Token)match(input,KW_BUCKETS,FOLLOW_KW_BUCKETS_in_tableBuckets13343); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BUCKETS.add(KW_BUCKETS796);

			// AST REWRITE
			// elements: bucketCols, num, sortCols
			// token labels: num
			// rule labels: bucketCols, sortCols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
			RewriteRuleSubtreeStream stream_bucketCols=new RewriteRuleSubtreeStream(adaptor,"rule bucketCols",bucketCols!=null?bucketCols.getTree():null);
			RewriteRuleSubtreeStream stream_sortCols=new RewriteRuleSubtreeStream(adaptor,"rule sortCols",sortCols!=null?sortCols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2217:5: -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2217:8: ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_BUCKETS, "TOK_ALTERTABLE_BUCKETS"), root_1);
				adaptor.addChild(root_1, stream_bucketCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2217:46: ( $sortCols)?
				if ( stream_sortCols.hasNext() ) {
					adaptor.addChild(root_1, stream_sortCols.nextTree());
				}
				stream_sortCols.reset();

				adaptor.addChild(root_1, stream_num.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableBuckets"


	public static class tableSkewed_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableSkewed"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2220:1: tableSkewed : KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) ;
	public final HiveParser.tableSkewed_return tableSkewed() throws RecognitionException {
		HiveParser.tableSkewed_return retval = new HiveParser.tableSkewed_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SKEWED797=null;
		Token KW_BY798=null;
		Token LPAREN799=null;
		Token RPAREN800=null;
		Token KW_ON801=null;
		Token LPAREN802=null;
		Token RPAREN803=null;
		ParserRuleReturnScope skewedCols =null;
		ParserRuleReturnScope skewedValues =null;
		ParserRuleReturnScope storedAsDirs804 =null;

		ASTNode KW_SKEWED797_tree=null;
		ASTNode KW_BY798_tree=null;
		ASTNode LPAREN799_tree=null;
		ASTNode RPAREN800_tree=null;
		ASTNode KW_ON801_tree=null;
		ASTNode LPAREN802_tree=null;
		ASTNode RPAREN803_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleSubtreeStream stream_skewedValueElement=new RewriteRuleSubtreeStream(adaptor,"rule skewedValueElement");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
		RewriteRuleSubtreeStream stream_storedAsDirs=new RewriteRuleSubtreeStream(adaptor,"rule storedAsDirs");

		 pushMsg("table skewed specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2223:5: ( KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:6: KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )?
			{
			KW_SKEWED797=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_tableSkewed13395); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SKEWED.add(KW_SKEWED797);

			KW_BY798=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableSkewed13397); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY798);

			LPAREN799=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableSkewed13399); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN799);

			pushFollow(FOLLOW_columnNameList_in_tableSkewed13403);
			skewedCols=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(skewedCols.getTree());
			RPAREN800=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableSkewed13405); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN800);

			KW_ON801=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_tableSkewed13407); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON801);

			LPAREN802=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableSkewed13409); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN802);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:75: (skewedValues= skewedValueElement )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:76: skewedValues= skewedValueElement
			{
			pushFollow(FOLLOW_skewedValueElement_in_tableSkewed13414);
			skewedValues=skewedValueElement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedValueElement.add(skewedValues.getTree());
			}

			RPAREN803=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableSkewed13417); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN803);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:116: ( ( storedAsDirs )=> storedAsDirs )?
			int alt239=2;
			int LA239_0 = input.LA(1);
			if ( (LA239_0==KW_STORED) ) {
				int LA239_1 = input.LA(2);
				if ( (LA239_1==KW_AS) ) {
					int LA239_7 = input.LA(3);
					if ( (LA239_7==KW_DIRECTORIES) ) {
						int LA239_9 = input.LA(4);
						if ( (synpred17_HiveParser()) ) {
							alt239=1;
						}
					}
				}
			}
			switch (alt239) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:117: ( storedAsDirs )=> storedAsDirs
					{
					pushFollow(FOLLOW_storedAsDirs_in_tableSkewed13426);
					storedAsDirs804=storedAsDirs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_storedAsDirs.add(storedAsDirs804.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: skewedValues, storedAsDirs, skewedCols
			// token labels: 
			// rule labels: skewedCols, skewedValues, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_skewedCols=new RewriteRuleSubtreeStream(adaptor,"rule skewedCols",skewedCols!=null?skewedCols.getTree():null);
			RewriteRuleSubtreeStream stream_skewedValues=new RewriteRuleSubtreeStream(adaptor,"rule skewedValues",skewedValues!=null?skewedValues.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2225:5: -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2225:8: ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLESKEWED, "TOK_TABLESKEWED"), root_1);
				adaptor.addChild(root_1, stream_skewedCols.nextTree());
				adaptor.addChild(root_1, stream_skewedValues.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2225:52: ( storedAsDirs )?
				if ( stream_storedAsDirs.hasNext() ) {
					adaptor.addChild(root_1, stream_storedAsDirs.nextTree());
				}
				stream_storedAsDirs.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableSkewed"


	public static class rowFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rowFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:1: rowFormat : ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) );
	public final HiveParser.rowFormat_return rowFormat() throws RecognitionException {
		HiveParser.rowFormat_return retval = new HiveParser.rowFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope rowFormatSerde805 =null;
		ParserRuleReturnScope rowFormatDelimited806 =null;

		RewriteRuleSubtreeStream stream_rowFormatSerde=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatSerde");
		RewriteRuleSubtreeStream stream_rowFormatDelimited=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatDelimited");

		 pushMsg("serde specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2231:5: ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) )
			int alt240=3;
			int LA240_0 = input.LA(1);
			if ( (LA240_0==KW_ROW) ) {
				int LA240_1 = input.LA(2);
				if ( (LA240_1==KW_FORMAT) ) {
					int LA240_27 = input.LA(3);
					if ( (LA240_27==KW_SERDE) ) {
						alt240=1;
					}
					else if ( (LA240_27==KW_DELIMITED) ) {
						alt240=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 240, 27, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 240, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( (LA240_0==EOF||LA240_0==COMMA||LA240_0==KW_CLUSTER||LA240_0==KW_DISTRIBUTE||LA240_0==KW_EXCEPT||LA240_0==KW_FROM||LA240_0==KW_GROUP||LA240_0==KW_HAVING||LA240_0==KW_INSERT||LA240_0==KW_INTERSECT||LA240_0==KW_LATERAL||LA240_0==KW_LIMIT||LA240_0==KW_MAP||LA240_0==KW_MINUS||LA240_0==KW_ORDER||(LA240_0 >= KW_RECORDREADER && LA240_0 <= KW_REDUCE)||LA240_0==KW_SELECT||LA240_0==KW_SORT||LA240_0==KW_UNION||LA240_0==KW_USING||LA240_0==KW_WHERE||LA240_0==KW_WINDOW||LA240_0==RPAREN) ) {
				alt240=3;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 240, 0, input);
				throw nvae;
			}

			switch (alt240) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2231:7: rowFormatSerde
					{
					pushFollow(FOLLOW_rowFormatSerde_in_rowFormat13474);
					rowFormatSerde805=rowFormatSerde();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatSerde.add(rowFormatSerde805.getTree());
					// AST REWRITE
					// elements: rowFormatSerde
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2231:22: -> ^( TOK_SERDE rowFormatSerde )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2231:25: ^( TOK_SERDE rowFormatSerde )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);
						adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:7: rowFormatDelimited
					{
					pushFollow(FOLLOW_rowFormatDelimited_in_rowFormat13490);
					rowFormatDelimited806=rowFormatDelimited();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatDelimited.add(rowFormatDelimited806.getTree());
					// AST REWRITE
					// elements: rowFormatDelimited
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2232:26: -> ^( TOK_SERDE rowFormatDelimited )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:29: ^( TOK_SERDE rowFormatDelimited )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);
						adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2233:9: 
					{
					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2233:9: -> ^( TOK_SERDE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2233:12: ^( TOK_SERDE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rowFormat"


	public static class recordReader_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "recordReader"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:1: recordReader : ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) );
	public final HiveParser.recordReader_return recordReader() throws RecognitionException {
		HiveParser.recordReader_return retval = new HiveParser.recordReader_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RECORDREADER807=null;
		Token StringLiteral808=null;

		ASTNode KW_RECORDREADER807_tree=null;
		ASTNode StringLiteral808_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_RECORDREADER=new RewriteRuleTokenStream(adaptor,"token KW_RECORDREADER");

		 pushMsg("record reader specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2239:5: ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) )
			int alt241=2;
			int LA241_0 = input.LA(1);
			if ( (LA241_0==KW_RECORDREADER) ) {
				alt241=1;
			}
			else if ( (LA241_0==EOF||LA241_0==COMMA||LA241_0==KW_CLUSTER||LA241_0==KW_DISTRIBUTE||LA241_0==KW_EXCEPT||LA241_0==KW_FROM||LA241_0==KW_GROUP||LA241_0==KW_HAVING||LA241_0==KW_INSERT||LA241_0==KW_INTERSECT||LA241_0==KW_LATERAL||LA241_0==KW_LIMIT||LA241_0==KW_MAP||LA241_0==KW_MINUS||LA241_0==KW_ORDER||LA241_0==KW_REDUCE||LA241_0==KW_SELECT||LA241_0==KW_SORT||LA241_0==KW_UNION||LA241_0==KW_WHERE||LA241_0==KW_WINDOW||LA241_0==RPAREN) ) {
				alt241=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 241, 0, input);
				throw nvae;
			}

			switch (alt241) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2239:7: KW_RECORDREADER StringLiteral
					{
					KW_RECORDREADER807=(Token)match(input,KW_RECORDREADER,FOLLOW_KW_RECORDREADER_in_recordReader13539); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RECORDREADER.add(KW_RECORDREADER807);

					StringLiteral808=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_recordReader13541); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral808);

					// AST REWRITE
					// elements: StringLiteral
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2239:37: -> ^( TOK_RECORDREADER StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2239:40: ^( TOK_RECORDREADER StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2240:9: 
					{
					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2240:9: -> ^( TOK_RECORDREADER )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2240:12: ^( TOK_RECORDREADER )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "recordReader"


	public static class recordWriter_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "recordWriter"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2243:1: recordWriter : ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) );
	public final HiveParser.recordWriter_return recordWriter() throws RecognitionException {
		HiveParser.recordWriter_return retval = new HiveParser.recordWriter_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RECORDWRITER809=null;
		Token StringLiteral810=null;

		ASTNode KW_RECORDWRITER809_tree=null;
		ASTNode StringLiteral810_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_RECORDWRITER=new RewriteRuleTokenStream(adaptor,"token KW_RECORDWRITER");

		 pushMsg("record writer specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:5: ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) )
			int alt242=2;
			int LA242_0 = input.LA(1);
			if ( (LA242_0==KW_RECORDWRITER) ) {
				alt242=1;
			}
			else if ( (LA242_0==KW_USING) ) {
				alt242=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 242, 0, input);
				throw nvae;
			}

			switch (alt242) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:7: KW_RECORDWRITER StringLiteral
					{
					KW_RECORDWRITER809=(Token)match(input,KW_RECORDWRITER,FOLLOW_KW_RECORDWRITER_in_recordWriter13590); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RECORDWRITER.add(KW_RECORDWRITER809);

					StringLiteral810=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_recordWriter13592); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral810);

					// AST REWRITE
					// elements: StringLiteral
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2246:37: -> ^( TOK_RECORDWRITER StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:40: ^( TOK_RECORDWRITER StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2247:9: 
					{
					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2247:9: -> ^( TOK_RECORDWRITER )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2247:12: ^( TOK_RECORDWRITER )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "recordWriter"


	public static class rowFormatSerde_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rowFormatSerde"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2250:1: rowFormatSerde : KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) ;
	public final HiveParser.rowFormatSerde_return rowFormatSerde() throws RecognitionException {
		HiveParser.rowFormatSerde_return retval = new HiveParser.rowFormatSerde_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token name=null;
		Token KW_ROW811=null;
		Token KW_FORMAT812=null;
		Token KW_SERDE813=null;
		Token KW_WITH814=null;
		Token KW_SERDEPROPERTIES815=null;
		ParserRuleReturnScope serdeprops =null;

		ASTNode name_tree=null;
		ASTNode KW_ROW811_tree=null;
		ASTNode KW_FORMAT812_tree=null;
		ASTNode KW_SERDE813_tree=null;
		ASTNode KW_WITH814_tree=null;
		ASTNode KW_SERDEPROPERTIES815_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_ROW=new RewriteRuleTokenStream(adaptor,"token KW_ROW");
		RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
		RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
		RewriteRuleTokenStream stream_KW_FORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FORMAT");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("serde format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2253:5: ( KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2253:7: KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
			{
			KW_ROW811=(Token)match(input,KW_ROW,FOLLOW_KW_ROW_in_rowFormatSerde13641); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROW.add(KW_ROW811);

			KW_FORMAT812=(Token)match(input,KW_FORMAT,FOLLOW_KW_FORMAT_in_rowFormatSerde13643); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FORMAT.add(KW_FORMAT812);

			KW_SERDE813=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_rowFormatSerde13645); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE813);

			name=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_rowFormatSerde13649); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(name);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2253:52: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
			int alt243=2;
			int LA243_0 = input.LA(1);
			if ( (LA243_0==KW_WITH) ) {
				alt243=1;
			}
			switch (alt243) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2253:53: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
					{
					KW_WITH814=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_rowFormatSerde13652); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH814);

					KW_SERDEPROPERTIES815=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde13654); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES815);

					pushFollow(FOLLOW_tableProperties_in_rowFormatSerde13658);
					serdeprops=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(serdeprops.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: serdeprops, name
			// token labels: name
			// rule labels: serdeprops, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_name=new RewriteRuleTokenStream(adaptor,"token name",name);
			RewriteRuleSubtreeStream stream_serdeprops=new RewriteRuleSubtreeStream(adaptor,"rule serdeprops",serdeprops!=null?serdeprops.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2254:5: -> ^( TOK_SERDENAME $name ( $serdeprops)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2254:8: ^( TOK_SERDENAME $name ( $serdeprops)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDENAME, "TOK_SERDENAME"), root_1);
				adaptor.addChild(root_1, stream_name.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2254:31: ( $serdeprops)?
				if ( stream_serdeprops.hasNext() ) {
					adaptor.addChild(root_1, stream_serdeprops.nextTree());
				}
				stream_serdeprops.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rowFormatSerde"


	public static class rowFormatDelimited_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rowFormatDelimited"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2257:1: rowFormatDelimited : KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) ;
	public final HiveParser.rowFormatDelimited_return rowFormatDelimited() throws RecognitionException {
		HiveParser.rowFormatDelimited_return retval = new HiveParser.rowFormatDelimited_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ROW816=null;
		Token KW_FORMAT817=null;
		Token KW_DELIMITED818=null;
		ParserRuleReturnScope tableRowFormatFieldIdentifier819 =null;
		ParserRuleReturnScope tableRowFormatCollItemsIdentifier820 =null;
		ParserRuleReturnScope tableRowFormatMapKeysIdentifier821 =null;
		ParserRuleReturnScope tableRowFormatLinesIdentifier822 =null;
		ParserRuleReturnScope tableRowNullFormat823 =null;

		ASTNode KW_ROW816_tree=null;
		ASTNode KW_FORMAT817_tree=null;
		ASTNode KW_DELIMITED818_tree=null;
		RewriteRuleTokenStream stream_KW_ROW=new RewriteRuleTokenStream(adaptor,"token KW_ROW");
		RewriteRuleTokenStream stream_KW_DELIMITED=new RewriteRuleTokenStream(adaptor,"token KW_DELIMITED");
		RewriteRuleTokenStream stream_KW_FORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FORMAT");
		RewriteRuleSubtreeStream stream_tableRowNullFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowNullFormat");
		RewriteRuleSubtreeStream stream_tableRowFormatFieldIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatFieldIdentifier");
		RewriteRuleSubtreeStream stream_tableRowFormatCollItemsIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatCollItemsIdentifier");
		RewriteRuleSubtreeStream stream_tableRowFormatMapKeysIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatMapKeysIdentifier");
		RewriteRuleSubtreeStream stream_tableRowFormatLinesIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatLinesIdentifier");

		 pushMsg("serde properties specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2260:5: ( KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:7: KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )?
			{
			KW_ROW816=(Token)match(input,KW_ROW,FOLLOW_KW_ROW_in_rowFormatDelimited13710); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROW.add(KW_ROW816);

			KW_FORMAT817=(Token)match(input,KW_FORMAT,FOLLOW_KW_FORMAT_in_rowFormatDelimited13712); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FORMAT.add(KW_FORMAT817);

			KW_DELIMITED818=(Token)match(input,KW_DELIMITED,FOLLOW_KW_DELIMITED_in_rowFormatDelimited13714); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DELIMITED.add(KW_DELIMITED818);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:37: ( tableRowFormatFieldIdentifier )?
			int alt244=2;
			int LA244_0 = input.LA(1);
			if ( (LA244_0==KW_FIELDS) ) {
				alt244=1;
			}
			switch (alt244) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:37: tableRowFormatFieldIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited13716);
					tableRowFormatFieldIdentifier819=tableRowFormatFieldIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatFieldIdentifier.add(tableRowFormatFieldIdentifier819.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:68: ( tableRowFormatCollItemsIdentifier )?
			int alt245=2;
			int LA245_0 = input.LA(1);
			if ( (LA245_0==KW_COLLECTION) ) {
				alt245=1;
			}
			switch (alt245) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:68: tableRowFormatCollItemsIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited13719);
					tableRowFormatCollItemsIdentifier820=tableRowFormatCollItemsIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatCollItemsIdentifier.add(tableRowFormatCollItemsIdentifier820.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:103: ( tableRowFormatMapKeysIdentifier )?
			int alt246=2;
			alt246 = dfa246.predict(input);
			switch (alt246) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:103: tableRowFormatMapKeysIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited13722);
					tableRowFormatMapKeysIdentifier821=tableRowFormatMapKeysIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatMapKeysIdentifier.add(tableRowFormatMapKeysIdentifier821.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:136: ( tableRowFormatLinesIdentifier )?
			int alt247=2;
			int LA247_0 = input.LA(1);
			if ( (LA247_0==KW_LINES) ) {
				alt247=1;
			}
			switch (alt247) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:136: tableRowFormatLinesIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited13725);
					tableRowFormatLinesIdentifier822=tableRowFormatLinesIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatLinesIdentifier.add(tableRowFormatLinesIdentifier822.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:167: ( tableRowNullFormat )?
			int alt248=2;
			int LA248_0 = input.LA(1);
			if ( (LA248_0==KW_NULL) ) {
				alt248=1;
			}
			switch (alt248) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:167: tableRowNullFormat
					{
					pushFollow(FOLLOW_tableRowNullFormat_in_rowFormatDelimited13728);
					tableRowNullFormat823=tableRowNullFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowNullFormat.add(tableRowNullFormat823.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableRowFormatLinesIdentifier, tableRowFormatFieldIdentifier, tableRowFormatCollItemsIdentifier, tableRowFormatMapKeysIdentifier, tableRowNullFormat
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2262:5: -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:8: ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDEPROPS, "TOK_SERDEPROPS"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:25: ( tableRowFormatFieldIdentifier )?
				if ( stream_tableRowFormatFieldIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatFieldIdentifier.nextTree());
				}
				stream_tableRowFormatFieldIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:56: ( tableRowFormatCollItemsIdentifier )?
				if ( stream_tableRowFormatCollItemsIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatCollItemsIdentifier.nextTree());
				}
				stream_tableRowFormatCollItemsIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:91: ( tableRowFormatMapKeysIdentifier )?
				if ( stream_tableRowFormatMapKeysIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatMapKeysIdentifier.nextTree());
				}
				stream_tableRowFormatMapKeysIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:124: ( tableRowFormatLinesIdentifier )?
				if ( stream_tableRowFormatLinesIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatLinesIdentifier.nextTree());
				}
				stream_tableRowFormatLinesIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:155: ( tableRowNullFormat )?
				if ( stream_tableRowNullFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowNullFormat.nextTree());
				}
				stream_tableRowNullFormat.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rowFormatDelimited"


	public static class tableRowFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2265:1: tableRowFormat : ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) );
	public final HiveParser.tableRowFormat_return tableRowFormat() throws RecognitionException {
		HiveParser.tableRowFormat_return retval = new HiveParser.tableRowFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope rowFormatDelimited824 =null;
		ParserRuleReturnScope rowFormatSerde825 =null;

		RewriteRuleSubtreeStream stream_rowFormatSerde=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatSerde");
		RewriteRuleSubtreeStream stream_rowFormatDelimited=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatDelimited");

		 pushMsg("table row format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2268:5: ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) )
			int alt249=2;
			int LA249_0 = input.LA(1);
			if ( (LA249_0==KW_ROW) ) {
				int LA249_1 = input.LA(2);
				if ( (LA249_1==KW_FORMAT) ) {
					int LA249_2 = input.LA(3);
					if ( (LA249_2==KW_DELIMITED) ) {
						alt249=1;
					}
					else if ( (LA249_2==KW_SERDE) ) {
						alt249=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 249, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 249, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 249, 0, input);
				throw nvae;
			}

			switch (alt249) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2269:7: rowFormatDelimited
					{
					pushFollow(FOLLOW_rowFormatDelimited_in_tableRowFormat13787);
					rowFormatDelimited824=rowFormatDelimited();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatDelimited.add(rowFormatDelimited824.getTree());
					// AST REWRITE
					// elements: rowFormatDelimited
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2270:5: -> ^( TOK_TABLEROWFORMAT rowFormatDelimited )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2270:8: ^( TOK_TABLEROWFORMAT rowFormatDelimited )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMAT, "TOK_TABLEROWFORMAT"), root_1);
						adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2271:7: rowFormatSerde
					{
					pushFollow(FOLLOW_rowFormatSerde_in_tableRowFormat13807);
					rowFormatSerde825=rowFormatSerde();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatSerde.add(rowFormatSerde825.getTree());
					// AST REWRITE
					// elements: rowFormatSerde
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2272:5: -> ^( TOK_TABLESERIALIZER rowFormatSerde )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2272:8: ^( TOK_TABLESERIALIZER rowFormatSerde )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLESERIALIZER, "TOK_TABLESERIALIZER"), root_1);
						adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormat"


	public static class tablePropertiesPrefixed_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tablePropertiesPrefixed"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2275:1: tablePropertiesPrefixed : KW_TBLPROPERTIES ! tableProperties ;
	public final HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed() throws RecognitionException {
		HiveParser.tablePropertiesPrefixed_return retval = new HiveParser.tablePropertiesPrefixed_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_TBLPROPERTIES826=null;
		ParserRuleReturnScope tableProperties827 =null;

		ASTNode KW_TBLPROPERTIES826_tree=null;

		 pushMsg("table properties with prefix", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2278:5: ( KW_TBLPROPERTIES ! tableProperties )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2279:9: KW_TBLPROPERTIES ! tableProperties
			{
			root_0 = (ASTNode)adaptor.nil();


			KW_TBLPROPERTIES826=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed13854); if (state.failed) return retval;
			pushFollow(FOLLOW_tableProperties_in_tablePropertiesPrefixed13857);
			tableProperties827=tableProperties();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, tableProperties827.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tablePropertiesPrefixed"


	public static class tableProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2282:1: tableProperties : LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) ;
	public final HiveParser.tableProperties_return tableProperties() throws RecognitionException {
		HiveParser.tableProperties_return retval = new HiveParser.tableProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN828=null;
		Token RPAREN830=null;
		ParserRuleReturnScope tablePropertiesList829 =null;

		ASTNode LPAREN828_tree=null;
		ASTNode RPAREN830_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_tablePropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesList");

		 pushMsg("table properties", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:5: ( LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2286:7: LPAREN tablePropertiesList RPAREN
			{
			LPAREN828=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableProperties13890); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN828);

			pushFollow(FOLLOW_tablePropertiesList_in_tableProperties13892);
			tablePropertiesList829=tablePropertiesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tablePropertiesList.add(tablePropertiesList829.getTree());
			RPAREN830=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableProperties13894); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN830);

			// AST REWRITE
			// elements: tablePropertiesList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2286:41: -> ^( TOK_TABLEPROPERTIES tablePropertiesList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2286:44: ^( TOK_TABLEPROPERTIES tablePropertiesList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPERTIES, "TOK_TABLEPROPERTIES"), root_1);
				adaptor.addChild(root_1, stream_tablePropertiesList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableProperties"


	public static class tablePropertiesList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tablePropertiesList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2289:1: tablePropertiesList : ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) );
	public final HiveParser.tablePropertiesList_return tablePropertiesList() throws RecognitionException {
		HiveParser.tablePropertiesList_return retval = new HiveParser.tablePropertiesList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA832=null;
		Token COMMA835=null;
		ParserRuleReturnScope keyValueProperty831 =null;
		ParserRuleReturnScope keyValueProperty833 =null;
		ParserRuleReturnScope keyProperty834 =null;
		ParserRuleReturnScope keyProperty836 =null;

		ASTNode COMMA832_tree=null;
		ASTNode COMMA835_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");
		RewriteRuleSubtreeStream stream_keyProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyProperty");

		 pushMsg("table properties list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2292:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) )
			int alt252=2;
			int LA252_0 = input.LA(1);
			if ( (LA252_0==StringLiteral) ) {
				int LA252_1 = input.LA(2);
				if ( (LA252_1==EQUAL) ) {
					alt252=1;
				}
				else if ( (LA252_1==COMMA||LA252_1==RPAREN) ) {
					alt252=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 252, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 252, 0, input);
				throw nvae;
			}

			switch (alt252) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:7: keyValueProperty ( COMMA keyValueProperty )*
					{
					pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList13935);
					keyValueProperty831=keyValueProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty831.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:24: ( COMMA keyValueProperty )*
					loop250:
					while (true) {
						int alt250=2;
						int LA250_0 = input.LA(1);
						if ( (LA250_0==COMMA) ) {
							alt250=1;
						}

						switch (alt250) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:25: COMMA keyValueProperty
							{
							COMMA832=(Token)match(input,COMMA,FOLLOW_COMMA_in_tablePropertiesList13938); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA832);

							pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList13940);
							keyValueProperty833=keyValueProperty();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty833.getTree());
							}
							break;

						default :
							break loop250;
						}
					}

					// AST REWRITE
					// elements: keyValueProperty
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2293:50: -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:53: ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST"), root_1);
						if ( !(stream_keyValueProperty.hasNext()) ) {
							throw new RewriteEarlyExitException();
						}
						while ( stream_keyValueProperty.hasNext() ) {
							adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
						}
						stream_keyValueProperty.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2295:7: keyProperty ( COMMA keyProperty )*
					{
					pushFollow(FOLLOW_keyProperty_in_tablePropertiesList13965);
					keyProperty834=keyProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyProperty.add(keyProperty834.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2295:19: ( COMMA keyProperty )*
					loop251:
					while (true) {
						int alt251=2;
						int LA251_0 = input.LA(1);
						if ( (LA251_0==COMMA) ) {
							alt251=1;
						}

						switch (alt251) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2295:20: COMMA keyProperty
							{
							COMMA835=(Token)match(input,COMMA,FOLLOW_COMMA_in_tablePropertiesList13968); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA835);

							pushFollow(FOLLOW_keyProperty_in_tablePropertiesList13970);
							keyProperty836=keyProperty();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_keyProperty.add(keyProperty836.getTree());
							}
							break;

						default :
							break loop251;
						}
					}

					// AST REWRITE
					// elements: keyProperty
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2295:40: -> ^( TOK_TABLEPROPLIST ( keyProperty )+ )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2295:43: ^( TOK_TABLEPROPLIST ( keyProperty )+ )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST"), root_1);
						if ( !(stream_keyProperty.hasNext()) ) {
							throw new RewriteEarlyExitException();
						}
						while ( stream_keyProperty.hasNext() ) {
							adaptor.addChild(root_1, stream_keyProperty.nextTree());
						}
						stream_keyProperty.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tablePropertiesList"


	public static class keyValueProperty_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "keyValueProperty"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2298:1: keyValueProperty : key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) ;
	public final HiveParser.keyValueProperty_return keyValueProperty() throws RecognitionException {
		HiveParser.keyValueProperty_return retval = new HiveParser.keyValueProperty_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token key=null;
		Token value=null;
		Token EQUAL837=null;

		ASTNode key_tree=null;
		ASTNode value_tree=null;
		ASTNode EQUAL837_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");

		 pushMsg("specifying key/value property", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2301:5: (key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2302:7: key= StringLiteral EQUAL value= StringLiteral
			{
			key=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyValueProperty14016); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(key);

			EQUAL837=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_keyValueProperty14018); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_EQUAL.add(EQUAL837);

			value=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyValueProperty14022); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(value);

			// AST REWRITE
			// elements: key, value
			// token labels: value, key
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
			RewriteRuleTokenStream stream_key=new RewriteRuleTokenStream(adaptor,"token key",key);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2302:51: -> ^( TOK_TABLEPROPERTY $key $value)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2302:54: ^( TOK_TABLEPROPERTY $key $value)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY"), root_1);
				adaptor.addChild(root_1, stream_key.nextNode());
				adaptor.addChild(root_1, stream_value.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "keyValueProperty"


	public static class keyProperty_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "keyProperty"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2305:1: keyProperty : key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) ;
	public final HiveParser.keyProperty_return keyProperty() throws RecognitionException {
		HiveParser.keyProperty_return retval = new HiveParser.keyProperty_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token key=null;

		ASTNode key_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");

		 pushMsg("specifying key property", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2308:5: (key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2309:7: key= StringLiteral
			{
			key=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyProperty14069); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(key);

			// AST REWRITE
			// elements: key
			// token labels: key
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_key=new RewriteRuleTokenStream(adaptor,"token key",key);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2309:25: -> ^( TOK_TABLEPROPERTY $key TOK_NULL )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2309:28: ^( TOK_TABLEPROPERTY $key TOK_NULL )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY"), root_1);
				adaptor.addChild(root_1, stream_key.nextNode());
				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_NULL, "TOK_NULL"));
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "keyProperty"


	public static class tableRowFormatFieldIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatFieldIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2312:1: tableRowFormatFieldIdentifier : KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) ;
	public final HiveParser.tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatFieldIdentifier_return retval = new HiveParser.tableRowFormatFieldIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token fldIdnt=null;
		Token fldEscape=null;
		Token KW_FIELDS838=null;
		Token KW_TERMINATED839=null;
		Token KW_BY840=null;
		Token KW_ESCAPED841=null;
		Token KW_BY842=null;

		ASTNode fldIdnt_tree=null;
		ASTNode fldEscape_tree=null;
		ASTNode KW_FIELDS838_tree=null;
		ASTNode KW_TERMINATED839_tree=null;
		ASTNode KW_BY840_tree=null;
		ASTNode KW_ESCAPED841_tree=null;
		ASTNode KW_BY842_tree=null;
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_ESCAPED=new RewriteRuleTokenStream(adaptor,"token KW_ESCAPED");
		RewriteRuleTokenStream stream_KW_FIELDS=new RewriteRuleTokenStream(adaptor,"token KW_FIELDS");

		 pushMsg("table row format's field separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2315:5: ( KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2316:7: KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
			{
			KW_FIELDS838=(Token)match(input,KW_FIELDS,FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier14113); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FIELDS.add(KW_FIELDS838);

			KW_TERMINATED839=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier14115); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED839);

			KW_BY840=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier14117); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY840);

			fldIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier14121); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(fldIdnt);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2316:59: ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
			int alt253=2;
			int LA253_0 = input.LA(1);
			if ( (LA253_0==KW_ESCAPED) ) {
				alt253=1;
			}
			switch (alt253) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2316:60: KW_ESCAPED KW_BY fldEscape= StringLiteral
					{
					KW_ESCAPED841=(Token)match(input,KW_ESCAPED,FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier14124); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ESCAPED.add(KW_ESCAPED841);

					KW_BY842=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier14126); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY842);

					fldEscape=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier14130); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(fldEscape);

					}
					break;

			}

			// AST REWRITE
			// elements: fldEscape, fldIdnt
			// token labels: fldIdnt, fldEscape
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_fldIdnt=new RewriteRuleTokenStream(adaptor,"token fldIdnt",fldIdnt);
			RewriteRuleTokenStream stream_fldEscape=new RewriteRuleTokenStream(adaptor,"token fldEscape",fldEscape);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2317:5: -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2317:8: ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATFIELD, "TOK_TABLEROWFORMATFIELD"), root_1);
				adaptor.addChild(root_1, stream_fldIdnt.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2317:44: ( $fldEscape)?
				if ( stream_fldEscape.hasNext() ) {
					adaptor.addChild(root_1, stream_fldEscape.nextNode());
				}
				stream_fldEscape.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatFieldIdentifier"


	public static class tableRowFormatCollItemsIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatCollItemsIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2320:1: tableRowFormatCollItemsIdentifier : KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) ;
	public final HiveParser.tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatCollItemsIdentifier_return retval = new HiveParser.tableRowFormatCollItemsIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token collIdnt=null;
		Token KW_COLLECTION843=null;
		Token KW_ITEMS844=null;
		Token KW_TERMINATED845=null;
		Token KW_BY846=null;

		ASTNode collIdnt_tree=null;
		ASTNode KW_COLLECTION843_tree=null;
		ASTNode KW_ITEMS844_tree=null;
		ASTNode KW_TERMINATED845_tree=null;
		ASTNode KW_BY846_tree=null;
		RewriteRuleTokenStream stream_KW_COLLECTION=new RewriteRuleTokenStream(adaptor,"token KW_COLLECTION");
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_ITEMS=new RewriteRuleTokenStream(adaptor,"token KW_ITEMS");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");

		 pushMsg("table row format's column separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2323:5: ( KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2324:7: KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral
			{
			KW_COLLECTION843=(Token)match(input,KW_COLLECTION,FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier14182); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COLLECTION.add(KW_COLLECTION843);

			KW_ITEMS844=(Token)match(input,KW_ITEMS,FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier14184); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ITEMS.add(KW_ITEMS844);

			KW_TERMINATED845=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier14186); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED845);

			KW_BY846=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier14188); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY846);

			collIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier14192); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(collIdnt);

			// AST REWRITE
			// elements: collIdnt
			// token labels: collIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_collIdnt=new RewriteRuleTokenStream(adaptor,"token collIdnt",collIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2325:5: -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2325:8: ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATCOLLITEMS, "TOK_TABLEROWFORMATCOLLITEMS"), root_1);
				adaptor.addChild(root_1, stream_collIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatCollItemsIdentifier"


	public static class tableRowFormatMapKeysIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatMapKeysIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2328:1: tableRowFormatMapKeysIdentifier : KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) ;
	public final HiveParser.tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatMapKeysIdentifier_return retval = new HiveParser.tableRowFormatMapKeysIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token mapKeysIdnt=null;
		Token KW_MAP847=null;
		Token KW_KEYS848=null;
		Token KW_TERMINATED849=null;
		Token KW_BY850=null;

		ASTNode mapKeysIdnt_tree=null;
		ASTNode KW_MAP847_tree=null;
		ASTNode KW_KEYS848_tree=null;
		ASTNode KW_TERMINATED849_tree=null;
		ASTNode KW_BY850_tree=null;
		RewriteRuleTokenStream stream_KW_KEYS=new RewriteRuleTokenStream(adaptor,"token KW_KEYS");
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_MAP=new RewriteRuleTokenStream(adaptor,"token KW_MAP");

		 pushMsg("table row format's map key separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2331:5: ( KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2332:7: KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral
			{
			KW_MAP847=(Token)match(input,KW_MAP,FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier14238); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MAP.add(KW_MAP847);

			KW_KEYS848=(Token)match(input,KW_KEYS,FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier14240); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KEYS.add(KW_KEYS848);

			KW_TERMINATED849=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier14242); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED849);

			KW_BY850=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier14244); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY850);

			mapKeysIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier14248); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(mapKeysIdnt);

			// AST REWRITE
			// elements: mapKeysIdnt
			// token labels: mapKeysIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_mapKeysIdnt=new RewriteRuleTokenStream(adaptor,"token mapKeysIdnt",mapKeysIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2333:5: -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2333:8: ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATMAPKEYS, "TOK_TABLEROWFORMATMAPKEYS"), root_1);
				adaptor.addChild(root_1, stream_mapKeysIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatMapKeysIdentifier"


	public static class tableRowFormatLinesIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatLinesIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2336:1: tableRowFormatLinesIdentifier : KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) ;
	public final HiveParser.tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatLinesIdentifier_return retval = new HiveParser.tableRowFormatLinesIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token linesIdnt=null;
		Token KW_LINES851=null;
		Token KW_TERMINATED852=null;
		Token KW_BY853=null;

		ASTNode linesIdnt_tree=null;
		ASTNode KW_LINES851_tree=null;
		ASTNode KW_TERMINATED852_tree=null;
		ASTNode KW_BY853_tree=null;
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LINES=new RewriteRuleTokenStream(adaptor,"token KW_LINES");

		 pushMsg("table row format's line separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2339:5: ( KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2340:7: KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral
			{
			KW_LINES851=(Token)match(input,KW_LINES,FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier14294); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LINES.add(KW_LINES851);

			KW_TERMINATED852=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier14296); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED852);

			KW_BY853=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier14298); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY853);

			linesIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier14302); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(linesIdnt);

			// AST REWRITE
			// elements: linesIdnt
			// token labels: linesIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_linesIdnt=new RewriteRuleTokenStream(adaptor,"token linesIdnt",linesIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2341:5: -> ^( TOK_TABLEROWFORMATLINES $linesIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2341:8: ^( TOK_TABLEROWFORMATLINES $linesIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATLINES, "TOK_TABLEROWFORMATLINES"), root_1);
				adaptor.addChild(root_1, stream_linesIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatLinesIdentifier"


	public static class tableRowNullFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowNullFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2344:1: tableRowNullFormat : KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) ;
	public final HiveParser.tableRowNullFormat_return tableRowNullFormat() throws RecognitionException {
		HiveParser.tableRowNullFormat_return retval = new HiveParser.tableRowNullFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token nullIdnt=null;
		Token KW_NULL854=null;
		Token KW_DEFINED855=null;
		Token KW_AS856=null;

		ASTNode nullIdnt_tree=null;
		ASTNode KW_NULL854_tree=null;
		ASTNode KW_DEFINED855_tree=null;
		ASTNode KW_AS856_tree=null;
		RewriteRuleTokenStream stream_KW_NULL=new RewriteRuleTokenStream(adaptor,"token KW_NULL");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_DEFINED=new RewriteRuleTokenStream(adaptor,"token KW_DEFINED");

		 pushMsg("table row format's null specifier", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2347:5: ( KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2348:7: KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral
			{
			KW_NULL854=(Token)match(input,KW_NULL,FOLLOW_KW_NULL_in_tableRowNullFormat14348); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_NULL.add(KW_NULL854);

			KW_DEFINED855=(Token)match(input,KW_DEFINED,FOLLOW_KW_DEFINED_in_tableRowNullFormat14350); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DEFINED.add(KW_DEFINED855);

			KW_AS856=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableRowNullFormat14352); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS856);

			nullIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowNullFormat14356); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(nullIdnt);

			// AST REWRITE
			// elements: nullIdnt
			// token labels: nullIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_nullIdnt=new RewriteRuleTokenStream(adaptor,"token nullIdnt",nullIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2349:5: -> ^( TOK_TABLEROWFORMATNULL $nullIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2349:8: ^( TOK_TABLEROWFORMATNULL $nullIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATNULL, "TOK_TABLEROWFORMATNULL"), root_1);
				adaptor.addChild(root_1, stream_nullIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowNullFormat"


	public static class tableFileFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableFileFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2351:1: tableFileFormat : ( ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
	public final HiveParser.tableFileFormat_return tableFileFormat() throws RecognitionException {
		HiveParser.tableFileFormat_return retval = new HiveParser.tableFileFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token inFmt=null;
		Token outFmt=null;
		Token inDriver=null;
		Token outDriver=null;
		Token storageHandler=null;
		Token KW_STORED857=null;
		Token KW_AS858=null;
		Token KW_INPUTFORMAT859=null;
		Token KW_OUTPUTFORMAT860=null;
		Token KW_INPUTDRIVER861=null;
		Token KW_OUTPUTDRIVER862=null;
		Token KW_STORED863=null;
		Token KW_BY864=null;
		Token KW_WITH865=null;
		Token KW_SERDEPROPERTIES866=null;
		Token KW_STORED867=null;
		Token KW_AS868=null;
		ParserRuleReturnScope serdeprops =null;
		ParserRuleReturnScope genericSpec =null;

		ASTNode inFmt_tree=null;
		ASTNode outFmt_tree=null;
		ASTNode inDriver_tree=null;
		ASTNode outDriver_tree=null;
		ASTNode storageHandler_tree=null;
		ASTNode KW_STORED857_tree=null;
		ASTNode KW_AS858_tree=null;
		ASTNode KW_INPUTFORMAT859_tree=null;
		ASTNode KW_OUTPUTFORMAT860_tree=null;
		ASTNode KW_INPUTDRIVER861_tree=null;
		ASTNode KW_OUTPUTDRIVER862_tree=null;
		ASTNode KW_STORED863_tree=null;
		ASTNode KW_BY864_tree=null;
		ASTNode KW_WITH865_tree=null;
		ASTNode KW_SERDEPROPERTIES866_tree=null;
		ASTNode KW_STORED867_tree=null;
		ASTNode KW_AS868_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
		RewriteRuleTokenStream stream_KW_INPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_INPUTDRIVER");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_OUTPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTFORMAT");
		RewriteRuleTokenStream stream_KW_STORED=new RewriteRuleTokenStream(adaptor,"token KW_STORED");
		RewriteRuleTokenStream stream_KW_OUTPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTDRIVER");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("table file format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2354:5: ( ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
			int alt256=3;
			int LA256_0 = input.LA(1);
			if ( (LA256_0==KW_STORED) ) {
				int LA256_1 = input.LA(2);
				if ( (LA256_1==KW_AS) ) {
					int LA256_2 = input.LA(3);
					if ( (LA256_2==KW_INPUTFORMAT) ) {
						int LA256_4 = input.LA(4);
						if ( (synpred18_HiveParser()) ) {
							alt256=1;
						}
						else if ( (true) ) {
							alt256=3;
						}

					}
					else if ( (LA256_2==Identifier||(LA256_2 >= KW_ABORT && LA256_2 <= KW_AFTER)||LA256_2==KW_ALLOC_FRACTION||LA256_2==KW_ANALYZE||LA256_2==KW_ARCHIVE||(LA256_2 >= KW_ASC && LA256_2 <= KW_AT)||(LA256_2 >= KW_AUTOCOMMIT && LA256_2 <= KW_BEFORE)||(LA256_2 >= KW_BUCKET && LA256_2 <= KW_BUCKETS)||(LA256_2 >= KW_CACHE && LA256_2 <= KW_CASCADE)||(LA256_2 >= KW_CBO && LA256_2 <= KW_CHANGE)||(LA256_2 >= KW_CHECK && LA256_2 <= KW_COLLECTION)||(LA256_2 >= KW_COLUMNS && LA256_2 <= KW_COMMENT)||(LA256_2 >= KW_COMPACT && LA256_2 <= KW_CONCATENATE)||(LA256_2 >= KW_CONTINUE && LA256_2 <= KW_COST)||LA256_2==KW_CRON||LA256_2==KW_DATA||LA256_2==KW_DATABASES||(LA256_2 >= KW_DATETIME && LA256_2 <= KW_DEBUG)||(LA256_2 >= KW_DEFAULT && LA256_2 <= KW_DEFINED)||(LA256_2 >= KW_DELIMITED && LA256_2 <= KW_DESC)||(LA256_2 >= KW_DETAIL && LA256_2 <= KW_DISABLE)||(LA256_2 >= KW_DISTRIBUTE && LA256_2 <= KW_DO)||LA256_2==KW_DOW||(LA256_2 >= KW_DUMP && LA256_2 <= KW_ELEM_TYPE)||LA256_2==KW_ENABLE||(LA256_2 >= KW_ENFORCED && LA256_2 <= KW_EVERY)||(LA256_2 >= KW_EXCLUSIVE && LA256_2 <= KW_EXECUTED)||(LA256_2 >= KW_EXPLAIN && LA256_2 <= KW_EXPRESSION)||(LA256_2 >= KW_FIELDS && LA256_2 <= KW_FIRST)||(LA256_2 >= KW_FORMAT && LA256_2 <= KW_FORMATTED)||LA256_2==KW_FUNCTIONS||(LA256_2 >= KW_HOUR && LA256_2 <= KW_IDXPROPERTIES)||(LA256_2 >= KW_INDEX && LA256_2 <= KW_INDEXES)||(LA256_2 >= KW_INPATH && LA256_2 <= KW_INPUTDRIVER)||(LA256_2 >= KW_ISOLATION && LA256_2 <= KW_JAR)||(LA256_2 >= KW_JOINCOST && LA256_2 <= KW_LAST)||LA256_2==KW_LEVEL||(LA256_2 >= KW_LIMIT && LA256_2 <= KW_LOAD)||(LA256_2 >= KW_LOCATION && LA256_2 <= KW_LONG)||(LA256_2 >= KW_MANAGEDLOCATION && LA256_2 <= KW_MANAGEMENT)||(LA256_2 >= KW_MAPJOIN && LA256_2 <= KW_MATERIALIZED)||LA256_2==KW_METADATA||(LA256_2 >= KW_MINUTE && LA256_2 <= KW_MONTH)||(LA256_2 >= KW_MOVE && LA256_2 <= KW_MSCK)||(LA256_2 >= KW_NORELY && LA256_2 <= KW_NOSCAN)||LA256_2==KW_NOVALIDATE||LA256_2==KW_NULLS||LA256_2==KW_OFFSET||(LA256_2 >= KW_OPERATOR && LA256_2 <= KW_OPTION)||(LA256_2 >= KW_OUTPUTDRIVER && LA256_2 <= KW_OUTPUTFORMAT)||(LA256_2 >= KW_OVERWRITE && LA256_2 <= KW_OWNER)||(LA256_2 >= KW_PARTITIONED && LA256_2 <= KW_PATH)||(LA256_2 >= KW_PLAN && LA256_2 <= KW_POOL)||LA256_2==KW_PRINCIPALS||(LA256_2 >= KW_PURGE && LA256_2 <= KW_QUERY_PARALLELISM)||LA256_2==KW_READ||(LA256_2 >= KW_REBUILD && LA256_2 <= KW_RECORDWRITER)||(LA256_2 >= KW_RELOAD && LA256_2 <= KW_RESTRICT)||LA256_2==KW_REWRITE||(LA256_2 >= KW_ROLE && LA256_2 <= KW_ROLES)||(LA256_2 >= KW_SCHEDULED && LA256_2 <= KW_SECOND)||(LA256_2 >= KW_SEMI && LA256_2 <= KW_SERVER)||(LA256_2 >= KW_SETS && LA256_2 <= KW_SKEWED)||(LA256_2 >= KW_SNAPSHOT && LA256_2 <= KW_SSL)||(LA256_2 >= KW_STATISTICS && LA256_2 <= KW_SUMMARY)||LA256_2==KW_TABLES||(LA256_2 >= KW_TBLPROPERTIES && LA256_2 <= KW_TERMINATED)||LA256_2==KW_TINYINT||(LA256_2 >= KW_TOUCH && LA256_2 <= KW_TRANSACTIONS)||LA256_2==KW_UNARCHIVE||LA256_2==KW_UNDO||LA256_2==KW_UNIONTYPE||(LA256_2 >= KW_UNLOCK && LA256_2 <= KW_UNSIGNED)||(LA256_2 >= KW_URI && LA256_2 <= KW_USE)||(LA256_2 >= KW_UTC && LA256_2 <= KW_VALIDATE)||LA256_2==KW_VALUE_TYPE||(LA256_2 >= KW_VECTORIZATION && LA256_2 <= KW_WEEK)||LA256_2==KW_WHILE||(LA256_2 >= KW_WORK && LA256_2 <= KW_ZONE)||LA256_2==KW_BATCH||LA256_2==KW_DAYOFWEEK||LA256_2==KW_HOLD_DDLTIME||LA256_2==KW_IGNORE||LA256_2==KW_NO_DROP||LA256_2==KW_OFFLINE||LA256_2==KW_PROTECTION||LA256_2==KW_READONLY||LA256_2==KW_TIMESTAMPTZ) ) {
						alt256=3;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 256, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( (LA256_1==KW_BY) ) {
					alt256=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 256, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 256, 0, input);
				throw nvae;
			}

			switch (alt256) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2355:7: ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
					{
					KW_STORED857=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat14411); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED857);

					KW_AS858=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat14413); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS858);

					KW_INPUTFORMAT859=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_tableFileFormat14415); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT859);

					inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat14419); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(inFmt);

					KW_OUTPUTFORMAT860=(Token)match(input,KW_OUTPUTFORMAT,FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat14421); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT860);

					outFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat14425); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(outFmt);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2355:131: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
					int alt254=2;
					int LA254_0 = input.LA(1);
					if ( (LA254_0==KW_INPUTDRIVER) ) {
						alt254=1;
					}
					switch (alt254) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2355:132: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
							{
							KW_INPUTDRIVER861=(Token)match(input,KW_INPUTDRIVER,FOLLOW_KW_INPUTDRIVER_in_tableFileFormat14428); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER861);

							inDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat14432); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(inDriver);

							KW_OUTPUTDRIVER862=(Token)match(input,KW_OUTPUTDRIVER,FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat14434); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER862);

							outDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat14438); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(outDriver);

							}
							break;

					}

					// AST REWRITE
					// elements: outDriver, inFmt, outFmt, inDriver
					// token labels: inFmt, inDriver, outDriver, outFmt
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
					RewriteRuleTokenStream stream_inDriver=new RewriteRuleTokenStream(adaptor,"token inDriver",inDriver);
					RewriteRuleTokenStream stream_outDriver=new RewriteRuleTokenStream(adaptor,"token outDriver",outDriver);
					RewriteRuleTokenStream stream_outFmt=new RewriteRuleTokenStream(adaptor,"token outFmt",outFmt);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2356:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2356:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT"), root_1);
						adaptor.addChild(root_1, stream_inFmt.nextNode());
						adaptor.addChild(root_1, stream_outFmt.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2356:48: ( $inDriver)?
						if ( stream_inDriver.hasNext() ) {
							adaptor.addChild(root_1, stream_inDriver.nextNode());
						}
						stream_inDriver.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2356:59: ( $outDriver)?
						if ( stream_outDriver.hasNext() ) {
							adaptor.addChild(root_1, stream_outDriver.nextNode());
						}
						stream_outDriver.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2357:9: KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
					{
					KW_STORED863=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat14476); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED863);

					KW_BY864=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableFileFormat14478); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY864);

					storageHandler=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat14482); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(storageHandler);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2358:10: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
					int alt255=2;
					int LA255_0 = input.LA(1);
					if ( (LA255_0==KW_WITH) ) {
						alt255=1;
					}
					switch (alt255) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2358:11: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
							{
							KW_WITH865=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_tableFileFormat14494); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH865);

							KW_SERDEPROPERTIES866=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat14496); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES866);

							pushFollow(FOLLOW_tableProperties_in_tableFileFormat14500);
							serdeprops=tableProperties();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableProperties.add(serdeprops.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: storageHandler, serdeprops
					// token labels: storageHandler
					// rule labels: serdeprops, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_storageHandler=new RewriteRuleTokenStream(adaptor,"token storageHandler",storageHandler);
					RewriteRuleSubtreeStream stream_serdeprops=new RewriteRuleSubtreeStream(adaptor,"rule serdeprops",serdeprops!=null?serdeprops.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2359:7: -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2359:10: ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_STORAGEHANDLER, "TOK_STORAGEHANDLER"), root_1);
						adaptor.addChild(root_1, stream_storageHandler.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2359:48: ( $serdeprops)?
						if ( stream_serdeprops.hasNext() ) {
							adaptor.addChild(root_1, stream_serdeprops.nextTree());
						}
						stream_serdeprops.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2360:9: KW_STORED KW_AS genericSpec= identifier
					{
					KW_STORED867=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat14531); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED867);

					KW_AS868=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat14533); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS868);

					pushFollow(FOLLOW_identifier_in_tableFileFormat14537);
					genericSpec=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(genericSpec.getTree());
					// AST REWRITE
					// elements: genericSpec
					// token labels: 
					// rule labels: genericSpec, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_genericSpec=new RewriteRuleSubtreeStream(adaptor,"rule genericSpec",genericSpec!=null?genericSpec.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2361:7: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2361:10: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC"), root_1);
						adaptor.addChild(root_1, stream_genericSpec.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableFileFormat"


	public static class tableLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2364:1: tableLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_TABLELOCATION $locn) ;
	public final HiveParser.tableLocation_return tableLocation() throws RecognitionException {
		HiveParser.tableLocation_return retval = new HiveParser.tableLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token locn=null;
		Token KW_LOCATION869=null;

		ASTNode locn_tree=null;
		ASTNode KW_LOCATION869_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

		 pushMsg("table location specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2367:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_TABLELOCATION $locn) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2368:7: KW_LOCATION locn= StringLiteral
			{
			KW_LOCATION869=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_tableLocation14585); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION869);

			locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableLocation14589); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(locn);

			// AST REWRITE
			// elements: locn
			// token labels: locn
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2368:38: -> ^( TOK_TABLELOCATION $locn)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2368:41: ^( TOK_TABLELOCATION $locn)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLELOCATION, "TOK_TABLELOCATION"), root_1);
				adaptor.addChild(root_1, stream_locn.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableLocation"


	public static class columnNameTypeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2371:1: columnNameTypeList : columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) ;
	public final HiveParser.columnNameTypeList_return columnNameTypeList() throws RecognitionException {
		HiveParser.columnNameTypeList_return retval = new HiveParser.columnNameTypeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA871=null;
		ParserRuleReturnScope columnNameType870 =null;
		ParserRuleReturnScope columnNameType872 =null;

		ASTNode COMMA871_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameType");

		 pushMsg("column name type list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2374:5: ( columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2374:7: columnNameType ( COMMA columnNameType )*
			{
			pushFollow(FOLLOW_columnNameType_in_columnNameTypeList14625);
			columnNameType870=columnNameType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameType.add(columnNameType870.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2374:22: ( COMMA columnNameType )*
			loop257:
			while (true) {
				int alt257=2;
				int LA257_0 = input.LA(1);
				if ( (LA257_0==COMMA) ) {
					int LA257_20 = input.LA(2);
					if ( (LA257_20==Identifier||(LA257_20 >= KW_ABORT && LA257_20 <= KW_AFTER)||LA257_20==KW_ALLOC_FRACTION||LA257_20==KW_ANALYZE||LA257_20==KW_ARCHIVE||(LA257_20 >= KW_ASC && LA257_20 <= KW_AT)||(LA257_20 >= KW_AUTOCOMMIT && LA257_20 <= KW_BEFORE)||(LA257_20 >= KW_BUCKET && LA257_20 <= KW_BUCKETS)||(LA257_20 >= KW_CACHE && LA257_20 <= KW_CASCADE)||(LA257_20 >= KW_CBO && LA257_20 <= KW_CHANGE)||(LA257_20 >= KW_CHECK && LA257_20 <= KW_COLLECTION)||(LA257_20 >= KW_COLUMNS && LA257_20 <= KW_COMMENT)||(LA257_20 >= KW_COMPACT && LA257_20 <= KW_CONCATENATE)||(LA257_20 >= KW_CONTINUE && LA257_20 <= KW_COST)||LA257_20==KW_CRON||LA257_20==KW_DATA||LA257_20==KW_DATABASES||(LA257_20 >= KW_DATETIME && LA257_20 <= KW_DEBUG)||(LA257_20 >= KW_DEFAULT && LA257_20 <= KW_DEFINED)||(LA257_20 >= KW_DELIMITED && LA257_20 <= KW_DESC)||(LA257_20 >= KW_DETAIL && LA257_20 <= KW_DISABLE)||(LA257_20 >= KW_DISTRIBUTE && LA257_20 <= KW_DO)||LA257_20==KW_DOW||(LA257_20 >= KW_DUMP && LA257_20 <= KW_ELEM_TYPE)||LA257_20==KW_ENABLE||(LA257_20 >= KW_ENFORCED && LA257_20 <= KW_EVERY)||(LA257_20 >= KW_EXCLUSIVE && LA257_20 <= KW_EXECUTED)||(LA257_20 >= KW_EXPLAIN && LA257_20 <= KW_EXPRESSION)||(LA257_20 >= KW_FIELDS && LA257_20 <= KW_FIRST)||(LA257_20 >= KW_FORMAT && LA257_20 <= KW_FORMATTED)||LA257_20==KW_FUNCTIONS||(LA257_20 >= KW_HOUR && LA257_20 <= KW_IDXPROPERTIES)||(LA257_20 >= KW_INDEX && LA257_20 <= KW_INDEXES)||(LA257_20 >= KW_INPATH && LA257_20 <= KW_INPUTFORMAT)||(LA257_20 >= KW_ISOLATION && LA257_20 <= KW_JAR)||(LA257_20 >= KW_JOINCOST && LA257_20 <= KW_LAST)||LA257_20==KW_LEVEL||(LA257_20 >= KW_LIMIT && LA257_20 <= KW_LOAD)||(LA257_20 >= KW_LOCATION && LA257_20 <= KW_LONG)||(LA257_20 >= KW_MANAGEDLOCATION && LA257_20 <= KW_MANAGEMENT)||(LA257_20 >= KW_MAPJOIN && LA257_20 <= KW_MATERIALIZED)||LA257_20==KW_METADATA||(LA257_20 >= KW_MINUTE && LA257_20 <= KW_MONTH)||(LA257_20 >= KW_MOVE && LA257_20 <= KW_MSCK)||(LA257_20 >= KW_NORELY && LA257_20 <= KW_NOSCAN)||LA257_20==KW_NOVALIDATE||LA257_20==KW_NULLS||LA257_20==KW_OFFSET||(LA257_20 >= KW_OPERATOR && LA257_20 <= KW_OPTION)||(LA257_20 >= KW_OUTPUTDRIVER && LA257_20 <= KW_OUTPUTFORMAT)||(LA257_20 >= KW_OVERWRITE && LA257_20 <= KW_OWNER)||(LA257_20 >= KW_PARTITIONED && LA257_20 <= KW_PATH)||(LA257_20 >= KW_PLAN && LA257_20 <= KW_POOL)||LA257_20==KW_PRINCIPALS||(LA257_20 >= KW_PURGE && LA257_20 <= KW_QUERY_PARALLELISM)||LA257_20==KW_READ||(LA257_20 >= KW_REBUILD && LA257_20 <= KW_RECORDWRITER)||(LA257_20 >= KW_RELOAD && LA257_20 <= KW_RESTRICT)||LA257_20==KW_REWRITE||(LA257_20 >= KW_ROLE && LA257_20 <= KW_ROLES)||(LA257_20 >= KW_SCHEDULED && LA257_20 <= KW_SECOND)||(LA257_20 >= KW_SEMI && LA257_20 <= KW_SERVER)||(LA257_20 >= KW_SETS && LA257_20 <= KW_SKEWED)||(LA257_20 >= KW_SNAPSHOT && LA257_20 <= KW_SSL)||(LA257_20 >= KW_STATISTICS && LA257_20 <= KW_SUMMARY)||LA257_20==KW_TABLES||(LA257_20 >= KW_TBLPROPERTIES && LA257_20 <= KW_TERMINATED)||LA257_20==KW_TINYINT||(LA257_20 >= KW_TOUCH && LA257_20 <= KW_TRANSACTIONS)||LA257_20==KW_UNARCHIVE||LA257_20==KW_UNDO||LA257_20==KW_UNIONTYPE||(LA257_20 >= KW_UNLOCK && LA257_20 <= KW_UNSIGNED)||(LA257_20 >= KW_URI && LA257_20 <= KW_USE)||(LA257_20 >= KW_UTC && LA257_20 <= KW_VALIDATE)||LA257_20==KW_VALUE_TYPE||(LA257_20 >= KW_VECTORIZATION && LA257_20 <= KW_WEEK)||LA257_20==KW_WHILE||(LA257_20 >= KW_WORK && LA257_20 <= KW_ZONE)||LA257_20==KW_BATCH||LA257_20==KW_DAYOFWEEK||LA257_20==KW_HOLD_DDLTIME||LA257_20==KW_IGNORE||LA257_20==KW_NO_DROP||LA257_20==KW_OFFLINE||LA257_20==KW_PROTECTION||LA257_20==KW_READONLY||LA257_20==KW_TIMESTAMPTZ) ) {
						alt257=1;
					}

				}

				switch (alt257) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2374:23: COMMA columnNameType
					{
					COMMA871=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameTypeList14628); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA871);

					pushFollow(FOLLOW_columnNameType_in_columnNameTypeList14630);
					columnNameType872=columnNameType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameType.add(columnNameType872.getTree());
					}
					break;

				default :
					break loop257;
				}
			}

			// AST REWRITE
			// elements: columnNameType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2374:46: -> ^( TOK_TABCOLLIST ( columnNameType )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2374:49: ^( TOK_TABCOLLIST ( columnNameType )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);
				if ( !(stream_columnNameType.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameType.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameType.nextTree());
				}
				stream_columnNameType.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeList"


	public static class columnNameTypeOrConstraintList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeOrConstraintList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2377:1: columnNameTypeOrConstraintList : columnNameTypeOrConstraint ( COMMA columnNameTypeOrConstraint )* -> ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ ) ;
	public final HiveParser.columnNameTypeOrConstraintList_return columnNameTypeOrConstraintList() throws RecognitionException {
		HiveParser.columnNameTypeOrConstraintList_return retval = new HiveParser.columnNameTypeOrConstraintList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA874=null;
		ParserRuleReturnScope columnNameTypeOrConstraint873 =null;
		ParserRuleReturnScope columnNameTypeOrConstraint875 =null;

		ASTNode COMMA874_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameTypeOrConstraint=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeOrConstraint");

		 pushMsg("column name type and constraints list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:5: ( columnNameTypeOrConstraint ( COMMA columnNameTypeOrConstraint )* -> ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:7: columnNameTypeOrConstraint ( COMMA columnNameTypeOrConstraint )*
			{
			pushFollow(FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList14668);
			columnNameTypeOrConstraint873=columnNameTypeOrConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameTypeOrConstraint.add(columnNameTypeOrConstraint873.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:34: ( COMMA columnNameTypeOrConstraint )*
			loop258:
			while (true) {
				int alt258=2;
				int LA258_0 = input.LA(1);
				if ( (LA258_0==COMMA) ) {
					alt258=1;
				}

				switch (alt258) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:35: COMMA columnNameTypeOrConstraint
					{
					COMMA874=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameTypeOrConstraintList14671); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA874);

					pushFollow(FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList14673);
					columnNameTypeOrConstraint875=columnNameTypeOrConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameTypeOrConstraint.add(columnNameTypeOrConstraint875.getTree());
					}
					break;

				default :
					break loop258;
				}
			}

			// AST REWRITE
			// elements: columnNameTypeOrConstraint
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2380:70: -> ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:73: ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);
				if ( !(stream_columnNameTypeOrConstraint.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameTypeOrConstraint.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameTypeOrConstraint.nextTree());
				}
				stream_columnNameTypeOrConstraint.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeOrConstraintList"


	public static class columnNameColonTypeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameColonTypeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2383:1: columnNameColonTypeList : columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) ;
	public final HiveParser.columnNameColonTypeList_return columnNameColonTypeList() throws RecognitionException {
		HiveParser.columnNameColonTypeList_return retval = new HiveParser.columnNameColonTypeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA877=null;
		ParserRuleReturnScope columnNameColonType876 =null;
		ParserRuleReturnScope columnNameColonType878 =null;

		ASTNode COMMA877_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameColonType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameColonType");

		 pushMsg("column name type list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2386:5: ( columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2386:7: columnNameColonType ( COMMA columnNameColonType )*
			{
			pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList14711);
			columnNameColonType876=columnNameColonType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameColonType.add(columnNameColonType876.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2386:27: ( COMMA columnNameColonType )*
			loop259:
			while (true) {
				int alt259=2;
				int LA259_0 = input.LA(1);
				if ( (LA259_0==COMMA) ) {
					alt259=1;
				}

				switch (alt259) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2386:28: COMMA columnNameColonType
					{
					COMMA877=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameColonTypeList14714); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA877);

					pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList14716);
					columnNameColonType878=columnNameColonType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameColonType.add(columnNameColonType878.getTree());
					}
					break;

				default :
					break loop259;
				}
			}

			// AST REWRITE
			// elements: columnNameColonType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2386:56: -> ^( TOK_TABCOLLIST ( columnNameColonType )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2386:59: ^( TOK_TABCOLLIST ( columnNameColonType )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);
				if ( !(stream_columnNameColonType.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameColonType.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameColonType.nextTree());
				}
				stream_columnNameColonType.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameColonTypeList"


	public static class columnNameList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2389:1: columnNameList : columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) ;
	public final HiveParser.columnNameList_return columnNameList() throws RecognitionException {
		HiveParser.columnNameList_return retval = new HiveParser.columnNameList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA880=null;
		ParserRuleReturnScope columnName879 =null;
		ParserRuleReturnScope columnName881 =null;

		ASTNode COMMA880_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("column name list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2392:5: ( columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2392:7: columnName ( COMMA columnName )*
			{
			pushFollow(FOLLOW_columnName_in_columnNameList14754);
			columnName879=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(columnName879.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2392:18: ( COMMA columnName )*
			loop260:
			while (true) {
				int alt260=2;
				int LA260_0 = input.LA(1);
				if ( (LA260_0==COMMA) ) {
					alt260=1;
				}

				switch (alt260) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2392:19: COMMA columnName
					{
					COMMA880=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameList14757); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA880);

					pushFollow(FOLLOW_columnName_in_columnNameList14759);
					columnName881=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName881.getTree());
					}
					break;

				default :
					break loop260;
				}
			}

			// AST REWRITE
			// elements: columnName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2392:38: -> ^( TOK_TABCOLNAME ( columnName )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2392:41: ^( TOK_TABCOLNAME ( columnName )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);
				if ( !(stream_columnName.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnName.hasNext() ) {
					adaptor.addChild(root_1, stream_columnName.nextTree());
				}
				stream_columnName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameList"


	public static class columnName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2395:1: columnName : identifier ;
	public final HiveParser.columnName_return columnName() throws RecognitionException {
		HiveParser.columnName_return retval = new HiveParser.columnName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope identifier882 =null;


		 pushMsg("column name", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2398:5: ( identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2399:7: identifier
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_identifier_in_columnName14803);
			identifier882=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier882.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnName"


	public static class extColumnName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "extColumnName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2402:1: extColumnName : identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* ;
	public final HiveParser.extColumnName_return extColumnName() throws RecognitionException {
		HiveParser.extColumnName_return retval = new HiveParser.extColumnName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token DOT884=null;
		Token KW_ELEM_TYPE885=null;
		Token KW_KEY_TYPE886=null;
		Token KW_VALUE_TYPE887=null;
		ParserRuleReturnScope identifier883 =null;
		ParserRuleReturnScope identifier888 =null;

		ASTNode DOT884_tree=null;
		ASTNode KW_ELEM_TYPE885_tree=null;
		ASTNode KW_KEY_TYPE886_tree=null;
		ASTNode KW_VALUE_TYPE887_tree=null;

		 pushMsg("column name for complex types", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2405:5: ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:7: identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_identifier_in_extColumnName14836);
			identifier883=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier883.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:18: ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
			loop262:
			while (true) {
				int alt262=2;
				int LA262_0 = input.LA(1);
				if ( (LA262_0==DOT) ) {
					alt262=1;
				}

				switch (alt262) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:19: DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
					{
					DOT884=(Token)match(input,DOT,FOLLOW_DOT_in_extColumnName14839); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					DOT884_tree = (ASTNode)adaptor.create(DOT884);
					root_0 = (ASTNode)adaptor.becomeRoot(DOT884_tree, root_0);
					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:24: ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
					int alt261=4;
					switch ( input.LA(1) ) {
					case KW_ELEM_TYPE:
						{
						int LA261_1 = input.LA(2);
						if ( (synpred19_HiveParser()) ) {
							alt261=1;
						}
						else if ( (true) ) {
							alt261=4;
						}

						}
						break;
					case KW_KEY_TYPE:
						{
						int LA261_2 = input.LA(2);
						if ( (synpred20_HiveParser()) ) {
							alt261=2;
						}
						else if ( (true) ) {
							alt261=4;
						}

						}
						break;
					case KW_VALUE_TYPE:
						{
						int LA261_3 = input.LA(2);
						if ( (synpred21_HiveParser()) ) {
							alt261=3;
						}
						else if ( (true) ) {
							alt261=4;
						}

						}
						break;
					case Identifier:
					case KW_ABORT:
					case KW_ACTIVATE:
					case KW_ACTIVE:
					case KW_ADD:
					case KW_ADMIN:
					case KW_AFTER:
					case KW_ALLOC_FRACTION:
					case KW_ANALYZE:
					case KW_ARCHIVE:
					case KW_ASC:
					case KW_AT:
					case KW_AUTOCOMMIT:
					case KW_BEFORE:
					case KW_BUCKET:
					case KW_BUCKETS:
					case KW_CACHE:
					case KW_CASCADE:
					case KW_CBO:
					case KW_CHANGE:
					case KW_CHECK:
					case KW_CLUSTER:
					case KW_CLUSTERED:
					case KW_CLUSTERSTATUS:
					case KW_COLLECTION:
					case KW_COLUMNS:
					case KW_COMMENT:
					case KW_COMPACT:
					case KW_COMPACTIONS:
					case KW_COMPUTE:
					case KW_CONCATENATE:
					case KW_CONTINUE:
					case KW_COST:
					case KW_CRON:
					case KW_DATA:
					case KW_DATABASES:
					case KW_DATETIME:
					case KW_DAY:
					case KW_DBPROPERTIES:
					case KW_DEBUG:
					case KW_DEFAULT:
					case KW_DEFERRED:
					case KW_DEFINED:
					case KW_DELIMITED:
					case KW_DEPENDENCY:
					case KW_DESC:
					case KW_DETAIL:
					case KW_DIRECTORIES:
					case KW_DIRECTORY:
					case KW_DISABLE:
					case KW_DISTRIBUTE:
					case KW_DISTRIBUTED:
					case KW_DO:
					case KW_DOW:
					case KW_DUMP:
					case KW_ENABLE:
					case KW_ENFORCED:
					case KW_ESCAPED:
					case KW_EVERY:
					case KW_EXCLUSIVE:
					case KW_EXECUTE:
					case KW_EXECUTED:
					case KW_EXPLAIN:
					case KW_EXPORT:
					case KW_EXPRESSION:
					case KW_FIELDS:
					case KW_FILE:
					case KW_FILEFORMAT:
					case KW_FIRST:
					case KW_FORMAT:
					case KW_FORMATTED:
					case KW_FUNCTIONS:
					case KW_HOUR:
					case KW_IDXPROPERTIES:
					case KW_INDEX:
					case KW_INDEXES:
					case KW_INPATH:
					case KW_INPUTDRIVER:
					case KW_INPUTFORMAT:
					case KW_ISOLATION:
					case KW_ITEMS:
					case KW_JAR:
					case KW_JOINCOST:
					case KW_KEY:
					case KW_KEYS:
					case KW_KILL:
					case KW_LAST:
					case KW_LEVEL:
					case KW_LIMIT:
					case KW_LINES:
					case KW_LOAD:
					case KW_LOCATION:
					case KW_LOCK:
					case KW_LOCKS:
					case KW_LOGICAL:
					case KW_LONG:
					case KW_MANAGEDLOCATION:
					case KW_MANAGEMENT:
					case KW_MAPJOIN:
					case KW_MAPPING:
					case KW_MATCHED:
					case KW_MATERIALIZED:
					case KW_METADATA:
					case KW_MINUTE:
					case KW_MONTH:
					case KW_MOVE:
					case KW_MSCK:
					case KW_NORELY:
					case KW_NOSCAN:
					case KW_NOVALIDATE:
					case KW_NULLS:
					case KW_OFFSET:
					case KW_OPERATOR:
					case KW_OPTION:
					case KW_OUTPUTDRIVER:
					case KW_OUTPUTFORMAT:
					case KW_OVERWRITE:
					case KW_OWNER:
					case KW_PARTITIONED:
					case KW_PARTITIONS:
					case KW_PATH:
					case KW_PLAN:
					case KW_PLANS:
					case KW_PLUS:
					case KW_POOL:
					case KW_PRINCIPALS:
					case KW_PURGE:
					case KW_QUARTER:
					case KW_QUERY:
					case KW_QUERY_PARALLELISM:
					case KW_READ:
					case KW_REBUILD:
					case KW_RECORDREADER:
					case KW_RECORDWRITER:
					case KW_RELOAD:
					case KW_RELY:
					case KW_RENAME:
					case KW_REOPTIMIZATION:
					case KW_REPAIR:
					case KW_REPL:
					case KW_REPLACE:
					case KW_REPLICATION:
					case KW_RESOURCE:
					case KW_RESTRICT:
					case KW_REWRITE:
					case KW_ROLE:
					case KW_ROLES:
					case KW_SCHEDULED:
					case KW_SCHEDULING_POLICY:
					case KW_SCHEMA:
					case KW_SCHEMAS:
					case KW_SECOND:
					case KW_SEMI:
					case KW_SERDE:
					case KW_SERDEPROPERTIES:
					case KW_SERVER:
					case KW_SETS:
					case KW_SHARED:
					case KW_SHOW:
					case KW_SHOW_DATABASE:
					case KW_SKEWED:
					case KW_SNAPSHOT:
					case KW_SORT:
					case KW_SORTED:
					case KW_SSL:
					case KW_STATISTICS:
					case KW_STATUS:
					case KW_STORED:
					case KW_STREAMTABLE:
					case KW_STRING:
					case KW_STRUCT:
					case KW_SUMMARY:
					case KW_TABLES:
					case KW_TBLPROPERTIES:
					case KW_TEMPORARY:
					case KW_TERMINATED:
					case KW_TINYINT:
					case KW_TOUCH:
					case KW_TRANSACTION:
					case KW_TRANSACTIONAL:
					case KW_TRANSACTIONS:
					case KW_UNARCHIVE:
					case KW_UNDO:
					case KW_UNIONTYPE:
					case KW_UNLOCK:
					case KW_UNMANAGED:
					case KW_UNSET:
					case KW_UNSIGNED:
					case KW_URI:
					case KW_USE:
					case KW_UTC:
					case KW_UTCTIMESTAMP:
					case KW_VALIDATE:
					case KW_VECTORIZATION:
					case KW_VIEW:
					case KW_VIEWS:
					case KW_WAIT:
					case KW_WEEK:
					case KW_WHILE:
					case KW_WORK:
					case KW_WORKLOAD:
					case KW_WRITE:
					case KW_YEAR:
					case KW_ZONE:
					case KW_BATCH:
					case KW_DAYOFWEEK:
					case KW_HOLD_DDLTIME:
					case KW_IGNORE:
					case KW_NO_DROP:
					case KW_OFFLINE:
					case KW_PROTECTION:
					case KW_READONLY:
					case KW_TIMESTAMPTZ:
						{
						alt261=4;
						}
						break;
					default:
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 261, 0, input);
						throw nvae;
					}
					switch (alt261) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:25: ( KW_ELEM_TYPE )=> KW_ELEM_TYPE
							{
							KW_ELEM_TYPE885=(Token)match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_extColumnName14849); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							KW_ELEM_TYPE885_tree = (ASTNode)adaptor.create(KW_ELEM_TYPE885);
							adaptor.addChild(root_0, KW_ELEM_TYPE885_tree);
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:58: ( KW_KEY_TYPE )=> KW_KEY_TYPE
							{
							KW_KEY_TYPE886=(Token)match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_extColumnName14859); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							KW_KEY_TYPE886_tree = (ASTNode)adaptor.create(KW_KEY_TYPE886);
							adaptor.addChild(root_0, KW_KEY_TYPE886_tree);
							}

							}
							break;
						case 3 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:89: ( KW_VALUE_TYPE )=> KW_VALUE_TYPE
							{
							KW_VALUE_TYPE887=(Token)match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_extColumnName14869); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							KW_VALUE_TYPE887_tree = (ASTNode)adaptor.create(KW_VALUE_TYPE887);
							adaptor.addChild(root_0, KW_VALUE_TYPE887_tree);
							}

							}
							break;
						case 4 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:124: identifier
							{
							pushFollow(FOLLOW_identifier_in_extColumnName14873);
							identifier888=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier888.getTree());

							}
							break;

					}

					}
					break;

				default :
					break loop262;
				}
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "extColumnName"


	public static class columnNameOrderList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameOrderList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2409:1: columnNameOrderList : columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) ;
	public final HiveParser.columnNameOrderList_return columnNameOrderList() throws RecognitionException {
		HiveParser.columnNameOrderList_return retval = new HiveParser.columnNameOrderList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA890=null;
		ParserRuleReturnScope columnNameOrder889 =null;
		ParserRuleReturnScope columnNameOrder891 =null;

		ASTNode COMMA890_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameOrder=new RewriteRuleSubtreeStream(adaptor,"rule columnNameOrder");

		 pushMsg("column name order list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2412:5: ( columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2412:7: columnNameOrder ( COMMA columnNameOrder )*
			{
			pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList14903);
			columnNameOrder889=columnNameOrder();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameOrder.add(columnNameOrder889.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2412:23: ( COMMA columnNameOrder )*
			loop263:
			while (true) {
				int alt263=2;
				int LA263_0 = input.LA(1);
				if ( (LA263_0==COMMA) ) {
					alt263=1;
				}

				switch (alt263) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2412:24: COMMA columnNameOrder
					{
					COMMA890=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameOrderList14906); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA890);

					pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList14908);
					columnNameOrder891=columnNameOrder();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameOrder.add(columnNameOrder891.getTree());
					}
					break;

				default :
					break loop263;
				}
			}

			// AST REWRITE
			// elements: columnNameOrder
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2412:48: -> ^( TOK_TABCOLNAME ( columnNameOrder )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2412:51: ^( TOK_TABCOLNAME ( columnNameOrder )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);
				if ( !(stream_columnNameOrder.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameOrder.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameOrder.nextTree());
				}
				stream_columnNameOrder.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameOrderList"


	public static class columnParenthesesList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnParenthesesList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2415:1: columnParenthesesList : LPAREN ! columnNameList RPAREN !;
	public final HiveParser.columnParenthesesList_return columnParenthesesList() throws RecognitionException {
		HiveParser.columnParenthesesList_return retval = new HiveParser.columnParenthesesList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN892=null;
		Token RPAREN894=null;
		ParserRuleReturnScope columnNameList893 =null;

		ASTNode LPAREN892_tree=null;
		ASTNode RPAREN894_tree=null;

		 pushMsg("column parentheses list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2418:5: ( LPAREN ! columnNameList RPAREN !)
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2418:7: LPAREN ! columnNameList RPAREN !
			{
			root_0 = (ASTNode)adaptor.nil();


			LPAREN892=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_columnParenthesesList14946); if (state.failed) return retval;
			pushFollow(FOLLOW_columnNameList_in_columnParenthesesList14949);
			columnNameList893=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, columnNameList893.getTree());

			RPAREN894=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_columnParenthesesList14951); if (state.failed) return retval;
			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnParenthesesList"


	public static class enableValidateSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "enableValidateSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2421:1: enableValidateSpecification : ( enableSpecification ( validateSpecification )? | enforcedSpecification );
	public final HiveParser.enableValidateSpecification_return enableValidateSpecification() throws RecognitionException {
		HiveParser.enableValidateSpecification_return retval = new HiveParser.enableValidateSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope enableSpecification895 =null;
		ParserRuleReturnScope validateSpecification896 =null;
		ParserRuleReturnScope enforcedSpecification897 =null;


		 pushMsg("enable specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2424:5: ( enableSpecification ( validateSpecification )? | enforcedSpecification )
			int alt265=2;
			int LA265_0 = input.LA(1);
			if ( (LA265_0==KW_DISABLE||LA265_0==KW_ENABLE) ) {
				alt265=1;
			}
			else if ( (LA265_0==KW_ENFORCED||LA265_0==KW_NOT) ) {
				alt265=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 265, 0, input);
				throw nvae;
			}

			switch (alt265) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2424:7: enableSpecification ( validateSpecification )?
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_enableSpecification_in_enableValidateSpecification14979);
					enableSpecification895=enableSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, enableSpecification895.getTree());

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2424:27: ( validateSpecification )?
					int alt264=2;
					int LA264_0 = input.LA(1);
					if ( (LA264_0==KW_NOVALIDATE||LA264_0==KW_VALIDATE) ) {
						alt264=1;
					}
					switch (alt264) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2424:27: validateSpecification
							{
							pushFollow(FOLLOW_validateSpecification_in_enableValidateSpecification14981);
							validateSpecification896=validateSpecification();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, validateSpecification896.getTree());

							}
							break;

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2425:7: enforcedSpecification
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_enforcedSpecification_in_enableValidateSpecification14990);
					enforcedSpecification897=enforcedSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, enforcedSpecification897.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "enableValidateSpecification"


	public static class enableSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "enableSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2428:1: enableSpecification : ( KW_ENABLE -> ^( TOK_ENABLE ) | KW_DISABLE -> ^( TOK_DISABLE ) );
	public final HiveParser.enableSpecification_return enableSpecification() throws RecognitionException {
		HiveParser.enableSpecification_return retval = new HiveParser.enableSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ENABLE898=null;
		Token KW_DISABLE899=null;

		ASTNode KW_ENABLE898_tree=null;
		ASTNode KW_DISABLE899_tree=null;
		RewriteRuleTokenStream stream_KW_DISABLE=new RewriteRuleTokenStream(adaptor,"token KW_DISABLE");
		RewriteRuleTokenStream stream_KW_ENABLE=new RewriteRuleTokenStream(adaptor,"token KW_ENABLE");

		 pushMsg("enable specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2431:5: ( KW_ENABLE -> ^( TOK_ENABLE ) | KW_DISABLE -> ^( TOK_DISABLE ) )
			int alt266=2;
			int LA266_0 = input.LA(1);
			if ( (LA266_0==KW_ENABLE) ) {
				alt266=1;
			}
			else if ( (LA266_0==KW_DISABLE) ) {
				alt266=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 266, 0, input);
				throw nvae;
			}

			switch (alt266) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2431:7: KW_ENABLE
					{
					KW_ENABLE898=(Token)match(input,KW_ENABLE,FOLLOW_KW_ENABLE_in_enableSpecification15017); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ENABLE.add(KW_ENABLE898);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2431:17: -> ^( TOK_ENABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2431:20: ^( TOK_ENABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ENABLE, "TOK_ENABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2432:7: KW_DISABLE
					{
					KW_DISABLE899=(Token)match(input,KW_DISABLE,FOLLOW_KW_DISABLE_in_enableSpecification15031); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DISABLE.add(KW_DISABLE899);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2432:18: -> ^( TOK_DISABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2432:21: ^( TOK_DISABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DISABLE, "TOK_DISABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "enableSpecification"


	public static class validateSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "validateSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2435:1: validateSpecification : ( KW_VALIDATE -> ^( TOK_VALIDATE ) | KW_NOVALIDATE -> ^( TOK_NOVALIDATE ) );
	public final HiveParser.validateSpecification_return validateSpecification() throws RecognitionException {
		HiveParser.validateSpecification_return retval = new HiveParser.validateSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_VALIDATE900=null;
		Token KW_NOVALIDATE901=null;

		ASTNode KW_VALIDATE900_tree=null;
		ASTNode KW_NOVALIDATE901_tree=null;
		RewriteRuleTokenStream stream_KW_VALIDATE=new RewriteRuleTokenStream(adaptor,"token KW_VALIDATE");
		RewriteRuleTokenStream stream_KW_NOVALIDATE=new RewriteRuleTokenStream(adaptor,"token KW_NOVALIDATE");

		 pushMsg("validate specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2438:5: ( KW_VALIDATE -> ^( TOK_VALIDATE ) | KW_NOVALIDATE -> ^( TOK_NOVALIDATE ) )
			int alt267=2;
			int LA267_0 = input.LA(1);
			if ( (LA267_0==KW_VALIDATE) ) {
				alt267=1;
			}
			else if ( (LA267_0==KW_NOVALIDATE) ) {
				alt267=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 267, 0, input);
				throw nvae;
			}

			switch (alt267) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2438:7: KW_VALIDATE
					{
					KW_VALIDATE900=(Token)match(input,KW_VALIDATE,FOLLOW_KW_VALIDATE_in_validateSpecification15064); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VALIDATE.add(KW_VALIDATE900);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2438:19: -> ^( TOK_VALIDATE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2438:22: ^( TOK_VALIDATE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VALIDATE, "TOK_VALIDATE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2439:7: KW_NOVALIDATE
					{
					KW_NOVALIDATE901=(Token)match(input,KW_NOVALIDATE,FOLLOW_KW_NOVALIDATE_in_validateSpecification15078); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOVALIDATE.add(KW_NOVALIDATE901);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2439:21: -> ^( TOK_NOVALIDATE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2439:24: ^( TOK_NOVALIDATE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NOVALIDATE, "TOK_NOVALIDATE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "validateSpecification"


	public static class enforcedSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "enforcedSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2442:1: enforcedSpecification : ( KW_ENFORCED -> ^( TOK_ENABLE ) | KW_NOT KW_ENFORCED -> ^( TOK_DISABLE ) );
	public final HiveParser.enforcedSpecification_return enforcedSpecification() throws RecognitionException {
		HiveParser.enforcedSpecification_return retval = new HiveParser.enforcedSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ENFORCED902=null;
		Token KW_NOT903=null;
		Token KW_ENFORCED904=null;

		ASTNode KW_ENFORCED902_tree=null;
		ASTNode KW_NOT903_tree=null;
		ASTNode KW_ENFORCED904_tree=null;
		RewriteRuleTokenStream stream_KW_ENFORCED=new RewriteRuleTokenStream(adaptor,"token KW_ENFORCED");
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");

		 pushMsg("enforced specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2445:5: ( KW_ENFORCED -> ^( TOK_ENABLE ) | KW_NOT KW_ENFORCED -> ^( TOK_DISABLE ) )
			int alt268=2;
			int LA268_0 = input.LA(1);
			if ( (LA268_0==KW_ENFORCED) ) {
				alt268=1;
			}
			else if ( (LA268_0==KW_NOT) ) {
				alt268=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 268, 0, input);
				throw nvae;
			}

			switch (alt268) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2445:7: KW_ENFORCED
					{
					KW_ENFORCED902=(Token)match(input,KW_ENFORCED,FOLLOW_KW_ENFORCED_in_enforcedSpecification15111); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ENFORCED.add(KW_ENFORCED902);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2445:19: -> ^( TOK_ENABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2445:22: ^( TOK_ENABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ENABLE, "TOK_ENABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2446:7: KW_NOT KW_ENFORCED
					{
					KW_NOT903=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_enforcedSpecification15125); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT903);

					KW_ENFORCED904=(Token)match(input,KW_ENFORCED,FOLLOW_KW_ENFORCED_in_enforcedSpecification15127); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ENFORCED.add(KW_ENFORCED904);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2446:26: -> ^( TOK_DISABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2446:29: ^( TOK_DISABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DISABLE, "TOK_DISABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "enforcedSpecification"


	public static class relySpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "relySpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2449:1: relySpecification : ( KW_RELY -> ^( TOK_RELY ) | KW_NORELY -> ^( TOK_NORELY ) );
	public final HiveParser.relySpecification_return relySpecification() throws RecognitionException {
		HiveParser.relySpecification_return retval = new HiveParser.relySpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RELY905=null;
		Token KW_NORELY906=null;

		ASTNode KW_RELY905_tree=null;
		ASTNode KW_NORELY906_tree=null;
		RewriteRuleTokenStream stream_KW_NORELY=new RewriteRuleTokenStream(adaptor,"token KW_NORELY");
		RewriteRuleTokenStream stream_KW_RELY=new RewriteRuleTokenStream(adaptor,"token KW_RELY");

		 pushMsg("rely specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2452:5: ( KW_RELY -> ^( TOK_RELY ) | KW_NORELY -> ^( TOK_NORELY ) )
			int alt269=2;
			int LA269_0 = input.LA(1);
			if ( (LA269_0==KW_RELY) ) {
				alt269=1;
			}
			else if ( (LA269_0==KW_NORELY) ) {
				alt269=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 269, 0, input);
				throw nvae;
			}

			switch (alt269) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2452:8: KW_RELY
					{
					KW_RELY905=(Token)match(input,KW_RELY,FOLLOW_KW_RELY_in_relySpecification15161); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RELY.add(KW_RELY905);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2452:16: -> ^( TOK_RELY )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2452:19: ^( TOK_RELY )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RELY, "TOK_RELY"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2453:8: KW_NORELY
					{
					KW_NORELY906=(Token)match(input,KW_NORELY,FOLLOW_KW_NORELY_in_relySpecification15176); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NORELY.add(KW_NORELY906);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2453:18: -> ^( TOK_NORELY )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2453:21: ^( TOK_NORELY )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NORELY, "TOK_NORELY"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "relySpecification"


	public static class createConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2456:1: createConstraint : ( KW_CONSTRAINT constraintName= identifier )? tableLevelConstraint ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) ;
	public final HiveParser.createConstraint_return createConstraint() throws RecognitionException {
		HiveParser.createConstraint_return retval = new HiveParser.createConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT907=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tableLevelConstraint908 =null;
		ParserRuleReturnScope constraintOptsCreate909 =null;

		ASTNode KW_CONSTRAINT907_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableLevelConstraint=new RewriteRuleSubtreeStream(adaptor,"rule tableLevelConstraint");

		 pushMsg("pk or uk or nn constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:5: ( ( KW_CONSTRAINT constraintName= identifier )? tableLevelConstraint ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:7: ( KW_CONSTRAINT constraintName= identifier )? tableLevelConstraint ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt270=2;
			int LA270_0 = input.LA(1);
			if ( (LA270_0==KW_CONSTRAINT) ) {
				alt270=1;
			}
			switch (alt270) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT907=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_createConstraint15210); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT907);

					pushFollow(FOLLOW_identifier_in_createConstraint15214);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableLevelConstraint_in_createConstraint15218);
			tableLevelConstraint908=tableLevelConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableLevelConstraint.add(tableLevelConstraint908.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:71: ( constraintOptsCreate )?
			int alt271=2;
			int LA271_0 = input.LA(1);
			if ( (LA271_0==KW_DISABLE||LA271_0==KW_ENABLE||LA271_0==KW_ENFORCED||LA271_0==KW_NOT) ) {
				alt271=1;
			}
			switch (alt271) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:71: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_createConstraint15220);
					constraintOptsCreate909=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate909.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsCreate, constraintName, constraintOptsCreate
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2460:5: -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2461:13: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((tableLevelConstraint908!=null?((ASTNode)tableLevelConstraint908.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2461:44: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2461:83: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2462:5: -> ^( ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2462:8: ^( ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((tableLevelConstraint908!=null?((ASTNode)tableLevelConstraint908.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2462:39: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createConstraint"


	public static class alterConstraintWithName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterConstraintWithName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2465:1: alterConstraintWithName : KW_CONSTRAINT constraintName= identifier tableLevelConstraint ( constraintOptsAlter )? -> ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) ;
	public final HiveParser.alterConstraintWithName_return alterConstraintWithName() throws RecognitionException {
		HiveParser.alterConstraintWithName_return retval = new HiveParser.alterConstraintWithName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT910=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tableLevelConstraint911 =null;
		ParserRuleReturnScope constraintOptsAlter912 =null;

		ASTNode KW_CONSTRAINT910_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableLevelConstraint=new RewriteRuleSubtreeStream(adaptor,"rule tableLevelConstraint");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");

		 pushMsg("pk or uk or nn constraint with name", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2468:5: ( KW_CONSTRAINT constraintName= identifier tableLevelConstraint ( constraintOptsAlter )? -> ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2468:7: KW_CONSTRAINT constraintName= identifier tableLevelConstraint ( constraintOptsAlter )?
			{
			KW_CONSTRAINT910=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterConstraintWithName15295); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT910);

			pushFollow(FOLLOW_identifier_in_alterConstraintWithName15299);
			constraintName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
			pushFollow(FOLLOW_tableLevelConstraint_in_alterConstraintWithName15301);
			tableLevelConstraint911=tableLevelConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableLevelConstraint.add(tableLevelConstraint911.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2468:68: ( constraintOptsAlter )?
			int alt272=2;
			int LA272_0 = input.LA(1);
			if ( (LA272_0==KW_DISABLE||LA272_0==KW_ENABLE||LA272_0==KW_ENFORCED||LA272_0==KW_NOT) ) {
				alt272=1;
			}
			switch (alt272) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2468:68: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterConstraintWithName15303);
					constraintOptsAlter912=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter912.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsAlter, constraintName
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2469:5: -> ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2469:7: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((tableLevelConstraint911!=null?((ASTNode)tableLevelConstraint911.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2469:38: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2469:77: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterConstraintWithName"


	public static class tableLevelConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableLevelConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2472:1: tableLevelConstraint : ( pkUkConstraint | checkConstraint );
	public final HiveParser.tableLevelConstraint_return tableLevelConstraint() throws RecognitionException {
		HiveParser.tableLevelConstraint_return retval = new HiveParser.tableLevelConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope pkUkConstraint913 =null;
		ParserRuleReturnScope checkConstraint914 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2473:5: ( pkUkConstraint | checkConstraint )
			int alt273=2;
			int LA273_0 = input.LA(1);
			if ( (LA273_0==KW_PRIMARY||LA273_0==KW_UNIQUE) ) {
				alt273=1;
			}
			else if ( (LA273_0==KW_CHECK) ) {
				alt273=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 273, 0, input);
				throw nvae;
			}

			switch (alt273) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2473:7: pkUkConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_pkUkConstraint_in_tableLevelConstraint15340);
					pkUkConstraint913=pkUkConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, pkUkConstraint913.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2474:7: checkConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_checkConstraint_in_tableLevelConstraint15348);
					checkConstraint914=checkConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, checkConstraint914.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableLevelConstraint"


	public static class pkUkConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "pkUkConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2477:1: pkUkConstraint : tableConstraintType pkCols= columnParenthesesList -> ^( tableConstraintType $pkCols) ;
	public final HiveParser.pkUkConstraint_return pkUkConstraint() throws RecognitionException {
		HiveParser.pkUkConstraint_return retval = new HiveParser.pkUkConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope pkCols =null;
		ParserRuleReturnScope tableConstraintType915 =null;

		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_tableConstraintType=new RewriteRuleSubtreeStream(adaptor,"rule tableConstraintType");

		 pushMsg("pk or uk table level constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2480:5: ( tableConstraintType pkCols= columnParenthesesList -> ^( tableConstraintType $pkCols) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2480:7: tableConstraintType pkCols= columnParenthesesList
			{
			pushFollow(FOLLOW_tableConstraintType_in_pkUkConstraint15375);
			tableConstraintType915=tableConstraintType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableConstraintType.add(tableConstraintType915.getTree());
			pushFollow(FOLLOW_columnParenthesesList_in_pkUkConstraint15379);
			pkCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(pkCols.getTree());
			// AST REWRITE
			// elements: pkCols, tableConstraintType
			// token labels: 
			// rule labels: pkCols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_pkCols=new RewriteRuleSubtreeStream(adaptor,"rule pkCols",pkCols!=null?pkCols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2481:5: -> ^( tableConstraintType $pkCols)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2481:8: ^( tableConstraintType $pkCols)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_tableConstraintType.nextNode(), root_1);
				adaptor.addChild(root_1, stream_pkCols.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "pkUkConstraint"


	public static class checkConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "checkConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2484:1: checkConstraint : KW_CHECK LPAREN expression RPAREN -> ^( TOK_CHECK_CONSTRAINT expression ) ;
	public final HiveParser.checkConstraint_return checkConstraint() throws RecognitionException {
		HiveParser.checkConstraint_return retval = new HiveParser.checkConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CHECK916=null;
		Token LPAREN917=null;
		Token RPAREN919=null;
		ParserRuleReturnScope expression918 =null;

		ASTNode KW_CHECK916_tree=null;
		ASTNode LPAREN917_tree=null;
		ASTNode RPAREN919_tree=null;
		RewriteRuleTokenStream stream_KW_CHECK=new RewriteRuleTokenStream(adaptor,"token KW_CHECK");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");

		 pushMsg("CHECK constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2487:5: ( KW_CHECK LPAREN expression RPAREN -> ^( TOK_CHECK_CONSTRAINT expression ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2487:7: KW_CHECK LPAREN expression RPAREN
			{
			KW_CHECK916=(Token)match(input,KW_CHECK,FOLLOW_KW_CHECK_in_checkConstraint15419); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CHECK.add(KW_CHECK916);

			LPAREN917=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_checkConstraint15421); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN917);

			pushFollow(FOLLOW_expression_in_checkConstraint15423);
			expression918=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression918.getTree());
			RPAREN919=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_checkConstraint15425); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN919);

			// AST REWRITE
			// elements: expression
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2488:5: -> ^( TOK_CHECK_CONSTRAINT expression )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2488:8: ^( TOK_CHECK_CONSTRAINT expression )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CHECK_CONSTRAINT, "TOK_CHECK_CONSTRAINT"), root_1);
				adaptor.addChild(root_1, stream_expression.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "checkConstraint"


	public static class createForeignKey_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createForeignKey"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2491:1: createForeignKey : ( KW_CONSTRAINT constraintName= identifier )? KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? ) ;
	public final HiveParser.createForeignKey_return createForeignKey() throws RecognitionException {
		HiveParser.createForeignKey_return retval = new HiveParser.createForeignKey_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT920=null;
		Token KW_FOREIGN921=null;
		Token KW_KEY922=null;
		Token KW_REFERENCES923=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope fkCols =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope parCols =null;
		ParserRuleReturnScope constraintOptsCreate924 =null;

		ASTNode KW_CONSTRAINT920_tree=null;
		ASTNode KW_FOREIGN921_tree=null;
		ASTNode KW_KEY922_tree=null;
		ASTNode KW_REFERENCES923_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleTokenStream stream_KW_FOREIGN=new RewriteRuleTokenStream(adaptor,"token KW_FOREIGN");
		RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("foreign key", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2494:5: ( ( KW_CONSTRAINT constraintName= identifier )? KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2494:7: ( KW_CONSTRAINT constraintName= identifier )? KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2494:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt274=2;
			int LA274_0 = input.LA(1);
			if ( (LA274_0==KW_CONSTRAINT) ) {
				alt274=1;
			}
			switch (alt274) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2494:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT920=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_createForeignKey15465); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT920);

					pushFollow(FOLLOW_identifier_in_createForeignKey15469);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			KW_FOREIGN921=(Token)match(input,KW_FOREIGN,FOLLOW_KW_FOREIGN_in_createForeignKey15473); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOREIGN.add(KW_FOREIGN921);

			KW_KEY922=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_createForeignKey15475); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY922);

			pushFollow(FOLLOW_columnParenthesesList_in_createForeignKey15479);
			fkCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(fkCols.getTree());
			KW_REFERENCES923=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_createForeignKey15482); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES923);

			pushFollow(FOLLOW_tableName_in_createForeignKey15486);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			pushFollow(FOLLOW_columnParenthesesList_in_createForeignKey15490);
			parCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(parCols.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2494:160: ( constraintOptsCreate )?
			int alt275=2;
			int LA275_0 = input.LA(1);
			if ( (LA275_0==KW_DISABLE||LA275_0==KW_ENABLE||LA275_0==KW_ENFORCED||LA275_0==KW_NOT) ) {
				alt275=1;
			}
			switch (alt275) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2494:160: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_createForeignKey15492);
					constraintOptsCreate924=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate924.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsCreate, constraintOptsCreate, parCols, fkCols, fkCols, tabName, parCols, constraintName, tabName
			// token labels: 
			// rule labels: parCols, tabName, fkCols, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_parCols=new RewriteRuleSubtreeStream(adaptor,"rule parCols",parCols!=null?parCols.getTree():null);
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_fkCols=new RewriteRuleSubtreeStream(adaptor,"rule fkCols",fkCols!=null?fkCols.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2495:5: -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:13: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:31: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_fkCols.nextTree());
				adaptor.addChild(root_1, stream_tabName.nextTree());
				adaptor.addChild(root_1, stream_parCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:96: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2497:5: -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2497:8: ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				adaptor.addChild(root_1, stream_fkCols.nextTree());
				adaptor.addChild(root_1, stream_tabName.nextTree());
				adaptor.addChild(root_1, stream_parCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2497:52: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createForeignKey"


	public static class alterForeignKeyWithName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterForeignKeyWithName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2500:1: alterForeignKeyWithName : KW_CONSTRAINT constraintName= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsAlter )? -> ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? ) ;
	public final HiveParser.alterForeignKeyWithName_return alterForeignKeyWithName() throws RecognitionException {
		HiveParser.alterForeignKeyWithName_return retval = new HiveParser.alterForeignKeyWithName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT925=null;
		Token KW_FOREIGN926=null;
		Token KW_KEY927=null;
		Token KW_REFERENCES928=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope fkCols =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope parCols =null;
		ParserRuleReturnScope constraintOptsAlter929 =null;

		ASTNode KW_CONSTRAINT925_tree=null;
		ASTNode KW_FOREIGN926_tree=null;
		ASTNode KW_KEY927_tree=null;
		ASTNode KW_REFERENCES928_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleTokenStream stream_KW_FOREIGN=new RewriteRuleTokenStream(adaptor,"token KW_FOREIGN");
		RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");
		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("foreign key with key name", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2503:5: ( KW_CONSTRAINT constraintName= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsAlter )? -> ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2503:7: KW_CONSTRAINT constraintName= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsAlter )?
			{
			KW_CONSTRAINT925=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterForeignKeyWithName15585); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT925);

			pushFollow(FOLLOW_identifier_in_alterForeignKeyWithName15589);
			constraintName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
			KW_FOREIGN926=(Token)match(input,KW_FOREIGN,FOLLOW_KW_FOREIGN_in_alterForeignKeyWithName15591); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOREIGN.add(KW_FOREIGN926);

			KW_KEY927=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_alterForeignKeyWithName15593); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY927);

			pushFollow(FOLLOW_columnParenthesesList_in_alterForeignKeyWithName15597);
			fkCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(fkCols.getTree());
			KW_REFERENCES928=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_alterForeignKeyWithName15600); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES928);

			pushFollow(FOLLOW_tableName_in_alterForeignKeyWithName15604);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			pushFollow(FOLLOW_columnParenthesesList_in_alterForeignKeyWithName15608);
			parCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(parCols.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2503:157: ( constraintOptsAlter )?
			int alt276=2;
			int LA276_0 = input.LA(1);
			if ( (LA276_0==KW_DISABLE||LA276_0==KW_ENABLE||LA276_0==KW_ENFORCED||LA276_0==KW_NOT) ) {
				alt276=1;
			}
			switch (alt276) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2503:157: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterForeignKeyWithName15610);
					constraintOptsAlter929=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter929.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: fkCols, tabName, constraintName, constraintOptsAlter, parCols
			// token labels: 
			// rule labels: tabName, parCols, fkCols, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_parCols=new RewriteRuleSubtreeStream(adaptor,"rule parCols",parCols!=null?parCols.getTree():null);
			RewriteRuleSubtreeStream stream_fkCols=new RewriteRuleSubtreeStream(adaptor,"rule fkCols",fkCols!=null?fkCols.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2504:5: -> ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2504:8: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2504:26: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_fkCols.nextTree());
				adaptor.addChild(root_1, stream_tabName.nextTree());
				adaptor.addChild(root_1, stream_parCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2504:91: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterForeignKeyWithName"


	public static class skewedValueElement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedValueElement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2507:1: skewedValueElement : ( skewedColumnValues | skewedColumnValuePairList );
	public final HiveParser.skewedValueElement_return skewedValueElement() throws RecognitionException {
		HiveParser.skewedValueElement_return retval = new HiveParser.skewedValueElement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope skewedColumnValues930 =null;
		ParserRuleReturnScope skewedColumnValuePairList931 =null;


		 pushMsg("skewed value element", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2510:5: ( skewedColumnValues | skewedColumnValuePairList )
			int alt277=2;
			int LA277_0 = input.LA(1);
			if ( (LA277_0==CharSetName||LA277_0==IntegralLiteral||(LA277_0 >= KW_CURRENT_DATE && LA277_0 <= KW_CURRENT_TIMESTAMP)||LA277_0==KW_DATE||LA277_0==KW_FALSE||LA277_0==KW_NULL||(LA277_0 >= KW_TIMESTAMP && LA277_0 <= KW_TIMESTAMPLOCALTZ)||LA277_0==KW_TRUE||(LA277_0 >= Number && LA277_0 <= NumberLiteral)||LA277_0==StringLiteral) ) {
				alt277=1;
			}
			else if ( (LA277_0==LPAREN) ) {
				alt277=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 277, 0, input);
				throw nvae;
			}

			switch (alt277) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2511:7: skewedColumnValues
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValues_in_skewedValueElement15674);
					skewedColumnValues930=skewedColumnValues();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValues930.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2512:8: skewedColumnValuePairList
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValuePairList_in_skewedValueElement15683);
					skewedColumnValuePairList931=skewedColumnValuePairList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValuePairList931.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedValueElement"


	public static class skewedColumnValuePairList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValuePairList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2515:1: skewedColumnValuePairList : skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) ;
	public final HiveParser.skewedColumnValuePairList_return skewedColumnValuePairList() throws RecognitionException {
		HiveParser.skewedColumnValuePairList_return retval = new HiveParser.skewedColumnValuePairList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA933=null;
		ParserRuleReturnScope skewedColumnValuePair932 =null;
		ParserRuleReturnScope skewedColumnValuePair934 =null;

		ASTNode COMMA933_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_skewedColumnValuePair=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValuePair");

		 pushMsg("column value pair list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2518:5: ( skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2518:7: skewedColumnValuePair ( COMMA skewedColumnValuePair )*
			{
			pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList15710);
			skewedColumnValuePair932=skewedColumnValuePair();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedColumnValuePair.add(skewedColumnValuePair932.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2518:29: ( COMMA skewedColumnValuePair )*
			loop278:
			while (true) {
				int alt278=2;
				int LA278_0 = input.LA(1);
				if ( (LA278_0==COMMA) ) {
					alt278=1;
				}

				switch (alt278) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2518:30: COMMA skewedColumnValuePair
					{
					COMMA933=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedColumnValuePairList15713); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA933);

					pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList15715);
					skewedColumnValuePair934=skewedColumnValuePair();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_skewedColumnValuePair.add(skewedColumnValuePair934.getTree());
					}
					break;

				default :
					break loop278;
				}
			}

			// AST REWRITE
			// elements: skewedColumnValuePair
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2518:60: -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2518:63: ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLVALUE_PAIR, "TOK_TABCOLVALUE_PAIR"), root_1);
				if ( !(stream_skewedColumnValuePair.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_skewedColumnValuePair.hasNext() ) {
					adaptor.addChild(root_1, stream_skewedColumnValuePair.nextTree());
				}
				stream_skewedColumnValuePair.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValuePairList"


	public static class skewedColumnValuePair_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValuePair"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2521:1: skewedColumnValuePair : LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) ;
	public final HiveParser.skewedColumnValuePair_return skewedColumnValuePair() throws RecognitionException {
		HiveParser.skewedColumnValuePair_return retval = new HiveParser.skewedColumnValuePair_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN935=null;
		Token RPAREN936=null;
		ParserRuleReturnScope colValues =null;

		ASTNode LPAREN935_tree=null;
		ASTNode RPAREN936_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_skewedColumnValues=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValues");

		 pushMsg("column value pair", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2524:5: ( LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2525:7: LPAREN colValues= skewedColumnValues RPAREN
			{
			LPAREN935=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_skewedColumnValuePair15760); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN935);

			pushFollow(FOLLOW_skewedColumnValues_in_skewedColumnValuePair15764);
			colValues=skewedColumnValues();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedColumnValues.add(colValues.getTree());
			RPAREN936=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_skewedColumnValuePair15766); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN936);

			// AST REWRITE
			// elements: colValues
			// token labels: 
			// rule labels: colValues, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colValues=new RewriteRuleSubtreeStream(adaptor,"rule colValues",colValues!=null?colValues.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2526:7: -> ^( TOK_TABCOLVALUES $colValues)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2526:10: ^( TOK_TABCOLVALUES $colValues)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLVALUES, "TOK_TABCOLVALUES"), root_1);
				adaptor.addChild(root_1, stream_colValues.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValuePair"


	public static class skewedColumnValues_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValues"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2529:1: skewedColumnValues : skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) ;
	public final HiveParser.skewedColumnValues_return skewedColumnValues() throws RecognitionException {
		HiveParser.skewedColumnValues_return retval = new HiveParser.skewedColumnValues_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA938=null;
		ParserRuleReturnScope skewedColumnValue937 =null;
		ParserRuleReturnScope skewedColumnValue939 =null;

		ASTNode COMMA938_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_skewedColumnValue=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValue");

		 pushMsg("column values", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2532:5: ( skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2532:7: skewedColumnValue ( COMMA skewedColumnValue )*
			{
			pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues15809);
			skewedColumnValue937=skewedColumnValue();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedColumnValue.add(skewedColumnValue937.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2532:25: ( COMMA skewedColumnValue )*
			loop279:
			while (true) {
				int alt279=2;
				int LA279_0 = input.LA(1);
				if ( (LA279_0==COMMA) ) {
					alt279=1;
				}

				switch (alt279) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2532:26: COMMA skewedColumnValue
					{
					COMMA938=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedColumnValues15812); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA938);

					pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues15814);
					skewedColumnValue939=skewedColumnValue();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_skewedColumnValue.add(skewedColumnValue939.getTree());
					}
					break;

				default :
					break loop279;
				}
			}

			// AST REWRITE
			// elements: skewedColumnValue
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2532:52: -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2532:55: ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLVALUE, "TOK_TABCOLVALUE"), root_1);
				if ( !(stream_skewedColumnValue.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_skewedColumnValue.hasNext() ) {
					adaptor.addChild(root_1, stream_skewedColumnValue.nextTree());
				}
				stream_skewedColumnValue.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValues"


	public static class skewedColumnValue_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValue"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2535:1: skewedColumnValue : constant ;
	public final HiveParser.skewedColumnValue_return skewedColumnValue() throws RecognitionException {
		HiveParser.skewedColumnValue_return retval = new HiveParser.skewedColumnValue_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope constant940 =null;


		 pushMsg("column value", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2538:5: ( constant )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2539:7: constant
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_constant_in_skewedColumnValue15858);
			constant940=constant();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, constant940.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValue"


	public static class skewedValueLocationElement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedValueLocationElement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2542:1: skewedValueLocationElement : ( skewedColumnValue | skewedColumnValuePair );
	public final HiveParser.skewedValueLocationElement_return skewedValueLocationElement() throws RecognitionException {
		HiveParser.skewedValueLocationElement_return retval = new HiveParser.skewedValueLocationElement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope skewedColumnValue941 =null;
		ParserRuleReturnScope skewedColumnValuePair942 =null;


		 pushMsg("skewed value location element", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2545:5: ( skewedColumnValue | skewedColumnValuePair )
			int alt280=2;
			int LA280_0 = input.LA(1);
			if ( (LA280_0==CharSetName||LA280_0==IntegralLiteral||(LA280_0 >= KW_CURRENT_DATE && LA280_0 <= KW_CURRENT_TIMESTAMP)||LA280_0==KW_DATE||LA280_0==KW_FALSE||LA280_0==KW_NULL||(LA280_0 >= KW_TIMESTAMP && LA280_0 <= KW_TIMESTAMPLOCALTZ)||LA280_0==KW_TRUE||(LA280_0 >= Number && LA280_0 <= NumberLiteral)||LA280_0==StringLiteral) ) {
				alt280=1;
			}
			else if ( (LA280_0==LPAREN) ) {
				alt280=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 280, 0, input);
				throw nvae;
			}

			switch (alt280) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2546:7: skewedColumnValue
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValue_in_skewedValueLocationElement15892);
					skewedColumnValue941=skewedColumnValue();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValue941.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2547:8: skewedColumnValuePair
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement15901);
					skewedColumnValuePair942=skewedColumnValuePair();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValuePair942.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedValueLocationElement"


	public static class orderSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "orderSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2550:1: orderSpecification : ( KW_ASC | KW_DESC );
	public final HiveParser.orderSpecification_return orderSpecification() throws RecognitionException {
		HiveParser.orderSpecification_return retval = new HiveParser.orderSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token set943=null;

		ASTNode set943_tree=null;

		 pushMsg("order specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2553:5: ( KW_ASC | KW_DESC )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:
			{
			root_0 = (ASTNode)adaptor.nil();


			set943=input.LT(1);
			if ( input.LA(1)==KW_ASC||input.LA(1)==KW_DESC ) {
				input.consume();
				if ( state.backtracking==0 ) adaptor.addChild(root_0, (ASTNode)adaptor.create(set943));
				state.errorRecovery=false;
				state.failed=false;
			}
			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				MismatchedSetException mse = new MismatchedSetException(null,input);
				throw mse;
			}
			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "orderSpecification"


	public static class nullOrdering_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "nullOrdering"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2555:1: nullOrdering : ( KW_NULLS KW_FIRST -> ^( TOK_NULLS_FIRST ) | KW_NULLS KW_LAST -> ^( TOK_NULLS_LAST ) );
	public final HiveParser.nullOrdering_return nullOrdering() throws RecognitionException {
		HiveParser.nullOrdering_return retval = new HiveParser.nullOrdering_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_NULLS944=null;
		Token KW_FIRST945=null;
		Token KW_NULLS946=null;
		Token KW_LAST947=null;

		ASTNode KW_NULLS944_tree=null;
		ASTNode KW_FIRST945_tree=null;
		ASTNode KW_NULLS946_tree=null;
		ASTNode KW_LAST947_tree=null;
		RewriteRuleTokenStream stream_KW_FIRST=new RewriteRuleTokenStream(adaptor,"token KW_FIRST");
		RewriteRuleTokenStream stream_KW_NULLS=new RewriteRuleTokenStream(adaptor,"token KW_NULLS");
		RewriteRuleTokenStream stream_KW_LAST=new RewriteRuleTokenStream(adaptor,"token KW_LAST");

		 pushMsg("nulls ordering", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2558:5: ( KW_NULLS KW_FIRST -> ^( TOK_NULLS_FIRST ) | KW_NULLS KW_LAST -> ^( TOK_NULLS_LAST ) )
			int alt281=2;
			int LA281_0 = input.LA(1);
			if ( (LA281_0==KW_NULLS) ) {
				int LA281_1 = input.LA(2);
				if ( (LA281_1==KW_FIRST) ) {
					alt281=1;
				}
				else if ( (LA281_1==KW_LAST) ) {
					alt281=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 281, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 281, 0, input);
				throw nvae;
			}

			switch (alt281) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2558:7: KW_NULLS KW_FIRST
					{
					KW_NULLS944=(Token)match(input,KW_NULLS,FOLLOW_KW_NULLS_in_nullOrdering15955); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NULLS.add(KW_NULLS944);

					KW_FIRST945=(Token)match(input,KW_FIRST,FOLLOW_KW_FIRST_in_nullOrdering15957); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FIRST.add(KW_FIRST945);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2558:25: -> ^( TOK_NULLS_FIRST )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2558:28: ^( TOK_NULLS_FIRST )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2559:7: KW_NULLS KW_LAST
					{
					KW_NULLS946=(Token)match(input,KW_NULLS,FOLLOW_KW_NULLS_in_nullOrdering15971); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NULLS.add(KW_NULLS946);

					KW_LAST947=(Token)match(input,KW_LAST,FOLLOW_KW_LAST_in_nullOrdering15973); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LAST.add(KW_LAST947);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2559:24: -> ^( TOK_NULLS_LAST )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2559:27: ^( TOK_NULLS_LAST )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "nullOrdering"


	public static class columnNameOrder_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameOrder"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2562:1: columnNameOrder : identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) ) -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) ) ;
	public final HiveParser.columnNameOrder_return columnNameOrder() throws RecognitionException {
		HiveParser.columnNameOrder_return retval = new HiveParser.columnNameOrder_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope orderSpec =null;
		ParserRuleReturnScope nullSpec =null;
		ParserRuleReturnScope identifier948 =null;

		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_nullOrdering=new RewriteRuleSubtreeStream(adaptor,"rule nullOrdering");
		RewriteRuleSubtreeStream stream_orderSpecification=new RewriteRuleSubtreeStream(adaptor,"rule orderSpecification");

		 pushMsg("column name order", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:5: ( identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) ) -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:7: identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameOrder16006);
			identifier948=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier948.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:27: (orderSpec= orderSpecification )?
			int alt282=2;
			int LA282_0 = input.LA(1);
			if ( (LA282_0==KW_ASC||LA282_0==KW_DESC) ) {
				alt282=1;
			}
			switch (alt282) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:27: orderSpec= orderSpecification
					{
					pushFollow(FOLLOW_orderSpecification_in_columnNameOrder16010);
					orderSpec=orderSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orderSpecification.add(orderSpec.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:56: (nullSpec= nullOrdering )?
			int alt283=2;
			int LA283_0 = input.LA(1);
			if ( (LA283_0==KW_NULLS) ) {
				alt283=1;
			}
			switch (alt283) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:56: nullSpec= nullOrdering
					{
					pushFollow(FOLLOW_nullOrdering_in_columnNameOrder16015);
					nullSpec=nullOrdering();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_nullOrdering.add(nullSpec.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: identifier, identifier, identifier, identifier, nullSpec, nullSpec, identifier, nullSpec, identifier
			// token labels: 
			// rule labels: nullSpec, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_nullSpec=new RewriteRuleSubtreeStream(adaptor,"rule nullSpec",nullSpec!=null?nullSpec.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2566:5: -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null && (nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2567:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2567:37: ^( TOK_NULLS_FIRST identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2568:5: -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2569:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2569:37: ^( $nullSpec identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2570:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && (orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType()==HiveParser.KW_ASC) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2571:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2571:37: ^( TOK_NULLS_FIRST identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2572:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && (orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType()==HiveParser.KW_DESC) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2573:13: ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2573:38: ^( TOK_NULLS_LAST identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2574:5: -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType()==HiveParser.KW_ASC) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2575:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2575:37: ^( $nullSpec identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2576:5: -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2576:8: ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2576:33: ^( $nullSpec identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameOrder"


	public static class columnNameCommentList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameCommentList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2579:1: columnNameCommentList : columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) ;
	public final HiveParser.columnNameCommentList_return columnNameCommentList() throws RecognitionException {
		HiveParser.columnNameCommentList_return retval = new HiveParser.columnNameCommentList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA950=null;
		ParserRuleReturnScope columnNameComment949 =null;
		ParserRuleReturnScope columnNameComment951 =null;

		ASTNode COMMA950_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameComment=new RewriteRuleSubtreeStream(adaptor,"rule columnNameComment");

		 pushMsg("column name comment list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2582:5: ( columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2582:7: columnNameComment ( COMMA columnNameComment )*
			{
			pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList16212);
			columnNameComment949=columnNameComment();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameComment.add(columnNameComment949.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2582:25: ( COMMA columnNameComment )*
			loop284:
			while (true) {
				int alt284=2;
				int LA284_0 = input.LA(1);
				if ( (LA284_0==COMMA) ) {
					alt284=1;
				}

				switch (alt284) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2582:26: COMMA columnNameComment
					{
					COMMA950=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameCommentList16215); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA950);

					pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList16217);
					columnNameComment951=columnNameComment();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameComment.add(columnNameComment951.getTree());
					}
					break;

				default :
					break loop284;
				}
			}

			// AST REWRITE
			// elements: columnNameComment
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2582:52: -> ^( TOK_TABCOLNAME ( columnNameComment )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2582:55: ^( TOK_TABCOLNAME ( columnNameComment )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);
				if ( !(stream_columnNameComment.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameComment.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameComment.nextTree());
				}
				stream_columnNameComment.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameCommentList"


	public static class columnNameComment_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameComment"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2585:1: columnNameComment : colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) ;
	public final HiveParser.columnNameComment_return columnNameComment() throws RecognitionException {
		HiveParser.columnNameComment_return retval = new HiveParser.columnNameComment_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT952=null;
		ParserRuleReturnScope colName =null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT952_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("column name comment", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2588:5: (colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2588:7: colName= identifier ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameComment16257);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2588:26: ( KW_COMMENT comment= StringLiteral )?
			int alt285=2;
			int LA285_0 = input.LA(1);
			if ( (LA285_0==KW_COMMENT) ) {
				alt285=1;
			}
			switch (alt285) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2588:27: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT952=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameComment16260); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT952);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameComment16264); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: comment, colName
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2589:5: -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2589:8: ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_NULL, "TOK_NULL"));
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2589:40: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameComment"


	public static class orderSpecificationRewrite_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "orderSpecificationRewrite"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2592:1: orderSpecificationRewrite : ( KW_ASC -> ^( TOK_TABSORTCOLNAMEASC ) | KW_DESC -> ^( TOK_TABSORTCOLNAMEDESC ) );
	public final HiveParser.orderSpecificationRewrite_return orderSpecificationRewrite() throws RecognitionException {
		HiveParser.orderSpecificationRewrite_return retval = new HiveParser.orderSpecificationRewrite_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ASC953=null;
		Token KW_DESC954=null;

		ASTNode KW_ASC953_tree=null;
		ASTNode KW_DESC954_tree=null;
		RewriteRuleTokenStream stream_KW_DESC=new RewriteRuleTokenStream(adaptor,"token KW_DESC");
		RewriteRuleTokenStream stream_KW_ASC=new RewriteRuleTokenStream(adaptor,"token KW_ASC");

		 pushMsg("order specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2595:5: ( KW_ASC -> ^( TOK_TABSORTCOLNAMEASC ) | KW_DESC -> ^( TOK_TABSORTCOLNAMEDESC ) )
			int alt286=2;
			int LA286_0 = input.LA(1);
			if ( (LA286_0==KW_ASC) ) {
				alt286=1;
			}
			else if ( (LA286_0==KW_DESC) ) {
				alt286=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 286, 0, input);
				throw nvae;
			}

			switch (alt286) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2595:7: KW_ASC
					{
					KW_ASC953=(Token)match(input,KW_ASC,FOLLOW_KW_ASC_in_orderSpecificationRewrite16312); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ASC.add(KW_ASC953);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2595:14: -> ^( TOK_TABSORTCOLNAMEASC )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2595:17: ^( TOK_TABSORTCOLNAMEASC )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2596:7: KW_DESC
					{
					KW_DESC954=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_orderSpecificationRewrite16326); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DESC.add(KW_DESC954);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2596:15: -> ^( TOK_TABSORTCOLNAMEDESC )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2596:18: ^( TOK_TABSORTCOLNAMEDESC )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "orderSpecificationRewrite"


	public static class columnRefOrder_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnRefOrder"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2599:1: columnRefOrder : expression (orderSpec= orderSpecificationRewrite )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null && nullsLast()}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) ) -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) ) -> {$nullSpec.tree == null && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) ) -> {$nullSpec.tree == null}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) ) -> ^( $orderSpec ^( $nullSpec expression ) ) ;
	public final HiveParser.columnRefOrder_return columnRefOrder() throws RecognitionException {
		HiveParser.columnRefOrder_return retval = new HiveParser.columnRefOrder_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope orderSpec =null;
		ParserRuleReturnScope nullSpec =null;
		ParserRuleReturnScope expression955 =null;

		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_orderSpecificationRewrite=new RewriteRuleSubtreeStream(adaptor,"rule orderSpecificationRewrite");
		RewriteRuleSubtreeStream stream_nullOrdering=new RewriteRuleSubtreeStream(adaptor,"rule nullOrdering");

		 pushMsg("column order", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2602:5: ( expression (orderSpec= orderSpecificationRewrite )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null && nullsLast()}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) ) -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) ) -> {$nullSpec.tree == null && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) ) -> {$nullSpec.tree == null}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) ) -> ^( $orderSpec ^( $nullSpec expression ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2602:7: expression (orderSpec= orderSpecificationRewrite )? (nullSpec= nullOrdering )?
			{
			pushFollow(FOLLOW_expression_in_columnRefOrder16359);
			expression955=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression955.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2602:27: (orderSpec= orderSpecificationRewrite )?
			int alt287=2;
			int LA287_0 = input.LA(1);
			if ( (LA287_0==KW_ASC||LA287_0==KW_DESC) ) {
				alt287=1;
			}
			switch (alt287) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2602:27: orderSpec= orderSpecificationRewrite
					{
					pushFollow(FOLLOW_orderSpecificationRewrite_in_columnRefOrder16363);
					orderSpec=orderSpecificationRewrite();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orderSpecificationRewrite.add(orderSpec.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2602:63: (nullSpec= nullOrdering )?
			int alt288=2;
			int LA288_0 = input.LA(1);
			if ( (LA288_0==KW_NULLS) ) {
				alt288=1;
			}
			switch (alt288) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2602:63: nullSpec= nullOrdering
					{
					pushFollow(FOLLOW_nullOrdering_in_columnRefOrder16368);
					nullSpec=nullOrdering();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_nullOrdering.add(nullSpec.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: orderSpec, expression, nullSpec, orderSpec, orderSpec, nullSpec, expression, expression, expression, expression, expression
			// token labels: 
			// rule labels: orderSpec, nullSpec, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_orderSpec=new RewriteRuleSubtreeStream(adaptor,"rule orderSpec",orderSpec!=null?orderSpec.getTree():null);
			RewriteRuleSubtreeStream stream_nullSpec=new RewriteRuleSubtreeStream(adaptor,"rule nullSpec",nullSpec!=null?nullSpec.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2604:5: -> {$orderSpec.tree == null && $nullSpec.tree == null && nullsLast()}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null && (nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && nullsLast()) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2605:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2605:37: ^( TOK_NULLS_LAST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2607:5: -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null && (nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2608:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2608:37: ^( TOK_NULLS_FIRST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2610:5: -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2611:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2611:37: ^( $nullSpec expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2613:5: -> {$nullSpec.tree == null && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && nullsLast()) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2614:13: ^( $orderSpec ^( TOK_NULLS_LAST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_orderSpec.nextNode(), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2614:26: ^( TOK_NULLS_LAST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2616:5: -> {$nullSpec.tree == null}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2617:13: ^( $orderSpec ^( TOK_NULLS_FIRST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_orderSpec.nextNode(), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2617:26: ^( TOK_NULLS_FIRST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2619:5: -> ^( $orderSpec ^( $nullSpec expression ) )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2619:8: ^( $orderSpec ^( $nullSpec expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_orderSpec.nextNode(), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2619:21: ^( $nullSpec expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnRefOrder"


	public static class columnNameType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2622:1: columnNameType : colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
	public final HiveParser.columnNameType_return columnNameType() throws RecognitionException {
		HiveParser.columnNameType_return retval = new HiveParser.columnNameType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT957=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope colType956 =null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT957_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2625:5: (colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2625:7: colName= identifier colType ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameType16599);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			pushFollow(FOLLOW_colType_in_columnNameType16601);
			colType956=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType956.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2625:34: ( KW_COMMENT comment= StringLiteral )?
			int alt289=2;
			int LA289_0 = input.LA(1);
			if ( (LA289_0==KW_COMMENT) ) {
				alt289=1;
			}
			switch (alt289) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2625:35: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT957=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameType16604); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT957);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameType16608); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: colName, colType, colName, comment, colType
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2626:5: -> {containExcludedCharForCreateTableColumnName($colName.text)}?
			if (containExcludedCharForCreateTableColumnName((colName!=null?input.toString(colName.start,colName.stop):null))) {
				adaptor.addChild(root_0, throwColumnNameException());
			}

			else // 2627:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
			if (comment == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2627:28: ^( TOK_TABCOL $colName colType )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2628:5: -> ^( TOK_TABCOL $colName colType $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2628:28: ^( TOK_TABCOL $colName colType $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameType"


	public static class columnNameTypeOrConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeOrConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2631:1: columnNameTypeOrConstraint : ( ( tableConstraint ) | ( columnNameTypeConstraint ) );
	public final HiveParser.columnNameTypeOrConstraint_return columnNameTypeOrConstraint() throws RecognitionException {
		HiveParser.columnNameTypeOrConstraint_return retval = new HiveParser.columnNameTypeOrConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope tableConstraint958 =null;
		ParserRuleReturnScope columnNameTypeConstraint959 =null;


		 pushMsg("column name or constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2634:5: ( ( tableConstraint ) | ( columnNameTypeConstraint ) )
			int alt290=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
			case KW_FOREIGN:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt290=1;
				}
				break;
			case KW_CHECK:
				{
				int LA290_5 = input.LA(2);
				if ( (LA290_5==LPAREN) ) {
					alt290=1;
				}
				else if ( (LA290_5==KW_ARRAY||(LA290_5 >= KW_BIGINT && LA290_5 <= KW_BOOLEAN)||LA290_5==KW_CHAR||(LA290_5 >= KW_DATE && LA290_5 <= KW_DATETIME)||LA290_5==KW_DECIMAL||LA290_5==KW_DOUBLE||LA290_5==KW_FLOAT||LA290_5==KW_INT||LA290_5==KW_MAP||LA290_5==KW_SMALLINT||(LA290_5 >= KW_STRING && LA290_5 <= KW_STRUCT)||(LA290_5 >= KW_TIMESTAMP && LA290_5 <= KW_TINYINT)||LA290_5==KW_UNIONTYPE||LA290_5==KW_VARCHAR) ) {
					alt290=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 290, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AT:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_CRON:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EVERY:
			case KW_EXCLUSIVE:
			case KW_EXECUTE:
			case KW_EXECUTED:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_IDXPROPERTIES:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGEDLOCATION:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULED:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMA:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SERVER:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URI:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_IGNORE:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt290=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 290, 0, input);
				throw nvae;
			}
			switch (alt290) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2634:7: ( tableConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2634:7: ( tableConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2634:9: tableConstraint
					{
					pushFollow(FOLLOW_tableConstraint_in_columnNameTypeOrConstraint16704);
					tableConstraint958=tableConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, tableConstraint958.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2635:7: ( columnNameTypeConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2635:7: ( columnNameTypeConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2635:9: columnNameTypeConstraint
					{
					pushFollow(FOLLOW_columnNameTypeConstraint_in_columnNameTypeOrConstraint16716);
					columnNameTypeConstraint959=columnNameTypeConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, columnNameTypeConstraint959.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeOrConstraint"


	public static class tableConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2638:1: tableConstraint : ( ( createForeignKey ) | ( createConstraint ) );
	public final HiveParser.tableConstraint_return tableConstraint() throws RecognitionException {
		HiveParser.tableConstraint_return retval = new HiveParser.tableConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope createForeignKey960 =null;
		ParserRuleReturnScope createConstraint961 =null;


		 pushMsg("table constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:5: ( ( createForeignKey ) | ( createConstraint ) )
			int alt291=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
				{
				int LA291_1 = input.LA(2);
				if ( (LA291_1==Identifier) ) {
					int LA291_6 = input.LA(3);
					if ( (LA291_6==KW_FOREIGN) ) {
						alt291=1;
					}
					else if ( (LA291_6==KW_CHECK||LA291_6==KW_PRIMARY||LA291_6==KW_UNIQUE) ) {
						alt291=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 291, 6, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( ((LA291_1 >= KW_ABORT && LA291_1 <= KW_AFTER)||LA291_1==KW_ALLOC_FRACTION||LA291_1==KW_ANALYZE||LA291_1==KW_ARCHIVE||(LA291_1 >= KW_ASC && LA291_1 <= KW_AT)||(LA291_1 >= KW_AUTOCOMMIT && LA291_1 <= KW_BEFORE)||(LA291_1 >= KW_BUCKET && LA291_1 <= KW_BUCKETS)||(LA291_1 >= KW_CACHE && LA291_1 <= KW_CASCADE)||(LA291_1 >= KW_CBO && LA291_1 <= KW_CHANGE)||(LA291_1 >= KW_CHECK && LA291_1 <= KW_COLLECTION)||(LA291_1 >= KW_COLUMNS && LA291_1 <= KW_COMMENT)||(LA291_1 >= KW_COMPACT && LA291_1 <= KW_CONCATENATE)||(LA291_1 >= KW_CONTINUE && LA291_1 <= KW_COST)||LA291_1==KW_CRON||LA291_1==KW_DATA||LA291_1==KW_DATABASES||(LA291_1 >= KW_DATETIME && LA291_1 <= KW_DEBUG)||(LA291_1 >= KW_DEFAULT && LA291_1 <= KW_DEFINED)||(LA291_1 >= KW_DELIMITED && LA291_1 <= KW_DESC)||(LA291_1 >= KW_DETAIL && LA291_1 <= KW_DISABLE)||(LA291_1 >= KW_DISTRIBUTE && LA291_1 <= KW_DO)||LA291_1==KW_DOW||(LA291_1 >= KW_DUMP && LA291_1 <= KW_ELEM_TYPE)||LA291_1==KW_ENABLE||(LA291_1 >= KW_ENFORCED && LA291_1 <= KW_EVERY)||(LA291_1 >= KW_EXCLUSIVE && LA291_1 <= KW_EXECUTED)||(LA291_1 >= KW_EXPLAIN && LA291_1 <= KW_EXPRESSION)||(LA291_1 >= KW_FIELDS && LA291_1 <= KW_FIRST)||(LA291_1 >= KW_FORMAT && LA291_1 <= KW_FORMATTED)||LA291_1==KW_FUNCTIONS||(LA291_1 >= KW_HOUR && LA291_1 <= KW_IDXPROPERTIES)||(LA291_1 >= KW_INDEX && LA291_1 <= KW_INDEXES)||(LA291_1 >= KW_INPATH && LA291_1 <= KW_INPUTFORMAT)||(LA291_1 >= KW_ISOLATION && LA291_1 <= KW_JAR)||(LA291_1 >= KW_JOINCOST && LA291_1 <= KW_LAST)||LA291_1==KW_LEVEL||(LA291_1 >= KW_LIMIT && LA291_1 <= KW_LOAD)||(LA291_1 >= KW_LOCATION && LA291_1 <= KW_LONG)||(LA291_1 >= KW_MANAGEDLOCATION && LA291_1 <= KW_MANAGEMENT)||(LA291_1 >= KW_MAPJOIN && LA291_1 <= KW_MATERIALIZED)||LA291_1==KW_METADATA||(LA291_1 >= KW_MINUTE && LA291_1 <= KW_MONTH)||(LA291_1 >= KW_MOVE && LA291_1 <= KW_MSCK)||(LA291_1 >= KW_NORELY && LA291_1 <= KW_NOSCAN)||LA291_1==KW_NOVALIDATE||LA291_1==KW_NULLS||LA291_1==KW_OFFSET||(LA291_1 >= KW_OPERATOR && LA291_1 <= KW_OPTION)||(LA291_1 >= KW_OUTPUTDRIVER && LA291_1 <= KW_OUTPUTFORMAT)||(LA291_1 >= KW_OVERWRITE && LA291_1 <= KW_OWNER)||(LA291_1 >= KW_PARTITIONED && LA291_1 <= KW_PATH)||(LA291_1 >= KW_PLAN && LA291_1 <= KW_POOL)||LA291_1==KW_PRINCIPALS||(LA291_1 >= KW_PURGE && LA291_1 <= KW_QUERY_PARALLELISM)||LA291_1==KW_READ||(LA291_1 >= KW_REBUILD && LA291_1 <= KW_RECORDWRITER)||(LA291_1 >= KW_RELOAD && LA291_1 <= KW_RESTRICT)||LA291_1==KW_REWRITE||(LA291_1 >= KW_ROLE && LA291_1 <= KW_ROLES)||(LA291_1 >= KW_SCHEDULED && LA291_1 <= KW_SECOND)||(LA291_1 >= KW_SEMI && LA291_1 <= KW_SERVER)||(LA291_1 >= KW_SETS && LA291_1 <= KW_SKEWED)||(LA291_1 >= KW_SNAPSHOT && LA291_1 <= KW_SSL)||(LA291_1 >= KW_STATISTICS && LA291_1 <= KW_SUMMARY)||LA291_1==KW_TABLES||(LA291_1 >= KW_TBLPROPERTIES && LA291_1 <= KW_TERMINATED)||LA291_1==KW_TINYINT||(LA291_1 >= KW_TOUCH && LA291_1 <= KW_TRANSACTIONS)||LA291_1==KW_UNARCHIVE||LA291_1==KW_UNDO||LA291_1==KW_UNIONTYPE||(LA291_1 >= KW_UNLOCK && LA291_1 <= KW_UNSIGNED)||(LA291_1 >= KW_URI && LA291_1 <= KW_USE)||(LA291_1 >= KW_UTC && LA291_1 <= KW_VALIDATE)||LA291_1==KW_VALUE_TYPE||(LA291_1 >= KW_VECTORIZATION && LA291_1 <= KW_WEEK)||LA291_1==KW_WHILE||(LA291_1 >= KW_WORK && LA291_1 <= KW_ZONE)||LA291_1==KW_BATCH||LA291_1==KW_DAYOFWEEK||LA291_1==KW_HOLD_DDLTIME||LA291_1==KW_IGNORE||LA291_1==KW_NO_DROP||LA291_1==KW_OFFLINE||LA291_1==KW_PROTECTION||LA291_1==KW_READONLY||LA291_1==KW_TIMESTAMPTZ) ) {
					int LA291_7 = input.LA(3);
					if ( (LA291_7==KW_FOREIGN) ) {
						alt291=1;
					}
					else if ( (LA291_7==KW_CHECK||LA291_7==KW_PRIMARY||LA291_7==KW_UNIQUE) ) {
						alt291=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 291, 7, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 291, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_FOREIGN:
				{
				alt291=1;
				}
				break;
			case KW_CHECK:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt291=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 291, 0, input);
				throw nvae;
			}
			switch (alt291) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:7: ( createForeignKey )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:7: ( createForeignKey )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:9: createForeignKey
					{
					pushFollow(FOLLOW_createForeignKey_in_tableConstraint16747);
					createForeignKey960=createForeignKey();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createForeignKey960.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2642:7: ( createConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2642:7: ( createConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2642:9: createConstraint
					{
					pushFollow(FOLLOW_createConstraint_in_tableConstraint16759);
					createConstraint961=createConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createConstraint961.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableConstraint"


	public static class columnNameTypeConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2645:1: columnNameTypeConstraint : colName= identifier colType ( columnConstraint[$colName.tree] )? ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? ) ;
	public final HiveParser.columnNameTypeConstraint_return columnNameTypeConstraint() throws RecognitionException {
		HiveParser.columnNameTypeConstraint_return retval = new HiveParser.columnNameTypeConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT964=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope colType962 =null;
		ParserRuleReturnScope columnConstraint963 =null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT964_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnConstraint=new RewriteRuleSubtreeStream(adaptor,"rule columnConstraint");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2648:5: (colName= identifier colType ( columnConstraint[$colName.tree] )? ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2648:7: colName= identifier colType ( columnConstraint[$colName.tree] )? ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameTypeConstraint16790);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			pushFollow(FOLLOW_colType_in_columnNameTypeConstraint16792);
			colType962=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType962.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2648:34: ( columnConstraint[$colName.tree] )?
			int alt292=2;
			int LA292_0 = input.LA(1);
			if ( (LA292_0==KW_CHECK||LA292_0==KW_CONSTRAINT||LA292_0==KW_DEFAULT||LA292_0==KW_NOT||LA292_0==KW_PRIMARY||LA292_0==KW_REFERENCES||LA292_0==KW_UNIQUE) ) {
				alt292=1;
			}
			switch (alt292) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2648:34: columnConstraint[$colName.tree]
					{
					pushFollow(FOLLOW_columnConstraint_in_columnNameTypeConstraint16794);
					columnConstraint963=columnConstraint((colName!=null?((ASTNode)colName.getTree()):null));
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnConstraint.add(columnConstraint963.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2648:67: ( KW_COMMENT comment= StringLiteral )?
			int alt293=2;
			int LA293_0 = input.LA(1);
			if ( (LA293_0==KW_COMMENT) ) {
				alt293=1;
			}
			switch (alt293) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2648:68: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT964=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameTypeConstraint16799); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT964);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameTypeConstraint16803); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: comment, columnConstraint, colName, colType
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2649:5: -> {containExcludedCharForCreateTableColumnName($colName.text)}?
			if (containExcludedCharForCreateTableColumnName((colName!=null?input.toString(colName.start,colName.stop):null))) {
				adaptor.addChild(root_0, throwColumnNameException());
			}

			else // 2650:5: -> ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2650:8: ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2650:39: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2650:48: ( columnConstraint )?
				if ( stream_columnConstraint.hasNext() ) {
					adaptor.addChild(root_1, stream_columnConstraint.nextTree());
				}
				stream_columnConstraint.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeConstraint"


	public static class columnConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2653:1: columnConstraint[CommonTree fkColName] : ( ( foreignKeyConstraint[$fkColName] ) | ( colConstraint ) );
	public final HiveParser.columnConstraint_return columnConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.columnConstraint_return retval = new HiveParser.columnConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope foreignKeyConstraint965 =null;
		ParserRuleReturnScope colConstraint966 =null;


		 pushMsg("column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2656:5: ( ( foreignKeyConstraint[$fkColName] ) | ( colConstraint ) )
			int alt294=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
				{
				int LA294_1 = input.LA(2);
				if ( (LA294_1==Identifier) ) {
					int LA294_8 = input.LA(3);
					if ( (LA294_8==KW_REFERENCES) ) {
						alt294=1;
					}
					else if ( (LA294_8==KW_CHECK||LA294_8==KW_DEFAULT||LA294_8==KW_NOT||LA294_8==KW_PRIMARY||LA294_8==KW_UNIQUE) ) {
						alt294=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 294, 8, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( ((LA294_1 >= KW_ABORT && LA294_1 <= KW_AFTER)||LA294_1==KW_ALLOC_FRACTION||LA294_1==KW_ANALYZE||LA294_1==KW_ARCHIVE||(LA294_1 >= KW_ASC && LA294_1 <= KW_AT)||(LA294_1 >= KW_AUTOCOMMIT && LA294_1 <= KW_BEFORE)||(LA294_1 >= KW_BUCKET && LA294_1 <= KW_BUCKETS)||(LA294_1 >= KW_CACHE && LA294_1 <= KW_CASCADE)||(LA294_1 >= KW_CBO && LA294_1 <= KW_CHANGE)||(LA294_1 >= KW_CHECK && LA294_1 <= KW_COLLECTION)||(LA294_1 >= KW_COLUMNS && LA294_1 <= KW_COMMENT)||(LA294_1 >= KW_COMPACT && LA294_1 <= KW_CONCATENATE)||(LA294_1 >= KW_CONTINUE && LA294_1 <= KW_COST)||LA294_1==KW_CRON||LA294_1==KW_DATA||LA294_1==KW_DATABASES||(LA294_1 >= KW_DATETIME && LA294_1 <= KW_DEBUG)||(LA294_1 >= KW_DEFAULT && LA294_1 <= KW_DEFINED)||(LA294_1 >= KW_DELIMITED && LA294_1 <= KW_DESC)||(LA294_1 >= KW_DETAIL && LA294_1 <= KW_DISABLE)||(LA294_1 >= KW_DISTRIBUTE && LA294_1 <= KW_DO)||LA294_1==KW_DOW||(LA294_1 >= KW_DUMP && LA294_1 <= KW_ELEM_TYPE)||LA294_1==KW_ENABLE||(LA294_1 >= KW_ENFORCED && LA294_1 <= KW_EVERY)||(LA294_1 >= KW_EXCLUSIVE && LA294_1 <= KW_EXECUTED)||(LA294_1 >= KW_EXPLAIN && LA294_1 <= KW_EXPRESSION)||(LA294_1 >= KW_FIELDS && LA294_1 <= KW_FIRST)||(LA294_1 >= KW_FORMAT && LA294_1 <= KW_FORMATTED)||LA294_1==KW_FUNCTIONS||(LA294_1 >= KW_HOUR && LA294_1 <= KW_IDXPROPERTIES)||(LA294_1 >= KW_INDEX && LA294_1 <= KW_INDEXES)||(LA294_1 >= KW_INPATH && LA294_1 <= KW_INPUTFORMAT)||(LA294_1 >= KW_ISOLATION && LA294_1 <= KW_JAR)||(LA294_1 >= KW_JOINCOST && LA294_1 <= KW_LAST)||LA294_1==KW_LEVEL||(LA294_1 >= KW_LIMIT && LA294_1 <= KW_LOAD)||(LA294_1 >= KW_LOCATION && LA294_1 <= KW_LONG)||(LA294_1 >= KW_MANAGEDLOCATION && LA294_1 <= KW_MANAGEMENT)||(LA294_1 >= KW_MAPJOIN && LA294_1 <= KW_MATERIALIZED)||LA294_1==KW_METADATA||(LA294_1 >= KW_MINUTE && LA294_1 <= KW_MONTH)||(LA294_1 >= KW_MOVE && LA294_1 <= KW_MSCK)||(LA294_1 >= KW_NORELY && LA294_1 <= KW_NOSCAN)||LA294_1==KW_NOVALIDATE||LA294_1==KW_NULLS||LA294_1==KW_OFFSET||(LA294_1 >= KW_OPERATOR && LA294_1 <= KW_OPTION)||(LA294_1 >= KW_OUTPUTDRIVER && LA294_1 <= KW_OUTPUTFORMAT)||(LA294_1 >= KW_OVERWRITE && LA294_1 <= KW_OWNER)||(LA294_1 >= KW_PARTITIONED && LA294_1 <= KW_PATH)||(LA294_1 >= KW_PLAN && LA294_1 <= KW_POOL)||LA294_1==KW_PRINCIPALS||(LA294_1 >= KW_PURGE && LA294_1 <= KW_QUERY_PARALLELISM)||LA294_1==KW_READ||(LA294_1 >= KW_REBUILD && LA294_1 <= KW_RECORDWRITER)||(LA294_1 >= KW_RELOAD && LA294_1 <= KW_RESTRICT)||LA294_1==KW_REWRITE||(LA294_1 >= KW_ROLE && LA294_1 <= KW_ROLES)||(LA294_1 >= KW_SCHEDULED && LA294_1 <= KW_SECOND)||(LA294_1 >= KW_SEMI && LA294_1 <= KW_SERVER)||(LA294_1 >= KW_SETS && LA294_1 <= KW_SKEWED)||(LA294_1 >= KW_SNAPSHOT && LA294_1 <= KW_SSL)||(LA294_1 >= KW_STATISTICS && LA294_1 <= KW_SUMMARY)||LA294_1==KW_TABLES||(LA294_1 >= KW_TBLPROPERTIES && LA294_1 <= KW_TERMINATED)||LA294_1==KW_TINYINT||(LA294_1 >= KW_TOUCH && LA294_1 <= KW_TRANSACTIONS)||LA294_1==KW_UNARCHIVE||LA294_1==KW_UNDO||LA294_1==KW_UNIONTYPE||(LA294_1 >= KW_UNLOCK && LA294_1 <= KW_UNSIGNED)||(LA294_1 >= KW_URI && LA294_1 <= KW_USE)||(LA294_1 >= KW_UTC && LA294_1 <= KW_VALIDATE)||LA294_1==KW_VALUE_TYPE||(LA294_1 >= KW_VECTORIZATION && LA294_1 <= KW_WEEK)||LA294_1==KW_WHILE||(LA294_1 >= KW_WORK && LA294_1 <= KW_ZONE)||LA294_1==KW_BATCH||LA294_1==KW_DAYOFWEEK||LA294_1==KW_HOLD_DDLTIME||LA294_1==KW_IGNORE||LA294_1==KW_NO_DROP||LA294_1==KW_OFFLINE||LA294_1==KW_PROTECTION||LA294_1==KW_READONLY||LA294_1==KW_TIMESTAMPTZ) ) {
					int LA294_9 = input.LA(3);
					if ( (LA294_9==KW_REFERENCES) ) {
						alt294=1;
					}
					else if ( (LA294_9==KW_CHECK||LA294_9==KW_DEFAULT||LA294_9==KW_NOT||LA294_9==KW_PRIMARY||LA294_9==KW_UNIQUE) ) {
						alt294=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 294, 9, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 294, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_REFERENCES:
				{
				alt294=1;
				}
				break;
			case KW_CHECK:
			case KW_DEFAULT:
			case KW_NOT:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt294=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 294, 0, input);
				throw nvae;
			}
			switch (alt294) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2656:7: ( foreignKeyConstraint[$fkColName] )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2656:7: ( foreignKeyConstraint[$fkColName] )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2656:9: foreignKeyConstraint[$fkColName]
					{
					pushFollow(FOLLOW_foreignKeyConstraint_in_columnConstraint16867);
					foreignKeyConstraint965=foreignKeyConstraint(fkColName);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, foreignKeyConstraint965.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2657:7: ( colConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2657:7: ( colConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2657:9: colConstraint
					{
					pushFollow(FOLLOW_colConstraint_in_columnConstraint16880);
					colConstraint966=colConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, colConstraint966.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnConstraint"


	public static class foreignKeyConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "foreignKeyConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2660:1: foreignKeyConstraint[CommonTree fkColName] : ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) ;
	public final HiveParser.foreignKeyConstraint_return foreignKeyConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.foreignKeyConstraint_return retval = new HiveParser.foreignKeyConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT967=null;
		Token KW_REFERENCES968=null;
		Token LPAREN969=null;
		Token RPAREN970=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope constraintOptsCreate971 =null;

		ASTNode KW_CONSTRAINT967_tree=null;
		ASTNode KW_REFERENCES968_tree=null;
		ASTNode LPAREN969_tree=null;
		ASTNode RPAREN970_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:5: ( ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:7: ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt295=2;
			int LA295_0 = input.LA(1);
			if ( (LA295_0==KW_CONSTRAINT) ) {
				alt295=1;
			}
			switch (alt295) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT967=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_foreignKeyConstraint16911); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT967);

					pushFollow(FOLLOW_identifier_in_foreignKeyConstraint16915);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			KW_REFERENCES968=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_foreignKeyConstraint16919); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES968);

			pushFollow(FOLLOW_tableName_in_foreignKeyConstraint16923);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			LPAREN969=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_foreignKeyConstraint16925); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN969);

			pushFollow(FOLLOW_columnName_in_foreignKeyConstraint16929);
			colName=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(colName.getTree());
			RPAREN970=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_foreignKeyConstraint16931); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN970);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:115: ( constraintOptsCreate )?
			int alt296=2;
			int LA296_0 = input.LA(1);
			if ( (LA296_0==KW_DISABLE||LA296_0==KW_ENABLE||LA296_0==KW_ENFORCED||LA296_0==KW_NOT) ) {
				alt296=1;
			}
			switch (alt296) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:115: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_foreignKeyConstraint16933);
					constraintOptsCreate971=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate971.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: colName, tabName, constraintName, constraintOptsCreate, constraintOptsCreate, tabName, colName
			// token labels: 
			// rule labels: colName, tabName, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2664:5: -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2665:13: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2665:31: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2665:70: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2665:110: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2665:137: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2666:5: -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2666:8: ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2666:26: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2666:66: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2666:93: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "foreignKeyConstraint"


	public static class colConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "colConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2669:1: colConstraint : ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) ;
	public final HiveParser.colConstraint_return colConstraint() throws RecognitionException {
		HiveParser.colConstraint_return retval = new HiveParser.colConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT972=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope columnConstraintType973 =null;
		ParserRuleReturnScope constraintOptsCreate974 =null;

		ASTNode KW_CONSTRAINT972_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnConstraintType=new RewriteRuleSubtreeStream(adaptor,"rule columnConstraintType");

		 pushMsg("column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2672:5: ( ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2672:7: ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2672:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt297=2;
			int LA297_0 = input.LA(1);
			if ( (LA297_0==KW_CONSTRAINT) ) {
				alt297=1;
			}
			switch (alt297) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2672:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT972=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_colConstraint17041); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT972);

					pushFollow(FOLLOW_identifier_in_colConstraint17045);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_columnConstraintType_in_colConstraint17049);
			columnConstraintType973=columnConstraintType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnConstraintType.add(columnConstraintType973.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2672:71: ( constraintOptsCreate )?
			int alt298=2;
			int LA298_0 = input.LA(1);
			if ( (LA298_0==KW_DISABLE||LA298_0==KW_ENABLE||LA298_0==KW_ENFORCED||LA298_0==KW_NOT) ) {
				alt298=1;
			}
			switch (alt298) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2672:71: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_colConstraint17051);
					constraintOptsCreate974=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate974.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsCreate, constraintOptsCreate, constraintName
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2673:5: -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2674:13: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType973!=null?((ASTNode)columnConstraintType973.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2674:44: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2674:83: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2675:5: -> ^( ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2675:8: ^( ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType973!=null?((ASTNode)columnConstraintType973.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2675:39: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "colConstraint"


	public static class alterColumnConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterColumnConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2678:1: alterColumnConstraint[CommonTree fkColName] : ( ( alterForeignKeyConstraint[$fkColName] ) | ( alterColConstraint ) );
	public final HiveParser.alterColumnConstraint_return alterColumnConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.alterColumnConstraint_return retval = new HiveParser.alterColumnConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterForeignKeyConstraint975 =null;
		ParserRuleReturnScope alterColConstraint976 =null;


		 pushMsg("alter column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2681:5: ( ( alterForeignKeyConstraint[$fkColName] ) | ( alterColConstraint ) )
			int alt299=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
				{
				int LA299_1 = input.LA(2);
				if ( (LA299_1==Identifier) ) {
					int LA299_8 = input.LA(3);
					if ( (LA299_8==KW_REFERENCES) ) {
						alt299=1;
					}
					else if ( (LA299_8==KW_CHECK||LA299_8==KW_DEFAULT||LA299_8==KW_NOT||LA299_8==KW_PRIMARY||LA299_8==KW_UNIQUE) ) {
						alt299=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 299, 8, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( ((LA299_1 >= KW_ABORT && LA299_1 <= KW_AFTER)||LA299_1==KW_ALLOC_FRACTION||LA299_1==KW_ANALYZE||LA299_1==KW_ARCHIVE||(LA299_1 >= KW_ASC && LA299_1 <= KW_AT)||(LA299_1 >= KW_AUTOCOMMIT && LA299_1 <= KW_BEFORE)||(LA299_1 >= KW_BUCKET && LA299_1 <= KW_BUCKETS)||(LA299_1 >= KW_CACHE && LA299_1 <= KW_CASCADE)||(LA299_1 >= KW_CBO && LA299_1 <= KW_CHANGE)||(LA299_1 >= KW_CHECK && LA299_1 <= KW_COLLECTION)||(LA299_1 >= KW_COLUMNS && LA299_1 <= KW_COMMENT)||(LA299_1 >= KW_COMPACT && LA299_1 <= KW_CONCATENATE)||(LA299_1 >= KW_CONTINUE && LA299_1 <= KW_COST)||LA299_1==KW_CRON||LA299_1==KW_DATA||LA299_1==KW_DATABASES||(LA299_1 >= KW_DATETIME && LA299_1 <= KW_DEBUG)||(LA299_1 >= KW_DEFAULT && LA299_1 <= KW_DEFINED)||(LA299_1 >= KW_DELIMITED && LA299_1 <= KW_DESC)||(LA299_1 >= KW_DETAIL && LA299_1 <= KW_DISABLE)||(LA299_1 >= KW_DISTRIBUTE && LA299_1 <= KW_DO)||LA299_1==KW_DOW||(LA299_1 >= KW_DUMP && LA299_1 <= KW_ELEM_TYPE)||LA299_1==KW_ENABLE||(LA299_1 >= KW_ENFORCED && LA299_1 <= KW_EVERY)||(LA299_1 >= KW_EXCLUSIVE && LA299_1 <= KW_EXECUTED)||(LA299_1 >= KW_EXPLAIN && LA299_1 <= KW_EXPRESSION)||(LA299_1 >= KW_FIELDS && LA299_1 <= KW_FIRST)||(LA299_1 >= KW_FORMAT && LA299_1 <= KW_FORMATTED)||LA299_1==KW_FUNCTIONS||(LA299_1 >= KW_HOUR && LA299_1 <= KW_IDXPROPERTIES)||(LA299_1 >= KW_INDEX && LA299_1 <= KW_INDEXES)||(LA299_1 >= KW_INPATH && LA299_1 <= KW_INPUTFORMAT)||(LA299_1 >= KW_ISOLATION && LA299_1 <= KW_JAR)||(LA299_1 >= KW_JOINCOST && LA299_1 <= KW_LAST)||LA299_1==KW_LEVEL||(LA299_1 >= KW_LIMIT && LA299_1 <= KW_LOAD)||(LA299_1 >= KW_LOCATION && LA299_1 <= KW_LONG)||(LA299_1 >= KW_MANAGEDLOCATION && LA299_1 <= KW_MANAGEMENT)||(LA299_1 >= KW_MAPJOIN && LA299_1 <= KW_MATERIALIZED)||LA299_1==KW_METADATA||(LA299_1 >= KW_MINUTE && LA299_1 <= KW_MONTH)||(LA299_1 >= KW_MOVE && LA299_1 <= KW_MSCK)||(LA299_1 >= KW_NORELY && LA299_1 <= KW_NOSCAN)||LA299_1==KW_NOVALIDATE||LA299_1==KW_NULLS||LA299_1==KW_OFFSET||(LA299_1 >= KW_OPERATOR && LA299_1 <= KW_OPTION)||(LA299_1 >= KW_OUTPUTDRIVER && LA299_1 <= KW_OUTPUTFORMAT)||(LA299_1 >= KW_OVERWRITE && LA299_1 <= KW_OWNER)||(LA299_1 >= KW_PARTITIONED && LA299_1 <= KW_PATH)||(LA299_1 >= KW_PLAN && LA299_1 <= KW_POOL)||LA299_1==KW_PRINCIPALS||(LA299_1 >= KW_PURGE && LA299_1 <= KW_QUERY_PARALLELISM)||LA299_1==KW_READ||(LA299_1 >= KW_REBUILD && LA299_1 <= KW_RECORDWRITER)||(LA299_1 >= KW_RELOAD && LA299_1 <= KW_RESTRICT)||LA299_1==KW_REWRITE||(LA299_1 >= KW_ROLE && LA299_1 <= KW_ROLES)||(LA299_1 >= KW_SCHEDULED && LA299_1 <= KW_SECOND)||(LA299_1 >= KW_SEMI && LA299_1 <= KW_SERVER)||(LA299_1 >= KW_SETS && LA299_1 <= KW_SKEWED)||(LA299_1 >= KW_SNAPSHOT && LA299_1 <= KW_SSL)||(LA299_1 >= KW_STATISTICS && LA299_1 <= KW_SUMMARY)||LA299_1==KW_TABLES||(LA299_1 >= KW_TBLPROPERTIES && LA299_1 <= KW_TERMINATED)||LA299_1==KW_TINYINT||(LA299_1 >= KW_TOUCH && LA299_1 <= KW_TRANSACTIONS)||LA299_1==KW_UNARCHIVE||LA299_1==KW_UNDO||LA299_1==KW_UNIONTYPE||(LA299_1 >= KW_UNLOCK && LA299_1 <= KW_UNSIGNED)||(LA299_1 >= KW_URI && LA299_1 <= KW_USE)||(LA299_1 >= KW_UTC && LA299_1 <= KW_VALIDATE)||LA299_1==KW_VALUE_TYPE||(LA299_1 >= KW_VECTORIZATION && LA299_1 <= KW_WEEK)||LA299_1==KW_WHILE||(LA299_1 >= KW_WORK && LA299_1 <= KW_ZONE)||LA299_1==KW_BATCH||LA299_1==KW_DAYOFWEEK||LA299_1==KW_HOLD_DDLTIME||LA299_1==KW_IGNORE||LA299_1==KW_NO_DROP||LA299_1==KW_OFFLINE||LA299_1==KW_PROTECTION||LA299_1==KW_READONLY||LA299_1==KW_TIMESTAMPTZ) ) {
					int LA299_9 = input.LA(3);
					if ( (LA299_9==KW_REFERENCES) ) {
						alt299=1;
					}
					else if ( (LA299_9==KW_CHECK||LA299_9==KW_DEFAULT||LA299_9==KW_NOT||LA299_9==KW_PRIMARY||LA299_9==KW_UNIQUE) ) {
						alt299=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 299, 9, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 299, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_REFERENCES:
				{
				alt299=1;
				}
				break;
			case KW_CHECK:
			case KW_DEFAULT:
			case KW_NOT:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt299=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 299, 0, input);
				throw nvae;
			}
			switch (alt299) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2681:7: ( alterForeignKeyConstraint[$fkColName] )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2681:7: ( alterForeignKeyConstraint[$fkColName] )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2681:9: alterForeignKeyConstraint[$fkColName]
					{
					pushFollow(FOLLOW_alterForeignKeyConstraint_in_alterColumnConstraint17129);
					alterForeignKeyConstraint975=alterForeignKeyConstraint(fkColName);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterForeignKeyConstraint975.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2682:7: ( alterColConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2682:7: ( alterColConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2682:9: alterColConstraint
					{
					pushFollow(FOLLOW_alterColConstraint_in_alterColumnConstraint17142);
					alterColConstraint976=alterColConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterColConstraint976.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterColumnConstraint"


	public static class alterForeignKeyConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterForeignKeyConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2685:1: alterForeignKeyConstraint[CommonTree fkColName] : ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) ;
	public final HiveParser.alterForeignKeyConstraint_return alterForeignKeyConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.alterForeignKeyConstraint_return retval = new HiveParser.alterForeignKeyConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT977=null;
		Token KW_REFERENCES978=null;
		Token LPAREN979=null;
		Token RPAREN980=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope constraintOptsAlter981 =null;

		ASTNode KW_CONSTRAINT977_tree=null;
		ASTNode KW_REFERENCES978_tree=null;
		ASTNode LPAREN979_tree=null;
		ASTNode RPAREN980_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("alter column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:5: ( ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:7: ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsAlter )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt300=2;
			int LA300_0 = input.LA(1);
			if ( (LA300_0==KW_CONSTRAINT) ) {
				alt300=1;
			}
			switch (alt300) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT977=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterForeignKeyConstraint17173); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT977);

					pushFollow(FOLLOW_identifier_in_alterForeignKeyConstraint17177);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			KW_REFERENCES978=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_alterForeignKeyConstraint17181); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES978);

			pushFollow(FOLLOW_tableName_in_alterForeignKeyConstraint17185);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			LPAREN979=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_alterForeignKeyConstraint17187); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN979);

			pushFollow(FOLLOW_columnName_in_alterForeignKeyConstraint17191);
			colName=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(colName.getTree());
			RPAREN980=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_alterForeignKeyConstraint17193); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN980);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:115: ( constraintOptsAlter )?
			int alt301=2;
			int LA301_0 = input.LA(1);
			if ( (LA301_0==KW_DISABLE||LA301_0==KW_ENABLE||LA301_0==KW_ENFORCED||LA301_0==KW_NOT) ) {
				alt301=1;
			}
			switch (alt301) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:115: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterForeignKeyConstraint17195);
					constraintOptsAlter981=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter981.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tabName, constraintName, constraintOptsAlter, colName, constraintOptsAlter, tabName, colName
			// token labels: 
			// rule labels: tabName, colName, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2689:5: -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2690:13: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2690:31: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2690:70: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2690:110: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2690:137: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2691:5: -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2691:8: ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2691:26: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2691:66: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2691:93: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterForeignKeyConstraint"


	public static class alterColConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterColConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2694:1: alterColConstraint : ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) -> ^( ( constraintOptsAlter )? ) ;
	public final HiveParser.alterColConstraint_return alterColConstraint() throws RecognitionException {
		HiveParser.alterColConstraint_return retval = new HiveParser.alterColConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT982=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope columnConstraintType983 =null;
		ParserRuleReturnScope constraintOptsAlter984 =null;

		ASTNode KW_CONSTRAINT982_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnConstraintType=new RewriteRuleSubtreeStream(adaptor,"rule columnConstraintType");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");

		 pushMsg("alter column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2697:5: ( ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) -> ^( ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2697:7: ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsAlter )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2697:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt302=2;
			int LA302_0 = input.LA(1);
			if ( (LA302_0==KW_CONSTRAINT) ) {
				alt302=1;
			}
			switch (alt302) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2697:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT982=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterColConstraint17303); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT982);

					pushFollow(FOLLOW_identifier_in_alterColConstraint17307);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_columnConstraintType_in_alterColConstraint17311);
			columnConstraintType983=columnConstraintType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnConstraintType.add(columnConstraintType983.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2697:71: ( constraintOptsAlter )?
			int alt303=2;
			int LA303_0 = input.LA(1);
			if ( (LA303_0==KW_DISABLE||LA303_0==KW_ENABLE||LA303_0==KW_ENFORCED||LA303_0==KW_NOT) ) {
				alt303=1;
			}
			switch (alt303) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2697:71: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterColConstraint17313);
					constraintOptsAlter984=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter984.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintName, constraintOptsAlter, constraintOptsAlter
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2698:5: -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2699:13: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType983!=null?((ASTNode)columnConstraintType983.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2699:44: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2699:83: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2700:5: -> ^( ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2700:8: ^( ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType983!=null?((ASTNode)columnConstraintType983.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2700:39: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterColConstraint"


	public static class columnConstraintType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnConstraintType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2703:1: columnConstraintType : ( KW_NOT KW_NULL -> TOK_NOT_NULL | KW_DEFAULT defaultVal -> ^( TOK_DEFAULT_VALUE defaultVal ) | checkConstraint | tableConstraintType );
	public final HiveParser.columnConstraintType_return columnConstraintType() throws RecognitionException {
		HiveParser.columnConstraintType_return retval = new HiveParser.columnConstraintType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_NOT985=null;
		Token KW_NULL986=null;
		Token KW_DEFAULT987=null;
		ParserRuleReturnScope defaultVal988 =null;
		ParserRuleReturnScope checkConstraint989 =null;
		ParserRuleReturnScope tableConstraintType990 =null;

		ASTNode KW_NOT985_tree=null;
		ASTNode KW_NULL986_tree=null;
		ASTNode KW_DEFAULT987_tree=null;
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_NULL=new RewriteRuleTokenStream(adaptor,"token KW_NULL");
		RewriteRuleTokenStream stream_KW_DEFAULT=new RewriteRuleTokenStream(adaptor,"token KW_DEFAULT");
		RewriteRuleSubtreeStream stream_defaultVal=new RewriteRuleSubtreeStream(adaptor,"rule defaultVal");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2704:5: ( KW_NOT KW_NULL -> TOK_NOT_NULL | KW_DEFAULT defaultVal -> ^( TOK_DEFAULT_VALUE defaultVal ) | checkConstraint | tableConstraintType )
			int alt304=4;
			switch ( input.LA(1) ) {
			case KW_NOT:
				{
				alt304=1;
				}
				break;
			case KW_DEFAULT:
				{
				alt304=2;
				}
				break;
			case KW_CHECK:
				{
				alt304=3;
				}
				break;
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt304=4;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 304, 0, input);
				throw nvae;
			}
			switch (alt304) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2704:7: KW_NOT KW_NULL
					{
					KW_NOT985=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_columnConstraintType17378); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT985);

					KW_NULL986=(Token)match(input,KW_NULL,FOLLOW_KW_NULL_in_columnConstraintType17380); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NULL.add(KW_NULL986);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2704:28: -> TOK_NOT_NULL
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_NOT_NULL, "TOK_NOT_NULL"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2705:7: KW_DEFAULT defaultVal
					{
					KW_DEFAULT987=(Token)match(input,KW_DEFAULT,FOLLOW_KW_DEFAULT_in_columnConstraintType17401); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DEFAULT.add(KW_DEFAULT987);

					pushFollow(FOLLOW_defaultVal_in_columnConstraintType17403);
					defaultVal988=defaultVal();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_defaultVal.add(defaultVal988.getTree());
					// AST REWRITE
					// elements: defaultVal
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2705:28: -> ^( TOK_DEFAULT_VALUE defaultVal )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2705:34: ^( TOK_DEFAULT_VALUE defaultVal )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DEFAULT_VALUE, "TOK_DEFAULT_VALUE"), root_1);
						adaptor.addChild(root_1, stream_defaultVal.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2706:7: checkConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_checkConstraint_in_columnConstraintType17421);
					checkConstraint989=checkConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, checkConstraint989.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2707:7: tableConstraintType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_tableConstraintType_in_columnConstraintType17429);
					tableConstraintType990=tableConstraintType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, tableConstraintType990.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnConstraintType"


	public static class defaultVal_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "defaultVal"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2710:1: defaultVal : ( constant | function | castExpression );
	public final HiveParser.defaultVal_return defaultVal() throws RecognitionException {
		HiveParser.defaultVal_return retval = new HiveParser.defaultVal_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope constant991 =null;
		ParserRuleReturnScope function992 =null;
		ParserRuleReturnScope castExpression993 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2711:5: ( constant | function | castExpression )
			int alt305=3;
			switch ( input.LA(1) ) {
			case CharSetName:
			case IntegralLiteral:
			case KW_FALSE:
			case KW_NULL:
			case KW_TIMESTAMPLOCALTZ:
			case KW_TRUE:
			case Number:
			case NumberLiteral:
			case StringLiteral:
				{
				alt305=1;
				}
				break;
			case KW_DATE:
				{
				int LA305_3 = input.LA(2);
				if ( (LA305_3==StringLiteral) ) {
					alt305=1;
				}
				else if ( (LA305_3==LPAREN) ) {
					alt305=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 305, 3, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_CURRENT_DATE:
				{
				int LA305_4 = input.LA(2);
				if ( (LA305_4==EOF||LA305_4==COMMA||LA305_4==KW_AFTER||LA305_4==KW_CASCADE||LA305_4==KW_COMMENT||LA305_4==KW_DISABLE||LA305_4==KW_ENABLE||LA305_4==KW_ENFORCED||LA305_4==KW_FIRST||LA305_4==KW_NOT||LA305_4==KW_RESTRICT||LA305_4==RPAREN) ) {
					alt305=1;
				}
				else if ( (LA305_4==LPAREN) ) {
					alt305=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 305, 4, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_TIMESTAMP:
				{
				int LA305_5 = input.LA(2);
				if ( (LA305_5==StringLiteral) ) {
					alt305=1;
				}
				else if ( (LA305_5==LPAREN) ) {
					alt305=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 305, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_CURRENT_TIMESTAMP:
				{
				int LA305_6 = input.LA(2);
				if ( (LA305_6==EOF||LA305_6==COMMA||LA305_6==KW_AFTER||LA305_6==KW_CASCADE||LA305_6==KW_COMMENT||LA305_6==KW_DISABLE||LA305_6==KW_ENABLE||LA305_6==KW_ENFORCED||LA305_6==KW_FIRST||LA305_6==KW_NOT||LA305_6==KW_RESTRICT||LA305_6==RPAREN) ) {
					alt305=1;
				}
				else if ( (LA305_6==LPAREN) ) {
					alt305=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 305, 6, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ARRAY:
			case KW_ASC:
			case KW_AT:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BIGINT:
			case KW_BINARY:
			case KW_BOOLEAN:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_CRON:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOUBLE:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EVERY:
			case KW_EXCLUSIVE:
			case KW_EXECUTE:
			case KW_EXECUTED:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FLOAT:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_GROUPING:
			case KW_HOUR:
			case KW_IDXPROPERTIES:
			case KW_IF:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_INT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGEDLOCATION:
			case KW_MANAGEMENT:
			case KW_MAP:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULED:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMA:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SERVER:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SMALLINT:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URI:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_IGNORE:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt305=2;
				}
				break;
			case KW_CAST:
				{
				alt305=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 305, 0, input);
				throw nvae;
			}
			switch (alt305) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2711:7: constant
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_constant_in_defaultVal17446);
					constant991=constant();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, constant991.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2712:7: function
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_function_in_defaultVal17454);
					function992=function();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, function992.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2713:7: castExpression
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_castExpression_in_defaultVal17462);
					castExpression993=castExpression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, castExpression993.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "defaultVal"


	public static class tableConstraintType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableConstraintType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2716:1: tableConstraintType : ( KW_PRIMARY KW_KEY -> TOK_PRIMARY_KEY | KW_UNIQUE -> TOK_UNIQUE );
	public final HiveParser.tableConstraintType_return tableConstraintType() throws RecognitionException {
		HiveParser.tableConstraintType_return retval = new HiveParser.tableConstraintType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_PRIMARY994=null;
		Token KW_KEY995=null;
		Token KW_UNIQUE996=null;

		ASTNode KW_PRIMARY994_tree=null;
		ASTNode KW_KEY995_tree=null;
		ASTNode KW_UNIQUE996_tree=null;
		RewriteRuleTokenStream stream_KW_PRIMARY=new RewriteRuleTokenStream(adaptor,"token KW_PRIMARY");
		RewriteRuleTokenStream stream_KW_UNIQUE=new RewriteRuleTokenStream(adaptor,"token KW_UNIQUE");
		RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2717:5: ( KW_PRIMARY KW_KEY -> TOK_PRIMARY_KEY | KW_UNIQUE -> TOK_UNIQUE )
			int alt306=2;
			int LA306_0 = input.LA(1);
			if ( (LA306_0==KW_PRIMARY) ) {
				alt306=1;
			}
			else if ( (LA306_0==KW_UNIQUE) ) {
				alt306=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 306, 0, input);
				throw nvae;
			}

			switch (alt306) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2717:7: KW_PRIMARY KW_KEY
					{
					KW_PRIMARY994=(Token)match(input,KW_PRIMARY,FOLLOW_KW_PRIMARY_in_tableConstraintType17479); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PRIMARY.add(KW_PRIMARY994);

					KW_KEY995=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_tableConstraintType17481); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY995);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2717:28: -> TOK_PRIMARY_KEY
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_PRIMARY_KEY, "TOK_PRIMARY_KEY"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2718:7: KW_UNIQUE
					{
					KW_UNIQUE996=(Token)match(input,KW_UNIQUE,FOLLOW_KW_UNIQUE_in_tableConstraintType17499); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNIQUE.add(KW_UNIQUE996);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2718:28: -> TOK_UNIQUE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_UNIQUE, "TOK_UNIQUE"));
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableConstraintType"


	public static class constraintOptsCreate_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "constraintOptsCreate"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2721:1: constraintOptsCreate : enableValidateSpecification ( relySpecification )? ;
	public final HiveParser.constraintOptsCreate_return constraintOptsCreate() throws RecognitionException {
		HiveParser.constraintOptsCreate_return retval = new HiveParser.constraintOptsCreate_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope enableValidateSpecification997 =null;
		ParserRuleReturnScope relySpecification998 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2722:5: ( enableValidateSpecification ( relySpecification )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2722:7: enableValidateSpecification ( relySpecification )?
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_enableValidateSpecification_in_constraintOptsCreate17534);
			enableValidateSpecification997=enableValidateSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, enableValidateSpecification997.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2722:35: ( relySpecification )?
			int alt307=2;
			int LA307_0 = input.LA(1);
			if ( (LA307_0==KW_NORELY||LA307_0==KW_RELY) ) {
				alt307=1;
			}
			switch (alt307) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2722:35: relySpecification
					{
					pushFollow(FOLLOW_relySpecification_in_constraintOptsCreate17536);
					relySpecification998=relySpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, relySpecification998.getTree());

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "constraintOptsCreate"


	public static class constraintOptsAlter_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "constraintOptsAlter"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2725:1: constraintOptsAlter : enableValidateSpecification ( relySpecification )? ;
	public final HiveParser.constraintOptsAlter_return constraintOptsAlter() throws RecognitionException {
		HiveParser.constraintOptsAlter_return retval = new HiveParser.constraintOptsAlter_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope enableValidateSpecification999 =null;
		ParserRuleReturnScope relySpecification1000 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2726:5: ( enableValidateSpecification ( relySpecification )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2726:7: enableValidateSpecification ( relySpecification )?
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_enableValidateSpecification_in_constraintOptsAlter17554);
			enableValidateSpecification999=enableValidateSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, enableValidateSpecification999.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2726:35: ( relySpecification )?
			int alt308=2;
			int LA308_0 = input.LA(1);
			if ( (LA308_0==KW_NORELY||LA308_0==KW_RELY) ) {
				alt308=1;
			}
			switch (alt308) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2726:35: relySpecification
					{
					pushFollow(FOLLOW_relySpecification_in_constraintOptsAlter17556);
					relySpecification1000=relySpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, relySpecification1000.getTree());

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "constraintOptsAlter"


	public static class columnNameColonType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameColonType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2729:1: columnNameColonType : colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
	public final HiveParser.columnNameColonType_return columnNameColonType() throws RecognitionException {
		HiveParser.columnNameColonType_return retval = new HiveParser.columnNameColonType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token COLON1001=null;
		Token KW_COMMENT1003=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope colType1002 =null;

		ASTNode comment_tree=null;
		ASTNode COLON1001_tree=null;
		ASTNode KW_COMMENT1003_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_COLON=new RewriteRuleTokenStream(adaptor,"token COLON");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2732:5: (colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2732:7: colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameColonType17586);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			COLON1001=(Token)match(input,COLON,FOLLOW_COLON_in_columnNameColonType17588); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_COLON.add(COLON1001);

			pushFollow(FOLLOW_colType_in_columnNameColonType17590);
			colType1002=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType1002.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2732:40: ( KW_COMMENT comment= StringLiteral )?
			int alt309=2;
			int LA309_0 = input.LA(1);
			if ( (LA309_0==KW_COMMENT) ) {
				alt309=1;
			}
			switch (alt309) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2732:41: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT1003=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameColonType17593); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT1003);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameColonType17597); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: colType, comment, colName, colName, colType
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2733:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
			if (comment == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2733:28: ^( TOK_TABCOL $colName colType )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2734:5: -> ^( TOK_TABCOL $colName colType $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2734:28: ^( TOK_TABCOL $colName colType $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameColonType"


	public static class colType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "colType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2737:1: colType : type ;
	public final HiveParser.colType_return colType() throws RecognitionException {
		HiveParser.colType_return retval = new HiveParser.colType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope type1004 =null;


		 pushMsg("column type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2740:5: ( type )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2740:7: type
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_type_in_colType17681);
			type1004=type();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, type1004.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "colType"


	public static class colTypeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "colTypeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2743:1: colTypeList : colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) ;
	public final HiveParser.colTypeList_return colTypeList() throws RecognitionException {
		HiveParser.colTypeList_return retval = new HiveParser.colTypeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA1006=null;
		ParserRuleReturnScope colType1005 =null;
		ParserRuleReturnScope colType1007 =null;

		ASTNode COMMA1006_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column type list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2746:5: ( colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2746:7: colType ( COMMA colType )*
			{
			pushFollow(FOLLOW_colType_in_colTypeList17708);
			colType1005=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType1005.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2746:15: ( COMMA colType )*
			loop310:
			while (true) {
				int alt310=2;
				int LA310_0 = input.LA(1);
				if ( (LA310_0==COMMA) ) {
					alt310=1;
				}

				switch (alt310) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2746:16: COMMA colType
					{
					COMMA1006=(Token)match(input,COMMA,FOLLOW_COMMA_in_colTypeList17711); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA1006);

					pushFollow(FOLLOW_colType_in_colTypeList17713);
					colType1007=colType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_colType.add(colType1007.getTree());
					}
					break;

				default :
					break loop310;
				}
			}

			// AST REWRITE
			// elements: colType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2746:32: -> ^( TOK_COLTYPELIST ( colType )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2746:35: ^( TOK_COLTYPELIST ( colType )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_COLTYPELIST, "TOK_COLTYPELIST"), root_1);
				if ( !(stream_colType.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_colType.hasNext() ) {
					adaptor.addChild(root_1, stream_colType.nextTree());
				}
				stream_colType.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "colTypeList"


	public static class type_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "type"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2749:1: type : ( primitiveType | listType | structType | mapType | unionType );
	public final HiveParser.type_return type() throws RecognitionException {
		HiveParser.type_return retval = new HiveParser.type_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope primitiveType1008 =null;
		ParserRuleReturnScope listType1009 =null;
		ParserRuleReturnScope structType1010 =null;
		ParserRuleReturnScope mapType1011 =null;
		ParserRuleReturnScope unionType1012 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2750:5: ( primitiveType | listType | structType | mapType | unionType )
			int alt311=5;
			switch ( input.LA(1) ) {
			case KW_BIGINT:
			case KW_BINARY:
			case KW_BOOLEAN:
			case KW_CHAR:
			case KW_DATE:
			case KW_DATETIME:
			case KW_DECIMAL:
			case KW_DOUBLE:
			case KW_FLOAT:
			case KW_INT:
			case KW_SMALLINT:
			case KW_STRING:
			case KW_TIMESTAMP:
			case KW_TIMESTAMPLOCALTZ:
			case KW_TINYINT:
			case KW_VARCHAR:
				{
				alt311=1;
				}
				break;
			case KW_ARRAY:
				{
				alt311=2;
				}
				break;
			case KW_STRUCT:
				{
				alt311=3;
				}
				break;
			case KW_MAP:
				{
				alt311=4;
				}
				break;
			case KW_UNIONTYPE:
				{
				alt311=5;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 311, 0, input);
				throw nvae;
			}
			switch (alt311) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2750:7: primitiveType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_primitiveType_in_type17741);
					primitiveType1008=primitiveType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, primitiveType1008.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2751:7: listType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_listType_in_type17749);
					listType1009=listType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, listType1009.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2752:7: structType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_structType_in_type17757);
					structType1010=structType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, structType1010.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2753:7: mapType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_mapType_in_type17765);
					mapType1011=mapType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, mapType1011.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2754:7: unionType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_unionType_in_type17773);
					unionType1012=unionType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, unionType1012.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "type"


	public static class primitiveType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "primitiveType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2756:1: primitiveType : ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE ( KW_PRECISION )? -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_TIMESTAMPLOCALTZ -> TOK_TIMESTAMPLOCALTZ | KW_TIMESTAMP KW_WITH KW_LOCAL KW_TIME KW_ZONE -> TOK_TIMESTAMPLOCALTZ | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) );
	public final HiveParser.primitiveType_return primitiveType() throws RecognitionException {
		HiveParser.primitiveType_return retval = new HiveParser.primitiveType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token prec=null;
		Token scale=null;
		Token length=null;
		Token KW_TINYINT1013=null;
		Token KW_SMALLINT1014=null;
		Token KW_INT1015=null;
		Token KW_BIGINT1016=null;
		Token KW_BOOLEAN1017=null;
		Token KW_FLOAT1018=null;
		Token KW_DOUBLE1019=null;
		Token KW_PRECISION1020=null;
		Token KW_DATE1021=null;
		Token KW_DATETIME1022=null;
		Token KW_TIMESTAMP1023=null;
		Token KW_TIMESTAMPLOCALTZ1024=null;
		Token KW_TIMESTAMP1025=null;
		Token KW_WITH1026=null;
		Token KW_LOCAL1027=null;
		Token KW_TIME1028=null;
		Token KW_ZONE1029=null;
		Token KW_STRING1030=null;
		Token KW_BINARY1031=null;
		Token KW_DECIMAL1032=null;
		Token LPAREN1033=null;
		Token COMMA1034=null;
		Token RPAREN1035=null;
		Token KW_VARCHAR1036=null;
		Token LPAREN1037=null;
		Token RPAREN1038=null;
		Token KW_CHAR1039=null;
		Token LPAREN1040=null;
		Token RPAREN1041=null;

		ASTNode prec_tree=null;
		ASTNode scale_tree=null;
		ASTNode length_tree=null;
		ASTNode KW_TINYINT1013_tree=null;
		ASTNode KW_SMALLINT1014_tree=null;
		ASTNode KW_INT1015_tree=null;
		ASTNode KW_BIGINT1016_tree=null;
		ASTNode KW_BOOLEAN1017_tree=null;
		ASTNode KW_FLOAT1018_tree=null;
		ASTNode KW_DOUBLE1019_tree=null;
		ASTNode KW_PRECISION1020_tree=null;
		ASTNode KW_DATE1021_tree=null;
		ASTNode KW_DATETIME1022_tree=null;
		ASTNode KW_TIMESTAMP1023_tree=null;
		ASTNode KW_TIMESTAMPLOCALTZ1024_tree=null;
		ASTNode KW_TIMESTAMP1025_tree=null;
		ASTNode KW_WITH1026_tree=null;
		ASTNode KW_LOCAL1027_tree=null;
		ASTNode KW_TIME1028_tree=null;
		ASTNode KW_ZONE1029_tree=null;
		ASTNode KW_STRING1030_tree=null;
		ASTNode KW_BINARY1031_tree=null;
		ASTNode KW_DECIMAL1032_tree=null;
		ASTNode LPAREN1033_tree=null;
		ASTNode COMMA1034_tree=null;
		ASTNode RPAREN1035_tree=null;
		ASTNode KW_VARCHAR1036_tree=null;
		ASTNode LPAREN1037_tree=null;
		ASTNode RPAREN1038_tree=null;
		ASTNode KW_CHAR1039_tree=null;
		ASTNode LPAREN1040_tree=null;
		ASTNode RPAREN1041_tree=null;
		RewriteRuleTokenStream stream_KW_DATETIME=new RewriteRuleTokenStream(adaptor,"token KW_DATETIME");
		RewriteRuleTokenStream stream_KW_TIMESTAMP=new RewriteRuleTokenStream(adaptor,"token KW_TIMESTAMP");
		RewriteRuleTokenStream stream_KW_BOOLEAN=new RewriteRuleTokenStream(adaptor,"token KW_BOOLEAN");
		RewriteRuleTokenStream stream_KW_DOUBLE=new RewriteRuleTokenStream(adaptor,"token KW_DOUBLE");
		RewriteRuleTokenStream stream_KW_TIME=new RewriteRuleTokenStream(adaptor,"token KW_TIME");
		RewriteRuleTokenStream stream_KW_CHAR=new RewriteRuleTokenStream(adaptor,"token KW_CHAR");
		RewriteRuleTokenStream stream_KW_INT=new RewriteRuleTokenStream(adaptor,"token KW_INT");
		RewriteRuleTokenStream stream_KW_DECIMAL=new RewriteRuleTokenStream(adaptor,"token KW_DECIMAL");
		RewriteRuleTokenStream stream_KW_ZONE=new RewriteRuleTokenStream(adaptor,"token KW_ZONE");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_TINYINT=new RewriteRuleTokenStream(adaptor,"token KW_TINYINT");
		RewriteRuleTokenStream stream_KW_PRECISION=new RewriteRuleTokenStream(adaptor,"token KW_PRECISION");
		RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_SMALLINT=new RewriteRuleTokenStream(adaptor,"token KW_SMALLINT");
		RewriteRuleTokenStream stream_KW_DATE=new RewriteRuleTokenStream(adaptor,"token KW_DATE");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_BIGINT=new RewriteRuleTokenStream(adaptor,"token KW_BIGINT");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_STRING=new RewriteRuleTokenStream(adaptor,"token KW_STRING");
		RewriteRuleTokenStream stream_KW_VARCHAR=new RewriteRuleTokenStream(adaptor,"token KW_VARCHAR");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_FLOAT=new RewriteRuleTokenStream(adaptor,"token KW_FLOAT");
		RewriteRuleTokenStream stream_KW_TIMESTAMPLOCALTZ=new RewriteRuleTokenStream(adaptor,"token KW_TIMESTAMPLOCALTZ");
		RewriteRuleTokenStream stream_KW_BINARY=new RewriteRuleTokenStream(adaptor,"token KW_BINARY");

		 pushMsg("primitive type specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2759:5: ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE ( KW_PRECISION )? -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_TIMESTAMPLOCALTZ -> TOK_TIMESTAMPLOCALTZ | KW_TIMESTAMP KW_WITH KW_LOCAL KW_TIME KW_ZONE -> TOK_TIMESTAMPLOCALTZ | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) )
			int alt315=17;
			switch ( input.LA(1) ) {
			case KW_TINYINT:
				{
				alt315=1;
				}
				break;
			case KW_SMALLINT:
				{
				alt315=2;
				}
				break;
			case KW_INT:
				{
				alt315=3;
				}
				break;
			case KW_BIGINT:
				{
				alt315=4;
				}
				break;
			case KW_BOOLEAN:
				{
				alt315=5;
				}
				break;
			case KW_FLOAT:
				{
				alt315=6;
				}
				break;
			case KW_DOUBLE:
				{
				alt315=7;
				}
				break;
			case KW_DATE:
				{
				alt315=8;
				}
				break;
			case KW_DATETIME:
				{
				alt315=9;
				}
				break;
			case KW_TIMESTAMP:
				{
				int LA315_10 = input.LA(2);
				if ( (LA315_10==KW_WITH) ) {
					alt315=12;
				}
				else if ( (LA315_10==EOF||LA315_10==COMMA||LA315_10==GREATERTHAN||LA315_10==KW_AFTER||LA315_10==KW_CASCADE||(LA315_10 >= KW_CHECK && LA315_10 <= KW_CLUSTER)||LA315_10==KW_COMMENT||LA315_10==KW_CONSTRAINT||LA315_10==KW_DEFAULT||LA315_10==KW_DISTRIBUTE||LA315_10==KW_EXCEPT||LA315_10==KW_FIRST||LA315_10==KW_FORMAT||LA315_10==KW_FROM||LA315_10==KW_GROUP||LA315_10==KW_HAVING||LA315_10==KW_INSERT||LA315_10==KW_INTERSECT||LA315_10==KW_LATERAL||LA315_10==KW_LIMIT||LA315_10==KW_MAP||LA315_10==KW_MINUS||LA315_10==KW_NOT||LA315_10==KW_ORDER||LA315_10==KW_PRIMARY||LA315_10==KW_RECORDREADER||(LA315_10 >= KW_REDUCE && LA315_10 <= KW_REFERENCES)||LA315_10==KW_RESTRICT||LA315_10==KW_ROW||LA315_10==KW_SELECT||LA315_10==KW_SORT||LA315_10==KW_UNION||LA315_10==KW_UNIQUE||LA315_10==KW_WHERE||LA315_10==KW_WINDOW||LA315_10==RPAREN) ) {
					alt315=10;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 315, 10, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_TIMESTAMPLOCALTZ:
				{
				alt315=11;
				}
				break;
			case KW_STRING:
				{
				alt315=13;
				}
				break;
			case KW_BINARY:
				{
				alt315=14;
				}
				break;
			case KW_DECIMAL:
				{
				alt315=15;
				}
				break;
			case KW_VARCHAR:
				{
				alt315=16;
				}
				break;
			case KW_CHAR:
				{
				alt315=17;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 315, 0, input);
				throw nvae;
			}
			switch (alt315) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2759:7: KW_TINYINT
					{
					KW_TINYINT1013=(Token)match(input,KW_TINYINT,FOLLOW_KW_TINYINT_in_primitiveType17795); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TINYINT.add(KW_TINYINT1013);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2759:24: -> TOK_TINYINT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TINYINT, "TOK_TINYINT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2760:7: KW_SMALLINT
					{
					KW_SMALLINT1014=(Token)match(input,KW_SMALLINT,FOLLOW_KW_SMALLINT_in_primitiveType17816); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SMALLINT.add(KW_SMALLINT1014);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2760:24: -> TOK_SMALLINT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_SMALLINT, "TOK_SMALLINT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2761:7: KW_INT
					{
					KW_INT1015=(Token)match(input,KW_INT,FOLLOW_KW_INT_in_primitiveType17836); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INT.add(KW_INT1015);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2761:24: -> TOK_INT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_INT, "TOK_INT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2762:7: KW_BIGINT
					{
					KW_BIGINT1016=(Token)match(input,KW_BIGINT,FOLLOW_KW_BIGINT_in_primitiveType17861); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BIGINT.add(KW_BIGINT1016);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2762:24: -> TOK_BIGINT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_BIGINT, "TOK_BIGINT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2763:7: KW_BOOLEAN
					{
					KW_BOOLEAN1017=(Token)match(input,KW_BOOLEAN,FOLLOW_KW_BOOLEAN_in_primitiveType17883); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BOOLEAN.add(KW_BOOLEAN1017);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2763:24: -> TOK_BOOLEAN
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_BOOLEAN, "TOK_BOOLEAN"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2764:7: KW_FLOAT
					{
					KW_FLOAT1018=(Token)match(input,KW_FLOAT,FOLLOW_KW_FLOAT_in_primitiveType17904); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FLOAT.add(KW_FLOAT1018);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2764:24: -> TOK_FLOAT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_FLOAT, "TOK_FLOAT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2765:7: KW_DOUBLE ( KW_PRECISION )?
					{
					KW_DOUBLE1019=(Token)match(input,KW_DOUBLE,FOLLOW_KW_DOUBLE_in_primitiveType17927); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DOUBLE.add(KW_DOUBLE1019);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2765:17: ( KW_PRECISION )?
					int alt312=2;
					int LA312_0 = input.LA(1);
					if ( (LA312_0==KW_PRECISION) ) {
						alt312=1;
					}
					switch (alt312) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2765:17: KW_PRECISION
							{
							KW_PRECISION1020=(Token)match(input,KW_PRECISION,FOLLOW_KW_PRECISION_in_primitiveType17929); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_PRECISION.add(KW_PRECISION1020);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2765:37: -> TOK_DOUBLE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DOUBLE, "TOK_DOUBLE"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2766:7: KW_DATE
					{
					KW_DATE1021=(Token)match(input,KW_DATE,FOLLOW_KW_DATE_in_primitiveType17951); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATE.add(KW_DATE1021);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2766:24: -> TOK_DATE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DATE, "TOK_DATE"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2767:7: KW_DATETIME
					{
					KW_DATETIME1022=(Token)match(input,KW_DATETIME,FOLLOW_KW_DATETIME_in_primitiveType17975); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATETIME.add(KW_DATETIME1022);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2767:24: -> TOK_DATETIME
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DATETIME, "TOK_DATETIME"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2768:7: KW_TIMESTAMP
					{
					KW_TIMESTAMP1023=(Token)match(input,KW_TIMESTAMP,FOLLOW_KW_TIMESTAMP_in_primitiveType17995); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIMESTAMP.add(KW_TIMESTAMP1023);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2768:24: -> TOK_TIMESTAMP
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TIMESTAMP, "TOK_TIMESTAMP"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2769:7: KW_TIMESTAMPLOCALTZ
					{
					KW_TIMESTAMPLOCALTZ1024=(Token)match(input,KW_TIMESTAMPLOCALTZ,FOLLOW_KW_TIMESTAMPLOCALTZ_in_primitiveType18014); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIMESTAMPLOCALTZ.add(KW_TIMESTAMPLOCALTZ1024);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2769:29: -> TOK_TIMESTAMPLOCALTZ
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TIMESTAMPLOCALTZ, "TOK_TIMESTAMPLOCALTZ"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2771:7: KW_TIMESTAMP KW_WITH KW_LOCAL KW_TIME KW_ZONE
					{
					KW_TIMESTAMP1025=(Token)match(input,KW_TIMESTAMP,FOLLOW_KW_TIMESTAMP_in_primitiveType18036); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIMESTAMP.add(KW_TIMESTAMP1025);

					KW_WITH1026=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_primitiveType18038); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH1026);

					KW_LOCAL1027=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_primitiveType18040); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCAL.add(KW_LOCAL1027);

					KW_TIME1028=(Token)match(input,KW_TIME,FOLLOW_KW_TIME_in_primitiveType18042); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIME.add(KW_TIME1028);

					KW_ZONE1029=(Token)match(input,KW_ZONE,FOLLOW_KW_ZONE_in_primitiveType18044); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ZONE.add(KW_ZONE1029);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2771:53: -> TOK_TIMESTAMPLOCALTZ
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TIMESTAMPLOCALTZ, "TOK_TIMESTAMPLOCALTZ"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2776:7: KW_STRING
					{
					KW_STRING1030=(Token)match(input,KW_STRING,FOLLOW_KW_STRING_in_primitiveType18076); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STRING.add(KW_STRING1030);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2776:24: -> TOK_STRING
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_STRING, "TOK_STRING"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2777:7: KW_BINARY
					{
					KW_BINARY1031=(Token)match(input,KW_BINARY,FOLLOW_KW_BINARY_in_primitiveType18098); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BINARY.add(KW_BINARY1031);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2777:24: -> TOK_BINARY
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_BINARY, "TOK_BINARY"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 15 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2778:7: KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
					{
					KW_DECIMAL1032=(Token)match(input,KW_DECIMAL,FOLLOW_KW_DECIMAL_in_primitiveType18120); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DECIMAL.add(KW_DECIMAL1032);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2778:18: ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
					int alt314=2;
					int LA314_0 = input.LA(1);
					if ( (LA314_0==LPAREN) ) {
						alt314=1;
					}
					switch (alt314) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2778:19: LPAREN prec= Number ( COMMA scale= Number )? RPAREN
							{
							LPAREN1033=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType18123); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN1033);

							prec=(Token)match(input,Number,FOLLOW_Number_in_primitiveType18127); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(prec);

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2778:38: ( COMMA scale= Number )?
							int alt313=2;
							int LA313_0 = input.LA(1);
							if ( (LA313_0==COMMA) ) {
								alt313=1;
							}
							switch (alt313) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:2778:39: COMMA scale= Number
									{
									COMMA1034=(Token)match(input,COMMA,FOLLOW_COMMA_in_primitiveType18130); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_COMMA.add(COMMA1034);

									scale=(Token)match(input,Number,FOLLOW_Number_in_primitiveType18134); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_Number.add(scale);

									}
									break;

							}

							RPAREN1035=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType18138); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN1035);

							}
							break;

					}

					// AST REWRITE
					// elements: scale, prec
					// token labels: prec, scale
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_prec=new RewriteRuleTokenStream(adaptor,"token prec",prec);
					RewriteRuleTokenStream stream_scale=new RewriteRuleTokenStream(adaptor,"token scale",scale);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2778:69: -> ^( TOK_DECIMAL ( $prec)? ( $scale)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2778:72: ^( TOK_DECIMAL ( $prec)? ( $scale)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DECIMAL, "TOK_DECIMAL"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2778:87: ( $prec)?
						if ( stream_prec.hasNext() ) {
							adaptor.addChild(root_1, stream_prec.nextNode());
						}
						stream_prec.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2778:94: ( $scale)?
						if ( stream_scale.hasNext() ) {
							adaptor.addChild(root_1, stream_scale.nextNode());
						}
						stream_scale.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 16 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2779:7: KW_VARCHAR LPAREN length= Number RPAREN
					{
					KW_VARCHAR1036=(Token)match(input,KW_VARCHAR,FOLLOW_KW_VARCHAR_in_primitiveType18162); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VARCHAR.add(KW_VARCHAR1036);

					LPAREN1037=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType18164); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN1037);

					length=(Token)match(input,Number,FOLLOW_Number_in_primitiveType18168); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(length);

					RPAREN1038=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType18170); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN1038);

					// AST REWRITE
					// elements: length
					// token labels: length
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_length=new RewriteRuleTokenStream(adaptor,"token length",length);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2779:51: -> ^( TOK_VARCHAR $length)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2779:57: ^( TOK_VARCHAR $length)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VARCHAR, "TOK_VARCHAR"), root_1);
						adaptor.addChild(root_1, stream_length.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 17 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2780:7: KW_CHAR LPAREN length= Number RPAREN
					{
					KW_CHAR1039=(Token)match(input,KW_CHAR,FOLLOW_KW_CHAR_in_primitiveType18195); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CHAR.add(KW_CHAR1039);

					LPAREN1040=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType18197); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN1040);

					length=(Token)match(input,Number,FOLLOW_Number_in_primitiveType18201); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(length);

					RPAREN1041=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType18203); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN1041);

					// AST REWRITE
					// elements: length
					// token labels: length
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_length=new RewriteRuleTokenStream(adaptor,"token length",length);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2780:48: -> ^( TOK_CHAR $length)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2780:54: ^( TOK_CHAR $length)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CHAR, "TOK_CHAR"), root_1);
						adaptor.addChild(root_1, stream_length.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "primitiveType"


	public static class listType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "listType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2783:1: listType : KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) ;
	public final HiveParser.listType_return listType() throws RecognitionException {
		HiveParser.listType_return retval = new HiveParser.listType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ARRAY1042=null;
		Token LESSTHAN1043=null;
		Token GREATERTHAN1045=null;
		ParserRuleReturnScope type1044 =null;

		ASTNode KW_ARRAY1042_tree=null;
		ASTNode LESSTHAN1043_tree=null;
		ASTNode GREATERTHAN1045_tree=null;
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_KW_ARRAY=new RewriteRuleTokenStream(adaptor,"token KW_ARRAY");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_type=new RewriteRuleSubtreeStream(adaptor,"rule type");

		 pushMsg("list type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2786:5: ( KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2786:7: KW_ARRAY LESSTHAN type GREATERTHAN
			{
			KW_ARRAY1042=(Token)match(input,KW_ARRAY,FOLLOW_KW_ARRAY_in_listType18247); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ARRAY.add(KW_ARRAY1042);

			LESSTHAN1043=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_listType18249); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN1043);

			pushFollow(FOLLOW_type_in_listType18251);
			type1044=type();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_type.add(type1044.getTree());
			GREATERTHAN1045=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_listType18253); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN1045);

			// AST REWRITE
			// elements: type
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2786:44: -> ^( TOK_LIST type )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2786:47: ^( TOK_LIST type )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LIST, "TOK_LIST"), root_1);
				adaptor.addChild(root_1, stream_type.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "listType"


	public static class structType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "structType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2789:1: structType : KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) ;
	public final HiveParser.structType_return structType() throws RecognitionException {
		HiveParser.structType_return retval = new HiveParser.structType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_STRUCT1046=null;
		Token LESSTHAN1047=null;
		Token GREATERTHAN1049=null;
		ParserRuleReturnScope columnNameColonTypeList1048 =null;

		ASTNode KW_STRUCT1046_tree=null;
		ASTNode LESSTHAN1047_tree=null;
		ASTNode GREATERTHAN1049_tree=null;
		RewriteRuleTokenStream stream_KW_STRUCT=new RewriteRuleTokenStream(adaptor,"token KW_STRUCT");
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_columnNameColonTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameColonTypeList");

		 pushMsg("struct type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2792:5: ( KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2792:7: KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN
			{
			KW_STRUCT1046=(Token)match(input,KW_STRUCT,FOLLOW_KW_STRUCT_in_structType18290); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STRUCT.add(KW_STRUCT1046);

			LESSTHAN1047=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_structType18292); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN1047);

			pushFollow(FOLLOW_columnNameColonTypeList_in_structType18294);
			columnNameColonTypeList1048=columnNameColonTypeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameColonTypeList.add(columnNameColonTypeList1048.getTree());
			GREATERTHAN1049=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_structType18296); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN1049);

			// AST REWRITE
			// elements: columnNameColonTypeList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2792:62: -> ^( TOK_STRUCT columnNameColonTypeList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2792:65: ^( TOK_STRUCT columnNameColonTypeList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_STRUCT, "TOK_STRUCT"), root_1);
				adaptor.addChild(root_1, stream_columnNameColonTypeList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "structType"


	public static class mapType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "mapType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2795:1: mapType : KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) ;
	public final HiveParser.mapType_return mapType() throws RecognitionException {
		HiveParser.mapType_return retval = new HiveParser.mapType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_MAP1050=null;
		Token LESSTHAN1051=null;
		Token COMMA1052=null;
		Token GREATERTHAN1053=null;
		ParserRuleReturnScope left =null;
		ParserRuleReturnScope right =null;

		ASTNode KW_MAP1050_tree=null;
		ASTNode LESSTHAN1051_tree=null;
		ASTNode COMMA1052_tree=null;
		ASTNode GREATERTHAN1053_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_MAP=new RewriteRuleTokenStream(adaptor,"token KW_MAP");
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_type=new RewriteRuleSubtreeStream(adaptor,"rule type");
		RewriteRuleSubtreeStream stream_primitiveType=new RewriteRuleSubtreeStream(adaptor,"rule primitiveType");

		 pushMsg("map type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2798:5: ( KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2798:7: KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN
			{
			KW_MAP1050=(Token)match(input,KW_MAP,FOLLOW_KW_MAP_in_mapType18331); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MAP.add(KW_MAP1050);

			LESSTHAN1051=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_mapType18333); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN1051);

			pushFollow(FOLLOW_primitiveType_in_mapType18337);
			left=primitiveType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_primitiveType.add(left.getTree());
			COMMA1052=(Token)match(input,COMMA,FOLLOW_COMMA_in_mapType18339); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_COMMA.add(COMMA1052);

			pushFollow(FOLLOW_type_in_mapType18343);
			right=type();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_type.add(right.getTree());
			GREATERTHAN1053=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_mapType18345); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN1053);

			// AST REWRITE
			// elements: right, left
			// token labels: 
			// rule labels: left, right, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_left=new RewriteRuleSubtreeStream(adaptor,"rule left",left!=null?left.getTree():null);
			RewriteRuleSubtreeStream stream_right=new RewriteRuleSubtreeStream(adaptor,"rule right",right!=null?right.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2799:5: -> ^( TOK_MAP $left $right)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2799:8: ^( TOK_MAP $left $right)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MAP, "TOK_MAP"), root_1);
				adaptor.addChild(root_1, stream_left.nextTree());
				adaptor.addChild(root_1, stream_right.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "mapType"


	public static class unionType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "unionType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2802:1: unionType : KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) ;
	public final HiveParser.unionType_return unionType() throws RecognitionException {
		HiveParser.unionType_return retval = new HiveParser.unionType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNIONTYPE1054=null;
		Token LESSTHAN1055=null;
		Token GREATERTHAN1057=null;
		ParserRuleReturnScope colTypeList1056 =null;

		ASTNode KW_UNIONTYPE1054_tree=null;
		ASTNode LESSTHAN1055_tree=null;
		ASTNode GREATERTHAN1057_tree=null;
		RewriteRuleTokenStream stream_KW_UNIONTYPE=new RewriteRuleTokenStream(adaptor,"token KW_UNIONTYPE");
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_colTypeList=new RewriteRuleSubtreeStream(adaptor,"rule colTypeList");

		 pushMsg("uniontype type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2805:5: ( KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2805:7: KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN
			{
			KW_UNIONTYPE1054=(Token)match(input,KW_UNIONTYPE,FOLLOW_KW_UNIONTYPE_in_unionType18388); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UNIONTYPE.add(KW_UNIONTYPE1054);

			LESSTHAN1055=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_unionType18390); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN1055);

			pushFollow(FOLLOW_colTypeList_in_unionType18392);
			colTypeList1056=colTypeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colTypeList.add(colTypeList1056.getTree());
			GREATERTHAN1057=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_unionType18394); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN1057);

			// AST REWRITE
			// elements: colTypeList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2805:53: -> ^( TOK_UNIONTYPE colTypeList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2805:56: ^( TOK_UNIONTYPE colTypeList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONTYPE, "TOK_UNIONTYPE"), root_1);
				adaptor.addChild(root_1, stream_colTypeList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "unionType"


	public static class setOperator_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setOperator"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2808:1: setOperator : ( KW_UNION KW_ALL -> ^( TOK_UNIONALL ) | KW_UNION ( KW_DISTINCT )? -> ^( TOK_UNIONDISTINCT ) | KW_INTERSECT KW_ALL -> ^( TOK_INTERSECTALL ) | KW_INTERSECT ( KW_DISTINCT )? -> ^( TOK_INTERSECTDISTINCT ) | KW_EXCEPT KW_ALL -> ^( TOK_EXCEPTALL ) | KW_EXCEPT ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) | KW_MINUS KW_ALL -> ^( TOK_EXCEPTALL ) | KW_MINUS ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) );
	public final HiveParser.setOperator_return setOperator() throws RecognitionException {
		HiveParser.setOperator_return retval = new HiveParser.setOperator_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNION1058=null;
		Token KW_ALL1059=null;
		Token KW_UNION1060=null;
		Token KW_DISTINCT1061=null;
		Token KW_INTERSECT1062=null;
		Token KW_ALL1063=null;
		Token KW_INTERSECT1064=null;
		Token KW_DISTINCT1065=null;
		Token KW_EXCEPT1066=null;
		Token KW_ALL1067=null;
		Token KW_EXCEPT1068=null;
		Token KW_DISTINCT1069=null;
		Token KW_MINUS1070=null;
		Token KW_ALL1071=null;
		Token KW_MINUS1072=null;
		Token KW_DISTINCT1073=null;

		ASTNode KW_UNION1058_tree=null;
		ASTNode KW_ALL1059_tree=null;
		ASTNode KW_UNION1060_tree=null;
		ASTNode KW_DISTINCT1061_tree=null;
		ASTNode KW_INTERSECT1062_tree=null;
		ASTNode KW_ALL1063_tree=null;
		ASTNode KW_INTERSECT1064_tree=null;
		ASTNode KW_DISTINCT1065_tree=null;
		ASTNode KW_EXCEPT1066_tree=null;
		ASTNode KW_ALL1067_tree=null;
		ASTNode KW_EXCEPT1068_tree=null;
		ASTNode KW_DISTINCT1069_tree=null;
		ASTNode KW_MINUS1070_tree=null;
		ASTNode KW_ALL1071_tree=null;
		ASTNode KW_MINUS1072_tree=null;
		ASTNode KW_DISTINCT1073_tree=null;
		RewriteRuleTokenStream stream_KW_INTERSECT=new RewriteRuleTokenStream(adaptor,"token KW_INTERSECT");
		RewriteRuleTokenStream stream_KW_EXCEPT=new RewriteRuleTokenStream(adaptor,"token KW_EXCEPT");
		RewriteRuleTokenStream stream_KW_UNION=new RewriteRuleTokenStream(adaptor,"token KW_UNION");
		RewriteRuleTokenStream stream_KW_DISTINCT=new RewriteRuleTokenStream(adaptor,"token KW_DISTINCT");
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
		RewriteRuleTokenStream stream_KW_MINUS=new RewriteRuleTokenStream(adaptor,"token KW_MINUS");

		 pushMsg("set operator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2811:5: ( KW_UNION KW_ALL -> ^( TOK_UNIONALL ) | KW_UNION ( KW_DISTINCT )? -> ^( TOK_UNIONDISTINCT ) | KW_INTERSECT KW_ALL -> ^( TOK_INTERSECTALL ) | KW_INTERSECT ( KW_DISTINCT )? -> ^( TOK_INTERSECTDISTINCT ) | KW_EXCEPT KW_ALL -> ^( TOK_EXCEPTALL ) | KW_EXCEPT ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) | KW_MINUS KW_ALL -> ^( TOK_EXCEPTALL ) | KW_MINUS ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) )
			int alt320=8;
			switch ( input.LA(1) ) {
			case KW_UNION:
				{
				int LA320_1 = input.LA(2);
				if ( (LA320_1==KW_ALL) ) {
					alt320=1;
				}
				else if ( (LA320_1==EOF||LA320_1==KW_DISTINCT||LA320_1==KW_FROM||LA320_1==KW_MAP||LA320_1==KW_REDUCE||LA320_1==KW_SELECT||LA320_1==LPAREN) ) {
					alt320=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 320, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_INTERSECT:
				{
				int LA320_2 = input.LA(2);
				if ( (LA320_2==KW_ALL) ) {
					alt320=3;
				}
				else if ( (LA320_2==EOF||LA320_2==KW_DISTINCT||LA320_2==KW_FROM||LA320_2==KW_MAP||LA320_2==KW_REDUCE||LA320_2==KW_SELECT||LA320_2==LPAREN) ) {
					alt320=4;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 320, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_EXCEPT:
				{
				int LA320_3 = input.LA(2);
				if ( (LA320_3==KW_ALL) ) {
					alt320=5;
				}
				else if ( (LA320_3==EOF||LA320_3==KW_DISTINCT||LA320_3==KW_FROM||LA320_3==KW_MAP||LA320_3==KW_REDUCE||LA320_3==KW_SELECT||LA320_3==LPAREN) ) {
					alt320=6;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 320, 3, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_MINUS:
				{
				int LA320_4 = input.LA(2);
				if ( (LA320_4==KW_ALL) ) {
					alt320=7;
				}
				else if ( (LA320_4==EOF||LA320_4==KW_DISTINCT||LA320_4==KW_FROM||LA320_4==KW_MAP||LA320_4==KW_REDUCE||LA320_4==KW_SELECT||LA320_4==LPAREN) ) {
					alt320=8;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 320, 4, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 320, 0, input);
				throw nvae;
			}
			switch (alt320) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2811:7: KW_UNION KW_ALL
					{
					KW_UNION1058=(Token)match(input,KW_UNION,FOLLOW_KW_UNION_in_setOperator18429); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNION.add(KW_UNION1058);

					KW_ALL1059=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator18431); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL1059);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2811:23: -> ^( TOK_UNIONALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2811:26: ^( TOK_UNIONALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2812:7: KW_UNION ( KW_DISTINCT )?
					{
					KW_UNION1060=(Token)match(input,KW_UNION,FOLLOW_KW_UNION_in_setOperator18445); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNION.add(KW_UNION1060);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2812:16: ( KW_DISTINCT )?
					int alt316=2;
					int LA316_0 = input.LA(1);
					if ( (LA316_0==KW_DISTINCT) ) {
						alt316=1;
					}
					switch (alt316) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2812:16: KW_DISTINCT
							{
							KW_DISTINCT1061=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator18447); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT1061);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2812:29: -> ^( TOK_UNIONDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2812:32: ^( TOK_UNIONDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONDISTINCT, "TOK_UNIONDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2813:7: KW_INTERSECT KW_ALL
					{
					KW_INTERSECT1062=(Token)match(input,KW_INTERSECT,FOLLOW_KW_INTERSECT_in_setOperator18462); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INTERSECT.add(KW_INTERSECT1062);

					KW_ALL1063=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator18464); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL1063);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2813:27: -> ^( TOK_INTERSECTALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2813:30: ^( TOK_INTERSECTALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INTERSECTALL, "TOK_INTERSECTALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2814:7: KW_INTERSECT ( KW_DISTINCT )?
					{
					KW_INTERSECT1064=(Token)match(input,KW_INTERSECT,FOLLOW_KW_INTERSECT_in_setOperator18478); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INTERSECT.add(KW_INTERSECT1064);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2814:20: ( KW_DISTINCT )?
					int alt317=2;
					int LA317_0 = input.LA(1);
					if ( (LA317_0==KW_DISTINCT) ) {
						alt317=1;
					}
					switch (alt317) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2814:20: KW_DISTINCT
							{
							KW_DISTINCT1065=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator18480); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT1065);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2814:33: -> ^( TOK_INTERSECTDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2814:36: ^( TOK_INTERSECTDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INTERSECTDISTINCT, "TOK_INTERSECTDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2815:7: KW_EXCEPT KW_ALL
					{
					KW_EXCEPT1066=(Token)match(input,KW_EXCEPT,FOLLOW_KW_EXCEPT_in_setOperator18495); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXCEPT.add(KW_EXCEPT1066);

					KW_ALL1067=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator18497); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL1067);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2815:24: -> ^( TOK_EXCEPTALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2815:27: ^( TOK_EXCEPTALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTALL, "TOK_EXCEPTALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2816:7: KW_EXCEPT ( KW_DISTINCT )?
					{
					KW_EXCEPT1068=(Token)match(input,KW_EXCEPT,FOLLOW_KW_EXCEPT_in_setOperator18511); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXCEPT.add(KW_EXCEPT1068);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2816:17: ( KW_DISTINCT )?
					int alt318=2;
					int LA318_0 = input.LA(1);
					if ( (LA318_0==KW_DISTINCT) ) {
						alt318=1;
					}
					switch (alt318) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2816:17: KW_DISTINCT
							{
							KW_DISTINCT1069=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator18513); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT1069);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2816:30: -> ^( TOK_EXCEPTDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2816:33: ^( TOK_EXCEPTDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTDISTINCT, "TOK_EXCEPTDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2817:7: KW_MINUS KW_ALL
					{
					KW_MINUS1070=(Token)match(input,KW_MINUS,FOLLOW_KW_MINUS_in_setOperator18528); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MINUS.add(KW_MINUS1070);

					KW_ALL1071=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator18530); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL1071);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2817:23: -> ^( TOK_EXCEPTALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2817:26: ^( TOK_EXCEPTALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTALL, "TOK_EXCEPTALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2818:7: KW_MINUS ( KW_DISTINCT )?
					{
					KW_MINUS1072=(Token)match(input,KW_MINUS,FOLLOW_KW_MINUS_in_setOperator18544); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MINUS.add(KW_MINUS1072);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2818:16: ( KW_DISTINCT )?
					int alt319=2;
					int LA319_0 = input.LA(1);
					if ( (LA319_0==KW_DISTINCT) ) {
						alt319=1;
					}
					switch (alt319) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2818:16: KW_DISTINCT
							{
							KW_DISTINCT1073=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator18546); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT1073);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2818:29: -> ^( TOK_EXCEPTDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2818:32: ^( TOK_EXCEPTDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTDISTINCT, "TOK_EXCEPTDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setOperator"


	public static class queryStatementExpression_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "queryStatementExpression"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2821:1: queryStatementExpression : (w= withClause )? queryStatementExpressionBody -> queryStatementExpressionBody ;
	public final HiveParser.queryStatementExpression_return queryStatementExpression() throws RecognitionException {
		HiveParser.queryStatementExpression_return retval = new HiveParser.queryStatementExpression_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope w =null;
		ParserRuleReturnScope queryStatementExpressionBody1074 =null;

		RewriteRuleSubtreeStream stream_withClause=new RewriteRuleSubtreeStream(adaptor,"rule withClause");
		RewriteRuleSubtreeStream stream_queryStatementExpressionBody=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpressionBody");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2822:5: ( (w= withClause )? queryStatementExpressionBody -> queryStatementExpressionBody )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2827:5: (w= withClause )? queryStatementExpressionBody
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2827:5: (w= withClause )?
			int alt321=2;
			int LA321_0 = input.LA(1);
			if ( (LA321_0==KW_WITH) ) {
				alt321=1;
			}
			switch (alt321) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2827:6: w= withClause
					{
					pushFollow(FOLLOW_withClause_in_queryStatementExpression18583);
					w=withClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withClause.add(w.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_queryStatementExpressionBody_in_queryStatementExpression18591);
			queryStatementExpressionBody1074=queryStatementExpressionBody();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_queryStatementExpressionBody.add(queryStatementExpressionBody1074.getTree());
			if ( state.backtracking==0 ) {
			      if ((w!=null?((ASTNode)w.getTree()):null) != null) {
			      (queryStatementExpressionBody1074!=null?((ASTNode)queryStatementExpressionBody1074.getTree()):null).insertChild(0, (w!=null?((ASTNode)w.getTree()):null));
			      }
			    }
			// AST REWRITE
			// elements: queryStatementExpressionBody
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2833:5: -> queryStatementExpressionBody
			{
				adaptor.addChild(root_0, stream_queryStatementExpressionBody.nextTree());
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "queryStatementExpression"


	public static class queryStatementExpressionBody_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "queryStatementExpressionBody"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2836:1: queryStatementExpressionBody : ( fromStatement | regularBody );
	public final HiveParser.queryStatementExpressionBody_return queryStatementExpressionBody() throws RecognitionException {
		HiveParser.queryStatementExpressionBody_return retval = new HiveParser.queryStatementExpressionBody_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope fromStatement1075 =null;
		ParserRuleReturnScope regularBody1076 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2837:5: ( fromStatement | regularBody )
			int alt322=2;
			int LA322_0 = input.LA(1);
			if ( (LA322_0==KW_FROM) ) {
				alt322=1;
			}
			else if ( (LA322_0==KW_INSERT||LA322_0==KW_MAP||LA322_0==KW_REDUCE||LA322_0==KW_SELECT||LA322_0==LPAREN) ) {
				alt322=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 322, 0, input);
				throw nvae;
			}

			switch (alt322) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2838:5: fromStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_fromStatement_in_queryStatementExpressionBody18623);
					fromStatement1075=fromStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, fromStatement1075.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2839:7: regularBody
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_regularBody_in_queryStatementExpressionBody18631);
					regularBody1076=regularBody();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, regularBody1076.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "queryStatementExpressionBody"


	public static class withClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "withClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2842:1: withClause : KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) ;
	public final HiveParser.withClause_return withClause() throws RecognitionException {
		HiveParser.withClause_return retval = new HiveParser.withClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WITH1077=null;
		Token COMMA1079=null;
		ParserRuleReturnScope cteStatement1078 =null;
		ParserRuleReturnScope cteStatement1080 =null;

		ASTNode KW_WITH1077_tree=null;
		ASTNode COMMA1079_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleSubtreeStream stream_cteStatement=new RewriteRuleSubtreeStream(adaptor,"rule cteStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2843:3: ( KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2844:3: KW_WITH cteStatement ( COMMA cteStatement )*
			{
			KW_WITH1077=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withClause18648); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH1077);

			pushFollow(FOLLOW_cteStatement_in_withClause18650);
			cteStatement1078=cteStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_cteStatement.add(cteStatement1078.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2844:24: ( COMMA cteStatement )*
			loop323:
			while (true) {
				int alt323=2;
				int LA323_0 = input.LA(1);
				if ( (LA323_0==COMMA) ) {
					alt323=1;
				}

				switch (alt323) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2844:25: COMMA cteStatement
					{
					COMMA1079=(Token)match(input,COMMA,FOLLOW_COMMA_in_withClause18653); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA1079);

					pushFollow(FOLLOW_cteStatement_in_withClause18655);
					cteStatement1080=cteStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_cteStatement.add(cteStatement1080.getTree());
					}
					break;

				default :
					break loop323;
				}
			}

			// AST REWRITE
			// elements: cteStatement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2844:46: -> ^( TOK_CTE ( cteStatement )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2844:49: ^( TOK_CTE ( cteStatement )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CTE, "TOK_CTE"), root_1);
				if ( !(stream_cteStatement.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_cteStatement.hasNext() ) {
					adaptor.addChild(root_1, stream_cteStatement.nextTree());
				}
				stream_cteStatement.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "withClause"


	public static class cteStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "cteStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2847:1: cteStatement : identifier KW_AS LPAREN queryStatementExpression RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ) ;
	public final HiveParser.cteStatement_return cteStatement() throws RecognitionException {
		HiveParser.cteStatement_return retval = new HiveParser.cteStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_AS1082=null;
		Token LPAREN1083=null;
		Token RPAREN1085=null;
		ParserRuleReturnScope identifier1081 =null;
		ParserRuleReturnScope queryStatementExpression1084 =null;

		ASTNode KW_AS1082_tree=null;
		ASTNode LPAREN1083_tree=null;
		ASTNode RPAREN1085_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_queryStatementExpression=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpression");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2848:4: ( identifier KW_AS LPAREN queryStatementExpression RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2849:4: identifier KW_AS LPAREN queryStatementExpression RPAREN
			{
			pushFollow(FOLLOW_identifier_in_cteStatement18681);
			identifier1081=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier1081.getTree());
			KW_AS1082=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_cteStatement18683); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS1082);

			LPAREN1083=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_cteStatement18685); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN1083);

			pushFollow(FOLLOW_queryStatementExpression_in_cteStatement18687);
			queryStatementExpression1084=queryStatementExpression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_queryStatementExpression.add(queryStatementExpression1084.getTree());
			RPAREN1085=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_cteStatement18689); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN1085);

			// AST REWRITE
			// elements: queryStatementExpression, identifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2850:4: -> ^( TOK_SUBQUERY queryStatementExpression identifier )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2850:7: ^( TOK_SUBQUERY queryStatementExpression identifier )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_1);
				adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());
				adaptor.addChild(root_1, stream_identifier.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "cteStatement"


	public static class fromStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "fromStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2853:1: fromStatement : ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->;
	public final HiveParser.fromStatement_return fromStatement() throws RecognitionException {
		HiveParser.fromStatement_return retval = new HiveParser.fromStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope u =null;
		ParserRuleReturnScope r =null;
		ParserRuleReturnScope singleFromStatement1086 =null;

		RewriteRuleSubtreeStream stream_setOperator=new RewriteRuleSubtreeStream(adaptor,"rule setOperator");
		RewriteRuleSubtreeStream stream_singleFromStatement=new RewriteRuleSubtreeStream(adaptor,"rule singleFromStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2854:3: ( ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->)
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2854:3: ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )*
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2854:3: ( singleFromStatement -> singleFromStatement )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2854:4: singleFromStatement
			{
			pushFollow(FOLLOW_singleFromStatement_in_fromStatement18712);
			singleFromStatement1086=singleFromStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_singleFromStatement.add(singleFromStatement1086.getTree());
			// AST REWRITE
			// elements: singleFromStatement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2854:25: -> singleFromStatement
			{
				adaptor.addChild(root_0, stream_singleFromStatement.nextTree());
			}


			retval.tree = root_0;
			}

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2855:2: (u= setOperator r= singleFromStatement -> ^( $u $r) )*
			loop324:
			while (true) {
				int alt324=2;
				int LA324_0 = input.LA(1);
				if ( (LA324_0==KW_EXCEPT||LA324_0==KW_INTERSECT||LA324_0==KW_MINUS||LA324_0==KW_UNION) ) {
					alt324=1;
				}

				switch (alt324) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2855:3: u= setOperator r= singleFromStatement
					{
					pushFollow(FOLLOW_setOperator_in_fromStatement18724);
					u=setOperator();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setOperator.add(u.getTree());
					pushFollow(FOLLOW_singleFromStatement_in_fromStatement18728);
					r=singleFromStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_singleFromStatement.add(r.getTree());
					// AST REWRITE
					// elements: u, r
					// token labels: 
					// rule labels: r, u, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_r=new RewriteRuleSubtreeStream(adaptor,"rule r",r!=null?r.getTree():null);
					RewriteRuleSubtreeStream stream_u=new RewriteRuleSubtreeStream(adaptor,"rule u",u!=null?u.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2856:4: -> ^( $u $r)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2856:7: ^( $u $r)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);
						adaptor.addChild(root_1, retval.tree);
						adaptor.addChild(root_1, stream_r.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

				default :
					break loop324;
				}
			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2858:3: -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
			if (u != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2858:19: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2859:9: ^( TOK_FROM ^( TOK_SUBQUERY ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2860:11: ^( TOK_SUBQUERY )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
				adaptor.addChild(root_3, retval.tree);
				adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2865:9: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2866:12: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2866:30: ^( TOK_DIR TOK_TMP_FILE )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2867:12: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2867:25: ^( TOK_SELEXPR TOK_SETCOLREF )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2870:5: ->
			{
				adaptor.addChild(root_0, retval.tree);
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "fromStatement"


	public static class singleFromStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "singleFromStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2874:1: singleFromStatement : fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) ;
	public final HiveParser.singleFromStatement_return singleFromStatement() throws RecognitionException {
		HiveParser.singleFromStatement_return retval = new HiveParser.singleFromStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		List<Object> list_b=null;
		ParserRuleReturnScope fromClause1087 =null;
		RuleReturnScope b = null;
		RewriteRuleSubtreeStream stream_fromClause=new RewriteRuleSubtreeStream(adaptor,"rule fromClause");
		RewriteRuleSubtreeStream stream_body=new RewriteRuleSubtreeStream(adaptor,"rule body");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2875:5: ( fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2876:5: fromClause (b+= body )+
			{
			pushFollow(FOLLOW_fromClause_in_singleFromStatement18935);
			fromClause1087=fromClause();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_fromClause.add(fromClause1087.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2877:5: (b+= body )+
			int cnt325=0;
			loop325:
			while (true) {
				int alt325=2;
				int LA325_0 = input.LA(1);
				if ( (LA325_0==KW_INSERT||LA325_0==KW_MAP||LA325_0==KW_REDUCE||LA325_0==KW_SELECT) ) {
					alt325=1;
				}

				switch (alt325) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2877:7: b+= body
					{
					pushFollow(FOLLOW_body_in_singleFromStatement18945);
					b=body();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_body.add(b.getTree());
					if (list_b==null) list_b=new ArrayList<Object>();
					list_b.add(b.getTree());
					}
					break;

				default :
					if ( cnt325 >= 1 ) break loop325;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(325, input);
					throw eee;
				}
				cnt325++;
			}

			// AST REWRITE
			// elements: fromClause, body
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2877:18: -> ^( TOK_QUERY fromClause ( body )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2877:21: ^( TOK_QUERY fromClause ( body )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				adaptor.addChild(root_1, stream_fromClause.nextTree());
				if ( !(stream_body.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_body.hasNext() ) {
					adaptor.addChild(root_1, stream_body.nextTree());
				}
				stream_body.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "singleFromStatement"


	public static class regularBody_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "regularBody"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2886:1: regularBody : (i= insertClause (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) ) ) | selectStatement );
	public final HiveParser.regularBody_return regularBody() throws RecognitionException {
		HiveParser.regularBody_return retval = new HiveParser.regularBody_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope i =null;
		ParserRuleReturnScope s =null;
		ParserRuleReturnScope valuesClause1088 =null;
		ParserRuleReturnScope selectStatement1089 =null;

		RewriteRuleSubtreeStream stream_insertClause=new RewriteRuleSubtreeStream(adaptor,"rule insertClause");
		RewriteRuleSubtreeStream stream_valuesClause=new RewriteRuleSubtreeStream(adaptor,"rule valuesClause");
		RewriteRuleSubtreeStream stream_selectStatement=new RewriteRuleSubtreeStream(adaptor,"rule selectStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2887:4: (i= insertClause (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) ) ) | selectStatement )
			int alt327=2;
			int LA327_0 = input.LA(1);
			if ( (LA327_0==KW_INSERT) ) {
				alt327=1;
			}
			else if ( (LA327_0==KW_MAP||LA327_0==KW_REDUCE||LA327_0==KW_SELECT||LA327_0==LPAREN) ) {
				alt327=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 327, 0, input);
				throw nvae;
			}

			switch (alt327) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2888:4: i= insertClause (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) ) )
					{
					pushFollow(FOLLOW_insertClause_in_regularBody18982);
					i=insertClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_insertClause.add(i.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2889:4: (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) ) )
					int alt326=2;
					int LA326_0 = input.LA(1);
					if ( (LA326_0==KW_MAP||LA326_0==KW_REDUCE||LA326_0==KW_SELECT||LA326_0==LPAREN) ) {
						alt326=1;
					}
					else if ( (LA326_0==KW_VALUES) ) {
						alt326=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 326, 0, input);
						throw nvae;
					}

					switch (alt326) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2890:4: s= selectStatement
							{
							pushFollow(FOLLOW_selectStatement_in_regularBody18994);
							s=selectStatement();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_selectStatement.add(s.getTree());
							if ( state.backtracking==0 ) {(s!=null?((ASTNode)s.getTree()):null).getFirstChildWithType(TOK_INSERT).replaceChildren(0, 0, (i!=null?((ASTNode)i.getTree()):null));}
							// AST REWRITE
							// elements: 
							// token labels: 
							// rule labels: retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 2891:82: ->
							{
								adaptor.addChild(root_0, (s!=null?((ASTNode)s.getTree()):null));
							}


							retval.tree = root_0;
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2893:6: valuesClause
							{
							pushFollow(FOLLOW_valuesClause_in_regularBody19019);
							valuesClause1088=valuesClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_valuesClause.add(valuesClause1088.getTree());
							// AST REWRITE
							// elements: valuesClause
							// token labels: 
							// rule labels: retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 2894:7: -> ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:2894:10: ^( TOK_QUERY ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) ) )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:2895:13: ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) ) )
								{
								ASTNode root_2 = (ASTNode)adaptor.nil();
								root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
								adaptor.addChild(root_2, (i!=null?((ASTNode)i.getTree()):null));
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:2895:36: ^( TOK_SELECT ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) ) )
								{
								ASTNode root_3 = (ASTNode)adaptor.nil();
								root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:2895:49: ^( TOK_SELEXPR ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause ) )
								{
								ASTNode root_4 = (ASTNode)adaptor.nil();
								root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:2895:63: ^( TOK_FUNCTION Identifier[\"inline\"] valuesClause )
								{
								ASTNode root_5 = (ASTNode)adaptor.nil();
								root_5 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FUNCTION, "TOK_FUNCTION"), root_5);
								adaptor.addChild(root_5, (ASTNode)adaptor.create(Identifier, "inline"));
								adaptor.addChild(root_5, stream_valuesClause.nextTree());
								adaptor.addChild(root_4, root_5);
								}

								adaptor.addChild(root_3, root_4);
								}

								adaptor.addChild(root_2, root_3);
								}

								adaptor.addChild(root_1, root_2);
								}

								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2899:4: selectStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_selectStatement_in_regularBody19092);
					selectStatement1089=selectStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, selectStatement1089.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "regularBody"


	public static class atomSelectStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "atomSelectStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2902:1: atomSelectStatement : (s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )? -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) ) | LPAREN ! selectStatement RPAREN !);
	public final HiveParser.atomSelectStatement_return atomSelectStatement() throws RecognitionException {
		HiveParser.atomSelectStatement_return retval = new HiveParser.atomSelectStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN1090=null;
		Token RPAREN1092=null;
		ParserRuleReturnScope s =null;
		ParserRuleReturnScope f =null;
		ParserRuleReturnScope w =null;
		ParserRuleReturnScope g =null;
		ParserRuleReturnScope h =null;
		ParserRuleReturnScope win =null;
		ParserRuleReturnScope selectStatement1091 =null;

		ASTNode LPAREN1090_tree=null;
		ASTNode RPAREN1092_tree=null;
		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_havingClause=new RewriteRuleSubtreeStream(adaptor,"rule havingClause");
		RewriteRuleSubtreeStream stream_fromClause=new RewriteRuleSubtreeStream(adaptor,"rule fromClause");
		RewriteRuleSubtreeStream stream_selectClause=new RewriteRuleSubtreeStream(adaptor,"rule selectClause");
		RewriteRuleSubtreeStream stream_groupByClause=new RewriteRuleSubtreeStream(adaptor,"rule groupByClause");
		RewriteRuleSubtreeStream stream_window_clause=new RewriteRuleSubtreeStream(adaptor,"rule window_clause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2903:4: (s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )? -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) ) | LPAREN ! selectStatement RPAREN !)
			int alt333=2;
			int LA333_0 = input.LA(1);
			if ( (LA333_0==KW_MAP||LA333_0==KW_REDUCE||LA333_0==KW_SELECT) ) {
				alt333=1;
			}
			else if ( (LA333_0==LPAREN) ) {
				alt333=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 333, 0, input);
				throw nvae;
			}

			switch (alt333) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2904:4: s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )?
					{
					pushFollow(FOLLOW_selectClause_in_atomSelectStatement19112);
					s=selectClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_selectClause.add(s.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2905:5: (f= fromClause )?
					int alt328=2;
					int LA328_0 = input.LA(1);
					if ( (LA328_0==KW_FROM) ) {
						alt328=1;
					}
					switch (alt328) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2905:5: f= fromClause
							{
							pushFollow(FOLLOW_fromClause_in_atomSelectStatement19119);
							f=fromClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_fromClause.add(f.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2906:5: (w= whereClause )?
					int alt329=2;
					int LA329_0 = input.LA(1);
					if ( (LA329_0==KW_WHERE) ) {
						alt329=1;
					}
					switch (alt329) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2906:5: w= whereClause
							{
							pushFollow(FOLLOW_whereClause_in_atomSelectStatement19127);
							w=whereClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_whereClause.add(w.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2907:5: (g= groupByClause )?
					int alt330=2;
					int LA330_0 = input.LA(1);
					if ( (LA330_0==KW_GROUP) ) {
						alt330=1;
					}
					switch (alt330) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2907:5: g= groupByClause
							{
							pushFollow(FOLLOW_groupByClause_in_atomSelectStatement19135);
							g=groupByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_groupByClause.add(g.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2908:5: (h= havingClause )?
					int alt331=2;
					int LA331_0 = input.LA(1);
					if ( (LA331_0==KW_HAVING) ) {
						alt331=1;
					}
					switch (alt331) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2908:5: h= havingClause
							{
							pushFollow(FOLLOW_havingClause_in_atomSelectStatement19143);
							h=havingClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_havingClause.add(h.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2909:7: (win= window_clause )?
					int alt332=2;
					int LA332_0 = input.LA(1);
					if ( (LA332_0==KW_WINDOW) ) {
						alt332=1;
					}
					switch (alt332) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2909:7: win= window_clause
							{
							pushFollow(FOLLOW_window_clause_in_atomSelectStatement19151);
							win=window_clause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_window_clause.add(win.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: win, s, h, f, w, g
					// token labels: 
					// rule labels: s, f, w, g, h, win, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_s=new RewriteRuleSubtreeStream(adaptor,"rule s",s!=null?s.getTree():null);
					RewriteRuleSubtreeStream stream_f=new RewriteRuleSubtreeStream(adaptor,"rule f",f!=null?f.getTree():null);
					RewriteRuleSubtreeStream stream_w=new RewriteRuleSubtreeStream(adaptor,"rule w",w!=null?w.getTree():null);
					RewriteRuleSubtreeStream stream_g=new RewriteRuleSubtreeStream(adaptor,"rule g",g!=null?g.getTree():null);
					RewriteRuleSubtreeStream stream_h=new RewriteRuleSubtreeStream(adaptor,"rule h",h!=null?h.getTree():null);
					RewriteRuleSubtreeStream stream_win=new RewriteRuleSubtreeStream(adaptor,"rule win",win!=null?win.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2910:4: -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2910:7: ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2910:20: ( $f)?
						if ( stream_f.hasNext() ) {
							adaptor.addChild(root_1, stream_f.nextTree());
						}
						stream_f.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2910:23: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2910:36: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2910:54: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_2, stream_s.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2911:26: ( $w)?
						if ( stream_w.hasNext() ) {
							adaptor.addChild(root_2, stream_w.nextTree());
						}
						stream_w.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2911:30: ( $g)?
						if ( stream_g.hasNext() ) {
							adaptor.addChild(root_2, stream_g.nextTree());
						}
						stream_g.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2911:34: ( $h)?
						if ( stream_h.hasNext() ) {
							adaptor.addChild(root_2, stream_h.nextTree());
						}
						stream_h.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2911:38: ( $win)?
						if ( stream_win.hasNext() ) {
							adaptor.addChild(root_2, stream_win.nextTree());
						}
						stream_win.reset();

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2913:4: LPAREN ! selectStatement RPAREN !
					{
					root_0 = (ASTNode)adaptor.nil();


					LPAREN1090=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_atomSelectStatement19229); if (state.failed) return retval;
					pushFollow(FOLLOW_selectStatement_in_atomSelectStatement19232);
					selectStatement1091=selectStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, selectStatement1091.getTree());

					RPAREN1092=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_atomSelectStatement19234); if (state.failed) return retval;
					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "atomSelectStatement"


	public static class selectStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "selectStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2916:1: selectStatement : a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )? -> {set == null}? -> {o==null && c==null && d==null && sort==null && l==null}? -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) ) ;
	public final HiveParser.selectStatement_return selectStatement() throws RecognitionException {
		HiveParser.selectStatement_return retval = new HiveParser.selectStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope a =null;
		ParserRuleReturnScope set =null;
		ParserRuleReturnScope o =null;
		ParserRuleReturnScope c =null;
		ParserRuleReturnScope d =null;
		ParserRuleReturnScope sort =null;
		ParserRuleReturnScope l =null;

		RewriteRuleSubtreeStream stream_clusterByClause=new RewriteRuleSubtreeStream(adaptor,"rule clusterByClause");
		RewriteRuleSubtreeStream stream_setOpSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule setOpSelectStatement");
		RewriteRuleSubtreeStream stream_sortByClause=new RewriteRuleSubtreeStream(adaptor,"rule sortByClause");
		RewriteRuleSubtreeStream stream_distributeByClause=new RewriteRuleSubtreeStream(adaptor,"rule distributeByClause");
		RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
		RewriteRuleSubtreeStream stream_atomSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule atomSelectStatement");
		RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2917:4: (a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )? -> {set == null}? -> {o==null && c==null && d==null && sort==null && l==null}? -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2918:4: a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )?
			{
			pushFollow(FOLLOW_atomSelectStatement_in_selectStatement19255);
			a=atomSelectStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_atomSelectStatement.add(a.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2919:7: (set= setOpSelectStatement[$atomSelectStatement.tree] )?
			int alt334=2;
			int LA334_0 = input.LA(1);
			if ( (LA334_0==KW_EXCEPT||LA334_0==KW_INTERSECT||LA334_0==KW_MINUS||LA334_0==KW_UNION) ) {
				alt334=1;
			}
			switch (alt334) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2919:7: set= setOpSelectStatement[$atomSelectStatement.tree]
					{
					pushFollow(FOLLOW_setOpSelectStatement_in_selectStatement19262);
					set=setOpSelectStatement((a!=null?((ASTNode)a.getTree()):null));
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setOpSelectStatement.add(set.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2920:5: (o= orderByClause )?
			int alt335=2;
			int LA335_0 = input.LA(1);
			if ( (LA335_0==KW_ORDER) ) {
				alt335=1;
			}
			switch (alt335) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2920:5: o= orderByClause
					{
					pushFollow(FOLLOW_orderByClause_in_selectStatement19271);
					o=orderByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orderByClause.add(o.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2921:5: (c= clusterByClause )?
			int alt336=2;
			int LA336_0 = input.LA(1);
			if ( (LA336_0==KW_CLUSTER) ) {
				alt336=1;
			}
			switch (alt336) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2921:5: c= clusterByClause
					{
					pushFollow(FOLLOW_clusterByClause_in_selectStatement19279);
					c=clusterByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_clusterByClause.add(c.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:5: (d= distributeByClause )?
			int alt337=2;
			int LA337_0 = input.LA(1);
			if ( (LA337_0==KW_DISTRIBUTE) ) {
				alt337=1;
			}
			switch (alt337) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:5: d= distributeByClause
					{
					pushFollow(FOLLOW_distributeByClause_in_selectStatement19287);
					d=distributeByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_distributeByClause.add(d.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2923:8: (sort= sortByClause )?
			int alt338=2;
			int LA338_0 = input.LA(1);
			if ( (LA338_0==KW_SORT) ) {
				alt338=1;
			}
			switch (alt338) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2923:8: sort= sortByClause
					{
					pushFollow(FOLLOW_sortByClause_in_selectStatement19295);
					sort=sortByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_sortByClause.add(sort.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2924:5: (l= limitClause )?
			int alt339=2;
			int LA339_0 = input.LA(1);
			if ( (LA339_0==KW_LIMIT) ) {
				alt339=1;
			}
			switch (alt339) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2924:5: l= limitClause
					{
					pushFollow(FOLLOW_limitClause_in_selectStatement19303);
					l=limitClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_limitClause.add(l.getTree());
					}
					break;

			}

			if ( state.backtracking==0 ) {
			   if(set == null){
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((o!=null?((ASTNode)o.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((c!=null?((ASTNode)c.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((d!=null?((ASTNode)d.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((sort!=null?((ASTNode)sort.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((l!=null?((ASTNode)l.getTree()):null));
			   }
			   }
			// AST REWRITE
			// elements: c, o, sort, d, l
			// token labels: 
			// rule labels: c, d, sort, l, retval, o
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_c=new RewriteRuleSubtreeStream(adaptor,"rule c",c!=null?c.getTree():null);
			RewriteRuleSubtreeStream stream_d=new RewriteRuleSubtreeStream(adaptor,"rule d",d!=null?d.getTree():null);
			RewriteRuleSubtreeStream stream_sort=new RewriteRuleSubtreeStream(adaptor,"rule sort",sort!=null?sort.getTree():null);
			RewriteRuleSubtreeStream stream_l=new RewriteRuleSubtreeStream(adaptor,"rule l",l!=null?l.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_o=new RewriteRuleSubtreeStream(adaptor,"rule o",o!=null?o.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2934:4: -> {set == null}?
			if (set == null) {
				adaptor.addChild(root_0, (a!=null?((ASTNode)a.getTree()):null));
			}

			else // 2936:4: -> {o==null && c==null && d==null && sort==null && l==null}?
			if (o==null && c==null && d==null && sort==null && l==null) {
				adaptor.addChild(root_0, (set!=null?((ASTNode)set.getTree()):null));
			}

			else // 2938:4: -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2938:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2939:11: ^( TOK_FROM ^( TOK_SUBQUERY ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2940:13: ^( TOK_SUBQUERY )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
				adaptor.addChild(root_3, (set!=null?((ASTNode)set.getTree()):null));
				adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2945:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2946:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2946:32: ^( TOK_DIR TOK_TMP_FILE )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2947:14: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2947:27: ^( TOK_SELEXPR TOK_SETCOLREF )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:15: ( $o)?
				if ( stream_o.hasNext() ) {
					adaptor.addChild(root_2, stream_o.nextTree());
				}
				stream_o.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:19: ( $c)?
				if ( stream_c.hasNext() ) {
					adaptor.addChild(root_2, stream_c.nextTree());
				}
				stream_c.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:23: ( $d)?
				if ( stream_d.hasNext() ) {
					adaptor.addChild(root_2, stream_d.nextTree());
				}
				stream_d.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:27: ( $sort)?
				if ( stream_sort.hasNext() ) {
					adaptor.addChild(root_2, stream_sort.nextTree());
				}
				stream_sort.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2948:34: ( $l)?
				if ( stream_l.hasNext() ) {
					adaptor.addChild(root_2, stream_l.nextTree());
				}
				stream_l.reset();

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "selectStatement"


	public static class setOpSelectStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setOpSelectStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2953:1: setOpSelectStatement[CommonTree t] : (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+ -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->;
	public final HiveParser.setOpSelectStatement_return setOpSelectStatement(CommonTree t) throws RecognitionException {
		HiveParser.setOpSelectStatement_return retval = new HiveParser.setOpSelectStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope u =null;
		ParserRuleReturnScope b =null;

		RewriteRuleSubtreeStream stream_setOperator=new RewriteRuleSubtreeStream(adaptor,"rule setOperator");
		RewriteRuleSubtreeStream stream_atomSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule atomSelectStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2954:4: ( (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+ -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->)
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2955:4: (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2955:4: (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+
			int cnt340=0;
			loop340:
			while (true) {
				int alt340=2;
				int LA340_0 = input.LA(1);
				if ( (LA340_0==KW_EXCEPT||LA340_0==KW_INTERSECT||LA340_0==KW_MINUS||LA340_0==KW_UNION) ) {
					alt340=1;
				}

				switch (alt340) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2955:5: u= setOperator b= atomSelectStatement
					{
					pushFollow(FOLLOW_setOperator_in_setOpSelectStatement19568);
					u=setOperator();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setOperator.add(u.getTree());
					pushFollow(FOLLOW_atomSelectStatement_in_setOpSelectStatement19572);
					b=atomSelectStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_atomSelectStatement.add(b.getTree());
					// AST REWRITE
					// elements: u, u, b, b, b, b
					// token labels: 
					// rule labels: b, u, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_b=new RewriteRuleSubtreeStream(adaptor,"rule b",b!=null?b.getTree():null);
					RewriteRuleSubtreeStream stream_u=new RewriteRuleSubtreeStream(adaptor,"rule u",u!=null?u.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2956:4: -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
					if (retval.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2957:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2958:11: ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2959:13: ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2960:15: ^( TOK_UNIONALL $b)
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL"), root_4);
						adaptor.addChild(root_4, retval.tree);
						adaptor.addChild(root_4, stream_b.nextTree());
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2964:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2965:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2965:32: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2966:14: ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECTDI, "TOK_SELECTDI"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2966:29: ^( TOK_SELEXPR TOK_SETCOLREF )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_0, root_1);
						}

					}

					else // 2969:4: -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b)
					if (retval.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2970:7: ^( $u $b)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);
						adaptor.addChild(root_1, retval.tree);
						adaptor.addChild(root_1, stream_b.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}

					else // 2971:4: -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
					if (retval.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2972:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2973:11: ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2974:13: ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2975:15: ^( TOK_UNIONALL $b)
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL"), root_4);
						adaptor.addChild(root_4, t);
						adaptor.addChild(root_4, stream_b.nextTree());
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2979:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2980:13: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2980:31: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2981:13: ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECTDI, "TOK_SELECTDI"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2981:28: ^( TOK_SELEXPR TOK_SETCOLREF )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_0, root_1);
						}

					}

					else // 2984:4: -> ^( $u $b)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2984:7: ^( $u $b)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);
						adaptor.addChild(root_1, t);
						adaptor.addChild(root_1, stream_b.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

				default :
					if ( cnt340 >= 1 ) break loop340;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(340, input);
					throw eee;
				}
				cnt340++;
			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2986:4: -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
			if (retval.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2991:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2992:11: ^( TOK_FROM ^( TOK_SUBQUERY ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2993:13: ^( TOK_SUBQUERY )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
				adaptor.addChild(root_3, retval.tree);
				adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2998:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2999:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2999:32: ^( TOK_DIR TOK_TMP_FILE )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3000:14: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3000:27: ^( TOK_SELEXPR TOK_SETCOLREF )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 3003:4: ->
			{
				adaptor.addChild(root_0, retval.tree);
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setOpSelectStatement"


	public static class selectStatementWithCTE_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "selectStatementWithCTE"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3006:1: selectStatementWithCTE : (w= withClause )? selectStatement -> selectStatement ;
	public final HiveParser.selectStatementWithCTE_return selectStatementWithCTE() throws RecognitionException {
		HiveParser.selectStatementWithCTE_return retval = new HiveParser.selectStatementWithCTE_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope w =null;
		ParserRuleReturnScope selectStatement1093 =null;

		RewriteRuleSubtreeStream stream_withClause=new RewriteRuleSubtreeStream(adaptor,"rule withClause");
		RewriteRuleSubtreeStream stream_selectStatement=new RewriteRuleSubtreeStream(adaptor,"rule selectStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3007:5: ( (w= withClause )? selectStatement -> selectStatement )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3008:5: (w= withClause )? selectStatement
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3008:5: (w= withClause )?
			int alt341=2;
			int LA341_0 = input.LA(1);
			if ( (LA341_0==KW_WITH) ) {
				alt341=1;
			}
			switch (alt341) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3008:6: w= withClause
					{
					pushFollow(FOLLOW_withClause_in_selectStatementWithCTE20207);
					w=withClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withClause.add(w.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_selectStatement_in_selectStatementWithCTE20215);
			selectStatement1093=selectStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_selectStatement.add(selectStatement1093.getTree());
			if ( state.backtracking==0 ) {
			      if ((w!=null?((ASTNode)w.getTree()):null) != null) {
			      (selectStatement1093!=null?((ASTNode)selectStatement1093.getTree()):null).insertChild(0, (w!=null?((ASTNode)w.getTree()):null));
			      }
			    }
			// AST REWRITE
			// elements: selectStatement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3014:5: -> selectStatement
			{
				adaptor.addChild(root_0, stream_selectStatement.nextTree());
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "selectStatementWithCTE"


	public static class body_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "body"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3017:1: body : ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) );
	public final HiveParser.body_return body() throws RecognitionException {
		HiveParser.body_return retval = new HiveParser.body_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope insertClause1094 =null;
		ParserRuleReturnScope selectClause1095 =null;
		ParserRuleReturnScope lateralView1096 =null;
		ParserRuleReturnScope whereClause1097 =null;
		ParserRuleReturnScope groupByClause1098 =null;
		ParserRuleReturnScope havingClause1099 =null;
		ParserRuleReturnScope window_clause1100 =null;
		ParserRuleReturnScope orderByClause1101 =null;
		ParserRuleReturnScope clusterByClause1102 =null;
		ParserRuleReturnScope distributeByClause1103 =null;
		ParserRuleReturnScope sortByClause1104 =null;
		ParserRuleReturnScope limitClause1105 =null;
		ParserRuleReturnScope selectClause1106 =null;
		ParserRuleReturnScope lateralView1107 =null;
		ParserRuleReturnScope whereClause1108 =null;
		ParserRuleReturnScope groupByClause1109 =null;
		ParserRuleReturnScope havingClause1110 =null;
		ParserRuleReturnScope window_clause1111 =null;
		ParserRuleReturnScope orderByClause1112 =null;
		ParserRuleReturnScope clusterByClause1113 =null;
		ParserRuleReturnScope distributeByClause1114 =null;
		ParserRuleReturnScope sortByClause1115 =null;
		ParserRuleReturnScope limitClause1116 =null;

		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_havingClause=new RewriteRuleSubtreeStream(adaptor,"rule havingClause");
		RewriteRuleSubtreeStream stream_clusterByClause=new RewriteRuleSubtreeStream(adaptor,"rule clusterByClause");
		RewriteRuleSubtreeStream stream_lateralView=new RewriteRuleSubtreeStream(adaptor,"rule lateralView");
		RewriteRuleSubtreeStream stream_insertClause=new RewriteRuleSubtreeStream(adaptor,"rule insertClause");
		RewriteRuleSubtreeStream stream_selectClause=new RewriteRuleSubtreeStream(adaptor,"rule selectClause");
		RewriteRuleSubtreeStream stream_sortByClause=new RewriteRuleSubtreeStream(adaptor,"rule sortByClause");
		RewriteRuleSubtreeStream stream_groupByClause=new RewriteRuleSubtreeStream(adaptor,"rule groupByClause");
		RewriteRuleSubtreeStream stream_distributeByClause=new RewriteRuleSubtreeStream(adaptor,"rule distributeByClause");
		RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
		RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");
		RewriteRuleSubtreeStream stream_window_clause=new RewriteRuleSubtreeStream(adaptor,"rule window_clause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3018:4: ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
			int alt362=2;
			int LA362_0 = input.LA(1);
			if ( (LA362_0==KW_INSERT) ) {
				alt362=1;
			}
			else if ( (LA362_0==KW_MAP||LA362_0==KW_REDUCE||LA362_0==KW_SELECT) ) {
				alt362=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 362, 0, input);
				throw nvae;
			}

			switch (alt362) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3019:4: insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )?
					{
					pushFollow(FOLLOW_insertClause_in_body20245);
					insertClause1094=insertClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_insertClause.add(insertClause1094.getTree());
					pushFollow(FOLLOW_selectClause_in_body20250);
					selectClause1095=selectClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_selectClause.add(selectClause1095.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3021:4: ( lateralView )?
					int alt342=2;
					int LA342_0 = input.LA(1);
					if ( (LA342_0==COMMA||LA342_0==KW_LATERAL) ) {
						alt342=1;
					}
					switch (alt342) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3021:4: lateralView
							{
							pushFollow(FOLLOW_lateralView_in_body20255);
							lateralView1096=lateralView();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_lateralView.add(lateralView1096.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3022:4: ( whereClause )?
					int alt343=2;
					int LA343_0 = input.LA(1);
					if ( (LA343_0==KW_WHERE) ) {
						alt343=1;
					}
					switch (alt343) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3022:4: whereClause
							{
							pushFollow(FOLLOW_whereClause_in_body20261);
							whereClause1097=whereClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_whereClause.add(whereClause1097.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3023:4: ( groupByClause )?
					int alt344=2;
					int LA344_0 = input.LA(1);
					if ( (LA344_0==KW_GROUP) ) {
						alt344=1;
					}
					switch (alt344) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3023:4: groupByClause
							{
							pushFollow(FOLLOW_groupByClause_in_body20267);
							groupByClause1098=groupByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_groupByClause.add(groupByClause1098.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3024:4: ( havingClause )?
					int alt345=2;
					int LA345_0 = input.LA(1);
					if ( (LA345_0==KW_HAVING) ) {
						alt345=1;
					}
					switch (alt345) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3024:4: havingClause
							{
							pushFollow(FOLLOW_havingClause_in_body20273);
							havingClause1099=havingClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_havingClause.add(havingClause1099.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3025:4: ( window_clause )?
					int alt346=2;
					int LA346_0 = input.LA(1);
					if ( (LA346_0==KW_WINDOW) ) {
						alt346=1;
					}
					switch (alt346) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3025:4: window_clause
							{
							pushFollow(FOLLOW_window_clause_in_body20279);
							window_clause1100=window_clause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_window_clause.add(window_clause1100.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3026:4: ( orderByClause )?
					int alt347=2;
					int LA347_0 = input.LA(1);
					if ( (LA347_0==KW_ORDER) ) {
						alt347=1;
					}
					switch (alt347) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3026:4: orderByClause
							{
							pushFollow(FOLLOW_orderByClause_in_body20285);
							orderByClause1101=orderByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_orderByClause.add(orderByClause1101.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3027:4: ( clusterByClause )?
					int alt348=2;
					int LA348_0 = input.LA(1);
					if ( (LA348_0==KW_CLUSTER) ) {
						alt348=1;
					}
					switch (alt348) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3027:4: clusterByClause
							{
							pushFollow(FOLLOW_clusterByClause_in_body20291);
							clusterByClause1102=clusterByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_clusterByClause.add(clusterByClause1102.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3028:4: ( distributeByClause )?
					int alt349=2;
					int LA349_0 = input.LA(1);
					if ( (LA349_0==KW_DISTRIBUTE) ) {
						alt349=1;
					}
					switch (alt349) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3028:4: distributeByClause
							{
							pushFollow(FOLLOW_distributeByClause_in_body20297);
							distributeByClause1103=distributeByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_distributeByClause.add(distributeByClause1103.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3029:4: ( sortByClause )?
					int alt350=2;
					int LA350_0 = input.LA(1);
					if ( (LA350_0==KW_SORT) ) {
						alt350=1;
					}
					switch (alt350) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3029:4: sortByClause
							{
							pushFollow(FOLLOW_sortByClause_in_body20303);
							sortByClause1104=sortByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_sortByClause.add(sortByClause1104.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3030:4: ( limitClause )?
					int alt351=2;
					int LA351_0 = input.LA(1);
					if ( (LA351_0==KW_LIMIT) ) {
						alt351=1;
					}
					switch (alt351) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3030:4: limitClause
							{
							pushFollow(FOLLOW_limitClause_in_body20309);
							limitClause1105=limitClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_limitClause.add(limitClause1105.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: distributeByClause, sortByClause, limitClause, orderByClause, window_clause, whereClause, lateralView, selectClause, groupByClause, clusterByClause, insertClause, havingClause
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3030:17: -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3030:20: ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_1);
						adaptor.addChild(root_1, stream_insertClause.nextTree());
						adaptor.addChild(root_1, stream_selectClause.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3031:35: ( lateralView )?
						if ( stream_lateralView.hasNext() ) {
							adaptor.addChild(root_1, stream_lateralView.nextTree());
						}
						stream_lateralView.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3031:48: ( whereClause )?
						if ( stream_whereClause.hasNext() ) {
							adaptor.addChild(root_1, stream_whereClause.nextTree());
						}
						stream_whereClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3031:61: ( groupByClause )?
						if ( stream_groupByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_groupByClause.nextTree());
						}
						stream_groupByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3031:76: ( havingClause )?
						if ( stream_havingClause.hasNext() ) {
							adaptor.addChild(root_1, stream_havingClause.nextTree());
						}
						stream_havingClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3031:90: ( orderByClause )?
						if ( stream_orderByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_orderByClause.nextTree());
						}
						stream_orderByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3031:105: ( clusterByClause )?
						if ( stream_clusterByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_clusterByClause.nextTree());
						}
						stream_clusterByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3032:22: ( distributeByClause )?
						if ( stream_distributeByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_distributeByClause.nextTree());
						}
						stream_distributeByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3032:42: ( sortByClause )?
						if ( stream_sortByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_sortByClause.nextTree());
						}
						stream_sortByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3032:56: ( window_clause )?
						if ( stream_window_clause.hasNext() ) {
							adaptor.addChild(root_1, stream_window_clause.nextTree());
						}
						stream_window_clause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3032:71: ( limitClause )?
						if ( stream_limitClause.hasNext() ) {
							adaptor.addChild(root_1, stream_limitClause.nextTree());
						}
						stream_limitClause.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3034:4: selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )?
					{
					pushFollow(FOLLOW_selectClause_in_body20402);
					selectClause1106=selectClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_selectClause.add(selectClause1106.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3035:4: ( lateralView )?
					int alt352=2;
					int LA352_0 = input.LA(1);
					if ( (LA352_0==COMMA||LA352_0==KW_LATERAL) ) {
						alt352=1;
					}
					switch (alt352) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3035:4: lateralView
							{
							pushFollow(FOLLOW_lateralView_in_body20407);
							lateralView1107=lateralView();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_lateralView.add(lateralView1107.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3036:4: ( whereClause )?
					int alt353=2;
					int LA353_0 = input.LA(1);
					if ( (LA353_0==KW_WHERE) ) {
						alt353=1;
					}
					switch (alt353) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3036:4: whereClause
							{
							pushFollow(FOLLOW_whereClause_in_body20413);
							whereClause1108=whereClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_whereClause.add(whereClause1108.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3037:4: ( groupByClause )?
					int alt354=2;
					int LA354_0 = input.LA(1);
					if ( (LA354_0==KW_GROUP) ) {
						alt354=1;
					}
					switch (alt354) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3037:4: groupByClause
							{
							pushFollow(FOLLOW_groupByClause_in_body20419);
							groupByClause1109=groupByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_groupByClause.add(groupByClause1109.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3038:4: ( havingClause )?
					int alt355=2;
					int LA355_0 = input.LA(1);
					if ( (LA355_0==KW_HAVING) ) {
						alt355=1;
					}
					switch (alt355) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3038:4: havingClause
							{
							pushFollow(FOLLOW_havingClause_in_body20425);
							havingClause1110=havingClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_havingClause.add(havingClause1110.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3039:4: ( window_clause )?
					int alt356=2;
					int LA356_0 = input.LA(1);
					if ( (LA356_0==KW_WINDOW) ) {
						alt356=1;
					}
					switch (alt356) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3039:4: window_clause
							{
							pushFollow(FOLLOW_window_clause_in_body20431);
							window_clause1111=window_clause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_window_clause.add(window_clause1111.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3040:4: ( orderByClause )?
					int alt357=2;
					int LA357_0 = input.LA(1);
					if ( (LA357_0==KW_ORDER) ) {
						alt357=1;
					}
					switch (alt357) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3040:4: orderByClause
							{
							pushFollow(FOLLOW_orderByClause_in_body20437);
							orderByClause1112=orderByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_orderByClause.add(orderByClause1112.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3041:4: ( clusterByClause )?
					int alt358=2;
					int LA358_0 = input.LA(1);
					if ( (LA358_0==KW_CLUSTER) ) {
						alt358=1;
					}
					switch (alt358) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3041:4: clusterByClause
							{
							pushFollow(FOLLOW_clusterByClause_in_body20443);
							clusterByClause1113=clusterByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_clusterByClause.add(clusterByClause1113.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3042:4: ( distributeByClause )?
					int alt359=2;
					int LA359_0 = input.LA(1);
					if ( (LA359_0==KW_DISTRIBUTE) ) {
						alt359=1;
					}
					switch (alt359) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3042:4: distributeByClause
							{
							pushFollow(FOLLOW_distributeByClause_in_body20449);
							distributeByClause1114=distributeByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_distributeByClause.add(distributeByClause1114.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3043:4: ( sortByClause )?
					int alt360=2;
					int LA360_0 = input.LA(1);
					if ( (LA360_0==KW_SORT) ) {
						alt360=1;
					}
					switch (alt360) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3043:4: sortByClause
							{
							pushFollow(FOLLOW_sortByClause_in_body20455);
							sortByClause1115=sortByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_sortByClause.add(sortByClause1115.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3044:4: ( limitClause )?
					int alt361=2;
					int LA361_0 = input.LA(1);
					if ( (LA361_0==KW_LIMIT) ) {
						alt361=1;
					}
					switch (alt361) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3044:4: limitClause
							{
							pushFollow(FOLLOW_limitClause_in_body20461);
							limitClause1116=limitClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_limitClause.add(limitClause1116.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: whereClause, distributeByClause, limitClause, clusterByClause, window_clause, lateralView, sortByClause, orderByClause, selectClause, havingClause, groupByClause
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3044:17: -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3044:20: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3044:33: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3044:51: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_3);
						adaptor.addChild(root_3, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_1, stream_selectClause.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3045:35: ( lateralView )?
						if ( stream_lateralView.hasNext() ) {
							adaptor.addChild(root_1, stream_lateralView.nextTree());
						}
						stream_lateralView.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3045:48: ( whereClause )?
						if ( stream_whereClause.hasNext() ) {
							adaptor.addChild(root_1, stream_whereClause.nextTree());
						}
						stream_whereClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3045:61: ( groupByClause )?
						if ( stream_groupByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_groupByClause.nextTree());
						}
						stream_groupByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3045:76: ( havingClause )?
						if ( stream_havingClause.hasNext() ) {
							adaptor.addChild(root_1, stream_havingClause.nextTree());
						}
						stream_havingClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3045:90: ( orderByClause )?
						if ( stream_orderByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_orderByClause.nextTree());
						}
						stream_orderByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3045:105: ( clusterByClause )?
						if ( stream_clusterByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_clusterByClause.nextTree());
						}
						stream_clusterByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3046:22: ( distributeByClause )?
						if ( stream_distributeByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_distributeByClause.nextTree());
						}
						stream_distributeByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3046:42: ( sortByClause )?
						if ( stream_sortByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_sortByClause.nextTree());
						}
						stream_sortByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3046:56: ( window_clause )?
						if ( stream_window_clause.hasNext() ) {
							adaptor.addChild(root_1, stream_window_clause.nextTree());
						}
						stream_window_clause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3046:71: ( limitClause )?
						if ( stream_limitClause.hasNext() ) {
							adaptor.addChild(root_1, stream_limitClause.nextTree());
						}
						stream_limitClause.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "body"


	public static class insertClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "insertClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3049:1: insertClause : ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )? -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? ) );
	public final HiveParser.insertClause_return insertClause() throws RecognitionException {
		HiveParser.insertClause_return retval = new HiveParser.insertClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_INSERT1117=null;
		Token KW_OVERWRITE1118=null;
		Token KW_INSERT1121=null;
		Token KW_INTO1122=null;
		Token KW_TABLE1123=null;
		Token LPAREN1125=null;
		Token RPAREN1126=null;
		ParserRuleReturnScope targetCols =null;
		ParserRuleReturnScope destination1119 =null;
		ParserRuleReturnScope ifNotExists1120 =null;
		ParserRuleReturnScope tableOrPartition1124 =null;

		ASTNode KW_INSERT1117_tree=null;
		ASTNode KW_OVERWRITE1118_tree=null;
		ASTNode KW_INSERT1121_tree=null;
		ASTNode KW_INTO1122_tree=null;
		ASTNode KW_TABLE1123_tree=null;
		ASTNode LPAREN1125_tree=null;
		ASTNode RPAREN1126_tree=null;
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
		RewriteRuleSubtreeStream stream_destination=new RewriteRuleSubtreeStream(adaptor,"rule destination");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("insert clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3052:4: ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )? -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? ) )
			int alt366=2;
			int LA366_0 = input.LA(1);
			if ( (LA366_0==KW_INSERT) ) {
				int LA366_1 = input.LA(2);
				if ( (LA366_1==KW_OVERWRITE) ) {
					alt366=1;
				}
				else if ( (LA366_1==KW_INTO) ) {
					alt366=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 366, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 366, 0, input);
				throw nvae;
			}

			switch (alt366) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3053:6: KW_INSERT KW_OVERWRITE destination ( ifNotExists )?
					{
					KW_INSERT1117=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_insertClause20582); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT1117);

					KW_OVERWRITE1118=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_insertClause20584); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OVERWRITE.add(KW_OVERWRITE1118);

					pushFollow(FOLLOW_destination_in_insertClause20586);
					destination1119=destination();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_destination.add(destination1119.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3053:41: ( ifNotExists )?
					int alt363=2;
					int LA363_0 = input.LA(1);
					if ( (LA363_0==KW_IF) ) {
						alt363=1;
					}
					switch (alt363) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3053:41: ifNotExists
							{
							pushFollow(FOLLOW_ifNotExists_in_insertClause20588);
							ifNotExists1120=ifNotExists();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists1120.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: destination, ifNotExists
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3053:54: -> ^( TOK_DESTINATION destination ( ifNotExists )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3053:57: ^( TOK_DESTINATION destination ( ifNotExists )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_1);
						adaptor.addChild(root_1, stream_destination.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3053:87: ( ifNotExists )?
						if ( stream_ifNotExists.hasNext() ) {
							adaptor.addChild(root_1, stream_ifNotExists.nextTree());
						}
						stream_ifNotExists.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3054:6: KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )?
					{
					KW_INSERT1121=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_insertClause20607); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT1121);

					KW_INTO1122=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_insertClause20609); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO1122);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3054:24: ( KW_TABLE )?
					int alt364=2;
					int LA364_0 = input.LA(1);
					if ( (LA364_0==KW_TABLE) ) {
						alt364=1;
					}
					switch (alt364) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3054:24: KW_TABLE
							{
							KW_TABLE1123=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_insertClause20611); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE1123);

							}
							break;

					}

					pushFollow(FOLLOW_tableOrPartition_in_insertClause20614);
					tableOrPartition1124=tableOrPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableOrPartition.add(tableOrPartition1124.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3054:51: ( LPAREN targetCols= columnNameList RPAREN )?
					int alt365=2;
					int LA365_0 = input.LA(1);
					if ( (LA365_0==LPAREN) ) {
						int LA365_1 = input.LA(2);
						if ( (LA365_1==Identifier||(LA365_1 >= KW_ABORT && LA365_1 <= KW_AFTER)||LA365_1==KW_ALLOC_FRACTION||LA365_1==KW_ANALYZE||LA365_1==KW_ARCHIVE||(LA365_1 >= KW_ASC && LA365_1 <= KW_AT)||(LA365_1 >= KW_AUTOCOMMIT && LA365_1 <= KW_BEFORE)||(LA365_1 >= KW_BUCKET && LA365_1 <= KW_BUCKETS)||(LA365_1 >= KW_CACHE && LA365_1 <= KW_CASCADE)||(LA365_1 >= KW_CBO && LA365_1 <= KW_CHANGE)||(LA365_1 >= KW_CHECK && LA365_1 <= KW_COLLECTION)||(LA365_1 >= KW_COLUMNS && LA365_1 <= KW_COMMENT)||(LA365_1 >= KW_COMPACT && LA365_1 <= KW_CONCATENATE)||(LA365_1 >= KW_CONTINUE && LA365_1 <= KW_COST)||LA365_1==KW_CRON||LA365_1==KW_DATA||LA365_1==KW_DATABASES||(LA365_1 >= KW_DATETIME && LA365_1 <= KW_DEBUG)||(LA365_1 >= KW_DEFAULT && LA365_1 <= KW_DEFINED)||(LA365_1 >= KW_DELIMITED && LA365_1 <= KW_DESC)||(LA365_1 >= KW_DETAIL && LA365_1 <= KW_DISABLE)||(LA365_1 >= KW_DISTRIBUTE && LA365_1 <= KW_DO)||LA365_1==KW_DOW||(LA365_1 >= KW_DUMP && LA365_1 <= KW_ELEM_TYPE)||LA365_1==KW_ENABLE||(LA365_1 >= KW_ENFORCED && LA365_1 <= KW_EVERY)||(LA365_1 >= KW_EXCLUSIVE && LA365_1 <= KW_EXECUTED)||(LA365_1 >= KW_EXPLAIN && LA365_1 <= KW_EXPRESSION)||(LA365_1 >= KW_FIELDS && LA365_1 <= KW_FIRST)||(LA365_1 >= KW_FORMAT && LA365_1 <= KW_FORMATTED)||LA365_1==KW_FUNCTIONS||(LA365_1 >= KW_HOUR && LA365_1 <= KW_IDXPROPERTIES)||(LA365_1 >= KW_INDEX && LA365_1 <= KW_INDEXES)||(LA365_1 >= KW_INPATH && LA365_1 <= KW_INPUTFORMAT)||(LA365_1 >= KW_ISOLATION && LA365_1 <= KW_JAR)||(LA365_1 >= KW_JOINCOST && LA365_1 <= KW_LAST)||LA365_1==KW_LEVEL||(LA365_1 >= KW_LIMIT && LA365_1 <= KW_LOAD)||(LA365_1 >= KW_LOCATION && LA365_1 <= KW_LONG)||(LA365_1 >= KW_MANAGEDLOCATION && LA365_1 <= KW_MANAGEMENT)||(LA365_1 >= KW_MAPJOIN && LA365_1 <= KW_MATERIALIZED)||LA365_1==KW_METADATA||(LA365_1 >= KW_MINUTE && LA365_1 <= KW_MONTH)||(LA365_1 >= KW_MOVE && LA365_1 <= KW_MSCK)||(LA365_1 >= KW_NORELY && LA365_1 <= KW_NOSCAN)||LA365_1==KW_NOVALIDATE||LA365_1==KW_NULLS||LA365_1==KW_OFFSET||(LA365_1 >= KW_OPERATOR && LA365_1 <= KW_OPTION)||(LA365_1 >= KW_OUTPUTDRIVER && LA365_1 <= KW_OUTPUTFORMAT)||(LA365_1 >= KW_OVERWRITE && LA365_1 <= KW_OWNER)||(LA365_1 >= KW_PARTITIONED && LA365_1 <= KW_PATH)||(LA365_1 >= KW_PLAN && LA365_1 <= KW_POOL)||LA365_1==KW_PRINCIPALS||(LA365_1 >= KW_PURGE && LA365_1 <= KW_QUERY_PARALLELISM)||LA365_1==KW_READ||(LA365_1 >= KW_REBUILD && LA365_1 <= KW_RECORDWRITER)||(LA365_1 >= KW_RELOAD && LA365_1 <= KW_RESTRICT)||LA365_1==KW_REWRITE||(LA365_1 >= KW_ROLE && LA365_1 <= KW_ROLES)||(LA365_1 >= KW_SCHEDULED && LA365_1 <= KW_SECOND)||(LA365_1 >= KW_SEMI && LA365_1 <= KW_SERVER)||(LA365_1 >= KW_SETS && LA365_1 <= KW_SKEWED)||(LA365_1 >= KW_SNAPSHOT && LA365_1 <= KW_SSL)||(LA365_1 >= KW_STATISTICS && LA365_1 <= KW_SUMMARY)||LA365_1==KW_TABLES||(LA365_1 >= KW_TBLPROPERTIES && LA365_1 <= KW_TERMINATED)||LA365_1==KW_TINYINT||(LA365_1 >= KW_TOUCH && LA365_1 <= KW_TRANSACTIONS)||LA365_1==KW_UNARCHIVE||LA365_1==KW_UNDO||LA365_1==KW_UNIONTYPE||(LA365_1 >= KW_UNLOCK && LA365_1 <= KW_UNSIGNED)||(LA365_1 >= KW_URI && LA365_1 <= KW_USE)||(LA365_1 >= KW_UTC && LA365_1 <= KW_VALIDATE)||LA365_1==KW_VALUE_TYPE||(LA365_1 >= KW_VECTORIZATION && LA365_1 <= KW_WEEK)||LA365_1==KW_WHILE||(LA365_1 >= KW_WORK && LA365_1 <= KW_ZONE)||LA365_1==KW_BATCH||LA365_1==KW_DAYOFWEEK||LA365_1==KW_HOLD_DDLTIME||LA365_1==KW_IGNORE||LA365_1==KW_NO_DROP||LA365_1==KW_OFFLINE||LA365_1==KW_PROTECTION||LA365_1==KW_READONLY||LA365_1==KW_TIMESTAMPTZ) ) {
							alt365=1;
						}
					}
					switch (alt365) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3054:52: LPAREN targetCols= columnNameList RPAREN
							{
							LPAREN1125=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_insertClause20617); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN1125);

							pushFollow(FOLLOW_columnNameList_in_insertClause20621);
							targetCols=columnNameList();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_columnNameList.add(targetCols.getTree());
							RPAREN1126=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_insertClause20623); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN1126);

							}
							break;

					}

					// AST REWRITE
					// elements: tableOrPartition, targetCols
					// token labels: 
					// rule labels: targetCols, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_targetCols=new RewriteRuleSubtreeStream(adaptor,"rule targetCols",targetCols!=null?targetCols.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3055:8: -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3055:11: ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT_INTO, "TOK_INSERT_INTO"), root_1);
						adaptor.addChild(root_1, stream_tableOrPartition.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3055:47: ( $targetCols)?
						if ( stream_targetCols.hasNext() ) {
							adaptor.addChild(root_1, stream_targetCols.nextTree());
						}
						stream_targetCols.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "insertClause"


	public static class destination_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "destination"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3058:1: destination : ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition );
	public final HiveParser.destination_return destination() throws RecognitionException {
		HiveParser.destination_return retval = new HiveParser.destination_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token local=null;
		Token KW_DIRECTORY1127=null;
		Token StringLiteral1128=null;
		Token KW_TABLE1131=null;
		ParserRuleReturnScope tableRowFormat1129 =null;
		ParserRuleReturnScope tableFileFormat1130 =null;
		ParserRuleReturnScope tableOrPartition1132 =null;

		ASTNode local_tree=null;
		ASTNode KW_DIRECTORY1127_tree=null;
		ASTNode StringLiteral1128_tree=null;
		ASTNode KW_TABLE1131_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_DIRECTORY=new RewriteRuleTokenStream(adaptor,"token KW_DIRECTORY");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
		RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
		RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");

		 pushMsg("destination specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3061:4: ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition )
			int alt370=2;
			int LA370_0 = input.LA(1);
			if ( (LA370_0==KW_DIRECTORY||LA370_0==KW_LOCAL) ) {
				alt370=1;
			}
			else if ( (LA370_0==KW_TABLE) ) {
				alt370=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 370, 0, input);
				throw nvae;
			}

			switch (alt370) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3062:6: (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3062:6: (local= KW_LOCAL )?
					int alt367=2;
					int LA367_0 = input.LA(1);
					if ( (LA367_0==KW_LOCAL) ) {
						alt367=1;
					}
					switch (alt367) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3062:7: local= KW_LOCAL
							{
							local=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_destination20679); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LOCAL.add(local);

							}
							break;

					}

					KW_DIRECTORY1127=(Token)match(input,KW_DIRECTORY,FOLLOW_KW_DIRECTORY_in_destination20683); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DIRECTORY.add(KW_DIRECTORY1127);

					StringLiteral1128=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_destination20685); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral1128);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3062:53: ( tableRowFormat )?
					int alt368=2;
					int LA368_0 = input.LA(1);
					if ( (LA368_0==KW_ROW) ) {
						alt368=1;
					}
					switch (alt368) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3062:53: tableRowFormat
							{
							pushFollow(FOLLOW_tableRowFormat_in_destination20687);
							tableRowFormat1129=tableRowFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat1129.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3062:69: ( tableFileFormat )?
					int alt369=2;
					int LA369_0 = input.LA(1);
					if ( (LA369_0==KW_STORED) ) {
						alt369=1;
					}
					switch (alt369) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3062:69: tableFileFormat
							{
							pushFollow(FOLLOW_tableFileFormat_in_destination20690);
							tableFileFormat1130=tableFileFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat1130.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: local, tableFileFormat, tableRowFormat, StringLiteral
					// token labels: local
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_local=new RewriteRuleTokenStream(adaptor,"token local",local);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3063:8: -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3063:11: ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3063:36: ( $local)?
						if ( stream_local.hasNext() ) {
							adaptor.addChild(root_1, stream_local.nextNode());
						}
						stream_local.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3063:43: ( tableRowFormat )?
						if ( stream_tableRowFormat.hasNext() ) {
							adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
						}
						stream_tableRowFormat.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3063:59: ( tableFileFormat )?
						if ( stream_tableFileFormat.hasNext() ) {
							adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
						}
						stream_tableFileFormat.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3064:6: KW_TABLE tableOrPartition
					{
					KW_TABLE1131=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_destination20723); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE1131);

					pushFollow(FOLLOW_tableOrPartition_in_destination20725);
					tableOrPartition1132=tableOrPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableOrPartition.add(tableOrPartition1132.getTree());
					// AST REWRITE
					// elements: tableOrPartition
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3064:32: -> tableOrPartition
					{
						adaptor.addChild(root_0, stream_tableOrPartition.nextTree());
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "destination"


	public static class limitClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "limitClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3067:1: limitClause : ( KW_LIMIT ( (offset= Number COMMA )? num= Number ) -> ^( TOK_LIMIT ( $offset)? $num) | KW_LIMIT num= Number KW_OFFSET offset= Number -> ^( TOK_LIMIT ( $offset)? $num) );
	public final HiveParser.limitClause_return limitClause() throws RecognitionException {
		HiveParser.limitClause_return retval = new HiveParser.limitClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token offset=null;
		Token num=null;
		Token KW_LIMIT1133=null;
		Token COMMA1134=null;
		Token KW_LIMIT1135=null;
		Token KW_OFFSET1136=null;

		ASTNode offset_tree=null;
		ASTNode num_tree=null;
		ASTNode KW_LIMIT1133_tree=null;
		ASTNode COMMA1134_tree=null;
		ASTNode KW_LIMIT1135_tree=null;
		ASTNode KW_OFFSET1136_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_LIMIT=new RewriteRuleTokenStream(adaptor,"token KW_LIMIT");
		RewriteRuleTokenStream stream_KW_OFFSET=new RewriteRuleTokenStream(adaptor,"token KW_OFFSET");

		 pushMsg("limit clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3070:4: ( KW_LIMIT ( (offset= Number COMMA )? num= Number ) -> ^( TOK_LIMIT ( $offset)? $num) | KW_LIMIT num= Number KW_OFFSET offset= Number -> ^( TOK_LIMIT ( $offset)? $num) )
			int alt372=2;
			int LA372_0 = input.LA(1);
			if ( (LA372_0==KW_LIMIT) ) {
				int LA372_1 = input.LA(2);
				if ( (LA372_1==Number) ) {
					int LA372_2 = input.LA(3);
					if ( (LA372_2==KW_OFFSET) ) {
						alt372=2;
					}
					else if ( (LA372_2==EOF||LA372_2==COMMA||LA372_2==KW_EXCEPT||LA372_2==KW_INSERT||LA372_2==KW_INTERSECT||LA372_2==KW_MAP||LA372_2==KW_MINUS||LA372_2==KW_REDUCE||LA372_2==KW_SELECT||LA372_2==KW_UNION||LA372_2==RPAREN) ) {
						alt372=1;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 372, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 372, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 372, 0, input);
				throw nvae;
			}

			switch (alt372) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3071:4: KW_LIMIT ( (offset= Number COMMA )? num= Number )
					{
					KW_LIMIT1133=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_limitClause20757); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LIMIT.add(KW_LIMIT1133);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3071:13: ( (offset= Number COMMA )? num= Number )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3071:14: (offset= Number COMMA )? num= Number
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3071:14: (offset= Number COMMA )?
					int alt371=2;
					int LA371_0 = input.LA(1);
					if ( (LA371_0==Number) ) {
						int LA371_1 = input.LA(2);
						if ( (LA371_1==COMMA) ) {
							alt371=1;
						}
					}
					switch (alt371) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3071:15: offset= Number COMMA
							{
							offset=(Token)match(input,Number,FOLLOW_Number_in_limitClause20763); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(offset);

							COMMA1134=(Token)match(input,COMMA,FOLLOW_COMMA_in_limitClause20765); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA1134);

							}
							break;

					}

					num=(Token)match(input,Number,FOLLOW_Number_in_limitClause20771); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(num);

					}

					// AST REWRITE
					// elements: num, offset
					// token labels: offset, num
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_offset=new RewriteRuleTokenStream(adaptor,"token offset",offset);
					RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3071:49: -> ^( TOK_LIMIT ( $offset)? $num)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3071:52: ^( TOK_LIMIT ( $offset)? $num)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LIMIT, "TOK_LIMIT"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3071:64: ( $offset)?
						if ( stream_offset.hasNext() ) {
							adaptor.addChild(root_1, stream_offset.nextNode());
						}
						stream_offset.reset();

						adaptor.addChild(root_1, stream_num.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3072:6: KW_LIMIT num= Number KW_OFFSET offset= Number
					{
					KW_LIMIT1135=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_limitClause20794); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LIMIT.add(KW_LIMIT1135);

					num=(Token)match(input,Number,FOLLOW_Number_in_limitClause20798); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(num);

					KW_OFFSET1136=(Token)match(input,KW_OFFSET,FOLLOW_KW_OFFSET_in_limitClause20800); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OFFSET.add(KW_OFFSET1136);

					offset=(Token)match(input,Number,FOLLOW_Number_in_limitClause20804); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(offset);

					// AST REWRITE
					// elements: num, offset
					// token labels: offset, num
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_offset=new RewriteRuleTokenStream(adaptor,"token offset",offset);
					RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3072:50: -> ^( TOK_LIMIT ( $offset)? $num)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3072:53: ^( TOK_LIMIT ( $offset)? $num)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LIMIT, "TOK_LIMIT"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3072:65: ( $offset)?
						if ( stream_offset.hasNext() ) {
							adaptor.addChild(root_1, stream_offset.nextNode());
						}
						stream_offset.reset();

						adaptor.addChild(root_1, stream_num.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "limitClause"


	public static class deleteStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "deleteStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3076:1: deleteStatement : KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) ;
	public final HiveParser.deleteStatement_return deleteStatement() throws RecognitionException {
		HiveParser.deleteStatement_return retval = new HiveParser.deleteStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DELETE1137=null;
		Token KW_FROM1138=null;
		ParserRuleReturnScope tableName1139 =null;
		ParserRuleReturnScope whereClause1140 =null;

		ASTNode KW_DELETE1137_tree=null;
		ASTNode KW_FROM1138_tree=null;
		RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("delete statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3079:4: ( KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3080:4: KW_DELETE KW_FROM tableName ( whereClause )?
			{
			KW_DELETE1137=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_deleteStatement20848); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE1137);

			KW_FROM1138=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_deleteStatement20850); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM1138);

			pushFollow(FOLLOW_tableName_in_deleteStatement20852);
			tableName1139=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName1139.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3080:32: ( whereClause )?
			int alt373=2;
			int LA373_0 = input.LA(1);
			if ( (LA373_0==KW_WHERE) ) {
				alt373=1;
			}
			switch (alt373) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3080:33: whereClause
					{
					pushFollow(FOLLOW_whereClause_in_deleteStatement20855);
					whereClause1140=whereClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_whereClause.add(whereClause1140.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableName, whereClause
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3080:47: -> ^( TOK_DELETE_FROM tableName ( whereClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3080:50: ^( TOK_DELETE_FROM tableName ( whereClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DELETE_FROM, "TOK_DELETE_FROM"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3080:78: ( whereClause )?
				if ( stream_whereClause.hasNext() ) {
					adaptor.addChild(root_1, stream_whereClause.nextTree());
				}
				stream_whereClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "deleteStatement"


	public static class columnAssignmentClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnAssignmentClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3084:1: columnAssignmentClause : tableOrColumn EQUAL ^ precedencePlusExpression ;
	public final HiveParser.columnAssignmentClause_return columnAssignmentClause() throws RecognitionException {
		HiveParser.columnAssignmentClause_return retval = new HiveParser.columnAssignmentClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token EQUAL1142=null;
		ParserRuleReturnScope tableOrColumn1141 =null;
		ParserRuleReturnScope precedencePlusExpression1143 =null;

		ASTNode EQUAL1142_tree=null;

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3085:4: ( tableOrColumn EQUAL ^ precedencePlusExpression )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3086:4: tableOrColumn EQUAL ^ precedencePlusExpression
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_tableOrColumn_in_columnAssignmentClause20888);
			tableOrColumn1141=tableOrColumn();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, tableOrColumn1141.getTree());

			EQUAL1142=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_columnAssignmentClause20890); if (state.failed) return retval;
			if ( state.backtracking==0 ) {
			EQUAL1142_tree = (ASTNode)adaptor.create(EQUAL1142);
			root_0 = (ASTNode)adaptor.becomeRoot(EQUAL1142_tree, root_0);
			}

			pushFollow(FOLLOW_precedencePlusExpression_in_columnAssignmentClause20893);
			precedencePlusExpression1143=precedencePlusExpression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, precedencePlusExpression1143.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnAssignmentClause"


	public static class setColumnsClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setColumnsClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3090:1: setColumnsClause : KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) ;
	public final HiveParser.setColumnsClause_return setColumnsClause() throws RecognitionException {
		HiveParser.setColumnsClause_return retval = new HiveParser.setColumnsClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET1144=null;
		Token COMMA1146=null;
		ParserRuleReturnScope columnAssignmentClause1145 =null;
		ParserRuleReturnScope columnAssignmentClause1147 =null;

		ASTNode KW_SET1144_tree=null;
		ASTNode COMMA1146_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_columnAssignmentClause=new RewriteRuleSubtreeStream(adaptor,"rule columnAssignmentClause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3091:4: ( KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3092:4: KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )*
			{
			KW_SET1144=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setColumnsClause20913); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET1144);

			pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause20915);
			columnAssignmentClause1145=columnAssignmentClause();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnAssignmentClause.add(columnAssignmentClause1145.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3092:34: ( COMMA columnAssignmentClause )*
			loop374:
			while (true) {
				int alt374=2;
				int LA374_0 = input.LA(1);
				if ( (LA374_0==COMMA) ) {
					alt374=1;
				}

				switch (alt374) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3092:35: COMMA columnAssignmentClause
					{
					COMMA1146=(Token)match(input,COMMA,FOLLOW_COMMA_in_setColumnsClause20918); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA1146);

					pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause20920);
					columnAssignmentClause1147=columnAssignmentClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnAssignmentClause.add(columnAssignmentClause1147.getTree());
					}
					break;

				default :
					break loop374;
				}
			}

			// AST REWRITE
			// elements: columnAssignmentClause
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3092:66: -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3092:69: ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_COLUMNS_CLAUSE, "TOK_SET_COLUMNS_CLAUSE"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3092:94: ( columnAssignmentClause )*
				while ( stream_columnAssignmentClause.hasNext() ) {
					adaptor.addChild(root_1, stream_columnAssignmentClause.nextTree());
				}
				stream_columnAssignmentClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setColumnsClause"


	public static class updateStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "updateStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3099:1: updateStatement : KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) ;
	public final HiveParser.updateStatement_return updateStatement() throws RecognitionException {
		HiveParser.updateStatement_return retval = new HiveParser.updateStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UPDATE1148=null;
		ParserRuleReturnScope tableName1149 =null;
		ParserRuleReturnScope setColumnsClause1150 =null;
		ParserRuleReturnScope whereClause1151 =null;

		ASTNode KW_UPDATE1148_tree=null;
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleSubtreeStream stream_setColumnsClause=new RewriteRuleSubtreeStream(adaptor,"rule setColumnsClause");
		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("update statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3102:4: ( KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3103:4: KW_UPDATE tableName setColumnsClause ( whereClause )?
			{
			KW_UPDATE1148=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_updateStatement20962); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE1148);

			pushFollow(FOLLOW_tableName_in_updateStatement20964);
			tableName1149=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName1149.getTree());
			pushFollow(FOLLOW_setColumnsClause_in_updateStatement20966);
			setColumnsClause1150=setColumnsClause();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_setColumnsClause.add(setColumnsClause1150.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3103:41: ( whereClause )?
			int alt375=2;
			int LA375_0 = input.LA(1);
			if ( (LA375_0==KW_WHERE) ) {
				alt375=1;
			}
			switch (alt375) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3103:41: whereClause
					{
					pushFollow(FOLLOW_whereClause_in_updateStatement20968);
					whereClause1151=whereClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_whereClause.add(whereClause1151.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: setColumnsClause, tableName, whereClause
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3103:54: -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3103:57: ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UPDATE_TABLE, "TOK_UPDATE_TABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				adaptor.addChild(root_1, stream_setColumnsClause.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3103:103: ( whereClause )?
				if ( stream_whereClause.hasNext() ) {
					adaptor.addChild(root_1, stream_whereClause.nextTree());
				}
				stream_whereClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "updateStatement"


	public static class sqlTransactionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "sqlTransactionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3110:1: sqlTransactionStatement : ( startTransactionStatement | commitStatement | rollbackStatement | setAutoCommitStatement );
	public final HiveParser.sqlTransactionStatement_return sqlTransactionStatement() throws RecognitionException {
		HiveParser.sqlTransactionStatement_return retval = new HiveParser.sqlTransactionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope startTransactionStatement1152 =null;
		ParserRuleReturnScope commitStatement1153 =null;
		ParserRuleReturnScope rollbackStatement1154 =null;
		ParserRuleReturnScope setAutoCommitStatement1155 =null;


		 pushMsg("transaction statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3113:3: ( startTransactionStatement | commitStatement | rollbackStatement | setAutoCommitStatement )
			int alt376=4;
			switch ( input.LA(1) ) {
			case KW_START:
				{
				alt376=1;
				}
				break;
			case KW_COMMIT:
				{
				alt376=2;
				}
				break;
			case KW_ROLLBACK:
				{
				alt376=3;
				}
				break;
			case KW_SET:
				{
				alt376=4;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 376, 0, input);
				throw nvae;
			}
			switch (alt376) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3114:3: startTransactionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_startTransactionStatement_in_sqlTransactionStatement21010);
					startTransactionStatement1152=startTransactionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, startTransactionStatement1152.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3115:4: commitStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_commitStatement_in_sqlTransactionStatement21015);
					commitStatement1153=commitStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, commitStatement1153.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3116:4: rollbackStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_rollbackStatement_in_sqlTransactionStatement21020);
					rollbackStatement1154=rollbackStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, rollbackStatement1154.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3117:4: setAutoCommitStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_setAutoCommitStatement_in_sqlTransactionStatement21025);
					setAutoCommitStatement1155=setAutoCommitStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, setAutoCommitStatement1155.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "sqlTransactionStatement"


	public static class startTransactionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "startTransactionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3120:1: startTransactionStatement : KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )? -> ^( TOK_START_TRANSACTION ( transactionMode )* ) ;
	public final HiveParser.startTransactionStatement_return startTransactionStatement() throws RecognitionException {
		HiveParser.startTransactionStatement_return retval = new HiveParser.startTransactionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_START1156=null;
		Token KW_TRANSACTION1157=null;
		Token COMMA1159=null;
		ParserRuleReturnScope transactionMode1158 =null;
		ParserRuleReturnScope transactionMode1160 =null;

		ASTNode KW_START1156_tree=null;
		ASTNode KW_TRANSACTION1157_tree=null;
		ASTNode COMMA1159_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_START=new RewriteRuleTokenStream(adaptor,"token KW_START");
		RewriteRuleTokenStream stream_KW_TRANSACTION=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTION");
		RewriteRuleSubtreeStream stream_transactionMode=new RewriteRuleSubtreeStream(adaptor,"rule transactionMode");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3121:3: ( KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )? -> ^( TOK_START_TRANSACTION ( transactionMode )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3122:3: KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )?
			{
			KW_START1156=(Token)match(input,KW_START,FOLLOW_KW_START_in_startTransactionStatement21039); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_START.add(KW_START1156);

			KW_TRANSACTION1157=(Token)match(input,KW_TRANSACTION,FOLLOW_KW_TRANSACTION_in_startTransactionStatement21041); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TRANSACTION.add(KW_TRANSACTION1157);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3122:27: ( transactionMode ( COMMA transactionMode )* )?
			int alt378=2;
			int LA378_0 = input.LA(1);
			if ( (LA378_0==KW_ISOLATION||LA378_0==KW_READ) ) {
				alt378=1;
			}
			switch (alt378) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3122:29: transactionMode ( COMMA transactionMode )*
					{
					pushFollow(FOLLOW_transactionMode_in_startTransactionStatement21045);
					transactionMode1158=transactionMode();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_transactionMode.add(transactionMode1158.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3122:46: ( COMMA transactionMode )*
					loop377:
					while (true) {
						int alt377=2;
						int LA377_0 = input.LA(1);
						if ( (LA377_0==COMMA) ) {
							alt377=1;
						}

						switch (alt377) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3122:48: COMMA transactionMode
							{
							COMMA1159=(Token)match(input,COMMA,FOLLOW_COMMA_in_startTransactionStatement21050); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA1159);

							pushFollow(FOLLOW_transactionMode_in_startTransactionStatement21052);
							transactionMode1160=transactionMode();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_transactionMode.add(transactionMode1160.getTree());
							}
							break;

						default :
							break loop377;
						}
					}

					}
					break;

			}

			// AST REWRITE
			// elements: transactionMode
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3122:77: -> ^( TOK_START_TRANSACTION ( transactionMode )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3122:80: ^( TOK_START_TRANSACTION ( transactionMode )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_START_TRANSACTION, "TOK_START_TRANSACTION"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3122:104: ( transactionMode )*
				while ( stream_transactionMode.hasNext() ) {
					adaptor.addChild(root_1, stream_transactionMode.nextTree());
				}
				stream_transactionMode.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "startTransactionStatement"


	public static class transactionMode_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "transactionMode"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3125:1: transactionMode : ( isolationLevel | transactionAccessMode -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode ) );
	public final HiveParser.transactionMode_return transactionMode() throws RecognitionException {
		HiveParser.transactionMode_return retval = new HiveParser.transactionMode_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope isolationLevel1161 =null;
		ParserRuleReturnScope transactionAccessMode1162 =null;

		RewriteRuleSubtreeStream stream_transactionAccessMode=new RewriteRuleSubtreeStream(adaptor,"rule transactionAccessMode");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3126:3: ( isolationLevel | transactionAccessMode -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode ) )
			int alt379=2;
			int LA379_0 = input.LA(1);
			if ( (LA379_0==KW_ISOLATION) ) {
				alt379=1;
			}
			else if ( (LA379_0==KW_READ) ) {
				alt379=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 379, 0, input);
				throw nvae;
			}

			switch (alt379) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3127:3: isolationLevel
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_isolationLevel_in_transactionMode21083);
					isolationLevel1161=isolationLevel();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, isolationLevel1161.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3128:5: transactionAccessMode
					{
					pushFollow(FOLLOW_transactionAccessMode_in_transactionMode21089);
					transactionAccessMode1162=transactionAccessMode();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_transactionAccessMode.add(transactionAccessMode1162.getTree());
					// AST REWRITE
					// elements: transactionAccessMode
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3128:27: -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3128:30: ^( TOK_TXN_ACCESS_MODE transactionAccessMode )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TXN_ACCESS_MODE, "TOK_TXN_ACCESS_MODE"), root_1);
						adaptor.addChild(root_1, stream_transactionAccessMode.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "transactionMode"


	public static class transactionAccessMode_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "transactionAccessMode"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3131:1: transactionAccessMode : ( KW_READ KW_ONLY -> TOK_TXN_READ_ONLY | KW_READ KW_WRITE -> TOK_TXN_READ_WRITE );
	public final HiveParser.transactionAccessMode_return transactionAccessMode() throws RecognitionException {
		HiveParser.transactionAccessMode_return retval = new HiveParser.transactionAccessMode_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_READ1163=null;
		Token KW_ONLY1164=null;
		Token KW_READ1165=null;
		Token KW_WRITE1166=null;

		ASTNode KW_READ1163_tree=null;
		ASTNode KW_ONLY1164_tree=null;
		ASTNode KW_READ1165_tree=null;
		ASTNode KW_WRITE1166_tree=null;
		RewriteRuleTokenStream stream_KW_READ=new RewriteRuleTokenStream(adaptor,"token KW_READ");
		RewriteRuleTokenStream stream_KW_ONLY=new RewriteRuleTokenStream(adaptor,"token KW_ONLY");
		RewriteRuleTokenStream stream_KW_WRITE=new RewriteRuleTokenStream(adaptor,"token KW_WRITE");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3132:3: ( KW_READ KW_ONLY -> TOK_TXN_READ_ONLY | KW_READ KW_WRITE -> TOK_TXN_READ_WRITE )
			int alt380=2;
			int LA380_0 = input.LA(1);
			if ( (LA380_0==KW_READ) ) {
				int LA380_1 = input.LA(2);
				if ( (LA380_1==KW_ONLY) ) {
					alt380=1;
				}
				else if ( (LA380_1==KW_WRITE) ) {
					alt380=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 380, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 380, 0, input);
				throw nvae;
			}

			switch (alt380) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3133:3: KW_READ KW_ONLY
					{
					KW_READ1163=(Token)match(input,KW_READ,FOLLOW_KW_READ_in_transactionAccessMode21112); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_READ.add(KW_READ1163);

					KW_ONLY1164=(Token)match(input,KW_ONLY,FOLLOW_KW_ONLY_in_transactionAccessMode21114); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ONLY.add(KW_ONLY1164);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3133:19: -> TOK_TXN_READ_ONLY
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TXN_READ_ONLY, "TOK_TXN_READ_ONLY"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3134:5: KW_READ KW_WRITE
					{
					KW_READ1165=(Token)match(input,KW_READ,FOLLOW_KW_READ_in_transactionAccessMode21124); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_READ.add(KW_READ1165);

					KW_WRITE1166=(Token)match(input,KW_WRITE,FOLLOW_KW_WRITE_in_transactionAccessMode21126); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WRITE.add(KW_WRITE1166);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3134:22: -> TOK_TXN_READ_WRITE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TXN_READ_WRITE, "TOK_TXN_READ_WRITE"));
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "transactionAccessMode"


	public static class isolationLevel_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "isolationLevel"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3137:1: isolationLevel : KW_ISOLATION KW_LEVEL levelOfIsolation -> ^( TOK_ISOLATION_LEVEL levelOfIsolation ) ;
	public final HiveParser.isolationLevel_return isolationLevel() throws RecognitionException {
		HiveParser.isolationLevel_return retval = new HiveParser.isolationLevel_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ISOLATION1167=null;
		Token KW_LEVEL1168=null;
		ParserRuleReturnScope levelOfIsolation1169 =null;

		ASTNode KW_ISOLATION1167_tree=null;
		ASTNode KW_LEVEL1168_tree=null;
		RewriteRuleTokenStream stream_KW_LEVEL=new RewriteRuleTokenStream(adaptor,"token KW_LEVEL");
		RewriteRuleTokenStream stream_KW_ISOLATION=new RewriteRuleTokenStream(adaptor,"token KW_ISOLATION");
		RewriteRuleSubtreeStream stream_levelOfIsolation=new RewriteRuleSubtreeStream(adaptor,"rule levelOfIsolation");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3138:3: ( KW_ISOLATION KW_LEVEL levelOfIsolation -> ^( TOK_ISOLATION_LEVEL levelOfIsolation ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3139:3: KW_ISOLATION KW_LEVEL levelOfIsolation
			{
			KW_ISOLATION1167=(Token)match(input,KW_ISOLATION,FOLLOW_KW_ISOLATION_in_isolationLevel21145); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ISOLATION.add(KW_ISOLATION1167);

			KW_LEVEL1168=(Token)match(input,KW_LEVEL,FOLLOW_KW_LEVEL_in_isolationLevel21147); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LEVEL.add(KW_LEVEL1168);

			pushFollow(FOLLOW_levelOfIsolation_in_isolationLevel21149);
			levelOfIsolation1169=levelOfIsolation();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_levelOfIsolation.add(levelOfIsolation1169.getTree());
			// AST REWRITE
			// elements: levelOfIsolation
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3139:42: -> ^( TOK_ISOLATION_LEVEL levelOfIsolation )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3139:45: ^( TOK_ISOLATION_LEVEL levelOfIsolation )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ISOLATION_LEVEL, "TOK_ISOLATION_LEVEL"), root_1);
				adaptor.addChild(root_1, stream_levelOfIsolation.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "isolationLevel"


	public static class levelOfIsolation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "levelOfIsolation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3143:1: levelOfIsolation : KW_SNAPSHOT -> TOK_ISOLATION_SNAPSHOT ;
	public final HiveParser.levelOfIsolation_return levelOfIsolation() throws RecognitionException {
		HiveParser.levelOfIsolation_return retval = new HiveParser.levelOfIsolation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SNAPSHOT1170=null;

		ASTNode KW_SNAPSHOT1170_tree=null;
		RewriteRuleTokenStream stream_KW_SNAPSHOT=new RewriteRuleTokenStream(adaptor,"token KW_SNAPSHOT");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3144:3: ( KW_SNAPSHOT -> TOK_ISOLATION_SNAPSHOT )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3145:3: KW_SNAPSHOT
			{
			KW_SNAPSHOT1170=(Token)match(input,KW_SNAPSHOT,FOLLOW_KW_SNAPSHOT_in_levelOfIsolation21174); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SNAPSHOT.add(KW_SNAPSHOT1170);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3145:15: -> TOK_ISOLATION_SNAPSHOT
			{
				adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_ISOLATION_SNAPSHOT, "TOK_ISOLATION_SNAPSHOT"));
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "levelOfIsolation"


	public static class commitStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "commitStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3148:1: commitStatement : KW_COMMIT ( KW_WORK )? -> TOK_COMMIT ;
	public final HiveParser.commitStatement_return commitStatement() throws RecognitionException {
		HiveParser.commitStatement_return retval = new HiveParser.commitStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_COMMIT1171=null;
		Token KW_WORK1172=null;

		ASTNode KW_COMMIT1171_tree=null;
		ASTNode KW_WORK1172_tree=null;
		RewriteRuleTokenStream stream_KW_WORK=new RewriteRuleTokenStream(adaptor,"token KW_WORK");
		RewriteRuleTokenStream stream_KW_COMMIT=new RewriteRuleTokenStream(adaptor,"token KW_COMMIT");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3149:3: ( KW_COMMIT ( KW_WORK )? -> TOK_COMMIT )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3150:3: KW_COMMIT ( KW_WORK )?
			{
			KW_COMMIT1171=(Token)match(input,KW_COMMIT,FOLLOW_KW_COMMIT_in_commitStatement21193); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COMMIT.add(KW_COMMIT1171);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3150:13: ( KW_WORK )?
			int alt381=2;
			int LA381_0 = input.LA(1);
			if ( (LA381_0==KW_WORK) ) {
				alt381=1;
			}
			switch (alt381) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3150:15: KW_WORK
					{
					KW_WORK1172=(Token)match(input,KW_WORK,FOLLOW_KW_WORK_in_commitStatement21197); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WORK.add(KW_WORK1172);

					}
					break;

			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3150:26: -> TOK_COMMIT
			{
				adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_COMMIT, "TOK_COMMIT"));
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "commitStatement"


	public static class rollbackStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rollbackStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3153:1: rollbackStatement : KW_ROLLBACK ( KW_WORK )? -> TOK_ROLLBACK ;
	public final HiveParser.rollbackStatement_return rollbackStatement() throws RecognitionException {
		HiveParser.rollbackStatement_return retval = new HiveParser.rollbackStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ROLLBACK1173=null;
		Token KW_WORK1174=null;

		ASTNode KW_ROLLBACK1173_tree=null;
		ASTNode KW_WORK1174_tree=null;
		RewriteRuleTokenStream stream_KW_ROLLBACK=new RewriteRuleTokenStream(adaptor,"token KW_ROLLBACK");
		RewriteRuleTokenStream stream_KW_WORK=new RewriteRuleTokenStream(adaptor,"token KW_WORK");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3154:3: ( KW_ROLLBACK ( KW_WORK )? -> TOK_ROLLBACK )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3155:3: KW_ROLLBACK ( KW_WORK )?
			{
			KW_ROLLBACK1173=(Token)match(input,KW_ROLLBACK,FOLLOW_KW_ROLLBACK_in_rollbackStatement21219); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLLBACK.add(KW_ROLLBACK1173);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3155:15: ( KW_WORK )?
			int alt382=2;
			int LA382_0 = input.LA(1);
			if ( (LA382_0==KW_WORK) ) {
				alt382=1;
			}
			switch (alt382) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3155:17: KW_WORK
					{
					KW_WORK1174=(Token)match(input,KW_WORK,FOLLOW_KW_WORK_in_rollbackStatement21223); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WORK.add(KW_WORK1174);

					}
					break;

			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3155:28: -> TOK_ROLLBACK
			{
				adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_ROLLBACK, "TOK_ROLLBACK"));
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rollbackStatement"


	public static class setAutoCommitStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setAutoCommitStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3157:1: setAutoCommitStatement : KW_SET KW_AUTOCOMMIT booleanValueTok -> ^( TOK_SET_AUTOCOMMIT booleanValueTok ) ;
	public final HiveParser.setAutoCommitStatement_return setAutoCommitStatement() throws RecognitionException {
		HiveParser.setAutoCommitStatement_return retval = new HiveParser.setAutoCommitStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET1175=null;
		Token KW_AUTOCOMMIT1176=null;
		ParserRuleReturnScope booleanValueTok1177 =null;

		ASTNode KW_SET1175_tree=null;
		ASTNode KW_AUTOCOMMIT1176_tree=null;
		RewriteRuleTokenStream stream_KW_AUTOCOMMIT=new RewriteRuleTokenStream(adaptor,"token KW_AUTOCOMMIT");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_booleanValueTok=new RewriteRuleSubtreeStream(adaptor,"rule booleanValueTok");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3158:3: ( KW_SET KW_AUTOCOMMIT booleanValueTok -> ^( TOK_SET_AUTOCOMMIT booleanValueTok ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3159:3: KW_SET KW_AUTOCOMMIT booleanValueTok
			{
			KW_SET1175=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setAutoCommitStatement21244); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET1175);

			KW_AUTOCOMMIT1176=(Token)match(input,KW_AUTOCOMMIT,FOLLOW_KW_AUTOCOMMIT_in_setAutoCommitStatement21246); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AUTOCOMMIT.add(KW_AUTOCOMMIT1176);

			pushFollow(FOLLOW_booleanValueTok_in_setAutoCommitStatement21248);
			booleanValueTok1177=booleanValueTok();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_booleanValueTok.add(booleanValueTok1177.getTree());
			// AST REWRITE
			// elements: booleanValueTok
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3159:40: -> ^( TOK_SET_AUTOCOMMIT booleanValueTok )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3159:43: ^( TOK_SET_AUTOCOMMIT booleanValueTok )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_AUTOCOMMIT, "TOK_SET_AUTOCOMMIT"), root_1);
				adaptor.addChild(root_1, stream_booleanValueTok.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setAutoCommitStatement"


	public static class abortTransactionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "abortTransactionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3165:1: abortTransactionStatement : KW_ABORT KW_TRANSACTIONS ( Number )+ -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ ) ;
	public final HiveParser.abortTransactionStatement_return abortTransactionStatement() throws RecognitionException {
		HiveParser.abortTransactionStatement_return retval = new HiveParser.abortTransactionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ABORT1178=null;
		Token KW_TRANSACTIONS1179=null;
		Token Number1180=null;

		ASTNode KW_ABORT1178_tree=null;
		ASTNode KW_TRANSACTIONS1179_tree=null;
		ASTNode Number1180_tree=null;
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_TRANSACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTIONS");
		RewriteRuleTokenStream stream_KW_ABORT=new RewriteRuleTokenStream(adaptor,"token KW_ABORT");

		 pushMsg("abort transactions statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3168:3: ( KW_ABORT KW_TRANSACTIONS ( Number )+ -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3169:3: KW_ABORT KW_TRANSACTIONS ( Number )+
			{
			KW_ABORT1178=(Token)match(input,KW_ABORT,FOLLOW_KW_ABORT_in_abortTransactionStatement21283); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ABORT.add(KW_ABORT1178);

			KW_TRANSACTIONS1179=(Token)match(input,KW_TRANSACTIONS,FOLLOW_KW_TRANSACTIONS_in_abortTransactionStatement21285); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TRANSACTIONS.add(KW_TRANSACTIONS1179);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3169:28: ( Number )+
			int cnt383=0;
			loop383:
			while (true) {
				int alt383=2;
				int LA383_0 = input.LA(1);
				if ( (LA383_0==Number) ) {
					alt383=1;
				}

				switch (alt383) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3169:30: Number
					{
					Number1180=(Token)match(input,Number,FOLLOW_Number_in_abortTransactionStatement21289); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(Number1180);

					}
					break;

				default :
					if ( cnt383 >= 1 ) break loop383;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(383, input);
					throw eee;
				}
				cnt383++;
			}

			// AST REWRITE
			// elements: Number
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3169:40: -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3169:43: ^( TOK_ABORT_TRANSACTIONS ( Number )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ABORT_TRANSACTIONS, "TOK_ABORT_TRANSACTIONS"), root_1);
				if ( !(stream_Number.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_Number.hasNext() ) {
					adaptor.addChild(root_1, stream_Number.nextNode());
				}
				stream_Number.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "abortTransactionStatement"


	public static class mergeStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "mergeStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3176:1: mergeStatement : KW_MERGE ( QUERY_HINT )? KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses ) ;
	public final HiveParser.mergeStatement_return mergeStatement() throws RecognitionException {
		HiveParser.mergeStatement_return retval = new HiveParser.mergeStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_MERGE1181=null;
		Token QUERY_HINT1182=null;
		Token KW_INTO1183=null;
		Token KW_AS1185=null;
		Token KW_USING1187=null;
		Token KW_ON1189=null;
		ParserRuleReturnScope tableName1184 =null;
		ParserRuleReturnScope identifier1186 =null;
		ParserRuleReturnScope joinSourcePart1188 =null;
		ParserRuleReturnScope expression1190 =null;
		ParserRuleReturnScope whenClauses1191 =null;

		ASTNode KW_MERGE1181_tree=null;
		ASTNode QUERY_HINT1182_tree=null;
		ASTNode KW_INTO1183_tree=null;
		ASTNode KW_AS1185_tree=null;
		ASTNode KW_USING1187_tree=null;
		ASTNode KW_ON1189_tree=null;
		RewriteRuleTokenStream stream_KW_MERGE=new RewriteRuleTokenStream(adaptor,"token KW_MERGE");
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_USING=new RewriteRuleTokenStream(adaptor,"token KW_USING");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_QUERY_HINT=new RewriteRuleTokenStream(adaptor,"token QUERY_HINT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_whenClauses=new RewriteRuleSubtreeStream(adaptor,"rule whenClauses");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
		RewriteRuleSubtreeStream stream_joinSourcePart=new RewriteRuleSubtreeStream(adaptor,"rule joinSourcePart");

		 pushMsg("MERGE statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3179:4: ( KW_MERGE ( QUERY_HINT )? KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3180:4: KW_MERGE ( QUERY_HINT )? KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses
			{
			KW_MERGE1181=(Token)match(input,KW_MERGE,FOLLOW_KW_MERGE_in_mergeStatement21335); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MERGE.add(KW_MERGE1181);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3180:13: ( QUERY_HINT )?
			int alt384=2;
			int LA384_0 = input.LA(1);
			if ( (LA384_0==QUERY_HINT) ) {
				alt384=1;
			}
			switch (alt384) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3180:13: QUERY_HINT
					{
					QUERY_HINT1182=(Token)match(input,QUERY_HINT,FOLLOW_QUERY_HINT_in_mergeStatement21337); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_QUERY_HINT.add(QUERY_HINT1182);

					}
					break;

			}

			KW_INTO1183=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_mergeStatement21340); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO1183);

			pushFollow(FOLLOW_tableName_in_mergeStatement21342);
			tableName1184=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName1184.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3180:43: ( ( KW_AS )? identifier )?
			int alt386=2;
			int LA386_0 = input.LA(1);
			if ( (LA386_0==Identifier||(LA386_0 >= KW_ABORT && LA386_0 <= KW_AFTER)||LA386_0==KW_ALLOC_FRACTION||LA386_0==KW_ANALYZE||LA386_0==KW_ARCHIVE||(LA386_0 >= KW_AS && LA386_0 <= KW_AT)||(LA386_0 >= KW_AUTOCOMMIT && LA386_0 <= KW_BEFORE)||(LA386_0 >= KW_BUCKET && LA386_0 <= KW_BUCKETS)||(LA386_0 >= KW_CACHE && LA386_0 <= KW_CASCADE)||(LA386_0 >= KW_CBO && LA386_0 <= KW_CHANGE)||(LA386_0 >= KW_CHECK && LA386_0 <= KW_COLLECTION)||(LA386_0 >= KW_COLUMNS && LA386_0 <= KW_COMMENT)||(LA386_0 >= KW_COMPACT && LA386_0 <= KW_CONCATENATE)||(LA386_0 >= KW_CONTINUE && LA386_0 <= KW_COST)||LA386_0==KW_CRON||LA386_0==KW_DATA||LA386_0==KW_DATABASES||(LA386_0 >= KW_DATETIME && LA386_0 <= KW_DEBUG)||(LA386_0 >= KW_DEFAULT && LA386_0 <= KW_DEFINED)||(LA386_0 >= KW_DELIMITED && LA386_0 <= KW_DESC)||(LA386_0 >= KW_DETAIL && LA386_0 <= KW_DISABLE)||(LA386_0 >= KW_DISTRIBUTE && LA386_0 <= KW_DO)||LA386_0==KW_DOW||(LA386_0 >= KW_DUMP && LA386_0 <= KW_ELEM_TYPE)||LA386_0==KW_ENABLE||(LA386_0 >= KW_ENFORCED && LA386_0 <= KW_EVERY)||(LA386_0 >= KW_EXCLUSIVE && LA386_0 <= KW_EXECUTED)||(LA386_0 >= KW_EXPLAIN && LA386_0 <= KW_EXPRESSION)||(LA386_0 >= KW_FIELDS && LA386_0 <= KW_FIRST)||(LA386_0 >= KW_FORMAT && LA386_0 <= KW_FORMATTED)||LA386_0==KW_FUNCTIONS||(LA386_0 >= KW_HOUR && LA386_0 <= KW_IDXPROPERTIES)||(LA386_0 >= KW_INDEX && LA386_0 <= KW_INDEXES)||(LA386_0 >= KW_INPATH && LA386_0 <= KW_INPUTFORMAT)||(LA386_0 >= KW_ISOLATION && LA386_0 <= KW_JAR)||(LA386_0 >= KW_JOINCOST && LA386_0 <= KW_LAST)||LA386_0==KW_LEVEL||(LA386_0 >= KW_LIMIT && LA386_0 <= KW_LOAD)||(LA386_0 >= KW_LOCATION && LA386_0 <= KW_LONG)||(LA386_0 >= KW_MANAGEDLOCATION && LA386_0 <= KW_MANAGEMENT)||(LA386_0 >= KW_MAPJOIN && LA386_0 <= KW_MATERIALIZED)||LA386_0==KW_METADATA||(LA386_0 >= KW_MINUTE && LA386_0 <= KW_MONTH)||(LA386_0 >= KW_MOVE && LA386_0 <= KW_MSCK)||(LA386_0 >= KW_NORELY && LA386_0 <= KW_NOSCAN)||LA386_0==KW_NOVALIDATE||LA386_0==KW_NULLS||LA386_0==KW_OFFSET||(LA386_0 >= KW_OPERATOR && LA386_0 <= KW_OPTION)||(LA386_0 >= KW_OUTPUTDRIVER && LA386_0 <= KW_OUTPUTFORMAT)||(LA386_0 >= KW_OVERWRITE && LA386_0 <= KW_OWNER)||(LA386_0 >= KW_PARTITIONED && LA386_0 <= KW_PATH)||(LA386_0 >= KW_PLAN && LA386_0 <= KW_POOL)||LA386_0==KW_PRINCIPALS||(LA386_0 >= KW_PURGE && LA386_0 <= KW_QUERY_PARALLELISM)||LA386_0==KW_READ||(LA386_0 >= KW_REBUILD && LA386_0 <= KW_RECORDWRITER)||(LA386_0 >= KW_RELOAD && LA386_0 <= KW_RESTRICT)||LA386_0==KW_REWRITE||(LA386_0 >= KW_ROLE && LA386_0 <= KW_ROLES)||(LA386_0 >= KW_SCHEDULED && LA386_0 <= KW_SECOND)||(LA386_0 >= KW_SEMI && LA386_0 <= KW_SERVER)||(LA386_0 >= KW_SETS && LA386_0 <= KW_SKEWED)||(LA386_0 >= KW_SNAPSHOT && LA386_0 <= KW_SSL)||(LA386_0 >= KW_STATISTICS && LA386_0 <= KW_SUMMARY)||LA386_0==KW_TABLES||(LA386_0 >= KW_TBLPROPERTIES && LA386_0 <= KW_TERMINATED)||LA386_0==KW_TINYINT||(LA386_0 >= KW_TOUCH && LA386_0 <= KW_TRANSACTIONS)||LA386_0==KW_UNARCHIVE||LA386_0==KW_UNDO||LA386_0==KW_UNIONTYPE||(LA386_0 >= KW_UNLOCK && LA386_0 <= KW_UNSIGNED)||(LA386_0 >= KW_URI && LA386_0 <= KW_USE)||(LA386_0 >= KW_UTC && LA386_0 <= KW_VALIDATE)||LA386_0==KW_VALUE_TYPE||(LA386_0 >= KW_VECTORIZATION && LA386_0 <= KW_WEEK)||LA386_0==KW_WHILE||(LA386_0 >= KW_WORK && LA386_0 <= KW_ZONE)||LA386_0==KW_BATCH||LA386_0==KW_DAYOFWEEK||LA386_0==KW_HOLD_DDLTIME||LA386_0==KW_IGNORE||LA386_0==KW_NO_DROP||LA386_0==KW_OFFLINE||LA386_0==KW_PROTECTION||LA386_0==KW_READONLY||LA386_0==KW_TIMESTAMPTZ) ) {
				alt386=1;
			}
			switch (alt386) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3180:44: ( KW_AS )? identifier
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3180:44: ( KW_AS )?
					int alt385=2;
					int LA385_0 = input.LA(1);
					if ( (LA385_0==KW_AS) ) {
						alt385=1;
					}
					switch (alt385) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:3180:44: KW_AS
							{
							KW_AS1185=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_mergeStatement21345); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS1185);

							}
							break;

					}

					pushFollow(FOLLOW_identifier_in_mergeStatement21348);
					identifier1186=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier1186.getTree());
					}
					break;

			}

			KW_USING1187=(Token)match(input,KW_USING,FOLLOW_KW_USING_in_mergeStatement21352); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_USING.add(KW_USING1187);

			pushFollow(FOLLOW_joinSourcePart_in_mergeStatement21354);
			joinSourcePart1188=joinSourcePart();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_joinSourcePart.add(joinSourcePart1188.getTree());
			KW_ON1189=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_mergeStatement21356); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON1189);

			pushFollow(FOLLOW_expression_in_mergeStatement21358);
			expression1190=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression1190.getTree());
			pushFollow(FOLLOW_whenClauses_in_mergeStatement21360);
			whenClauses1191=whenClauses();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_whenClauses.add(whenClauses1191.getTree());
			// AST REWRITE
			// elements: whenClauses, QUERY_HINT, joinSourcePart, tableName, expression, identifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3181:6: -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3181:9: ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MERGE, "TOK_MERGE"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3181:21: ^( TOK_TABREF tableName ( identifier )? )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABREF, "TOK_TABREF"), root_2);
				adaptor.addChild(root_2, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3181:44: ( identifier )?
				if ( stream_identifier.hasNext() ) {
					adaptor.addChild(root_2, stream_identifier.nextTree());
				}
				stream_identifier.reset();

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_joinSourcePart.nextTree());
				adaptor.addChild(root_1, stream_expression.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3181:83: ( QUERY_HINT )?
				if ( stream_QUERY_HINT.hasNext() ) {
					adaptor.addChild(root_1, stream_QUERY_HINT.nextNode());
				}
				stream_QUERY_HINT.reset();

				adaptor.addChild(root_1, stream_whenClauses.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "mergeStatement"


	public static class whenClauses_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenClauses"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3189:1: whenClauses : ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )? ;
	public final HiveParser.whenClauses_return whenClauses() throws RecognitionException {
		HiveParser.whenClauses_return retval = new HiveParser.whenClauses_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope whenMatchedAndClause1192 =null;
		ParserRuleReturnScope whenMatchedThenClause1193 =null;
		ParserRuleReturnScope whenNotMatchedClause1194 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3190:4: ( ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3191:4: ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )?
			{
			root_0 = (ASTNode)adaptor.nil();


			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3191:4: ( whenMatchedAndClause | whenMatchedThenClause )*
			loop387:
			while (true) {
				int alt387=3;
				int LA387_0 = input.LA(1);
				if ( (LA387_0==KW_WHEN) ) {
					int LA387_1 = input.LA(2);
					if ( (LA387_1==KW_MATCHED) ) {
						int LA387_4 = input.LA(3);
						if ( (LA387_4==KW_AND) ) {
							alt387=1;
						}
						else if ( (LA387_4==KW_THEN) ) {
							alt387=2;
						}

					}

				}

				switch (alt387) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3191:5: whenMatchedAndClause
					{
					pushFollow(FOLLOW_whenMatchedAndClause_in_whenClauses21409);
					whenMatchedAndClause1192=whenMatchedAndClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, whenMatchedAndClause1192.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3191:26: whenMatchedThenClause
					{
					pushFollow(FOLLOW_whenMatchedThenClause_in_whenClauses21411);
					whenMatchedThenClause1193=whenMatchedThenClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, whenMatchedThenClause1193.getTree());

					}
					break;

				default :
					break loop387;
				}
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3191:50: ( whenNotMatchedClause )?
			int alt388=2;
			int LA388_0 = input.LA(1);
			if ( (LA388_0==KW_WHEN) ) {
				alt388=1;
			}
			switch (alt388) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3191:50: whenNotMatchedClause
					{
					pushFollow(FOLLOW_whenNotMatchedClause_in_whenClauses21415);
					whenNotMatchedClause1194=whenNotMatchedClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, whenNotMatchedClause1194.getTree());

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenClauses"


	public static class whenNotMatchedClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenNotMatchedClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3193:1: whenNotMatchedClause : KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT (targetCols= columnParenthesesList )? KW_VALUES valueRowConstructor -> ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? ) ;
	public final HiveParser.whenNotMatchedClause_return whenNotMatchedClause() throws RecognitionException {
		HiveParser.whenNotMatchedClause_return retval = new HiveParser.whenNotMatchedClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHEN1195=null;
		Token KW_NOT1196=null;
		Token KW_MATCHED1197=null;
		Token KW_AND1198=null;
		Token KW_THEN1200=null;
		Token KW_INSERT1201=null;
		Token KW_VALUES1202=null;
		ParserRuleReturnScope targetCols =null;
		ParserRuleReturnScope expression1199 =null;
		ParserRuleReturnScope valueRowConstructor1203 =null;

		ASTNode KW_WHEN1195_tree=null;
		ASTNode KW_NOT1196_tree=null;
		ASTNode KW_MATCHED1197_tree=null;
		ASTNode KW_AND1198_tree=null;
		ASTNode KW_THEN1200_tree=null;
		ASTNode KW_INSERT1201_tree=null;
		ASTNode KW_VALUES1202_tree=null;
		RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_AND=new RewriteRuleTokenStream(adaptor,"token KW_AND");
		RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
		RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
		RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
		RewriteRuleTokenStream stream_KW_VALUES=new RewriteRuleTokenStream(adaptor,"token KW_VALUES");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_valueRowConstructor=new RewriteRuleSubtreeStream(adaptor,"rule valueRowConstructor");

		 pushMsg("WHEN NOT MATCHED clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3196:4: ( KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT (targetCols= columnParenthesesList )? KW_VALUES valueRowConstructor -> ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3197:3: KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT (targetCols= columnParenthesesList )? KW_VALUES valueRowConstructor
			{
			KW_WHEN1195=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenNotMatchedClause21442); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1195);

			KW_NOT1196=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_whenNotMatchedClause21444); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT1196);

			KW_MATCHED1197=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenNotMatchedClause21446); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1197);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3197:29: ( KW_AND expression )?
			int alt389=2;
			int LA389_0 = input.LA(1);
			if ( (LA389_0==KW_AND) ) {
				alt389=1;
			}
			switch (alt389) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3197:30: KW_AND expression
					{
					KW_AND1198=(Token)match(input,KW_AND,FOLLOW_KW_AND_in_whenNotMatchedClause21449); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_AND.add(KW_AND1198);

					pushFollow(FOLLOW_expression_in_whenNotMatchedClause21451);
					expression1199=expression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_expression.add(expression1199.getTree());
					}
					break;

			}

			KW_THEN1200=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenNotMatchedClause21455); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1200);

			KW_INSERT1201=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_whenNotMatchedClause21457); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT1201);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3197:68: (targetCols= columnParenthesesList )?
			int alt390=2;
			int LA390_0 = input.LA(1);
			if ( (LA390_0==LPAREN) ) {
				alt390=1;
			}
			switch (alt390) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3197:69: targetCols= columnParenthesesList
					{
					pushFollow(FOLLOW_columnParenthesesList_in_whenNotMatchedClause21462);
					targetCols=columnParenthesesList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnParenthesesList.add(targetCols.getTree());
					}
					break;

			}

			KW_VALUES1202=(Token)match(input,KW_VALUES,FOLLOW_KW_VALUES_in_whenNotMatchedClause21466); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VALUES.add(KW_VALUES1202);

			pushFollow(FOLLOW_valueRowConstructor_in_whenNotMatchedClause21468);
			valueRowConstructor1203=valueRowConstructor();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_valueRowConstructor.add(valueRowConstructor1203.getTree());
			// AST REWRITE
			// elements: expression, valueRowConstructor, targetCols
			// token labels: 
			// rule labels: targetCols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_targetCols=new RewriteRuleSubtreeStream(adaptor,"rule targetCols",targetCols!=null?targetCols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3197:134: -> ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3198:5: ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NOT_MATCHED, "TOK_NOT_MATCHED"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3198:23: ^( TOK_INSERT ( $targetCols)? valueRowConstructor )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3198:37: ( $targetCols)?
				if ( stream_targetCols.hasNext() ) {
					adaptor.addChild(root_2, stream_targetCols.nextTree());
				}
				stream_targetCols.reset();

				adaptor.addChild(root_2, stream_valueRowConstructor.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3198:70: ( expression )?
				if ( stream_expression.hasNext() ) {
					adaptor.addChild(root_1, stream_expression.nextTree());
				}
				stream_expression.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenNotMatchedClause"


	public static class whenMatchedAndClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenMatchedAndClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3200:1: whenMatchedAndClause : KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete expression ) ;
	public final HiveParser.whenMatchedAndClause_return whenMatchedAndClause() throws RecognitionException {
		HiveParser.whenMatchedAndClause_return retval = new HiveParser.whenMatchedAndClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHEN1204=null;
		Token KW_MATCHED1205=null;
		Token KW_AND1206=null;
		Token KW_THEN1208=null;
		ParserRuleReturnScope expression1207 =null;
		ParserRuleReturnScope updateOrDelete1209 =null;

		ASTNode KW_WHEN1204_tree=null;
		ASTNode KW_MATCHED1205_tree=null;
		ASTNode KW_AND1206_tree=null;
		ASTNode KW_THEN1208_tree=null;
		RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
		RewriteRuleTokenStream stream_KW_AND=new RewriteRuleTokenStream(adaptor,"token KW_AND");
		RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
		RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_updateOrDelete=new RewriteRuleSubtreeStream(adaptor,"rule updateOrDelete");

		 pushMsg("WHEN MATCHED AND clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3203:3: ( KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete expression ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3204:3: KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete
			{
			KW_WHEN1204=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenMatchedAndClause21515); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1204);

			KW_MATCHED1205=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenMatchedAndClause21517); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1205);

			KW_AND1206=(Token)match(input,KW_AND,FOLLOW_KW_AND_in_whenMatchedAndClause21519); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AND.add(KW_AND1206);

			pushFollow(FOLLOW_expression_in_whenMatchedAndClause21521);
			expression1207=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression1207.getTree());
			KW_THEN1208=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenMatchedAndClause21523); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1208);

			pushFollow(FOLLOW_updateOrDelete_in_whenMatchedAndClause21525);
			updateOrDelete1209=updateOrDelete();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_updateOrDelete.add(updateOrDelete1209.getTree());
			// AST REWRITE
			// elements: updateOrDelete, expression
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3204:63: -> ^( TOK_MATCHED updateOrDelete expression )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3205:5: ^( TOK_MATCHED updateOrDelete expression )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MATCHED, "TOK_MATCHED"), root_1);
				adaptor.addChild(root_1, stream_updateOrDelete.nextTree());
				adaptor.addChild(root_1, stream_expression.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenMatchedAndClause"


	public static class whenMatchedThenClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenMatchedThenClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3207:1: whenMatchedThenClause : KW_WHEN KW_MATCHED KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete ) ;
	public final HiveParser.whenMatchedThenClause_return whenMatchedThenClause() throws RecognitionException {
		HiveParser.whenMatchedThenClause_return retval = new HiveParser.whenMatchedThenClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHEN1210=null;
		Token KW_MATCHED1211=null;
		Token KW_THEN1212=null;
		ParserRuleReturnScope updateOrDelete1213 =null;

		ASTNode KW_WHEN1210_tree=null;
		ASTNode KW_MATCHED1211_tree=null;
		ASTNode KW_THEN1212_tree=null;
		RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
		RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
		RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
		RewriteRuleSubtreeStream stream_updateOrDelete=new RewriteRuleSubtreeStream(adaptor,"rule updateOrDelete");

		 pushMsg("WHEN MATCHED THEN clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3210:3: ( KW_WHEN KW_MATCHED KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3211:3: KW_WHEN KW_MATCHED KW_THEN updateOrDelete
			{
			KW_WHEN1210=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenMatchedThenClause21563); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1210);

			KW_MATCHED1211=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenMatchedThenClause21565); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1211);

			KW_THEN1212=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenMatchedThenClause21567); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1212);

			pushFollow(FOLLOW_updateOrDelete_in_whenMatchedThenClause21569);
			updateOrDelete1213=updateOrDelete();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_updateOrDelete.add(updateOrDelete1213.getTree());
			// AST REWRITE
			// elements: updateOrDelete
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3211:45: -> ^( TOK_MATCHED updateOrDelete )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3212:6: ^( TOK_MATCHED updateOrDelete )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MATCHED, "TOK_MATCHED"), root_1);
				adaptor.addChild(root_1, stream_updateOrDelete.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenMatchedThenClause"


	public static class updateOrDelete_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "updateOrDelete"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3214:1: updateOrDelete : ( KW_UPDATE setColumnsClause -> ^( TOK_UPDATE setColumnsClause ) | KW_DELETE -> TOK_DELETE );
	public final HiveParser.updateOrDelete_return updateOrDelete() throws RecognitionException {
		HiveParser.updateOrDelete_return retval = new HiveParser.updateOrDelete_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UPDATE1214=null;
		Token KW_DELETE1216=null;
		ParserRuleReturnScope setColumnsClause1215 =null;

		ASTNode KW_UPDATE1214_tree=null;
		ASTNode KW_DELETE1216_tree=null;
		RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleSubtreeStream stream_setColumnsClause=new RewriteRuleSubtreeStream(adaptor,"rule setColumnsClause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3215:4: ( KW_UPDATE setColumnsClause -> ^( TOK_UPDATE setColumnsClause ) | KW_DELETE -> TOK_DELETE )
			int alt391=2;
			int LA391_0 = input.LA(1);
			if ( (LA391_0==KW_UPDATE) ) {
				alt391=1;
			}
			else if ( (LA391_0==KW_DELETE) ) {
				alt391=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 391, 0, input);
				throw nvae;
			}

			switch (alt391) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3216:4: KW_UPDATE setColumnsClause
					{
					KW_UPDATE1214=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_updateOrDelete21598); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE1214);

					pushFollow(FOLLOW_setColumnsClause_in_updateOrDelete21600);
					setColumnsClause1215=setColumnsClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setColumnsClause.add(setColumnsClause1215.getTree());
					// AST REWRITE
					// elements: setColumnsClause
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3216:31: -> ^( TOK_UPDATE setColumnsClause )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:3216:34: ^( TOK_UPDATE setColumnsClause )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UPDATE, "TOK_UPDATE"), root_1);
						adaptor.addChild(root_1, stream_setColumnsClause.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3218:4: KW_DELETE
					{
					KW_DELETE1216=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_updateOrDelete21618); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE1216);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 3218:14: -> TOK_DELETE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DELETE, "TOK_DELETE"));
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "updateOrDelete"


	public static class killQueryStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "killQueryStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:3224:1: killQueryStatement : KW_KILL KW_QUERY ( StringLiteral )+ -> ^( TOK_KILL_QUERY ( StringLiteral )+ ) ;
	public final HiveParser.killQueryStatement_return killQueryStatement() throws RecognitionException {
		HiveParser.killQueryStatement_return retval = new HiveParser.killQueryStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_KILL1217=null;
		Token KW_QUERY1218=null;
		Token StringLiteral1219=null;

		ASTNode KW_KILL1217_tree=null;
		ASTNode KW_QUERY1218_tree=null;
		ASTNode StringLiteral1219_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_KILL=new RewriteRuleTokenStream(adaptor,"token KW_KILL");
		RewriteRuleTokenStream stream_KW_QUERY=new RewriteRuleTokenStream(adaptor,"token KW_QUERY");

		 pushMsg("kill query statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3227:3: ( KW_KILL KW_QUERY ( StringLiteral )+ -> ^( TOK_KILL_QUERY ( StringLiteral )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3228:3: KW_KILL KW_QUERY ( StringLiteral )+
			{
			KW_KILL1217=(Token)match(input,KW_KILL,FOLLOW_KW_KILL_in_killQueryStatement21650); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KILL.add(KW_KILL1217);

			KW_QUERY1218=(Token)match(input,KW_QUERY,FOLLOW_KW_QUERY_in_killQueryStatement21652); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_QUERY.add(KW_QUERY1218);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:3228:20: ( StringLiteral )+
			int cnt392=0;
			loop392:
			while (true) {
				int alt392=2;
				int LA392_0 = input.LA(1);
				if ( (LA392_0==StringLiteral) ) {
					alt392=1;
				}

				switch (alt392) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:3228:22: StringLiteral
					{
					StringLiteral1219=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_killQueryStatement21656); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral1219);

					}
					break;

				default :
					if ( cnt392 >= 1 ) break loop392;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(392, input);
					throw eee;
				}
				cnt392++;
			}

			// AST REWRITE
			// elements: StringLiteral
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 3228:39: -> ^( TOK_KILL_QUERY ( StringLiteral )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:3228:42: ^( TOK_KILL_QUERY ( StringLiteral )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_KILL_QUERY, "TOK_KILL_QUERY"), root_1);
				if ( !(stream_StringLiteral.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_StringLiteral.hasNext() ) {
					adaptor.addChild(root_1, stream_StringLiteral.nextNode());
				}
				stream_StringLiteral.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "killQueryStatement"

	// $ANTLR start synpred1_HiveParser
	public final void synpred1_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1012:7: ( grantPrivileges )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1012:8: grantPrivileges
		{
		pushFollow(FOLLOW_grantPrivileges_in_synpred1_HiveParser3043);
		grantPrivileges();
		state._fsp--;
		if (state.failed) return;

		}

	}
	// $ANTLR end synpred1_HiveParser

	// $ANTLR start synpred2_HiveParser
	public final void synpred2_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1013:7: ( revokePrivileges )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1013:8: revokePrivileges
		{
		pushFollow(FOLLOW_revokePrivileges_in_synpred2_HiveParser3057);
		revokePrivileges();
		state._fsp--;
		if (state.failed) return;

		}

	}
	// $ANTLR end synpred2_HiveParser

	// $ANTLR start synpred3_HiveParser
	public final void synpred3_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1208:7: ( alterStatementSuffixRename[true] )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1208:8: alterStatementSuffixRename[true]
		{
		pushFollow(FOLLOW_alterStatementSuffixRename_in_synpred3_HiveParser4642);
		alterStatementSuffixRename(true);
		state._fsp--;
		if (state.failed) return;

		}

	}
	// $ANTLR end synpred3_HiveParser

	// $ANTLR start synpred4_HiveParser
	public final void synpred4_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:4: ( KW_ELEM_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:5: KW_ELEM_TYPE
		{
		match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_synpred4_HiveParser7833); if (state.failed) return;

		}

	}
	// $ANTLR end synpred4_HiveParser

	// $ANTLR start synpred5_HiveParser
	public final void synpred5_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:4: ( KW_KEY_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:5: KW_KEY_TYPE
		{
		match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_synpred5_HiveParser7850); if (state.failed) return;

		}

	}
	// $ANTLR end synpred5_HiveParser

	// $ANTLR start synpred6_HiveParser
	public final void synpred6_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:4: ( KW_VALUE_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:5: KW_VALUE_TYPE
		{
		match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_synpred6_HiveParser7867); if (state.failed) return;

		}

	}
	// $ANTLR end synpred6_HiveParser

	// $ANTLR start synpred7_HiveParser
	public final void synpred7_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:5: ( KW_DATABASE | KW_SCHEMA )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred7_HiveParser

	// $ANTLR start synpred8_HiveParser
	public final void synpred8_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:5: ( KW_FUNCTION )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:6: KW_FUNCTION
		{
		match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_synpred8_HiveParser8075); if (state.failed) return;

		}

	}
	// $ANTLR end synpred8_HiveParser

	// $ANTLR start synpred9_HiveParser
	public final void synpred9_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:5: ( KW_FORMATTED | KW_EXTENDED )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_EXTENDED||input.LA(1)==KW_FORMATTED ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred9_HiveParser

	// $ANTLR start synpred10_HiveParser
	public final void synpred10_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:7: ( KW_COMPUTE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:8: KW_COMPUTE
		{
		match(input,KW_COMPUTE,FOLLOW_KW_COMPUTE_in_synpred10_HiveParser8228); if (state.failed) return;

		}

	}
	// $ANTLR end synpred10_HiveParser

	// $ANTLR start synpred11_HiveParser
	public final void synpred11_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1660:7: ( KW_CACHE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1660:8: KW_CACHE
		{
		match(input,KW_CACHE,FOLLOW_KW_CACHE_in_synpred11_HiveParser8356); if (state.failed) return;

		}

	}
	// $ANTLR end synpred11_HiveParser

	// $ANTLR start synpred12_HiveParser
	public final void synpred12_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1677:9: ( KW_DATABASE | KW_SCHEMA )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred12_HiveParser

	// $ANTLR start synpred13_HiveParser
	public final void synpred13_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:7: ( KW_DATABASE | KW_SCHEMA )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred13_HiveParser

	// $ANTLR start synpred14_HiveParser
	public final void synpred14_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1811:5: ( KW_ALL )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1811:6: KW_ALL
		{
		match(input,KW_ALL,FOLLOW_KW_ALL_in_synpred14_HiveParser9950); if (state.failed) return;

		}

	}
	// $ANTLR end synpred14_HiveParser

	// $ANTLR start synpred15_HiveParser
	public final void synpred15_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1813:5: ( KW_NONE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1813:6: KW_NONE
		{
		match(input,KW_NONE,FOLLOW_KW_NONE_in_synpred15_HiveParser9981); if (state.failed) return;

		}

	}
	// $ANTLR end synpred15_HiveParser

	// $ANTLR start synpred16_HiveParser
	public final void synpred16_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1837:7: ( KW_ALL )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1837:8: KW_ALL
		{
		match(input,KW_ALL,FOLLOW_KW_ALL_in_synpred16_HiveParser10155); if (state.failed) return;

		}

	}
	// $ANTLR end synpred16_HiveParser

	// $ANTLR start synpred17_HiveParser
	public final void synpred17_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:117: ( storedAsDirs )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:118: storedAsDirs
		{
		pushFollow(FOLLOW_storedAsDirs_in_synpred17_HiveParser13421);
		storedAsDirs();
		state._fsp--;
		if (state.failed) return;

		}

	}
	// $ANTLR end synpred17_HiveParser

	// $ANTLR start synpred18_HiveParser
	public final void synpred18_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2355:7: ( KW_STORED KW_AS KW_INPUTFORMAT )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2355:8: KW_STORED KW_AS KW_INPUTFORMAT
		{
		match(input,KW_STORED,FOLLOW_KW_STORED_in_synpred18_HiveParser14402); if (state.failed) return;

		match(input,KW_AS,FOLLOW_KW_AS_in_synpred18_HiveParser14404); if (state.failed) return;

		match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_synpred18_HiveParser14406); if (state.failed) return;

		}

	}
	// $ANTLR end synpred18_HiveParser

	// $ANTLR start synpred19_HiveParser
	public final void synpred19_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:25: ( KW_ELEM_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:26: KW_ELEM_TYPE
		{
		match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_synpred19_HiveParser14844); if (state.failed) return;

		}

	}
	// $ANTLR end synpred19_HiveParser

	// $ANTLR start synpred20_HiveParser
	public final void synpred20_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:58: ( KW_KEY_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:59: KW_KEY_TYPE
		{
		match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_synpred20_HiveParser14854); if (state.failed) return;

		}

	}
	// $ANTLR end synpred20_HiveParser

	// $ANTLR start synpred21_HiveParser
	public final void synpred21_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:89: ( KW_VALUE_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:90: KW_VALUE_TYPE
		{
		match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_synpred21_HiveParser14864); if (state.failed) return;

		}

	}
	// $ANTLR end synpred21_HiveParser

	// Delegated rules
	public HiveParser_FromClauseParser.partitionTableFunctionSource_return partitionTableFunctionSource() throws RecognitionException { return gFromClauseParser.partitionTableFunctionSource(); }

	public HiveParser_FromClauseParser.joinSourcePart_return joinSourcePart() throws RecognitionException { return gFromClauseParser.joinSourcePart(); }

	public HiveParser_ResourcePlanParser.createResourcePlanStatement_return createResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.createResourcePlanStatement(); }

	public HiveParser_ResourcePlanParser.alterResourcePlanStatement_return alterResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.alterResourcePlanStatement(); }

	public HiveParser_SelectClauseParser.window_specification_return window_specification() throws RecognitionException { return gSelectClauseParser.window_specification(); }

	public HiveParser_ResourcePlanParser.rpUnassignList_return rpUnassignList() throws RecognitionException { return gResourcePlanParser.rpUnassignList(); }

	public HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier() throws RecognitionException { return gIdentifiersParser.functionIdentifier(); }

	public HiveParser_SelectClauseParser.window_range_expression_return window_range_expression() throws RecognitionException { return gSelectClauseParser.window_range_expression(); }

	public HiveParser_IdentifiersParser.identifier_return identifier() throws RecognitionException { return gIdentifiersParser.identifier(); }

	public HiveParser_ResourcePlanParser.dropResourcePlanStatement_return dropResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.dropResourcePlanStatement(); }

	public HiveParser_IdentifiersParser.groupByEmpty_return groupByEmpty() throws RecognitionException { return gIdentifiersParser.groupByEmpty(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseXorExpression_return precedenceBitwiseXorExpression() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseXorExpression(); }

	public HiveParser_IdentifiersParser.precedenceNotOperator_return precedenceNotOperator() throws RecognitionException { return gIdentifiersParser.precedenceNotOperator(); }

	public HiveParser_ResourcePlanParser.alterPoolStatement_return alterPoolStatement() throws RecognitionException { return gResourcePlanParser.alterPoolStatement(); }

	public HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition() throws RecognitionException { return gIdentifiersParser.tableOrPartition(); }

	public HiveParser_ResourcePlanParser.dropPoolStatement_return dropPoolStatement() throws RecognitionException { return gResourcePlanParser.dropPoolStatement(); }

	public HiveParser_FromClauseParser.valuesClause_return valuesClause() throws RecognitionException { return gFromClauseParser.valuesClause(); }

	public HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier() throws RecognitionException { return gIdentifiersParser.principalIdentifier(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionMain_return precedenceSimilarExpressionMain() throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionMain(); }

	public HiveParser_FromClauseParser.atomjoinSource_return atomjoinSource() throws RecognitionException { return gFromClauseParser.atomjoinSource(); }

	public HiveParser_IdentifiersParser.extractExpression_return extractExpression() throws RecognitionException { return gIdentifiersParser.extractExpression(); }

	public HiveParser_IdentifiersParser.rollupStandard_return rollupStandard() throws RecognitionException { return gIdentifiersParser.rollupStandard(); }

	public HiveParser_IdentifiersParser.orderByClause_return orderByClause() throws RecognitionException { return gIdentifiersParser.orderByClause(); }

	public HiveParser_IdentifiersParser.partitionVal_return partitionVal() throws RecognitionException { return gIdentifiersParser.partitionVal(); }

	public HiveParser_ResourcePlanParser.disable_return disable() throws RecognitionException { return gResourcePlanParser.disable(); }

	public HiveParser_IdentifiersParser.precedenceEqualExpression_return precedenceEqualExpression() throws RecognitionException { return gIdentifiersParser.precedenceEqualExpression(); }

	public HiveParser_SelectClauseParser.window_frame_boundary_return window_frame_boundary() throws RecognitionException { return gSelectClauseParser.window_frame_boundary(); }

	public HiveParser_FromClauseParser.virtualTableSource_return virtualTableSource() throws RecognitionException { return gFromClauseParser.virtualTableSource(); }

	public HiveParser_ResourcePlanParser.dropMappingStatement_return dropMappingStatement() throws RecognitionException { return gResourcePlanParser.dropMappingStatement(); }

	public HiveParser_IdentifiersParser.whenExpression_return whenExpression() throws RecognitionException { return gIdentifiersParser.whenExpression(); }

	public HiveParser_IdentifiersParser.dropPartitionVal_return dropPartitionVal() throws RecognitionException { return gIdentifiersParser.dropPartitionVal(); }

	public HiveParser_ResourcePlanParser.createTriggerStatement_return createTriggerStatement() throws RecognitionException { return gResourcePlanParser.createTriggerStatement(); }

	public HiveParser_IdentifiersParser.sysFuncNames_return sysFuncNames() throws RecognitionException { return gIdentifiersParser.sysFuncNames(); }

	public HiveParser_ResourcePlanParser.createMappingStatement_return createMappingStatement() throws RecognitionException { return gResourcePlanParser.createMappingStatement(); }

	public HiveParser_ResourcePlanParser.triggerExpressionStandalone_return triggerExpressionStandalone() throws RecognitionException { return gResourcePlanParser.triggerExpressionStandalone(); }

	public HiveParser_IdentifiersParser.groupby_expression_return groupby_expression() throws RecognitionException { return gIdentifiersParser.groupby_expression(); }

	public HiveParser_SelectClauseParser.window_frame_start_boundary_return window_frame_start_boundary() throws RecognitionException { return gSelectClauseParser.window_frame_start_boundary(); }

	public HiveParser_IdentifiersParser.functionName_return functionName() throws RecognitionException { return gIdentifiersParser.functionName(); }

	public HiveParser_IdentifiersParser.precedenceAndExpression_return precedenceAndExpression() throws RecognitionException { return gIdentifiersParser.precedenceAndExpression(); }

	public HiveParser_IdentifiersParser.precedenceRegexpOperator_return precedenceRegexpOperator() throws RecognitionException { return gIdentifiersParser.precedenceRegexpOperator(); }

	public HiveParser_ResourcePlanParser.poolAssign_return poolAssign() throws RecognitionException { return gResourcePlanParser.poolAssign(); }

	public HiveParser_IdentifiersParser.charSetStringLiteral_return charSetStringLiteral() throws RecognitionException { return gIdentifiersParser.charSetStringLiteral(); }

	public HiveParser_IdentifiersParser.function_return function() throws RecognitionException { return gIdentifiersParser.function(); }

	public HiveParser_IdentifiersParser.precedenceConcatenateExpression_return precedenceConcatenateExpression() throws RecognitionException { return gIdentifiersParser.precedenceConcatenateExpression(); }

	public HiveParser_FromClauseParser.uniqueJoinToken_return uniqueJoinToken() throws RecognitionException { return gFromClauseParser.uniqueJoinToken(); }

	public HiveParser_ResourcePlanParser.activate_return activate() throws RecognitionException { return gResourcePlanParser.activate(); }

	public HiveParser_FromClauseParser.splitSample_return splitSample() throws RecognitionException { return gFromClauseParser.splitSample(); }

	public HiveParser_FromClauseParser.fromClause_return fromClause() throws RecognitionException { return gFromClauseParser.fromClause(); }

	public HiveParser_FromClauseParser.uniqueJoinExpr_return uniqueJoinExpr() throws RecognitionException { return gFromClauseParser.uniqueJoinExpr(); }

	public HiveParser_FromClauseParser.valueRowConstructor_return valueRowConstructor() throws RecognitionException { return gFromClauseParser.valueRowConstructor(); }

	public HiveParser_IdentifiersParser.sql11ReservedKeywordsUsedAsFunctionName_return sql11ReservedKeywordsUsedAsFunctionName() throws RecognitionException { return gIdentifiersParser.sql11ReservedKeywordsUsedAsFunctionName(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionIn_return precedenceSimilarExpressionIn(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionIn(t); }

	public HiveParser_IdentifiersParser.precedenceAmpersandOperator_return precedenceAmpersandOperator() throws RecognitionException { return gIdentifiersParser.precedenceAmpersandOperator(); }

	public HiveParser_ResourcePlanParser.withReplace_return withReplace() throws RecognitionException { return gResourcePlanParser.withReplace(); }

	public HiveParser_FromClauseParser.valuesTableConstructor_return valuesTableConstructor() throws RecognitionException { return gFromClauseParser.valuesTableConstructor(); }

	public HiveParser_IdentifiersParser.expressions_return expressions() throws RecognitionException { return gIdentifiersParser.expressions(); }

	public HiveParser_IdentifiersParser.havingClause_return havingClause() throws RecognitionException { return gIdentifiersParser.havingClause(); }

	public HiveParser_FromClauseParser.tableOrColumn_return tableOrColumn() throws RecognitionException { return gFromClauseParser.tableOrColumn(); }

	public HiveParser_ResourcePlanParser.globalWmStatement_return globalWmStatement() throws RecognitionException { return gResourcePlanParser.globalWmStatement(); }

	public HiveParser_ResourcePlanParser.poolAssignList_return poolAssignList() throws RecognitionException { return gResourcePlanParser.poolAssignList(); }

	public HiveParser_IdentifiersParser.floorDateQualifiers_return floorDateQualifiers() throws RecognitionException { return gIdentifiersParser.floorDateQualifiers(); }

	public HiveParser_IdentifiersParser.precedenceNotExpression_return precedenceNotExpression() throws RecognitionException { return gIdentifiersParser.precedenceNotExpression(); }

	public HiveParser_IdentifiersParser.precedenceAmpersandExpression_return precedenceAmpersandExpression() throws RecognitionException { return gIdentifiersParser.precedenceAmpersandExpression(); }

	public HiveParser_ResourcePlanParser.triggerAtomExpression_return triggerAtomExpression() throws RecognitionException { return gResourcePlanParser.triggerAtomExpression(); }

	public HiveParser_IdentifiersParser.havingCondition_return havingCondition() throws RecognitionException { return gIdentifiersParser.havingCondition(); }

	public HiveParser_SelectClauseParser.window_clause_return window_clause() throws RecognitionException { return gSelectClauseParser.window_clause(); }

	public HiveParser_ResourcePlanParser.replaceResourcePlanStatement_return replaceResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.replaceResourcePlanStatement(); }

	public HiveParser_IdentifiersParser.rollupOldSyntax_return rollupOldSyntax() throws RecognitionException { return gIdentifiersParser.rollupOldSyntax(); }

	public HiveParser_FromClauseParser.viewName_return viewName() throws RecognitionException { return gFromClauseParser.viewName(); }

	public HiveParser_ResourcePlanParser.createPoolStatement_return createPoolStatement() throws RecognitionException { return gResourcePlanParser.createPoolStatement(); }

	public HiveParser_IdentifiersParser.booleanValue_return booleanValue() throws RecognitionException { return gIdentifiersParser.booleanValue(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionAtom_return precedenceSimilarExpressionAtom(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionAtom(t); }

	public HiveParser_IdentifiersParser.partitionSpec_return partitionSpec() throws RecognitionException { return gIdentifiersParser.partitionSpec(); }

	public HiveParser_IdentifiersParser.dateLiteral_return dateLiteral() throws RecognitionException { return gIdentifiersParser.dateLiteral(); }

	public HiveParser_IdentifiersParser.expressionsNotInParenthesis_return expressionsNotInParenthesis(boolean isStruct, boolean forceStruct) throws RecognitionException { return gIdentifiersParser.expressionsNotInParenthesis(isStruct, forceStruct); }

	public HiveParser_FromClauseParser.fromSource_return fromSource() throws RecognitionException { return gFromClauseParser.fromSource(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseOrExpression_return precedenceBitwiseOrExpression() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseOrExpression(); }

	public HiveParser_FromClauseParser.expressionList_return expressionList() throws RecognitionException { return gFromClauseParser.expressionList(); }

	public HiveParser_IdentifiersParser.expression_return expression() throws RecognitionException { return gIdentifiersParser.expression(); }

	public HiveParser_ResourcePlanParser.rpAssignList_return rpAssignList() throws RecognitionException { return gResourcePlanParser.rpAssignList(); }

	public HiveParser_IdentifiersParser.precedenceFieldExpression_return precedenceFieldExpression() throws RecognitionException { return gIdentifiersParser.precedenceFieldExpression(); }

	public HiveParser_IdentifiersParser.partitionByClause_return partitionByClause() throws RecognitionException { return gIdentifiersParser.partitionByClause(); }

	public HiveParser_IdentifiersParser.precedenceOrExpression_return precedenceOrExpression() throws RecognitionException { return gIdentifiersParser.precedenceOrExpression(); }

	public HiveParser_SelectClauseParser.window_frame_return window_frame() throws RecognitionException { return gSelectClauseParser.window_frame(); }

	public HiveParser_IdentifiersParser.expressionsInParenthesis_return expressionsInParenthesis(boolean isStruct, boolean forceStruct) throws RecognitionException { return gIdentifiersParser.expressionsInParenthesis(isStruct, forceStruct); }

	public HiveParser_ResourcePlanParser.triggerOrExpression_return triggerOrExpression() throws RecognitionException { return gResourcePlanParser.triggerOrExpression(); }

	public HiveParser_ResourcePlanParser.poolPath_return poolPath() throws RecognitionException { return gResourcePlanParser.poolPath(); }

	public HiveParser_ResourcePlanParser.rpUnassign_return rpUnassign() throws RecognitionException { return gResourcePlanParser.rpUnassign(); }

	public HiveParser_SelectClauseParser.window_value_expression_return window_value_expression() throws RecognitionException { return gSelectClauseParser.window_value_expression(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpression_return precedenceSimilarExpression() throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpression(); }

	public HiveParser_IdentifiersParser.distributeByClause_return distributeByClause() throws RecognitionException { return gIdentifiersParser.distributeByClause(); }

	public HiveParser_IdentifiersParser.timeQualifiers_return timeQualifiers() throws RecognitionException { return gIdentifiersParser.timeQualifiers(); }

	public HiveParser_SelectClauseParser.window_defn_return window_defn() throws RecognitionException { return gSelectClauseParser.window_defn(); }

	public HiveParser_IdentifiersParser.clusterByClause_return clusterByClause() throws RecognitionException { return gIdentifiersParser.clusterByClause(); }

	public HiveParser_IdentifiersParser.groupingSetExpressionMultiple_return groupingSetExpressionMultiple() throws RecognitionException { return gIdentifiersParser.groupingSetExpressionMultiple(); }

	public HiveParser_IdentifiersParser.precedenceEqualOperator_return precedenceEqualOperator() throws RecognitionException { return gIdentifiersParser.precedenceEqualOperator(); }

	public HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec() throws RecognitionException { return gIdentifiersParser.dropPartitionSpec(); }

	public HiveParser_FromClauseParser.uniqueJoinSource_return uniqueJoinSource() throws RecognitionException { return gFromClauseParser.uniqueJoinSource(); }

	public HiveParser_IdentifiersParser.columnRefOrderNotInParenthesis_return columnRefOrderNotInParenthesis() throws RecognitionException { return gIdentifiersParser.columnRefOrderNotInParenthesis(); }

	public HiveParser_IdentifiersParser.dropPartitionOperator_return dropPartitionOperator() throws RecognitionException { return gIdentifiersParser.dropPartitionOperator(); }

	public HiveParser_IdentifiersParser.groupingSetExpression_return groupingSetExpression() throws RecognitionException { return gIdentifiersParser.groupingSetExpression(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseXorOperator_return precedenceBitwiseXorOperator() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseXorOperator(); }

	public HiveParser_IdentifiersParser.columnRefOrderInParenthesis_return columnRefOrderInParenthesis() throws RecognitionException { return gIdentifiersParser.columnRefOrderInParenthesis(); }

	public HiveParser_IdentifiersParser.intervalExpression_return intervalExpression() throws RecognitionException { return gIdentifiersParser.intervalExpression(); }

	public HiveParser_FromClauseParser.joinSource_return joinSource() throws RecognitionException { return gFromClauseParser.joinSource(); }

	public HiveParser_ResourcePlanParser.unmanaged_return unmanaged() throws RecognitionException { return gResourcePlanParser.unmanaged(); }

	public HiveParser_IdentifiersParser.precedenceStarExpression_return precedenceStarExpression() throws RecognitionException { return gIdentifiersParser.precedenceStarExpression(); }

	public HiveParser_ResourcePlanParser.triggerLiteral_return triggerLiteral() throws RecognitionException { return gResourcePlanParser.triggerLiteral(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionPart_return precedenceSimilarExpressionPart(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionPart(t); }

	public HiveParser_FromClauseParser.aliasList_return aliasList() throws RecognitionException { return gFromClauseParser.aliasList(); }

	public HiveParser_FromClauseParser.tableName_return tableName() throws RecognitionException { return gFromClauseParser.tableName(); }

	public HiveParser_ResourcePlanParser.triggerActionExpression_return triggerActionExpression() throws RecognitionException { return gResourcePlanParser.triggerActionExpression(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionPartNot_return precedenceSimilarExpressionPartNot(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionPartNot(t); }

	public HiveParser_IdentifiersParser.atomExpression_return atomExpression() throws RecognitionException { return gIdentifiersParser.atomExpression(); }

	public HiveParser_FromClauseParser.partitionedTableFunction_return partitionedTableFunction() throws RecognitionException { return gFromClauseParser.partitionedTableFunction(); }

	public HiveParser_IdentifiersParser.caseExpression_return caseExpression() throws RecognitionException { return gIdentifiersParser.caseExpression(); }

	public HiveParser_IdentifiersParser.precedenceUnaryOperator_return precedenceUnaryOperator() throws RecognitionException { return gIdentifiersParser.precedenceUnaryOperator(); }

	public HiveParser_IdentifiersParser.floorExpression_return floorExpression() throws RecognitionException { return gIdentifiersParser.floorExpression(); }

	public HiveParser_ResourcePlanParser.triggerAndExpression_return triggerAndExpression() throws RecognitionException { return gResourcePlanParser.triggerAndExpression(); }

	public HiveParser_IdentifiersParser.timestampLiteral_return timestampLiteral() throws RecognitionException { return gIdentifiersParser.timestampLiteral(); }

	public HiveParser_IdentifiersParser.precedenceAndOperator_return precedenceAndOperator() throws RecognitionException { return gIdentifiersParser.precedenceAndOperator(); }

	public HiveParser_FromClauseParser.tableSource_return tableSource() throws RecognitionException { return gFromClauseParser.tableSource(); }

	public HiveParser_IdentifiersParser.constant_return constant() throws RecognitionException { return gIdentifiersParser.constant(); }

	public HiveParser_IdentifiersParser.descFuncNames_return descFuncNames() throws RecognitionException { return gIdentifiersParser.descFuncNames(); }

	public HiveParser_SelectClauseParser.trfmClause_return trfmClause() throws RecognitionException { return gSelectClauseParser.trfmClause(); }

	public HiveParser_FromClauseParser.tableAllColumns_return tableAllColumns() throws RecognitionException { return gFromClauseParser.tableAllColumns(); }

	public HiveParser_FromClauseParser.subQuerySource_return subQuerySource() throws RecognitionException { return gFromClauseParser.subQuerySource(); }

	public HiveParser_IdentifiersParser.precedencePlusExpression_return precedencePlusExpression() throws RecognitionException { return gIdentifiersParser.precedencePlusExpression(); }

	public HiveParser_FromClauseParser.partitioningSpec_return partitioningSpec() throws RecognitionException { return gFromClauseParser.partitioningSpec(); }

	public HiveParser_FromClauseParser.whereClause_return whereClause() throws RecognitionException { return gFromClauseParser.whereClause(); }

	public HiveParser_ResourcePlanParser.triggerActionExpressionStandalone_return triggerActionExpressionStandalone() throws RecognitionException { return gResourcePlanParser.triggerActionExpressionStandalone(); }

	public HiveParser_ResourcePlanParser.triggerExpression_return triggerExpression() throws RecognitionException { return gResourcePlanParser.triggerExpression(); }

	public HiveParser_ResourcePlanParser.rpAssign_return rpAssign() throws RecognitionException { return gResourcePlanParser.rpAssign(); }

	public HiveParser_IdentifiersParser.precedenceSimilarOperator_return precedenceSimilarOperator() throws RecognitionException { return gIdentifiersParser.precedenceSimilarOperator(); }

	public HiveParser_IdentifiersParser.stringLiteralSequence_return stringLiteralSequence() throws RecognitionException { return gIdentifiersParser.stringLiteralSequence(); }

	public HiveParser_IdentifiersParser.precedenceOrOperator_return precedenceOrOperator() throws RecognitionException { return gIdentifiersParser.precedenceOrOperator(); }

	public HiveParser_IdentifiersParser.intervalQualifiers_return intervalQualifiers() throws RecognitionException { return gIdentifiersParser.intervalQualifiers(); }

	public HiveParser_IdentifiersParser.timestampLocalTZLiteral_return timestampLocalTZLiteral() throws RecognitionException { return gIdentifiersParser.timestampLocalTZLiteral(); }

	public HiveParser_FromClauseParser.tableSample_return tableSample() throws RecognitionException { return gFromClauseParser.tableSample(); }

	public HiveParser_IdentifiersParser.precedenceDistinctOperator_return precedenceDistinctOperator() throws RecognitionException { return gIdentifiersParser.precedenceDistinctOperator(); }

	public HiveParser_IdentifiersParser.intervalLiteral_return intervalLiteral() throws RecognitionException { return gIdentifiersParser.intervalLiteral(); }

	public HiveParser_SelectClauseParser.selectClause_return selectClause() throws RecognitionException { return gSelectClauseParser.selectClause(); }

	public HiveParser_ResourcePlanParser.alterMappingStatement_return alterMappingStatement() throws RecognitionException { return gResourcePlanParser.alterMappingStatement(); }

	public HiveParser_ResourcePlanParser.alterTriggerStatement_return alterTriggerStatement() throws RecognitionException { return gResourcePlanParser.alterTriggerStatement(); }

	public HiveParser_ResourcePlanParser.resourcePlanDdlStatements_return resourcePlanDdlStatements() throws RecognitionException { return gResourcePlanParser.resourcePlanDdlStatements(); }

	public HiveParser_IdentifiersParser.intervalValue_return intervalValue() throws RecognitionException { return gIdentifiersParser.intervalValue(); }

	public HiveParser_IdentifiersParser.isCondition_return isCondition() throws RecognitionException { return gIdentifiersParser.isCondition(); }

	public HiveParser_SelectClauseParser.selectList_return selectList() throws RecognitionException { return gSelectClauseParser.selectList(); }

	public HiveParser_SelectClauseParser.selectExpression_return selectExpression() throws RecognitionException { return gSelectClauseParser.selectExpression(); }

	public HiveParser_IdentifiersParser.castExpression_return castExpression() throws RecognitionException { return gIdentifiersParser.castExpression(); }

	public HiveParser_IdentifiersParser.precedenceConcatenateOperator_return precedenceConcatenateOperator() throws RecognitionException { return gIdentifiersParser.precedenceConcatenateOperator(); }

	public HiveParser_FromClauseParser.uniqueJoinTableSource_return uniqueJoinTableSource() throws RecognitionException { return gFromClauseParser.uniqueJoinTableSource(); }

	public HiveParser_ResourcePlanParser.enable_return enable() throws RecognitionException { return gResourcePlanParser.enable(); }

	public HiveParser_IdentifiersParser.nonReserved_return nonReserved() throws RecognitionException { return gIdentifiersParser.nonReserved(); }

	public HiveParser_ResourcePlanParser.dropTriggerStatement_return dropTriggerStatement() throws RecognitionException { return gResourcePlanParser.dropTriggerStatement(); }

	public HiveParser_FromClauseParser.searchCondition_return searchCondition() throws RecognitionException { return gFromClauseParser.searchCondition(); }

	public HiveParser_SelectClauseParser.selectExpressionList_return selectExpressionList() throws RecognitionException { return gSelectClauseParser.selectExpressionList(); }

	public HiveParser_IdentifiersParser.sortByClause_return sortByClause() throws RecognitionException { return gIdentifiersParser.sortByClause(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseOrOperator_return precedenceBitwiseOrOperator() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseOrOperator(); }

	public HiveParser_IdentifiersParser.subQueryExpression_return subQueryExpression() throws RecognitionException { return gIdentifiersParser.subQueryExpression(); }

	public HiveParser_SelectClauseParser.selectTrfmClause_return selectTrfmClause() throws RecognitionException { return gSelectClauseParser.selectTrfmClause(); }

	public HiveParser_SelectClauseParser.selectItem_return selectItem() throws RecognitionException { return gSelectClauseParser.selectItem(); }

	public HiveParser_IdentifiersParser.groupingExpressionSingle_return groupingExpressionSingle() throws RecognitionException { return gIdentifiersParser.groupingExpressionSingle(); }

	public HiveParser_FromClauseParser.lateralView_return lateralView() throws RecognitionException { return gFromClauseParser.lateralView(); }

	public HiveParser_ResourcePlanParser.comparisionOperator_return comparisionOperator() throws RecognitionException { return gResourcePlanParser.comparisionOperator(); }

	public HiveParser_IdentifiersParser.expressionPart_return expressionPart(CommonTree t, boolean isStruct) throws RecognitionException { return gIdentifiersParser.expressionPart(t, isStruct); }

	public HiveParser_FromClauseParser.joinToken_return joinToken() throws RecognitionException { return gFromClauseParser.joinToken(); }

	public HiveParser_IdentifiersParser.precedenceStarOperator_return precedenceStarOperator() throws RecognitionException { return gIdentifiersParser.precedenceStarOperator(); }

	public HiveParser_IdentifiersParser.booleanValueTok_return booleanValueTok() throws RecognitionException { return gIdentifiersParser.booleanValueTok(); }

	public HiveParser_IdentifiersParser.groupByClause_return groupByClause() throws RecognitionException { return gIdentifiersParser.groupByClause(); }

	public HiveParser_IdentifiersParser.precedencePlusOperator_return precedencePlusOperator() throws RecognitionException { return gIdentifiersParser.precedencePlusOperator(); }

	public HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression_return precedenceUnaryPrefixExpression() throws RecognitionException { return gIdentifiersParser.precedenceUnaryPrefixExpression(); }

	public HiveParser_FromClauseParser.tableBucketSample_return tableBucketSample() throws RecognitionException { return gFromClauseParser.tableBucketSample(); }

	public HiveParser_IdentifiersParser.precedenceUnarySuffixExpression_return precedenceUnarySuffixExpression() throws RecognitionException { return gIdentifiersParser.precedenceUnarySuffixExpression(); }

	public HiveParser_FromClauseParser.tableAlias_return tableAlias() throws RecognitionException { return gFromClauseParser.tableAlias(); }

	public final boolean synpred18_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred18_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred21_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred21_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred7_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred7_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred11_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred11_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred15_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred15_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred13_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred13_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred10_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred10_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred8_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred8_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred4_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred4_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred2_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred2_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred6_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred6_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred19_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred19_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred14_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred14_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred17_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred17_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred20_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred20_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred12_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred12_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred3_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred3_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred9_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred9_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred16_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred16_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred5_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred5_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred1_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred1_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}


	protected DFA2 dfa2 = new DFA2(this);
	protected DFA29 dfa29 = new DFA29(this);
	protected DFA246 dfa246 = new DFA246(this);
	static final String DFA2_eotS =
		"\142\uffff";
	static final String DFA2_eofS =
		"\142\uffff";
	static final String DFA2_minS =
		"\1\32\25\uffff\1\32\113\uffff";
	static final String DFA2_maxS =
		"\1\u0177\25\uffff\1\u0177\113\uffff";
	static final String DFA2_acceptS =
		"\1\uffff\1\2\45\uffff\1\1\72\uffff";
	static final String DFA2_specialS =
		"\142\uffff}>";
	static final String[] DFA2_transitionS = {
			"\1\1\7\uffff\1\1\1\26\10\uffff\1\47\16\uffff\1\47\12\uffff\1\1\10\uffff"+
			"\1\1\16\uffff\1\47\4\uffff\1\1\1\uffff\1\47\2\1\3\uffff\1\1\6\uffff\1"+
			"\1\3\uffff\1\1\13\uffff\1\1\1\uffff\1\47\17\uffff\1\47\1\1\3\uffff\1"+
			"\1\6\uffff\1\1\7\uffff\1\1\15\uffff\1\1\10\uffff\1\1\2\uffff\1\1\2\47"+
			"\4\uffff\1\1\4\uffff\1\1\6\uffff\1\1\57\uffff\1\1\2\uffff\1\1\2\uffff"+
			"\1\47\1\uffff\2\1\3\uffff\1\1\5\uffff\1\1\10\uffff\1\1\4\uffff\1\1\2"+
			"\uffff\1\1\7\uffff\1\1\33\uffff\1\1\7\uffff\1\1\3\uffff\1\1\1\uffff\1"+
			"\1\10\uffff\1\47\10\uffff\1\1\11\uffff\1\1",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\47\7\uffff\2\47\10\uffff\1\47\16\uffff\1\47\12\uffff\1\47\10\uffff"+
			"\1\47\16\uffff\1\47\4\uffff\1\47\1\uffff\3\47\3\uffff\1\47\6\uffff\1"+
			"\47\3\uffff\1\47\13\uffff\1\47\1\uffff\1\47\17\uffff\2\47\3\uffff\1\47"+
			"\6\uffff\1\47\7\uffff\1\47\15\uffff\1\47\10\uffff\1\47\2\uffff\3\47\4"+
			"\uffff\1\47\4\uffff\1\47\6\uffff\1\47\57\uffff\1\47\2\uffff\1\47\2\uffff"+
			"\1\47\1\uffff\2\47\3\uffff\1\47\5\uffff\1\47\10\uffff\1\47\4\uffff\1"+
			"\47\2\uffff\1\47\7\uffff\1\47\10\uffff\1\1\22\uffff\1\47\7\uffff\1\47"+
			"\3\uffff\1\47\1\uffff\1\47\10\uffff\1\47\10\uffff\1\47\11\uffff\1\47",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			""
	};

	static final short[] DFA2_eot = DFA.unpackEncodedString(DFA2_eotS);
	static final short[] DFA2_eof = DFA.unpackEncodedString(DFA2_eofS);
	static final char[] DFA2_min = DFA.unpackEncodedStringToUnsignedChars(DFA2_minS);
	static final char[] DFA2_max = DFA.unpackEncodedStringToUnsignedChars(DFA2_maxS);
	static final short[] DFA2_accept = DFA.unpackEncodedString(DFA2_acceptS);
	static final short[] DFA2_special = DFA.unpackEncodedString(DFA2_specialS);
	static final short[][] DFA2_transition;

	static {
		int numStates = DFA2_transitionS.length;
		DFA2_transition = new short[numStates][];
		for (int i=0; i<numStates; i++) {
			DFA2_transition[i] = DFA.unpackEncodedString(DFA2_transitionS[i]);
		}
	}

	protected class DFA2 extends DFA {

		public DFA2(BaseRecognizer recognizer) {
			this.recognizer = recognizer;
			this.decisionNumber = 2;
			this.eot = DFA2_eot;
			this.eof = DFA2_eof;
			this.min = DFA2_min;
			this.max = DFA2_max;
			this.accept = DFA2_accept;
			this.special = DFA2_special;
			this.transition = DFA2_transition;
		}
		@Override
		public String getDescription() {
			return "()* loopback of 825:6: ( explainOption )*";
		}
	}

	static final String DFA29_eotS =
		"\u0092\uffff";
	static final String DFA29_eofS =
		"\u0092\uffff";
	static final String DFA29_minS =
		"\1\32\1\46\1\uffff\1\46\1\uffff\1\46\2\uffff\1\104\3\uffff\2\130\2\30"+
		"\10\uffff\1\u0085\23\uffff\1\u0097\67\uffff\1\11\1\uffff\1\11\13\uffff"+
		"\1\11\1\uffff\1\11\16\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1"+
		"\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0";
	static final String DFA29_maxS =
		"\1\u015b\1\u0165\1\uffff\1\u0165\1\uffff\1\u0165\2\uffff\1\u0166\3\uffff"+
		"\2\u013a\2\u02a3\10\uffff\1\u0148\23\uffff\1\u00c6\67\uffff\1\u0177\1"+
		"\uffff\1\u0177\13\uffff\1\u0177\1\uffff\1\u0177\16\uffff\1\0\1\uffff\1"+
		"\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff"+
		"\1\0";
	static final String DFA29_acceptS =
		"\2\uffff\1\2\1\uffff\1\6\1\uffff\1\10\2\uffff\1\12\1\25\1\27\4\uffff\1"+
		"\46\1\50\1\51\1\52\2\uffff\1\14\1\15\1\uffff\1\34\3\uffff\1\1\1\uffff"+
		"\1\4\2\uffff\1\13\1\uffff\1\22\3\uffff\1\5\1\17\1\20\1\21\1\uffff\1\35"+
		"\3\uffff\1\3\1\uffff\1\24\3\uffff\1\7\2\uffff\1\16\10\uffff\1\11\14\uffff"+
		"\1\40\1\41\1\42\1\43\1\47\4\uffff\1\30\1\32\1\uffff\1\31\1\33\1\uffff"+
		"\5\36\1\uffff\1\36\1\uffff\2\36\1\44\2\uffff\6\37\1\uffff\1\37\1\uffff"+
		"\2\37\1\45\3\uffff\1\23\4\uffff\1\26\1\uffff\1\36\1\uffff\1\36\1\uffff"+
		"\1\36\1\uffff\1\36\1\uffff\1\37\1\uffff\1\37\1\uffff\1\37\1\uffff\1\37"+
		"\1\uffff";
	static final String DFA29_specialS =
		"\16\uffff\1\0\1\1\124\uffff\1\2\1\uffff\1\3\13\uffff\1\4\1\uffff\1\5\16"+
		"\uffff\1\6\1\uffff\1\7\1\uffff\1\10\1\uffff\1\11\1\uffff\1\12\1\uffff"+
		"\1\13\1\uffff\1\14\1\uffff\1\15}>";
	static final String[] DFA29_transitionS = {
			"\1\21\7\uffff\1\5\1\13\53\uffff\1\1\26\uffff\2\6\3\uffff\1\23\6\uffff"+
			"\1\3\3\uffff\1\23\42\uffff\1\16\34\uffff\1\22\13\uffff\1\14\22\uffff"+
			"\1\11\62\uffff\1\12\5\uffff\1\23\3\uffff\1\17\23\uffff\1\20\2\uffff\1"+
			"\10\43\uffff\1\4\7\uffff\1\15\5\uffff\1\2",
			"\1\23\61\uffff\1\35\54\uffff\1\37\21\uffff\1\44\2\uffff\1\23\62\uffff"+
			"\1\26\25\uffff\1\42\20\uffff\1\23\33\uffff\1\23\5\uffff\1\31\5\uffff"+
			"\1\27\1\uffff\1\35\33\uffff\1\37\3\uffff\1\30\11\uffff\1\37\2\uffff\1"+
			"\23\20\uffff\1\23\10\uffff\1\42",
			"",
			"\1\23\61\uffff\1\61\76\uffff\1\63\2\uffff\1\23\62\uffff\1\53\46\uffff"+
			"\1\23\33\uffff\1\23\5\uffff\1\55\5\uffff\1\51\1\uffff\1\61\33\uffff\1"+
			"\50\3\uffff\1\54\14\uffff\1\23\20\uffff\1\23\10\uffff\1\52",
			"",
			"\1\23\61\uffff\1\67\101\uffff\1\23\62\uffff\1\67\46\uffff\1\23\33\uffff"+
			"\1\23\13\uffff\1\72\1\uffff\1\67\33\uffff\1\67\20\uffff\1\23\20\uffff"+
			"\1\23\10\uffff\1\67",
			"",
			"",
			"\1\103\3\uffff\1\103\2\uffff\1\103\3\uffff\1\103\3\uffff\1\124\5\uffff"+
			"\1\103\52\uffff\1\103\23\uffff\1\103\1\120\51\uffff\1\103\11\uffff\1"+
			"\103\40\uffff\1\103\12\uffff\1\122\26\uffff\1\103\5\uffff\1\121\1\123"+
			"\7\uffff\1\103\32\uffff\2\103\1\uffff\1\103\13\uffff\1\103\34\uffff\1"+
			"\103",
			"",
			"",
			"",
			"\1\132\u00c5\uffff\1\132\33\uffff\1\131",
			"\1\135\u00c5\uffff\1\135\33\uffff\1\134",
			"\1\151\1\uffff\6\151\1\137\1\151\1\140\1\151\3\uffff\1\151\2\uffff\2"+
			"\151\1\uffff\2\151\5\uffff\2\151\1\uffff\2\151\2\uffff\2\151\1\uffff"+
			"\5\151\1\uffff\2\151\1\uffff\4\151\2\uffff\2\151\1\142\1\151\6\uffff"+
			"\1\151\1\uffff\1\151\1\uffff\4\151\1\uffff\3\151\1\150\3\151\1\uffff"+
			"\4\151\1\uffff\3\151\1\uffff\1\151\1\143\2\151\1\uffff\1\151\1\uffff"+
			"\3\151\2\uffff\3\151\1\uffff\3\151\5\uffff\4\151\6\uffff\2\151\3\uffff"+
			"\1\151\4\uffff\2\151\3\uffff\2\151\1\uffff\3\151\1\147\5\uffff\3\151"+
			"\1\uffff\6\151\3\uffff\1\151\1\uffff\3\151\1\uffff\1\151\1\144\3\151"+
			"\1\uffff\2\151\1\uffff\4\151\1\uffff\1\151\1\uffff\2\151\1\uffff\2\151"+
			"\1\uffff\2\151\1\uffff\1\151\1\uffff\1\151\1\uffff\1\151\2\uffff\2\151"+
			"\4\uffff\2\151\1\uffff\2\151\1\uffff\3\151\1\uffff\4\151\4\uffff\1\151"+
			"\1\uffff\4\151\1\uffff\1\151\1\uffff\3\151\3\uffff\12\151\1\uffff\1\151"+
			"\2\uffff\2\151\4\uffff\5\151\1\145\4\151\1\uffff\3\151\1\146\1\151\1"+
			"\uffff\4\151\1\uffff\7\151\2\uffff\1\151\1\uffff\3\151\4\uffff\1\151"+
			"\1\uffff\4\151\4\uffff\1\151\1\uffff\1\151\1\uffff\1\151\2\uffff\4\151"+
			"\1\141\2\151\2\uffff\3\151\1\uffff\1\151\1\uffff\5\151\2\uffff\1\151"+
			"\2\uffff\5\151\75\uffff\1\151\47\uffff\1\151\63\uffff\1\151\3\uffff\1"+
			"\151\60\uffff\1\151\3\uffff\1\151\31\uffff\1\151\6\uffff\1\151\74\uffff"+
			"\1\151",
			"\1\167\1\uffff\6\167\1\155\1\167\1\156\1\167\3\uffff\1\167\2\uffff\2"+
			"\167\1\uffff\2\167\5\uffff\2\167\1\uffff\2\167\2\uffff\2\167\1\uffff"+
			"\5\167\1\uffff\2\167\1\uffff\4\167\2\uffff\2\167\1\160\1\167\6\uffff"+
			"\1\167\1\uffff\1\167\1\uffff\4\167\1\uffff\3\167\1\166\3\167\1\uffff"+
			"\4\167\1\uffff\3\167\1\uffff\1\167\1\161\2\167\1\uffff\1\167\1\uffff"+
			"\3\167\2\uffff\3\167\1\uffff\3\167\5\uffff\4\167\6\uffff\2\167\3\uffff"+
			"\1\167\1\154\3\uffff\2\167\3\uffff\2\167\1\uffff\3\167\1\165\5\uffff"+
			"\3\167\1\uffff\6\167\3\uffff\1\167\1\uffff\3\167\1\uffff\1\167\1\162"+
			"\3\167\1\uffff\2\167\1\uffff\4\167\1\uffff\1\167\1\uffff\2\167\1\uffff"+
			"\2\167\1\uffff\2\167\1\uffff\1\167\1\uffff\1\167\1\uffff\1\167\2\uffff"+
			"\2\167\4\uffff\2\167\1\uffff\2\167\1\uffff\3\167\1\uffff\4\167\4\uffff"+
			"\1\167\1\uffff\4\167\1\uffff\1\167\1\uffff\3\167\3\uffff\12\167\1\uffff"+
			"\1\167\2\uffff\2\167\4\uffff\5\167\1\163\4\167\1\uffff\3\167\1\164\1"+
			"\167\1\uffff\4\167\1\uffff\7\167\2\uffff\1\167\1\uffff\3\167\4\uffff"+
			"\1\167\1\uffff\4\167\4\uffff\1\167\1\uffff\1\167\1\uffff\1\167\2\uffff"+
			"\4\167\1\157\2\167\2\uffff\3\167\1\uffff\1\167\1\uffff\5\167\2\uffff"+
			"\1\167\2\uffff\5\167\75\uffff\1\167\47\uffff\1\167\63\uffff\1\167\3\uffff"+
			"\1\167\60\uffff\1\167\3\uffff\1\167\31\uffff\1\167\6\uffff\1\167\74\uffff"+
			"\1\167",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\37\21\uffff\1\44\56\uffff\1\173\163\uffff\1\37\15\uffff\1\37",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\63\56\uffff\1\u0080",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\u0083\u00d5\uffff\1\u0084\145\uffff\1\u0085\61\uffff\1\u0082",
			"",
			"\1\u0087\u00d5\uffff\1\u0088\145\uffff\1\u0089\61\uffff\1\u0086",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\u008b\u008b\uffff\1\u008d\111\uffff\1\u008c\u0097\uffff\1\u008a",
			"",
			"\1\u008f\u008b\uffff\1\u0091\111\uffff\1\u0090\u0097\uffff\1\u008e",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff"
	};

	static final short[] DFA29_eot = DFA.unpackEncodedString(DFA29_eotS);
	static final short[] DFA29_eof = DFA.unpackEncodedString(DFA29_eofS);
	static final char[] DFA29_min = DFA.unpackEncodedStringToUnsignedChars(DFA29_minS);
	static final char[] DFA29_max = DFA.unpackEncodedStringToUnsignedChars(DFA29_maxS);
	static final short[] DFA29_accept = DFA.unpackEncodedString(DFA29_acceptS);
	static final short[] DFA29_special = DFA.unpackEncodedString(DFA29_specialS);
	static final short[][] DFA29_transition;

	static {
		int numStates = DFA29_transitionS.length;
		DFA29_transition = new short[numStates][];
		for (int i=0; i<numStates; i++) {
			DFA29_transition[i] = DFA.unpackEncodedString(DFA29_transitionS[i]);
		}
	}

	protected class DFA29 extends DFA {

		public DFA29(BaseRecognizer recognizer) {
			this.recognizer = recognizer;
			this.decisionNumber = 29;
			this.eot = DFA29_eot;
			this.eof = DFA29_eof;
			this.min = DFA29_min;
			this.max = DFA29_max;
			this.accept = DFA29_accept;
			this.special = DFA29_special;
			this.transition = DFA29_transition;
		}
		@Override
		public String getDescription() {
			return "980:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | createMaterializedViewStatement | createScheduledQueryStatement | alterScheduledQueryStatement | dropScheduledQueryStatement | dropViewStatement | dropMaterializedViewStatement | createFunctionStatement | createMacroStatement | dropFunctionStatement | reloadFunctionsStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement | killQueryStatement | resourcePlanDdlStatements );";
		}
		@Override
		public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
			TokenStream input = (TokenStream)_input;
			int _s = s;
			switch ( s ) {
					case 0 : 
						int LA29_14 = input.LA(1);
						 
						int index29_14 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_14==KW_ALL) && (synpred1_HiveParser())) {s = 95;}
						else if ( (LA29_14==KW_ALTER) && (synpred1_HiveParser())) {s = 96;}
						else if ( (LA29_14==KW_UPDATE) && (synpred1_HiveParser())) {s = 97;}
						else if ( (LA29_14==KW_CREATE) && (synpred1_HiveParser())) {s = 98;}
						else if ( (LA29_14==KW_DROP) && (synpred1_HiveParser())) {s = 99;}
						else if ( (LA29_14==KW_LOCK) ) {s = 100;}
						else if ( (LA29_14==KW_SELECT) && (synpred1_HiveParser())) {s = 101;}
						else if ( (LA29_14==KW_SHOW_DATABASE) ) {s = 102;}
						else if ( (LA29_14==KW_INSERT) && (synpred1_HiveParser())) {s = 103;}
						else if ( (LA29_14==KW_DELETE) && (synpred1_HiveParser())) {s = 104;}
						else if ( (LA29_14==Identifier||(LA29_14 >= KW_ABORT && LA29_14 <= KW_AFTER)||LA29_14==KW_ALLOC_FRACTION||LA29_14==KW_ANALYZE||LA29_14==KW_ARCHIVE||(LA29_14 >= KW_ASC && LA29_14 <= KW_AT)||(LA29_14 >= KW_AUTOCOMMIT && LA29_14 <= KW_BEFORE)||(LA29_14 >= KW_BUCKET && LA29_14 <= KW_BUCKETS)||(LA29_14 >= KW_CACHE && LA29_14 <= KW_CASCADE)||(LA29_14 >= KW_CBO && LA29_14 <= KW_CHANGE)||(LA29_14 >= KW_CHECK && LA29_14 <= KW_COLLECTION)||(LA29_14 >= KW_COLUMNS && LA29_14 <= KW_COMMENT)||(LA29_14 >= KW_COMPACT && LA29_14 <= KW_CONCATENATE)||(LA29_14 >= KW_CONTINUE && LA29_14 <= KW_COST)||LA29_14==KW_CRON||LA29_14==KW_DATA||LA29_14==KW_DATABASES||(LA29_14 >= KW_DATETIME && LA29_14 <= KW_DEBUG)||(LA29_14 >= KW_DEFAULT && LA29_14 <= KW_DEFINED)||(LA29_14 >= KW_DELIMITED && LA29_14 <= KW_DESC)||(LA29_14 >= KW_DETAIL && LA29_14 <= KW_DISABLE)||(LA29_14 >= KW_DISTRIBUTE && LA29_14 <= KW_DO)||LA29_14==KW_DOW||(LA29_14 >= KW_DUMP && LA29_14 <= KW_ELEM_TYPE)||LA29_14==KW_ENABLE||(LA29_14 >= KW_ENFORCED && LA29_14 <= KW_EVERY)||(LA29_14 >= KW_EXCLUSIVE && LA29_14 <= KW_EXECUTED)||(LA29_14 >= KW_EXPLAIN && LA29_14 <= KW_EXPRESSION)||(LA29_14 >= KW_FIELDS && LA29_14 <= KW_FIRST)||(LA29_14 >= KW_FORMAT && LA29_14 <= KW_FORMATTED)||LA29_14==KW_FUNCTIONS||(LA29_14 >= KW_HOUR && LA29_14 <= KW_IDXPROPERTIES)||(LA29_14 >= KW_INDEX && LA29_14 <= KW_INDEXES)||(LA29_14 >= KW_INPATH && LA29_14 <= KW_INPUTFORMAT)||(LA29_14 >= KW_ISOLATION && LA29_14 <= KW_JAR)||(LA29_14 >= KW_JOINCOST && LA29_14 <= KW_LAST)||LA29_14==KW_LEVEL||(LA29_14 >= KW_LIMIT && LA29_14 <= KW_LOAD)||LA29_14==KW_LOCATION||(LA29_14 >= KW_LOCKS && LA29_14 <= KW_LONG)||(LA29_14 >= KW_MANAGEDLOCATION && LA29_14 <= KW_MANAGEMENT)||(LA29_14 >= KW_MAPJOIN && LA29_14 <= KW_MATERIALIZED)||LA29_14==KW_METADATA||(LA29_14 >= KW_MINUTE && LA29_14 <= KW_MONTH)||(LA29_14 >= KW_MOVE && LA29_14 <= KW_MSCK)||(LA29_14 >= KW_NORELY && LA29_14 <= KW_NOSCAN)||LA29_14==KW_NOVALIDATE||LA29_14==KW_NULLS||LA29_14==KW_OFFSET||(LA29_14 >= KW_OPERATOR && LA29_14 <= KW_OPTION)||(LA29_14 >= KW_OUTPUTDRIVER && LA29_14 <= KW_OUTPUTFORMAT)||(LA29_14 >= KW_OVERWRITE && LA29_14 <= KW_OWNER)||(LA29_14 >= KW_PARTITIONED && LA29_14 <= KW_PATH)||(LA29_14 >= KW_PLAN && LA29_14 <= KW_POOL)||LA29_14==KW_PRINCIPALS||(LA29_14 >= KW_PURGE && LA29_14 <= KW_QUERY_PARALLELISM)||LA29_14==KW_READ||(LA29_14 >= KW_REBUILD && LA29_14 <= KW_RECORDWRITER)||(LA29_14 >= KW_RELOAD && LA29_14 <= KW_RESTRICT)||LA29_14==KW_REWRITE||(LA29_14 >= KW_ROLE && LA29_14 <= KW_ROLES)||(LA29_14 >= KW_SCHEDULED && LA29_14 <= KW_SECOND)||(LA29_14 >= KW_SEMI && LA29_14 <= KW_SERVER)||(LA29_14 >= KW_SETS && LA29_14 <= KW_SHOW)||LA29_14==KW_SKEWED||(LA29_14 >= KW_SNAPSHOT && LA29_14 <= KW_SSL)||(LA29_14 >= KW_STATISTICS && LA29_14 <= KW_SUMMARY)||LA29_14==KW_TABLES||(LA29_14 >= KW_TBLPROPERTIES && LA29_14 <= KW_TERMINATED)||LA29_14==KW_TINYINT||(LA29_14 >= KW_TOUCH && LA29_14 <= KW_TRANSACTIONS)||LA29_14==KW_UNARCHIVE||LA29_14==KW_UNDO||LA29_14==KW_UNIONTYPE||(LA29_14 >= KW_UNLOCK && LA29_14 <= KW_UNSIGNED)||(LA29_14 >= KW_URI && LA29_14 <= KW_USE)||(LA29_14 >= KW_UTC && LA29_14 <= KW_VALIDATE)||LA29_14==KW_VALUE_TYPE||(LA29_14 >= KW_VECTORIZATION && LA29_14 <= KW_WEEK)||LA29_14==KW_WHILE||(LA29_14 >= KW_WORK && LA29_14 <= KW_ZONE)||LA29_14==KW_BATCH||LA29_14==KW_DAYOFWEEK||LA29_14==KW_HOLD_DDLTIME||LA29_14==KW_IGNORE||LA29_14==KW_NO_DROP||LA29_14==KW_OFFLINE||LA29_14==KW_PROTECTION||LA29_14==KW_READONLY||LA29_14==KW_TIMESTAMPTZ) ) {s = 105;}
						 
						input.seek(index29_14);
						if ( s>=0 ) return s;
						break;

					case 1 : 
						int LA29_15 = input.LA(1);
						 
						int index29_15 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_15==KW_GRANT) && (synpred2_HiveParser())) {s = 108;}
						else if ( (LA29_15==KW_ALL) && (synpred2_HiveParser())) {s = 109;}
						else if ( (LA29_15==KW_ALTER) && (synpred2_HiveParser())) {s = 110;}
						else if ( (LA29_15==KW_UPDATE) && (synpred2_HiveParser())) {s = 111;}
						else if ( (LA29_15==KW_CREATE) && (synpred2_HiveParser())) {s = 112;}
						else if ( (LA29_15==KW_DROP) && (synpred2_HiveParser())) {s = 113;}
						else if ( (LA29_15==KW_LOCK) ) {s = 114;}
						else if ( (LA29_15==KW_SELECT) && (synpred2_HiveParser())) {s = 115;}
						else if ( (LA29_15==KW_SHOW_DATABASE) ) {s = 116;}
						else if ( (LA29_15==KW_INSERT) && (synpred2_HiveParser())) {s = 117;}
						else if ( (LA29_15==KW_DELETE) && (synpred2_HiveParser())) {s = 118;}
						else if ( (LA29_15==Identifier||(LA29_15 >= KW_ABORT && LA29_15 <= KW_AFTER)||LA29_15==KW_ALLOC_FRACTION||LA29_15==KW_ANALYZE||LA29_15==KW_ARCHIVE||(LA29_15 >= KW_ASC && LA29_15 <= KW_AT)||(LA29_15 >= KW_AUTOCOMMIT && LA29_15 <= KW_BEFORE)||(LA29_15 >= KW_BUCKET && LA29_15 <= KW_BUCKETS)||(LA29_15 >= KW_CACHE && LA29_15 <= KW_CASCADE)||(LA29_15 >= KW_CBO && LA29_15 <= KW_CHANGE)||(LA29_15 >= KW_CHECK && LA29_15 <= KW_COLLECTION)||(LA29_15 >= KW_COLUMNS && LA29_15 <= KW_COMMENT)||(LA29_15 >= KW_COMPACT && LA29_15 <= KW_CONCATENATE)||(LA29_15 >= KW_CONTINUE && LA29_15 <= KW_COST)||LA29_15==KW_CRON||LA29_15==KW_DATA||LA29_15==KW_DATABASES||(LA29_15 >= KW_DATETIME && LA29_15 <= KW_DEBUG)||(LA29_15 >= KW_DEFAULT && LA29_15 <= KW_DEFINED)||(LA29_15 >= KW_DELIMITED && LA29_15 <= KW_DESC)||(LA29_15 >= KW_DETAIL && LA29_15 <= KW_DISABLE)||(LA29_15 >= KW_DISTRIBUTE && LA29_15 <= KW_DO)||LA29_15==KW_DOW||(LA29_15 >= KW_DUMP && LA29_15 <= KW_ELEM_TYPE)||LA29_15==KW_ENABLE||(LA29_15 >= KW_ENFORCED && LA29_15 <= KW_EVERY)||(LA29_15 >= KW_EXCLUSIVE && LA29_15 <= KW_EXECUTED)||(LA29_15 >= KW_EXPLAIN && LA29_15 <= KW_EXPRESSION)||(LA29_15 >= KW_FIELDS && LA29_15 <= KW_FIRST)||(LA29_15 >= KW_FORMAT && LA29_15 <= KW_FORMATTED)||LA29_15==KW_FUNCTIONS||(LA29_15 >= KW_HOUR && LA29_15 <= KW_IDXPROPERTIES)||(LA29_15 >= KW_INDEX && LA29_15 <= KW_INDEXES)||(LA29_15 >= KW_INPATH && LA29_15 <= KW_INPUTFORMAT)||(LA29_15 >= KW_ISOLATION && LA29_15 <= KW_JAR)||(LA29_15 >= KW_JOINCOST && LA29_15 <= KW_LAST)||LA29_15==KW_LEVEL||(LA29_15 >= KW_LIMIT && LA29_15 <= KW_LOAD)||LA29_15==KW_LOCATION||(LA29_15 >= KW_LOCKS && LA29_15 <= KW_LONG)||(LA29_15 >= KW_MANAGEDLOCATION && LA29_15 <= KW_MANAGEMENT)||(LA29_15 >= KW_MAPJOIN && LA29_15 <= KW_MATERIALIZED)||LA29_15==KW_METADATA||(LA29_15 >= KW_MINUTE && LA29_15 <= KW_MONTH)||(LA29_15 >= KW_MOVE && LA29_15 <= KW_MSCK)||(LA29_15 >= KW_NORELY && LA29_15 <= KW_NOSCAN)||LA29_15==KW_NOVALIDATE||LA29_15==KW_NULLS||LA29_15==KW_OFFSET||(LA29_15 >= KW_OPERATOR && LA29_15 <= KW_OPTION)||(LA29_15 >= KW_OUTPUTDRIVER && LA29_15 <= KW_OUTPUTFORMAT)||(LA29_15 >= KW_OVERWRITE && LA29_15 <= KW_OWNER)||(LA29_15 >= KW_PARTITIONED && LA29_15 <= KW_PATH)||(LA29_15 >= KW_PLAN && LA29_15 <= KW_POOL)||LA29_15==KW_PRINCIPALS||(LA29_15 >= KW_PURGE && LA29_15 <= KW_QUERY_PARALLELISM)||LA29_15==KW_READ||(LA29_15 >= KW_REBUILD && LA29_15 <= KW_RECORDWRITER)||(LA29_15 >= KW_RELOAD && LA29_15 <= KW_RESTRICT)||LA29_15==KW_REWRITE||(LA29_15 >= KW_ROLE && LA29_15 <= KW_ROLES)||(LA29_15 >= KW_SCHEDULED && LA29_15 <= KW_SECOND)||(LA29_15 >= KW_SEMI && LA29_15 <= KW_SERVER)||(LA29_15 >= KW_SETS && LA29_15 <= KW_SHOW)||LA29_15==KW_SKEWED||(LA29_15 >= KW_SNAPSHOT && LA29_15 <= KW_SSL)||(LA29_15 >= KW_STATISTICS && LA29_15 <= KW_SUMMARY)||LA29_15==KW_TABLES||(LA29_15 >= KW_TBLPROPERTIES && LA29_15 <= KW_TERMINATED)||LA29_15==KW_TINYINT||(LA29_15 >= KW_TOUCH && LA29_15 <= KW_TRANSACTIONS)||LA29_15==KW_UNARCHIVE||LA29_15==KW_UNDO||LA29_15==KW_UNIONTYPE||(LA29_15 >= KW_UNLOCK && LA29_15 <= KW_UNSIGNED)||(LA29_15 >= KW_URI && LA29_15 <= KW_USE)||(LA29_15 >= KW_UTC && LA29_15 <= KW_VALIDATE)||LA29_15==KW_VALUE_TYPE||(LA29_15 >= KW_VECTORIZATION && LA29_15 <= KW_WEEK)||LA29_15==KW_WHILE||(LA29_15 >= KW_WORK && LA29_15 <= KW_ZONE)||LA29_15==KW_BATCH||LA29_15==KW_DAYOFWEEK||LA29_15==KW_HOLD_DDLTIME||LA29_15==KW_IGNORE||LA29_15==KW_NO_DROP||LA29_15==KW_OFFLINE||LA29_15==KW_PROTECTION||LA29_15==KW_READONLY||LA29_15==KW_TIMESTAMPTZ) ) {s = 119;}
						 
						input.seek(index29_15);
						if ( s>=0 ) return s;
						break;

					case 2 : 
						int LA29_100 = input.LA(1);
						 
						int index29_100 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_100==LPAREN) && (synpred1_HiveParser())) {s = 130;}
						else if ( (LA29_100==COMMA) ) {s = 131;}
						else if ( (LA29_100==KW_ON) && (synpred1_HiveParser())) {s = 132;}
						else if ( (LA29_100==KW_TO) ) {s = 133;}
						 
						input.seek(index29_100);
						if ( s>=0 ) return s;
						break;

					case 3 : 
						int LA29_102 = input.LA(1);
						 
						int index29_102 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_102==LPAREN) && (synpred1_HiveParser())) {s = 134;}
						else if ( (LA29_102==COMMA) ) {s = 135;}
						else if ( (LA29_102==KW_ON) && (synpred1_HiveParser())) {s = 136;}
						else if ( (LA29_102==KW_TO) ) {s = 137;}
						 
						input.seek(index29_102);
						if ( s>=0 ) return s;
						break;

					case 4 : 
						int LA29_114 = input.LA(1);
						 
						int index29_114 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_114==LPAREN) && (synpred2_HiveParser())) {s = 138;}
						else if ( (LA29_114==COMMA) ) {s = 139;}
						else if ( (LA29_114==KW_ON) && (synpred2_HiveParser())) {s = 140;}
						else if ( (LA29_114==KW_FROM) ) {s = 141;}
						 
						input.seek(index29_114);
						if ( s>=0 ) return s;
						break;

					case 5 : 
						int LA29_116 = input.LA(1);
						 
						int index29_116 = input.index();
						input.rewind();
						s = -1;
						if ( (LA29_116==LPAREN) && (synpred2_HiveParser())) {s = 142;}
						else if ( (LA29_116==COMMA) ) {s = 143;}
						else if ( (LA29_116==KW_ON) && (synpred2_HiveParser())) {s = 144;}
						else if ( (LA29_116==KW_FROM) ) {s = 145;}
						 
						input.seek(index29_116);
						if ( s>=0 ) return s;
						break;

					case 6 : 
						int LA29_131 = input.LA(1);
						 
						int index29_131 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 136;}
						else if ( (true) ) {s = 105;}
						 
						input.seek(index29_131);
						if ( s>=0 ) return s;
						break;

					case 7 : 
						int LA29_133 = input.LA(1);
						 
						int index29_133 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 136;}
						else if ( (true) ) {s = 105;}
						 
						input.seek(index29_133);
						if ( s>=0 ) return s;
						break;

					case 8 : 
						int LA29_135 = input.LA(1);
						 
						int index29_135 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 136;}
						else if ( (true) ) {s = 105;}
						 
						input.seek(index29_135);
						if ( s>=0 ) return s;
						break;

					case 9 : 
						int LA29_137 = input.LA(1);
						 
						int index29_137 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 136;}
						else if ( (true) ) {s = 105;}
						 
						input.seek(index29_137);
						if ( s>=0 ) return s;
						break;

					case 10 : 
						int LA29_139 = input.LA(1);
						 
						int index29_139 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 144;}
						else if ( (true) ) {s = 119;}
						 
						input.seek(index29_139);
						if ( s>=0 ) return s;
						break;

					case 11 : 
						int LA29_141 = input.LA(1);
						 
						int index29_141 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 144;}
						else if ( (true) ) {s = 119;}
						 
						input.seek(index29_141);
						if ( s>=0 ) return s;
						break;

					case 12 : 
						int LA29_143 = input.LA(1);
						 
						int index29_143 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 144;}
						else if ( (true) ) {s = 119;}
						 
						input.seek(index29_143);
						if ( s>=0 ) return s;
						break;

					case 13 : 
						int LA29_145 = input.LA(1);
						 
						int index29_145 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 144;}
						else if ( (true) ) {s = 119;}
						 
						input.seek(index29_145);
						if ( s>=0 ) return s;
						break;
			}
			if (state.backtracking>0) {state.failed=true; return -1;}
			NoViableAltException nvae =
				new NoViableAltException(getDescription(), 29, _s, input);
			error(nvae);
			throw nvae;
		}
	}

	static final String DFA246_eotS =
		"\134\uffff";
	static final String DFA246_eofS =
		"\1\2\133\uffff";
	static final String DFA246_minS =
		"\1\11\1\14\41\uffff\1\4\70\uffff";
	static final String DFA246_maxS =
		"\1\u0184\1\u02a3\41\uffff\1\u0188\70\uffff";
	static final String DFA246_acceptS =
		"\2\uffff\1\2\73\uffff\1\1\35\uffff";
	static final String DFA246_specialS =
		"\134\uffff}>";
	static final String[] DFA246_transitionS = {
			"\1\2\37\uffff\1\2\25\uffff\1\2\55\uffff\1\2\15\uffff\1\2\31\uffff\1\2"+
			"\4\uffff\1\2\1\uffff\1\2\2\uffff\1\2\10\uffff\1\2\1\uffff\1\2\15\uffff"+
			"\1\2\4\uffff\2\2\2\uffff\1\2\7\uffff\1\1\6\uffff\1\2\12\uffff\1\2\10"+
			"\uffff\1\2\36\uffff\3\2\33\uffff\1\2\14\uffff\1\2\5\uffff\1\2\10\uffff"+
			"\1\2\23\uffff\1\2\13\uffff\1\2\3\uffff\1\2\10\uffff\1\2\1\uffff\1\2\12"+
			"\uffff\1\2\14\uffff\1\2",
			"\1\2\13\uffff\10\2\1\uffff\1\2\1\uffff\1\2\3\uffff\2\2\1\uffff\2\2\1"+
			"\uffff\2\2\1\uffff\3\2\1\uffff\2\2\1\uffff\6\2\1\uffff\5\2\1\uffff\2"+
			"\2\1\uffff\4\2\2\uffff\2\2\1\uffff\1\2\3\uffff\2\2\1\uffff\1\2\1\uffff"+
			"\6\2\1\uffff\3\2\1\uffff\3\2\1\uffff\4\2\1\uffff\5\2\1\uffff\2\2\1\uffff"+
			"\1\2\1\uffff\3\2\2\uffff\7\2\2\uffff\2\2\1\uffff\6\2\4\uffff\2\2\3\uffff"+
			"\1\2\2\uffff\1\2\1\uffff\3\2\2\uffff\2\2\1\uffff\3\2\1\uffff\1\2\1\uffff"+
			"\1\2\2\uffff\3\2\1\uffff\2\2\1\43\3\2\3\uffff\1\2\1\uffff\3\2\1\uffff"+
			"\5\2\1\uffff\7\2\1\uffff\1\2\1\uffff\2\2\1\uffff\2\2\1\uffff\6\2\1\uffff"+
			"\1\2\2\uffff\2\2\4\uffff\2\2\1\uffff\2\2\1\uffff\3\2\1\uffff\4\2\4\uffff"+
			"\1\2\1\uffff\4\2\1\uffff\1\2\1\uffff\3\2\3\uffff\12\2\1\uffff\1\2\2\uffff"+
			"\2\2\4\uffff\5\2\1\uffff\4\2\1\uffff\12\2\1\uffff\7\2\2\uffff\1\2\1\uffff"+
			"\3\2\2\uffff\3\2\1\uffff\4\2\2\uffff\1\2\1\uffff\1\2\1\uffff\1\2\1\uffff"+
			"\1\2\2\uffff\4\2\1\uffff\2\2\2\uffff\3\2\1\uffff\1\2\1\uffff\5\2\2\uffff"+
			"\1\2\2\uffff\5\2\4\uffff\1\2\2\uffff\1\2\2\uffff\3\2\10\uffff\3\2\45"+
			"\uffff\1\2\47\uffff\1\2\63\uffff\1\2\3\uffff\1\2\60\uffff\1\2\3\uffff"+
			"\1\2\31\uffff\1\2\6\uffff\1\2\74\uffff\1\2",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\3\2\2\uffff\2\2\2\uffff\2\2\1\uffff\1\2\1\uffff\2\2\1\uffff\2\2\15"+
			"\uffff\1\2\12\uffff\1\2\161\uffff\1\2\13\uffff\1\2\16\uffff\1\2\34\uffff"+
			"\1\2\11\uffff\1\2\40\uffff\1\2\2\uffff\1\2\15\uffff\1\2\4\uffff\1\2\44"+
			"\uffff\1\76\35\uffff\1\2\26\uffff\2\2\1\uffff\2\2\1\uffff\3\2\2\uffff"+
			"\1\2\10\uffff\1\2",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			""
	};

	static final short[] DFA246_eot = DFA.unpackEncodedString(DFA246_eotS);
	static final short[] DFA246_eof = DFA.unpackEncodedString(DFA246_eofS);
	static final char[] DFA246_min = DFA.unpackEncodedStringToUnsignedChars(DFA246_minS);
	static final char[] DFA246_max = DFA.unpackEncodedStringToUnsignedChars(DFA246_maxS);
	static final short[] DFA246_accept = DFA.unpackEncodedString(DFA246_acceptS);
	static final short[] DFA246_special = DFA.unpackEncodedString(DFA246_specialS);
	static final short[][] DFA246_transition;

	static {
		int numStates = DFA246_transitionS.length;
		DFA246_transition = new short[numStates][];
		for (int i=0; i<numStates; i++) {
			DFA246_transition[i] = DFA.unpackEncodedString(DFA246_transitionS[i]);
		}
	}

	protected class DFA246 extends DFA {

		public DFA246(BaseRecognizer recognizer) {
			this.recognizer = recognizer;
			this.decisionNumber = 246;
			this.eot = DFA246_eot;
			this.eof = DFA246_eof;
			this.min = DFA246_min;
			this.max = DFA246_max;
			this.accept = DFA246_accept;
			this.special = DFA246_special;
			this.transition = DFA246_transition;
		}
		@Override
		public String getDescription() {
			return "2261:103: ( tableRowFormatMapKeysIdentifier )?";
		}
	}

	public static final BitSet FOLLOW_explainStatement_in_statement1376 = new BitSet(new long[]{0x0000000000000000L});
	public static final BitSet FOLLOW_EOF_in_statement1378 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_execStatement_in_statement1383 = new BitSet(new long[]{0x0000000000000000L});
	public static final BitSet FOLLOW_EOF_in_statement1385 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXPLAIN_in_explainStatement1406 = new BitSet(new long[]{0x0800100C04000000L,0x004408E840008040L,0x8040010102300014L,0x000000000020421CL,0x00020242010C6920L,0x008020100A202000L});
	public static final BitSet FOLLOW_explainOption_in_explainStatement1415 = new BitSet(new long[]{0x0800100C04000000L,0x004408E840008040L,0x8040010102300014L,0x000000000020421CL,0x0002024201046920L,0x008020100A202000L});
	public static final BitSet FOLLOW_execStatement_in_explainStatement1418 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REWRITE_in_explainStatement1449 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000010000200000L,0x0000000000000200L,0x0000000200000020L,0x0080200000000000L});
	public static final BitSet FOLLOW_queryStatementExpression_in_explainStatement1451 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_explainOption1491 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FORMATTED_in_explainOption1499 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DEPENDENCY_in_explainOption1507 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CBO_in_explainOption1515 = new BitSet(new long[]{0x0000000000000002L,0x0000000000004000L,0x0004000000000000L});
	public static final BitSet FOLLOW_KW_LOGICAL_in_explainOption1532 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_AUTHORIZATION_in_explainOption1540 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ANALYZE_in_explainOption1548 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REOPTIMIZATION_in_explainOption1556 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCKS_in_explainOption1564 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_VECTORIZATION_in_explainOption1573 = new BitSet(new long[]{0x0000000000000002L,0x0000010000000000L,0x0000000000000008L,0x0000000300000000L,0x0100000000000000L});
	public static final BitSet FOLLOW_vectorizationOnly_in_explainOption1575 = new BitSet(new long[]{0x0000000000000002L,0x0000010000000000L,0x0000000000000008L,0x0000000200000000L,0x0100000000000000L});
	public static final BitSet FOLLOW_vectorizatonDetail_in_explainOption1578 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DEBUG_in_explainOption1588 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ONLY_in_vectorizationOnly1615 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SUMMARY_in_vectorizatonDetail1652 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_OPERATOR_in_vectorizatonDetail1670 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXPRESSION_in_vectorizatonDetail1688 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DETAIL_in_vectorizatonDetail1706 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_queryStatementExpression_in_execStatement1743 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_loadStatement_in_execStatement1751 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_exportStatement_in_execStatement1759 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_importStatement_in_execStatement1767 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_replDumpStatement_in_execStatement1775 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_replLoadStatement_in_execStatement1783 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_replStatusStatement_in_execStatement1791 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_ddlStatement_in_execStatement1799 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_deleteStatement_in_execStatement1807 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_updateStatement_in_execStatement1815 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_sqlTransactionStatement_in_execStatement1823 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_mergeStatement_in_execStatement1831 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOAD_in_loadStatement1858 = new BitSet(new long[]{0x0000000000000000L,0x0000000000800000L});
	public static final BitSet FOLLOW_KW_DATA_in_loadStatement1860 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000002000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_LOCAL_in_loadStatement1865 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_KW_INPATH_in_loadStatement1869 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_loadStatement1874 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000100000000000L,0x0000040000000000L});
	public static final BitSet FOLLOW_KW_OVERWRITE_in_loadStatement1880 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_INTO_in_loadStatement1884 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_loadStatement1886 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableOrPartition_in_loadStatement1891 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_inputFileFormat_in_loadStatement1894 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FOR_in_replicationClause1949 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L,0x0000000000008000L});
	public static final BitSet FOLLOW_KW_METADATA_in_replicationClause1954 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
	public static final BitSet FOLLOW_KW_REPLICATION_in_replicationClause1958 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_replicationClause1960 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_replicationClause1965 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_replicationClause1968 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXPORT_in_exportStatement2012 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_exportStatement2020 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableOrPartition_in_exportStatement2025 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
	public static final BitSet FOLLOW_KW_TO_in_exportStatement2034 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_exportStatement2039 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_replicationClause_in_exportStatement2048 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_IMPORT_in_importStatement2098 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200020L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_EXTERNAL_in_importStatement2113 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_importStatement2117 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableOrPartition_in_importStatement2122 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_FROM_in_importStatement2136 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_importStatement2141 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
	public static final BitSet FOLLOW_tableLocation_in_importStatement2153 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REPL_in_replDumpStatement2207 = new BitSet(new long[]{0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_DUMP_in_replDumpStatement2209 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_replDbPolicy_in_replDumpStatement2222 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000200000L,0x0000000000000000L,0x0000000000004000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_REPLACE_in_replDumpStatement2234 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_replDbPolicy_in_replDumpStatement2238 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000200000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_FROM_in_replDumpStatement2251 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_replDumpStatement2256 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x2000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000020L});
	public static final BitSet FOLLOW_KW_TO_in_replDumpStatement2270 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_replDumpStatement2275 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x2000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_LIMIT_in_replDumpStatement2291 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_replDumpStatement2296 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_replDumpStatement2321 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_replConfigs_in_replDumpStatement2325 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_replDbPolicy2412 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_DOT_in_replDbPolicy2416 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_replTableLevelPolicy_in_replDbPolicy2420 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REPL_in_replLoadStatement2460 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x8000000000000000L});
	public static final BitSet FOLLOW_KW_LOAD_in_replLoadStatement2462 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61381E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_replLoadStatement2475 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_FROM_in_replLoadStatement2487 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_replLoadStatement2492 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_replLoadStatement2504 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_replConfigs_in_replLoadStatement2508 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_replConfigs2572 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_replConfigsList_in_replConfigs2574 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_replConfigs2576 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_keyValueProperty_in_replConfigsList2617 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_replConfigsList2620 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_keyValueProperty_in_replConfigsList2622 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_StringLiteral_in_replTableLevelPolicy2670 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_DOT_in_replTableLevelPolicy2674 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_replTableLevelPolicy2678 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REPL_in_replStatusStatement2729 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_STATUS_in_replStatusStatement2731 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_replStatusStatement2744 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_replStatusStatement2756 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_replConfigs_in_replStatusStatement2760 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createDatabaseStatement_in_ddlStatement2810 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_switchDatabaseStatement_in_ddlStatement2818 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropDatabaseStatement_in_ddlStatement2826 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createTableStatement_in_ddlStatement2834 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropTableStatement_in_ddlStatement2842 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_truncateTableStatement_in_ddlStatement2850 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatement_in_ddlStatement2858 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_descStatement_in_ddlStatement2866 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showStatement_in_ddlStatement2874 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_metastoreCheck_in_ddlStatement2882 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createViewStatement_in_ddlStatement2890 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createMaterializedViewStatement_in_ddlStatement2898 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createScheduledQueryStatement_in_ddlStatement2906 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterScheduledQueryStatement_in_ddlStatement2914 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropScheduledQueryStatement_in_ddlStatement2922 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropViewStatement_in_ddlStatement2930 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropMaterializedViewStatement_in_ddlStatement2938 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createFunctionStatement_in_ddlStatement2946 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createMacroStatement_in_ddlStatement2954 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropFunctionStatement_in_ddlStatement2962 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_reloadFunctionsStatement_in_ddlStatement2970 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropMacroStatement_in_ddlStatement2978 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_analyzeStatement_in_ddlStatement2986 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_lockStatement_in_ddlStatement2994 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_unlockStatement_in_ddlStatement3002 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_lockDatabase_in_ddlStatement3010 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_unlockDatabase_in_ddlStatement3018 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createRoleStatement_in_ddlStatement3026 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_dropRoleStatement_in_ddlStatement3034 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_grantPrivileges_in_ddlStatement3048 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_revokePrivileges_in_ddlStatement3062 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showGrants_in_ddlStatement3070 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showRoleGrants_in_ddlStatement3078 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showRolePrincipals_in_ddlStatement3086 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showRoles_in_ddlStatement3094 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_grantRole_in_ddlStatement3102 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_revokeRole_in_ddlStatement3110 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_setRole_in_ddlStatement3118 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showCurrentRole_in_ddlStatement3126 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_abortTransactionStatement_in_ddlStatement3134 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_killQueryStatement_in_ddlStatement3142 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_resourcePlanDdlStatements_in_ddlStatement3150 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_IF_in_ifExists3177 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_EXISTS_in_ifExists3179 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RESTRICT_in_restrictOrCascade3216 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CASCADE_in_restrictOrCascade3234 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_IF_in_ifNotExists3271 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_NOT_in_ifNotExists3273 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_EXISTS_in_ifNotExists3275 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FORCE_in_force3312 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ENABLE_in_rewriteEnabled3349 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_KW_REWRITE_in_rewriteEnabled3351 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DISABLE_in_rewriteDisabled3388 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_KW_REWRITE_in_rewriteDisabled3390 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STORED_in_storedAsDirs3427 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_storedAsDirs3429 = new BitSet(new long[]{0x0000000000000000L,0x0000020000000000L});
	public static final BitSet FOLLOW_KW_DIRECTORIES_in_storedAsDirs3431 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_OR_in_orReplace3468 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
	public static final BitSet FOLLOW_KW_REPLACE_in_orReplace3470 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createDatabaseStatement3507 = new BitSet(new long[]{0x0000000000000000L,0x0000000001000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_createDatabaseStatement3510 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0ECE1181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_createDatabaseStatement3512 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0ECE1181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_ifNotExists_in_createDatabaseStatement3523 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_createDatabaseStatement3536 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000020L,0x0000000000000000L,0x0000000000000082L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_databaseComment_in_createDatabaseStatement3546 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000082L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_dbLocation_in_createDatabaseStatement3557 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_dbManagedLocation_in_createDatabaseStatement3568 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_createDatabaseStatement3580 = new BitSet(new long[]{0x0000000000000000L,0x0000000020000000L});
	public static final BitSet FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement3582 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_dbProperties_in_createDatabaseStatement3586 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCATION_in_dbLocation3650 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_dbLocation3654 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MANAGEDLOCATION_in_dbManagedLocation3696 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_dbManagedLocation3700 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_dbProperties3742 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_dbPropertiesList_in_dbProperties3744 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_dbProperties3746 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList3787 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_dbPropertiesList3790 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList3792 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_KW_USE_in_switchDatabaseStatement3831 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_switchDatabaseStatement3833 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropDatabaseStatement3872 = new BitSet(new long[]{0x0000000000000000L,0x0000000001000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_dropDatabaseStatement3875 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0ECE1181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_dropDatabaseStatement3877 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0ECE1181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_ifExists_in_dropDatabaseStatement3880 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_dropDatabaseStatement3883 = new BitSet(new long[]{0x0100000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_restrictOrCascade_in_dropDatabaseStatement3885 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COMMENT_in_databaseComment3931 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_databaseComment3935 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createTableStatement3975 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000020L,0x0000000000000000L,0x4400000000000000L,0x0000000000000100L});
	public static final BitSet FOLLOW_KW_TEMPORARY_in_createTableStatement3980 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000020L,0x0000000000000000L,0x0400000000000000L,0x0000000000000100L});
	public static final BitSet FOLLOW_KW_TRANSACTIONAL_in_createTableStatement3987 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000020L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_EXTERNAL_in_createTableStatement3994 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_createTableStatement3998 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0ECE1181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_ifNotExists_in_createTableStatement4000 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_createTableStatement4005 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000021L,0x1000000000000000L,0x0000200000000002L,0x2010080004000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_LIKE_in_createTableStatement4018 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_createTableStatement4022 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x2010000004000000L});
	public static final BitSet FOLLOW_tableRowFormat_in_createTableStatement4033 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x2010000000000000L});
	public static final BitSet FOLLOW_tableFileFormat_in_createTableStatement4045 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x2000000000000000L});
	public static final BitSet FOLLOW_tableLocation_in_createTableStatement4057 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement4069 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_createTableStatement4082 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8177B7L,0xE8FDC0EC611C1E0EL,0x7B1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDED43D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameTypeOrConstraintList_in_createTableStatement4084 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_createTableStatement4086 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000021L,0x0000000000000000L,0x0000200000000002L,0x2010080004000000L});
	public static final BitSet FOLLOW_tableComment_in_createTableStatement4099 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000001L,0x0000000000000000L,0x0000200000000002L,0x2010080004000000L});
	public static final BitSet FOLLOW_createTablePartitionSpec_in_createTableStatement4111 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000001L,0x0000000000000000L,0x0000000000000002L,0x2010080004000000L});
	public static final BitSet FOLLOW_tableBuckets_in_createTableStatement4123 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x2010080004000000L});
	public static final BitSet FOLLOW_tableSkewed_in_createTableStatement4135 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x2010000004000000L});
	public static final BitSet FOLLOW_tableRowFormat_in_createTableStatement4147 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x2010000000000000L});
	public static final BitSet FOLLOW_tableFileFormat_in_createTableStatement4159 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x2000000000000000L});
	public static final BitSet FOLLOW_tableLocation_in_createTableStatement4171 = new BitSet(new long[]{0x0000020000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement4183 = new BitSet(new long[]{0x0000020000000002L});
	public static final BitSet FOLLOW_KW_AS_in_createTableStatement4196 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L,0x0000000200000020L,0x0080200000000000L});
	public static final BitSet FOLLOW_selectStatementWithCTE_in_createTableStatement4198 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TRUNCATE_in_truncateTableStatement4409 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_truncateTableStatement4411 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tablePartitionPrefix_in_truncateTableStatement4413 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000010L,0x0000000000020000L});
	public static final BitSet FOLLOW_KW_COLUMNS_in_truncateTableStatement4416 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_truncateTableStatement4418 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_truncateTableStatement4420 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_truncateTableStatement4422 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_force_in_truncateTableStatement4426 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropTableStatement4467 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_dropTableStatement4469 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0ECE1181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_ifExists_in_dropTableStatement4471 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_dropTableStatement4474 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000010000L,0x0800000000000000L});
	public static final BitSet FOLLOW_KW_PURGE_in_dropTableStatement4476 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_replicationClause_in_dropTableStatement4479 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4528 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_alterStatement4530 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_alterStatement4532 = new BitSet(new long[]{0x1000008020000000L,0x1004000000000481L,0x0000100000000000L,0x0000100002000000L,0x0000084000004400L,0x0000000002804040L});
	public static final BitSet FOLLOW_alterTableStatementSuffix_in_alterStatement4534 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4552 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_alterStatement4554 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_alterStatement4556 = new BitSet(new long[]{0x0000020020000000L,0x0004000000000000L,0x0000000000000000L,0x0000000000000200L,0x0000004200000420L,0x0080200000800000L});
	public static final BitSet FOLLOW_KW_AS_in_alterStatement4558 = new BitSet(new long[]{0x0000000020000000L,0x0004000000000000L,0x0000000000000000L,0x0000000000000200L,0x0000004200000420L,0x0080200000800000L});
	public static final BitSet FOLLOW_alterViewStatementSuffix_in_alterStatement4561 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4579 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000002000L});
	public static final BitSet FOLLOW_KW_MATERIALIZED_in_alterStatement4581 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_alterStatement4583 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_alterStatement4587 = new BitSet(new long[]{0x0000000000000000L,0x0040080000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
	public static final BitSet FOLLOW_alterMaterializedViewStatementSuffix_in_alterStatement4589 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4602 = new BitSet(new long[]{0x0000000000000000L,0x0000000001000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_alterStatement4605 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_alterStatement4607 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_alterDatabaseStatementSuffix_in_alterStatement4610 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix4648 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix4657 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix4666 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix4675 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix4683 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix4691 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix4699 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix4707 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix4715 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementPartitionKeyType_in_alterTableStatementSuffix4723 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixDropConstraint_in_alterTableStatementSuffix4731 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixAddConstraint_in_alterTableStatementSuffix4739 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix4747 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_partitionSpec_in_alterTableStatementSuffix4756 = new BitSet(new long[]{0x1000000020000000L,0x0000000000000481L,0x0000100000000000L,0x0000000002000000L,0x0000004000004400L,0x0000000002000000L});
	public static final BitSet FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix4758 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixSetOwner_in_alterTableStatementSuffix4773 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix4799 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix4806 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix4813 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix4820 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix4827 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix4833 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix4840 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix4846 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixCompact_in_alterTblPartitionStatementSuffix4852 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTblPartitionStatementSuffix4858 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixUpdateStats_in_alterTblPartitionStatementSuffix4865 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixRenameCol_in_alterTblPartitionStatementSuffix4872 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixAddCol_in_alterTblPartitionStatementSuffix4878 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixUpdateColumns_in_alterTblPartitionStatementSuffix4884 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_PARTITION_in_alterStatementPartitionKeyType4906 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000008L});
	public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementPartitionKeyType4908 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_alterStatementPartitionKeyType4910 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameType_in_alterStatementPartitionKeyType4912 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_alterStatementPartitionKeyType4914 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix4947 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix4955 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix4964 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix4973 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_selectStatementWithCTE_in_alterViewStatementSuffix4982 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterMaterializedViewSuffixRewrite_in_alterMaterializedViewStatementSuffix5010 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterMaterializedViewSuffixRebuild_in_alterMaterializedViewStatementSuffix5019 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rewriteEnabled_in_alterMaterializedViewSuffixRewrite5051 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rewriteDisabled_in_alterMaterializedViewSuffixRewrite5057 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REBUILD_in_alterMaterializedViewSuffixRebuild5101 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix5136 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterDatabaseSuffixSetOwner_in_alterDatabaseStatementSuffix5144 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterDatabaseSuffixSetLocation_in_alterDatabaseStatementSuffix5152 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixProperties5181 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixProperties5183 = new BitSet(new long[]{0x0000000000000000L,0x0000000020000000L});
	public static final BitSet FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties5185 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_dbProperties_in_alterDatabaseSuffixProperties5187 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixSetOwner5231 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixSetOwner5233 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000080000000000L});
	public static final BitSet FOLLOW_KW_OWNER_in_alterDatabaseSuffixSetOwner5235 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000000400000L,0x0000000010000000L});
	public static final BitSet FOLLOW_principalName_in_alterDatabaseSuffixSetOwner5237 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixSetLocation5281 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixSetLocation5283 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCATION_in_alterDatabaseSuffixSetLocation5285 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_alterDatabaseSuffixSetLocation5289 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixSetLocation5315 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixSetLocation5317 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
	public static final BitSet FOLLOW_KW_MANAGEDLOCATION_in_alterDatabaseSuffixSetLocation5319 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_alterDatabaseSuffixSetLocation5323 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixSetManagedLocation5368 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixSetManagedLocation5370 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
	public static final BitSet FOLLOW_KW_MANAGEDLOCATION_in_alterDatabaseSuffixSetManagedLocation5372 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_alterDatabaseSuffixSetManagedLocation5376 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRename5420 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
	public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRename5422 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_alterStatementSuffixRename5424 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddCol5491 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol5497 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol5500 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_alterStatementSuffixAddCol5502 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol5504 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_alterStatementSuffixAddCol5506 = new BitSet(new long[]{0x0100000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixAddCol5508 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddConstraint5584 = new BitSet(new long[]{0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_alterForeignKeyWithName_in_alterStatementSuffixAddConstraint5589 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterConstraintWithName_in_alterStatementSuffixAddConstraint5593 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateColumns5658 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_COLUMNS_in_alterStatementSuffixUpdateColumns5660 = new BitSet(new long[]{0x0100000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixUpdateColumns5662 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_alterStatementSuffixDropConstraint5702 = new BitSet(new long[]{0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_alterStatementSuffixDropConstraint5704 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementSuffixDropConstraint5708 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol5745 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167BFL,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol5747 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol5752 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol5756 = new BitSet(new long[]{0x2007010000000000L,0x000100008C000000L,0x0000020000002000L,0x0000000000000200L,0x00C0100000000000L,0x000000080004001CL});
	public static final BitSet FOLLOW_colType_in_alterStatementSuffixRenameCol5758 = new BitSet(new long[]{0x4100000080000002L,0x0000000100001020L,0x0000000000001000L,0x0100000002000000L,0x0000000000020040L,0x0000000000080000L});
	public static final BitSet FOLLOW_alterColumnConstraint_in_alterStatementSuffixRenameCol5760 = new BitSet(new long[]{0x0100000080000002L,0x0000000000000020L,0x0000000000001000L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol5765 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol5769 = new BitSet(new long[]{0x0100000080000002L,0x0000000000000000L,0x0000000000001000L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol5773 = new BitSet(new long[]{0x0100000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixRenameCol5776 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStatsCol5835 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0004000000000000L});
	public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStatsCol5837 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_FOR_in_alterStatementSuffixUpdateStatsCol5839 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167BFL,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixUpdateStatsCol5841 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementSuffixUpdateStatsCol5846 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixUpdateStatsCol5848 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixUpdateStatsCol5850 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000020L});
	public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixUpdateStatsCol5853 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixUpdateStatsCol5857 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStats5940 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0004000000000000L});
	public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStats5942 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixUpdateStats5944 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixUpdateStats5946 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FIRST_in_alterStatementChangeColPosition6004 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_AFTER_in_alterStatementChangeColPosition6006 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementChangeColPosition6010 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions6063 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000080000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions6065 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions6068 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement6131 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
	public static final BitSet FOLLOW_partitionLocation_in_alterStatementSuffixAddPartitionsElement6133 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch6161 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixTouch6164 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive6208 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixArchive6211 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive6255 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive6258 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_LOCATION_in_partitionLocation6308 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_partitionLocation6312 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions6349 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000080000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixDropPartitions6351 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions6354 = new BitSet(new long[]{0x0000000000000202L,0x0000000000000000L,0x0000000000010000L,0x0800000000000000L});
	public static final BitSet FOLLOW_COMMA_in_alterStatementSuffixDropPartitions6357 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions6359 = new BitSet(new long[]{0x0000000000000202L,0x0000000000000000L,0x0000000000010000L,0x0800000000000000L});
	public static final BitSet FOLLOW_KW_PURGE_in_alterStatementSuffixDropPartitions6363 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_replicationClause_in_alterStatementSuffixDropPartitions6366 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixProperties6448 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties6450 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties6452 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNSET_in_alterStatementSuffixProperties6472 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties6474 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000080000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixProperties6476 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties6479 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterViewSuffixProperties6521 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties6523 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties6525 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNSET_in_alterViewSuffixProperties6545 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties6547 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000080000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_ifExists_in_alterViewSuffixProperties6549 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties6552 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties6595 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties6597 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties6601 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties6604 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
	public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties6606 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties6608 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties6665 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
	public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties6667 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties6669 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableName_in_tablePartitionPrefix6733 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_tablePartitionPrefix6735 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixFileFormat6772 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat6774 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_fileFormat_in_alterStatementSuffixFileFormat6776 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6834 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby6836 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6850 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000800000000000L});
	public static final BitSet FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby6852 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby6866 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation6897 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000080000000000L});
	public static final BitSet FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation6899 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation6901 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation6903 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_skewedLocations6946 = new BitSet(new long[]{0x0000000002001000L,0x0000000004300000L,0x0000000000000080L,0x0000000008000000L,0x0000000000000000L,0x608000000000100CL,0x0000000000000200L});
	public static final BitSet FOLLOW_skewedLocationsList_in_skewedLocations6948 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_skewedLocations6950 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList6991 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_skewedLocationsList6994 = new BitSet(new long[]{0x0000000002001000L,0x0000000004300000L,0x0000000000000080L,0x0000000008000000L,0x0000000000000000L,0x608000000000100CL,0x0000000000000200L});
	public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList6996 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_skewedValueLocationElement_in_skewedLocationMap7042 = new BitSet(new long[]{0x0000000000040000L});
	public static final BitSet FOLLOW_EQUAL_in_skewedLocationMap7044 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_skewedLocationMap7048 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixLocation7086 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCATION_in_alterStatementSuffixLocation7088 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixLocation7092 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby7152 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby7167 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000080000000000L});
	public static final BitSet FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby7169 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby7182 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
	public static final BitSet FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby7184 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition7215 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition7217 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition7219 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition7221 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_alterStatementSuffixExchangePartition7225 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart7267 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
	public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRenamePart7269 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart7271 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixStatsPart7309 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0004000000000000L});
	public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixStatsPart7311 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_FOR_in_alterStatementSuffixStatsPart7313 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167BFL,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixStatsPart7315 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_alterStatementSuffixStatsPart7320 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixStatsPart7322 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixStatsPart7324 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000020L});
	public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixStatsPart7327 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixStatsPart7331 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles7379 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum7442 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_alterStatementSuffixBucketNum7446 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum7448 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_AND_in_blocking7504 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_WAIT_in_blocking7506 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COMPACT_in_alterStatementSuffixCompact7537 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixCompact7541 = new BitSet(new long[]{0x0000001000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_blocking_in_alterStatementSuffixCompact7543 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixCompact7547 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000040000000000L});
	public static final BitSet FOLLOW_KW_OVERWRITE_in_alterStatementSuffixCompact7549 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixCompact7551 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixCompact7553 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSetOwner7601 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000080000000000L});
	public static final BitSet FOLLOW_KW_OWNER_in_alterStatementSuffixSetOwner7603 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000000400000L,0x0000000010000000L});
	public static final BitSet FOLLOW_principalName_in_alterStatementSuffixSetOwner7605 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INPUTFORMAT_in_fileFormat7644 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_fileFormat7648 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_fileFormat7650 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_fileFormat7654 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SERDE_in_fileFormat7656 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_fileFormat7660 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_INPUTDRIVER_in_fileFormat7663 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_fileFormat7667 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_fileFormat7669 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_fileFormat7673 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_fileFormat7714 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INPUTFORMAT_in_inputFileFormat7750 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_inputFileFormat7754 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SERDE_in_inputFileFormat7756 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_inputFileFormat7760 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_tabTypeExpr7804 = new BitSet(new long[]{0xD9B06C8AFD010002L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_DOT_in_tabTypeExpr7807 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_tabTypeExpr7810 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_tabTypeExpr7818 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_DOT_in_tabTypeExpr7821 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr7838 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_KW_KEY_TYPE_in_tabTypeExpr7855 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr7872 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_identifier_in_tabTypeExpr7880 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_tabTypeExpr_in_partTypeExpr7920 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_partTypeExpr7922 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableName_in_tabPartColTypeExpr7962 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EFD8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_partitionSpec_in_tabPartColTypeExpr7964 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_extColumnName_in_tabPartColTypeExpr7967 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement8014 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777B8167B7L,0xE8FDC0EC61981E1EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_DESC_in_descStatement8016 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777B8167B7L,0xE8FDC0EC61981E1EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_descStatement8038 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E1EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_descStatement8040 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E1EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement8043 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_descStatement8049 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FUNCTION_in_descStatement8080 = new BitSet(new long[]{0xDBB7ED9AFD6C6070L,0xE75BEF777A8167B7L,0xF8FDC2EEE1187E1EL,0x7A1EED8E57B6BFBEL,0xE9FDFFBDF0EBFF9DL,0x9C37CBF5CDE543D0L,0x0001000000000700L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement8082 = new BitSet(new long[]{0xDBB7ED9AFD6C6070L,0xE75BEF777A8167B7L,0xF8FDC2EEE1187E0EL,0x7A1EED8E57B6BFBEL,0xE9FDFFBDF0EBFF9DL,0x9C37CBF5CDE543D0L,0x0001000000000700L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_descFuncNames_in_descStatement8088 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FORMATTED_in_descStatement8125 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement8129 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tabPartColTypeExpr_in_descStatement8134 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tabPartColTypeExpr_in_descStatement8161 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ANALYZE_in_analyzeStatement8203 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_analyzeStatement8205 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableOrPartition_in_analyzeStatement8210 = new BitSet(new long[]{0x0080000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_KW_COMPUTE_in_analyzeStatement8233 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0004000000000000L});
	public static final BitSet FOLLOW_KW_STATISTICS_in_analyzeStatement8235 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000010000L,0x0000000001000000L});
	public static final BitSet FOLLOW_KW_NOSCAN_in_analyzeStatement8241 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FOR_in_analyzeStatement8301 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_COLUMNS_in_analyzeStatement8303 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_analyzeStatement8308 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CACHE_in_analyzeStatement8361 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
	public static final BitSet FOLLOW_KW_METADATA_in_analyzeStatement8363 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8407 = new BitSet(new long[]{0x0000000000000000L,0x0000000002000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_DATABASES_in_showStatement8410 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x1000000000000000L});
	public static final BitSet FOLLOW_KW_SCHEMAS_in_showStatement8412 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x1000000000000000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement8416 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8418 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8437 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000010L,0x0000000000000000L,0x0800000000000000L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement8442 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0800000000000000L});
	public static final BitSet FOLLOW_KW_TABLES_in_showStatement8446 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xF8FDC0EE61381E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007CDF5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement8450 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement8452 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8457 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xF8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007CDF5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_showTablesFilterExpr_in_showStatement8464 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8500 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_VIEWS_in_showStatement8502 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xF8FDC0EE61381E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement8506 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement8508 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8513 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xF8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement8518 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8520 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8522 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8550 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000002000L});
	public static final BitSet FOLLOW_KW_MATERIALIZED_in_showStatement8552 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_VIEWS_in_showStatement8554 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xF8FDC0EE61381E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement8558 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement8560 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8565 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xF8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement8570 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8572 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8574 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8602 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_COLUMNS_in_showStatement8604 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000200200000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement8607 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement8609 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_showStatement8612 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xF8FDC0EE61381E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement8616 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement8618 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8623 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777A8167B7L,0xF8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement8628 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8630 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8632 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8665 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
	public static final BitSet FOLLOW_KW_FUNCTIONS_in_showStatement8667 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x1000000000000000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement8670 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_showFunctionIdentifier_in_showStatement8672 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8695 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_KW_PARTITIONS_in_showStatement8697 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_showStatement8701 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_showStatement8703 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8725 = new BitSet(new long[]{0x0000000000000000L,0x0000000000008000L});
	public static final BitSet FOLLOW_KW_CREATE_in_showStatement8727 = new BitSet(new long[]{0x0000000000000000L,0x0000000001000000L,0x0000000000000000L,0x0000000000000000L,0x0400000040000000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_showStatement8748 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_showStatement8750 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8755 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TABLE_in_showStatement8784 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_showStatement8788 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8813 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_showStatement8815 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement8817 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x1000000200200000L});
	public static final BitSet FOLLOW_KW_FROM_in_showStatement8821 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_IN_in_showStatement8823 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8828 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x1000000000000000L});
	public static final BitSet FOLLOW_KW_LIKE_in_showStatement8832 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement8834 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_showStatement8836 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8864 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_showStatement8866 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_showStatement8868 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_showStatement8871 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_showStatement8875 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_showStatement8877 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement8899 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000008L});
	public static final BitSet FOLLOW_KW_LOCKS_in_showStatement8901 = new BitSet(new long[]{0xD9B06C8AFD000002L,0xE75AEF777B8167B7L,0xE8FDC0EC61181E1EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_showStatement8927 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_showStatement8929 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_showStatement8935 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement8941 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_partTypeExpr_in_showStatement8975 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement8982 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement9014 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000100L});
	public static final BitSet FOLLOW_KW_COMPACTIONS_in_showStatement9016 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement9030 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_KW_TRANSACTIONS_in_showStatement9032 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement9046 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000800L});
	public static final BitSet FOLLOW_KW_CONF_in_showStatement9048 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_showStatement9050 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showStatement9066 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_RESOURCE_in_showStatement9068 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0006000000000000L});
	public static final BitSet FOLLOW_KW_PLAN_in_showStatement9087 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_showStatement9091 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_PLANS_in_showStatement9114 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WHERE_in_showTablesFilterExpr9156 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_showTablesFilterExpr9158 = new BitSet(new long[]{0x0000000000040000L});
	public static final BitSet FOLLOW_EQUAL_in_showTablesFilterExpr9160 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_showTablesFilterExpr9162 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LIKE_in_showTablesFilterExpr9184 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showTablesFilterExpr9186 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_showStmtIdentifier_in_showTablesFilterExpr9188 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCK_in_lockStatement9223 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_lockStatement9225 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_lockStatement9227 = new BitSet(new long[]{0x0000000000000000L,0x2000000000000000L,0x0000000000000000L,0x0000100000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_lockStatement9229 = new BitSet(new long[]{0x0000000000000000L,0x2000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_lockMode_in_lockStatement9232 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCK_in_lockDatabase9272 = new BitSet(new long[]{0x0000000000000000L,0x0000000001000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_lockDatabase9275 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_lockDatabase9277 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_lockDatabase9283 = new BitSet(new long[]{0x0000000000000000L,0x2000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_lockMode_in_lockDatabase9286 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNLOCK_in_unlockStatement9355 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_unlockStatement9357 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_unlockStatement9359 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_unlockStatement9361 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNLOCK_in_unlockDatabase9401 = new BitSet(new long[]{0x0000000000000000L,0x0000000001000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_DATABASE_in_unlockDatabase9404 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_unlockDatabase9406 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_unlockDatabase9412 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createRoleStatement9449 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
	public static final BitSet FOLLOW_KW_ROLE_in_createRoleStatement9451 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_createRoleStatement9455 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropRoleStatement9495 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
	public static final BitSet FOLLOW_KW_ROLE_in_dropRoleStatement9497 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_dropRoleStatement9501 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_GRANT_in_grantPrivileges9541 = new BitSet(new long[]{0x0000000500000000L,0x0004000800008000L,0x0000010000000000L,0x0000000000000004L,0x0000040200000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_privilegeList_in_grantPrivileges9545 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L,0x0000000000000000L,0x0000000000000020L});
	public static final BitSet FOLLOW_privilegeObject_in_grantPrivileges9553 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
	public static final BitSet FOLLOW_KW_TO_in_grantPrivileges9562 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000000400000L,0x0000000010000000L});
	public static final BitSet FOLLOW_principalSpecification_in_grantPrivileges9564 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_withGrantOption_in_grantPrivileges9572 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REVOKE_in_revokePrivileges9621 = new BitSet(new long[]{0x0000000500000000L,0x0004000800008000L,0x0000010002000000L,0x0000000000000004L,0x0000040200000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_grantOptionFor_in_revokePrivileges9623 = new BitSet(new long[]{0x0000000500000000L,0x0004000800008000L,0x0000010000000000L,0x0000000000000004L,0x0000040200000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_privilegeList_in_revokePrivileges9626 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L,0x0000000080000000L});
	public static final BitSet FOLLOW_privilegeObject_in_revokePrivileges9628 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_FROM_in_revokePrivileges9631 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000000400000L,0x0000000010000000L});
	public static final BitSet FOLLOW_principalSpecification_in_revokePrivileges9633 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_GRANT_in_grantRole9680 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_ROLE_in_grantRole9682 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_grantRole9685 = new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
	public static final BitSet FOLLOW_COMMA_in_grantRole9688 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_grantRole9690 = new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
	public static final BitSet FOLLOW_KW_TO_in_grantRole9694 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000000400000L,0x0000000010000000L});
	public static final BitSet FOLLOW_principalSpecification_in_grantRole9696 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_withAdminOption_in_grantRole9698 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_REVOKE_in_revokeRole9744 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_adminOptionFor_in_revokeRole9746 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_ROLE_in_revokeRole9749 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_revokeRole9752 = new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000200000L});
	public static final BitSet FOLLOW_COMMA_in_revokeRole9755 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_revokeRole9757 = new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_FROM_in_revokeRole9761 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000000400000L,0x0000000010000000L});
	public static final BitSet FOLLOW_principalSpecification_in_revokeRole9763 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showRoleGrants9808 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
	public static final BitSet FOLLOW_KW_ROLE_in_showRoleGrants9810 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_GRANT_in_showRoleGrants9812 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000000400000L,0x0000000010000000L});
	public static final BitSet FOLLOW_principalName_in_showRoleGrants9814 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showRoles9854 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
	public static final BitSet FOLLOW_KW_ROLES_in_showRoles9856 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showCurrentRole9893 = new BitSet(new long[]{0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_KW_CURRENT_in_showCurrentRole9895 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
	public static final BitSet FOLLOW_KW_ROLES_in_showCurrentRole9897 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_setRole9934 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
	public static final BitSet FOLLOW_KW_ROLE_in_setRole9936 = new BitSet(new long[]{0xD9B06C8BFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655F6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_ALL_in_setRole9958 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NONE_in_setRole9989 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_setRole10011 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showGrants10052 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_GRANT_in_showGrants10054 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000004000000L,0x0000000080000000L,0x0000000000400000L,0x0000000010000000L});
	public static final BitSet FOLLOW_principalName_in_showGrants10056 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_ON_in_showGrants10060 = new BitSet(new long[]{0xD9B06C8BFD000000L,0xE75AEF777B8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xEDFDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_privilegeIncludeColObject_in_showGrants10062 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_in_showRolePrincipals10107 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0200000000000000L});
	public static final BitSet FOLLOW_KW_PRINCIPALS_in_showRolePrincipals10109 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_showRolePrincipals10113 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALL_in_privilegeIncludeColObject10160 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_privObjectCols_in_privilegeIncludeColObject10174 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ON_in_privilegeObject10209 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777B8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xEDFDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_privObject_in_privilegeObject10211 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DATABASE_in_privObject10238 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_privObject10240 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_privObject10243 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TABLE_in_privObject10259 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_privObject10262 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_privObject10264 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_URI_in_privObject10284 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_privObject10289 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SERVER_in_privObject10308 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_privObject10310 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DATABASE_in_privObjectCols10336 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SCHEMA_in_privObjectCols10338 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_privObjectCols10341 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TABLE_in_privObjectCols10357 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_privObjectCols10360 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_privObjectCols10363 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_privObjectCols10367 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_privObjectCols10369 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_partitionSpec_in_privObjectCols10373 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_URI_in_privObjectCols10397 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_privObjectCols10402 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SERVER_in_privObjectCols10421 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_privObjectCols10423 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_privlegeDef_in_privilegeList10458 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_privilegeList10461 = new BitSet(new long[]{0x0000000500000000L,0x0004000800008000L,0x0000010000000000L,0x0000000000000004L,0x0000040200000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_privlegeDef_in_privilegeList10463 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_privilegeType_in_privlegeDef10505 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_privlegeDef10508 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_privlegeDef10512 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_privlegeDef10514 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALL_in_privilegeType10559 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALTER_in_privilegeType10573 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_privilegeType10587 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_privilegeType10601 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_privilegeType10615 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCK_in_privilegeType10629 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SELECT_in_privilegeType10643 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SHOW_DATABASE_in_privilegeType10657 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INSERT_in_privilegeType10671 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DELETE_in_privilegeType10685 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_principalName_in_principalSpecification10718 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_principalSpecification10721 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000000400000L,0x0000000010000000L});
	public static final BitSet FOLLOW_principalName_in_principalSpecification10723 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_KW_USER_in_principalName10761 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000004L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_principalIdentifier_in_principalName10763 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_GROUP_in_principalName10779 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000004L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_principalIdentifier_in_principalName10781 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ROLE_in_principalName10797 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_principalName10799 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WITH_in_withGrantOption10834 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_GRANT_in_withGrantOption10836 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_KW_OPTION_in_withGrantOption10838 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_GRANT_in_grantOptionFor10875 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_KW_OPTION_in_grantOptionFor10877 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_FOR_in_grantOptionFor10879 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ADMIN_in_adminOptionFor10912 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_KW_OPTION_in_adminOptionFor10914 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
	public static final BitSet FOLLOW_KW_FOR_in_adminOptionFor10916 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WITH_in_withAdminOption10949 = new BitSet(new long[]{0x0000000040000000L});
	public static final BitSet FOLLOW_KW_ADMIN_in_withAdminOption10951 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_KW_OPTION_in_withAdminOption10953 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MSCK_in_metastoreCheck10990 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L,0x0400000000001000L});
	public static final BitSet FOLLOW_KW_REPAIR_in_metastoreCheck10995 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L,0x0400000000000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_metastoreCheck11006 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_metastoreCheck11008 = new BitSet(new long[]{0x0000000020000002L,0x0004000000000000L,0x0000000000000000L,0x0000000000000000L,0x0200000000000000L});
	public static final BitSet FOLLOW_KW_ADD_in_metastoreCheck11022 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_KW_DROP_in_metastoreCheck11028 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_KW_SYNC_in_metastoreCheck11034 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_KW_PARTITIONS_in_metastoreCheck11040 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_partitionSpec_in_metastoreCheck11056 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_resource_in_resourceList11121 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_resourceList11124 = new BitSet(new long[]{0x0000008000000000L,0x0000000000000000L,0x0001000000000400L});
	public static final BitSet FOLLOW_resource_in_resourceList11126 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_resourceType_in_resource11164 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_resource11168 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_JAR_in_resourceType11205 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FILE_in_resourceType11219 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ARCHIVE_in_resourceType11233 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createFunctionStatement11264 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000800000L,0x0000000000000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_KW_TEMPORARY_in_createFunctionStatement11269 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
	public static final BitSet FOLLOW_KW_FUNCTION_in_createFunctionStatement11273 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_functionIdentifier_in_createFunctionStatement11275 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_createFunctionStatement11277 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_createFunctionStatement11279 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
	public static final BitSet FOLLOW_KW_USING_in_createFunctionStatement11288 = new BitSet(new long[]{0x0000008000000000L,0x0000000000000000L,0x0001000000000400L});
	public static final BitSet FOLLOW_resourceList_in_createFunctionStatement11292 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropFunctionStatement11378 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000800000L,0x0000000000000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_KW_TEMPORARY_in_dropFunctionStatement11383 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
	public static final BitSet FOLLOW_KW_FUNCTION_in_dropFunctionStatement11387 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0ECE1181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_ifExists_in_dropFunctionStatement11389 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_functionIdentifier_in_dropFunctionStatement11392 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RELOAD_in_reloadFunctionsStatement11470 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000001800000L});
	public static final BitSet FOLLOW_KW_FUNCTIONS_in_reloadFunctionsStatement11473 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FUNCTION_in_reloadFunctionsStatement11475 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createMacroStatement11504 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_KW_TEMPORARY_in_createMacroStatement11506 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
	public static final BitSet FOLLOW_KW_MACRO_in_createMacroStatement11508 = new BitSet(new long[]{0x0000000001000000L});
	public static final BitSet FOLLOW_Identifier_in_createMacroStatement11510 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_createMacroStatement11518 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000010L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameTypeList_in_createMacroStatement11520 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_createMacroStatement11523 = new BitSet(new long[]{0xDFB76D8AFF001000L,0xE75BEF777EB167B7L,0xE8FDCAECE9187ECFL,0x7A1EED865FB6BFBEL,0xE9FDFFBDF0CBFF1DL,0xE487C9F5CDE553DCL,0x0001000000000600L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_expression_in_createMacroStatement11525 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropMacroStatement11569 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
	public static final BitSet FOLLOW_KW_TEMPORARY_in_dropMacroStatement11571 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
	public static final BitSet FOLLOW_KW_MACRO_in_dropMacroStatement11573 = new BitSet(new long[]{0x0000000001000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_ifExists_in_dropMacroStatement11575 = new BitSet(new long[]{0x0000000001000000L});
	public static final BitSet FOLLOW_Identifier_in_dropMacroStatement11578 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createViewStatement11620 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_orReplace_in_createViewStatement11623 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_createViewStatement11627 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0ECE1181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_ifNotExists_in_createViewStatement11630 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_createViewStatement11636 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000020L,0x0000000000000000L,0x0000200000000000L,0x2000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_createViewStatement11647 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameCommentList_in_createViewStatement11649 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_createViewStatement11651 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000020L,0x0000000000000000L,0x0000200000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_tableComment_in_createViewStatement11655 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_viewPartition_in_createViewStatement11658 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createViewStatement11669 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_createViewStatement11680 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L,0x0000000200000020L,0x0080200000000000L});
	public static final BitSet FOLLOW_selectStatementWithCTE_in_createViewStatement11690 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_PARTITIONED_in_viewPartition11813 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_ON_in_viewPartition11815 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_viewPartition11817 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_viewPartition11819 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_viewPartition11821 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_viewClusterSpec_in_viewOrganization11860 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_viewComplexSpec_in_viewOrganization11868 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CLUSTERED_in_viewClusterSpec11895 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_ON_in_viewClusterSpec11897 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_viewClusterSpec11899 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_viewClusterSpec11901 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_viewClusterSpec11903 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_viewDistSpec_in_viewComplexSpec11942 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000800000000000L});
	public static final BitSet FOLLOW_viewSortSpec_in_viewComplexSpec11944 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DISTRIBUTED_in_viewDistSpec11971 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_ON_in_viewDistSpec11973 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_viewDistSpec11975 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_viewDistSpec11979 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_viewDistSpec11981 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SORTED_in_viewSortSpec12021 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_ON_in_viewSortSpec12023 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_viewSortSpec12025 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_viewSortSpec12029 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_viewSortSpec12031 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropViewStatement12071 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_dropViewStatement12073 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0ECE1181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_ifExists_in_dropViewStatement12075 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_viewName_in_dropViewStatement12078 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createMaterializedViewStatement12116 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000002000L});
	public static final BitSet FOLLOW_KW_MATERIALIZED_in_createMaterializedViewStatement12118 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_createMaterializedViewStatement12120 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0ECE1181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_ifNotExists_in_createMaterializedViewStatement12123 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_createMaterializedViewStatement12129 = new BitSet(new long[]{0x0000020000000000L,0x0000480000000021L,0x0000000000000000L,0x0000200000000002L,0x2010000004000000L});
	public static final BitSet FOLLOW_rewriteDisabled_in_createMaterializedViewStatement12139 = new BitSet(new long[]{0x0000020000000000L,0x0000400000000021L,0x0000000000000000L,0x0000200000000002L,0x2010000004000000L});
	public static final BitSet FOLLOW_tableComment_in_createMaterializedViewStatement12142 = new BitSet(new long[]{0x0000020000000000L,0x0000400000000001L,0x0000000000000000L,0x0000200000000002L,0x2010000004000000L});
	public static final BitSet FOLLOW_viewPartition_in_createMaterializedViewStatement12145 = new BitSet(new long[]{0x0000020000000000L,0x0000400000000001L,0x0000000000000000L,0x0000000000000002L,0x2010000004000000L});
	public static final BitSet FOLLOW_viewOrganization_in_createMaterializedViewStatement12148 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x2010000004000000L});
	public static final BitSet FOLLOW_tableRowFormat_in_createMaterializedViewStatement12159 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x2010000000000000L});
	public static final BitSet FOLLOW_tableFileFormat_in_createMaterializedViewStatement12162 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x2000000000000000L});
	public static final BitSet FOLLOW_tableLocation_in_createMaterializedViewStatement12165 = new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createMaterializedViewStatement12176 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_createMaterializedViewStatement12179 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L,0x0000000200000020L,0x0080200000000000L});
	public static final BitSet FOLLOW_selectStatementWithCTE_in_createMaterializedViewStatement12181 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropMaterializedViewStatement12349 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000002000L});
	public static final BitSet FOLLOW_KW_MATERIALIZED_in_dropMaterializedViewStatement12351 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
	public static final BitSet FOLLOW_KW_VIEW_in_dropMaterializedViewStatement12353 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0ECE1181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_ifExists_in_dropMaterializedViewStatement12355 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_viewName_in_dropMaterializedViewStatement12358 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CREATE_in_createScheduledQueryStatement12396 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_KW_SCHEDULED_in_createScheduledQueryStatement12398 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_KW_QUERY_in_createScheduledQueryStatement12400 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_createScheduledQueryStatement12404 = new BitSet(new long[]{0x0000000000000000L,0x0400000000010000L});
	public static final BitSet FOLLOW_scheduleSpec_in_createScheduledQueryStatement12414 = new BitSet(new long[]{0x0000020000000000L,0x8040080400000000L});
	public static final BitSet FOLLOW_executedAsSpec_in_createScheduledQueryStatement12424 = new BitSet(new long[]{0x0000020000000000L,0x0040080400000000L});
	public static final BitSet FOLLOW_enableSpecification_in_createScheduledQueryStatement12435 = new BitSet(new long[]{0x0000020000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_definedAsSpec_in_createScheduledQueryStatement12446 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DROP_in_dropScheduledQueryStatement12569 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_KW_SCHEDULED_in_dropScheduledQueryStatement12571 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_KW_QUERY_in_dropScheduledQueryStatement12573 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_dropScheduledQueryStatement12577 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALTER_in_alterScheduledQueryStatement12643 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_KW_SCHEDULED_in_alterScheduledQueryStatement12645 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_KW_QUERY_in_alterScheduledQueryStatement12647 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_alterScheduledQueryStatement12651 = new BitSet(new long[]{0x0000020000000000L,0xC440080400010000L});
	public static final BitSet FOLLOW_alterScheduledQueryChange_in_alterScheduledQueryStatement12667 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_scheduleSpec_in_alterScheduledQueryChange12747 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_executedAsSpec_in_alterScheduledQueryChange12755 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_enableSpecification_in_alterScheduledQueryChange12763 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_definedAsSpec_in_alterScheduledQueryChange12771 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXECUTE_in_alterScheduledQueryChange12779 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CRON_in_scheduleSpec12816 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_scheduleSpec12820 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EVERY_in_scheduleSpec12841 = new BitSet(new long[]{0x0000000000000000L,0x0000000010000000L,0x0000000020000000L,0x0000000000060000L,0x0000000100000000L,0x2002000000000000L});
	public static final BitSet FOLLOW_Number_in_scheduleSpec12845 = new BitSet(new long[]{0x0000000000000000L,0x0000000010000000L,0x0000000020000000L,0x0000000000060000L,0x0000000100000000L,0x0002000000000000L});
	public static final BitSet FOLLOW_intervalQualifiers_in_scheduleSpec12850 = new BitSet(new long[]{0x0000080000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_AT_in_scheduleSpec12862 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_KW_OFFSET_in_scheduleSpec12864 = new BitSet(new long[]{0x0040000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_scheduleSpec12866 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_scheduleSpec12871 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXECUTED_in_executedAsSpec12930 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_executedAsSpec12932 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_executedAsSpec12936 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DEFINED_in_definedAsSpec12980 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_definedAsSpec12983 = new BitSet(new long[]{0x0000000C04000000L,0x004408C800008040L,0x8040010102200006L,0x0000000000204204L,0x0002024201046120L,0x008020000A202000L});
	public static final BitSet FOLLOW_statement_in_definedAsSpec12985 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_functionIdentifier_in_showFunctionIdentifier13024 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_StringLiteral_in_showFunctionIdentifier13032 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_showStmtIdentifier13059 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_StringLiteral_in_showStmtIdentifier13067 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COMMENT_in_tableComment13100 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableComment13104 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_PARTITIONED_in_createTablePartitionSpec13141 = new BitSet(new long[]{0x0040000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_createTablePartitionSpec13143 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_createTablePartitionSpec13145 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_createTablePartitionColumnTypeSpec_in_createTablePartitionSpec13152 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_createTablePartitionColumnSpec_in_createTablePartitionSpec13160 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_createTablePartitionSpec13163 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec13210 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_createTablePartitionColumnTypeSpec13213 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec13215 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_columnName_in_createTablePartitionColumnSpec13257 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_createTablePartitionColumnSpec13260 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnName_in_createTablePartitionColumnSpec13262 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_KW_CLUSTERED_in_tableBuckets13310 = new BitSet(new long[]{0x0040000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableBuckets13312 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_tableBuckets13314 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_tableBuckets13318 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_tableBuckets13320 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000100000000000L,0x0000000000000000L,0x0000800000000000L});
	public static final BitSet FOLLOW_KW_SORTED_in_tableBuckets13323 = new BitSet(new long[]{0x0040000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableBuckets13325 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_tableBuckets13327 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameOrderList_in_tableBuckets13331 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_tableBuckets13333 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_INTO_in_tableBuckets13337 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_tableBuckets13341 = new BitSet(new long[]{0x0020000000000000L});
	public static final BitSet FOLLOW_KW_BUCKETS_in_tableBuckets13343 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SKEWED_in_tableSkewed13395 = new BitSet(new long[]{0x0040000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableSkewed13397 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_tableSkewed13399 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_tableSkewed13403 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_tableSkewed13405 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_ON_in_tableSkewed13407 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_tableSkewed13409 = new BitSet(new long[]{0x0000000002001000L,0x0000000004300000L,0x0000000000000080L,0x0000000008000000L,0x0000000000000000L,0x608000000000100CL,0x0000000000000200L});
	public static final BitSet FOLLOW_skewedValueElement_in_tableSkewed13414 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_tableSkewed13417 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
	public static final BitSet FOLLOW_storedAsDirs_in_tableSkewed13426 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rowFormatSerde_in_rowFormat13474 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rowFormatDelimited_in_rowFormat13490 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RECORDREADER_in_recordReader13539 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_recordReader13541 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RECORDWRITER_in_recordWriter13590 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_recordWriter13592 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ROW_in_rowFormatSerde13641 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatSerde13643 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_SERDE_in_rowFormatSerde13645 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_rowFormatSerde13649 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_rowFormatSerde13652 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
	public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde13654 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_rowFormatSerde13658 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ROW_in_rowFormatDelimited13710 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatDelimited13712 = new BitSet(new long[]{0x0000000000000000L,0x0000001000000000L});
	public static final BitSet FOLLOW_KW_DELIMITED_in_rowFormatDelimited13714 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000004L,0x4000000000000200L,0x0000000008000200L});
	public static final BitSet FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited13716 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000004L,0x4000000000000000L,0x0000000008000200L});
	public static final BitSet FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited13719 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x4000000000000000L,0x0000000008000200L});
	public static final BitSet FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited13722 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x4000000000000000L,0x0000000008000000L});
	public static final BitSet FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited13725 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000008000000L});
	public static final BitSet FOLLOW_tableRowNullFormat_in_rowFormatDelimited13728 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rowFormatDelimited_in_tableRowFormat13787 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rowFormatSerde_in_tableRowFormat13807 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed13854 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_tablePropertiesPrefixed13857 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_tableProperties13890 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_tablePropertiesList_in_tableProperties13892 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_tableProperties13894 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList13935 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_tablePropertiesList13938 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList13940 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList13965 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_tablePropertiesList13968 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList13970 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty14016 = new BitSet(new long[]{0x0000000000040000L});
	public static final BitSet FOLLOW_EQUAL_in_keyValueProperty14018 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty14022 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_StringLiteral_in_keyProperty14069 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier14113 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000000L});
	public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier14115 = new BitSet(new long[]{0x0040000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier14117 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier14121 = new BitSet(new long[]{0x0000000000000002L,0x0200000000000000L});
	public static final BitSet FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier14124 = new BitSet(new long[]{0x0040000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier14126 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier14130 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier14182 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000800000000000L});
	public static final BitSet FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier14184 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000000L});
	public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier14186 = new BitSet(new long[]{0x0040000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier14188 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier14192 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier14238 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
	public static final BitSet FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier14240 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000000L});
	public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier14242 = new BitSet(new long[]{0x0040000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier14244 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier14248 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier14294 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000000L});
	public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier14296 = new BitSet(new long[]{0x0040000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier14298 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier14302 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NULL_in_tableRowNullFormat14348 = new BitSet(new long[]{0x0000000000000000L,0x0000000400000000L});
	public static final BitSet FOLLOW_KW_DEFINED_in_tableRowNullFormat14350 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_tableRowNullFormat14352 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableRowNullFormat14356 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat14411 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_tableFileFormat14413 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_INPUTFORMAT_in_tableFileFormat14415 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat14419 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat14421 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat14425 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_KW_INPUTDRIVER_in_tableFileFormat14428 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat14432 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat14434 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat14438 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat14476 = new BitSet(new long[]{0x0040000000000000L});
	public static final BitSet FOLLOW_KW_BY_in_tableFileFormat14478 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat14482 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_tableFileFormat14494 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
	public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat14496 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_tableProperties_in_tableFileFormat14500 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat14531 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_tableFileFormat14533 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_tableFileFormat14537 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCATION_in_tableLocation14585 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_tableLocation14589 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList14625 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameTypeList14628 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList14630 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList14668 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameTypeOrConstraintList14671 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8177B7L,0xE8FDC0EC611C1E0EL,0x7B1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDED43D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList14673 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList14711 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameColonTypeList14714 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList14716 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_columnName_in_columnNameList14754 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameList14757 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnName_in_columnNameList14759 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_identifier_in_columnName14803 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_extColumnName14836 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_DOT_in_extColumnName14839 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_ELEM_TYPE_in_extColumnName14849 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_KW_KEY_TYPE_in_extColumnName14859 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_KW_VALUE_TYPE_in_extColumnName14869 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_identifier_in_extColumnName14873 = new BitSet(new long[]{0x0000000000010002L});
	public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList14903 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameOrderList14906 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList14908 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_LPAREN_in_columnParenthesesList14946 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_columnParenthesesList14949 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_columnParenthesesList14951 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_enableSpecification_in_enableValidateSpecification14979 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000100000000L});
	public static final BitSet FOLLOW_validateSpecification_in_enableValidateSpecification14981 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_enforcedSpecification_in_enableValidateSpecification14990 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ENABLE_in_enableSpecification15017 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DISABLE_in_enableSpecification15031 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_VALIDATE_in_validateSpecification15064 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOVALIDATE_in_validateSpecification15078 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ENFORCED_in_enforcedSpecification15111 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_enforcedSpecification15125 = new BitSet(new long[]{0x0000000000000000L,0x0100000000000000L});
	public static final BitSet FOLLOW_KW_ENFORCED_in_enforcedSpecification15127 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_RELY_in_relySpecification15161 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NORELY_in_relySpecification15176 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_createConstraint15210 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_createConstraint15214 = new BitSet(new long[]{0x4000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0100000000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_tableLevelConstraint_in_createConstraint15218 = new BitSet(new long[]{0x0000000000000002L,0x0140080000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_constraintOptsCreate_in_createConstraint15220 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_alterConstraintWithName15295 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_alterConstraintWithName15299 = new BitSet(new long[]{0x4000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0100000000000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_tableLevelConstraint_in_alterConstraintWithName15301 = new BitSet(new long[]{0x0000000000000002L,0x0140080000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_constraintOptsAlter_in_alterConstraintWithName15303 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_pkUkConstraint_in_tableLevelConstraint15340 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_checkConstraint_in_tableLevelConstraint15348 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableConstraintType_in_pkUkConstraint15375 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_pkUkConstraint15379 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CHECK_in_checkConstraint15419 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_checkConstraint15421 = new BitSet(new long[]{0xDFB76D8AFF001000L,0xE75BEF777EB167B7L,0xE8FDCAECE9187ECFL,0x7A1EED865FB6BFBEL,0xE9FDFFBDF0CBFF1DL,0xE487C9F5CDE553DCL,0x0001000000000600L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_expression_in_checkConstraint15423 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_checkConstraint15425 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_createForeignKey15465 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_createForeignKey15469 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
	public static final BitSet FOLLOW_KW_FOREIGN_in_createForeignKey15473 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_KEY_in_createForeignKey15475 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_createForeignKey15479 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
	public static final BitSet FOLLOW_KW_REFERENCES_in_createForeignKey15482 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_createForeignKey15486 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_createForeignKey15490 = new BitSet(new long[]{0x0000000000000002L,0x0140080000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_constraintOptsCreate_in_createForeignKey15492 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_alterForeignKeyWithName15585 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_alterForeignKeyWithName15589 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
	public static final BitSet FOLLOW_KW_FOREIGN_in_alterForeignKeyWithName15591 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_KEY_in_alterForeignKeyWithName15593 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_alterForeignKeyWithName15597 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
	public static final BitSet FOLLOW_KW_REFERENCES_in_alterForeignKeyWithName15600 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_alterForeignKeyWithName15604 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_alterForeignKeyWithName15608 = new BitSet(new long[]{0x0000000000000002L,0x0140080000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_constraintOptsAlter_in_alterForeignKeyWithName15610 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValues_in_skewedValueElement15674 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValuePairList_in_skewedValueElement15683 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList15710 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_skewedColumnValuePairList15713 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList15715 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_LPAREN_in_skewedColumnValuePair15760 = new BitSet(new long[]{0x0000000002001000L,0x0000000004300000L,0x0000000000000080L,0x0000000008000000L,0x0000000000000000L,0x600000000000100CL,0x0000000000000200L});
	public static final BitSet FOLLOW_skewedColumnValues_in_skewedColumnValuePair15764 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_skewedColumnValuePair15766 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues15809 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_skewedColumnValues15812 = new BitSet(new long[]{0x0000000002001000L,0x0000000004300000L,0x0000000000000080L,0x0000000008000000L,0x0000000000000000L,0x600000000000100CL,0x0000000000000200L});
	public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues15814 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_constant_in_skewedColumnValue15858 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValue_in_skewedValueLocationElement15892 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement15901 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NULLS_in_nullOrdering15955 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_KW_FIRST_in_nullOrdering15957 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NULLS_in_nullOrdering15971 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_KW_LAST_in_nullOrdering15973 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_columnNameOrder16006 = new BitSet(new long[]{0x0000040000000002L,0x0000004000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_orderSpecification_in_columnNameOrder16010 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_nullOrdering_in_columnNameOrder16015 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList16212 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_columnNameCommentList16215 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList16217 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_identifier_in_columnNameComment16257 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000020L});
	public static final BitSet FOLLOW_KW_COMMENT_in_columnNameComment16260 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_columnNameComment16264 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ASC_in_orderSpecificationRewrite16312 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DESC_in_orderSpecificationRewrite16326 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_expression_in_columnRefOrder16359 = new BitSet(new long[]{0x0000040000000002L,0x0000004000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_orderSpecificationRewrite_in_columnRefOrder16363 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
	public static final BitSet FOLLOW_nullOrdering_in_columnRefOrder16368 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_columnNameType16599 = new BitSet(new long[]{0x2007010000000000L,0x000100008C000000L,0x0000020000002000L,0x0000000000000200L,0x00C0100000000000L,0x000000080004001CL});
	public static final BitSet FOLLOW_colType_in_columnNameType16601 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000020L});
	public static final BitSet FOLLOW_KW_COMMENT_in_columnNameType16604 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_columnNameType16608 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableConstraint_in_columnNameTypeOrConstraint16704 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_columnNameTypeConstraint_in_columnNameTypeOrConstraint16716 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createForeignKey_in_tableConstraint16747 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_createConstraint_in_tableConstraint16759 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_columnNameTypeConstraint16790 = new BitSet(new long[]{0x2007010000000000L,0x000100008C000000L,0x0000020000002000L,0x0000000000000200L,0x00C0100000000000L,0x000000080004001CL});
	public static final BitSet FOLLOW_colType_in_columnNameTypeConstraint16792 = new BitSet(new long[]{0x4000000000000002L,0x0000000100001020L,0x0000000000000000L,0x0100000002000000L,0x0000000000000040L,0x0000000000080000L});
	public static final BitSet FOLLOW_columnConstraint_in_columnNameTypeConstraint16794 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000020L});
	public static final BitSet FOLLOW_KW_COMMENT_in_columnNameTypeConstraint16799 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_columnNameTypeConstraint16803 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_foreignKeyConstraint_in_columnConstraint16867 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_colConstraint_in_columnConstraint16880 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_foreignKeyConstraint16911 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_foreignKeyConstraint16915 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
	public static final BitSet FOLLOW_KW_REFERENCES_in_foreignKeyConstraint16919 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_foreignKeyConstraint16923 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_foreignKeyConstraint16925 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnName_in_foreignKeyConstraint16929 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_foreignKeyConstraint16931 = new BitSet(new long[]{0x0000000000000002L,0x0140080000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_constraintOptsCreate_in_foreignKeyConstraint16933 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_colConstraint17041 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_colConstraint17045 = new BitSet(new long[]{0x4000000000000000L,0x0000000100000000L,0x0000000000000000L,0x0100000002000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_columnConstraintType_in_colConstraint17049 = new BitSet(new long[]{0x0000000000000002L,0x0140080000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_constraintOptsCreate_in_colConstraint17051 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterForeignKeyConstraint_in_alterColumnConstraint17129 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterColConstraint_in_alterColumnConstraint17142 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_alterForeignKeyConstraint17173 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_alterForeignKeyConstraint17177 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
	public static final BitSet FOLLOW_KW_REFERENCES_in_alterForeignKeyConstraint17181 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_alterForeignKeyConstraint17185 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_alterForeignKeyConstraint17187 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnName_in_alterForeignKeyConstraint17191 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_alterForeignKeyConstraint17193 = new BitSet(new long[]{0x0000000000000002L,0x0140080000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_constraintOptsAlter_in_alterForeignKeyConstraint17195 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CONSTRAINT_in_alterColConstraint17303 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_alterColConstraint17307 = new BitSet(new long[]{0x4000000000000000L,0x0000000100000000L,0x0000000000000000L,0x0100000002000000L,0x0000000000000000L,0x0000000000080000L});
	public static final BitSet FOLLOW_columnConstraintType_in_alterColConstraint17311 = new BitSet(new long[]{0x0000000000000002L,0x0140080000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_constraintOptsAlter_in_alterColConstraint17313 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NOT_in_columnConstraintType17378 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000008000000L});
	public static final BitSet FOLLOW_KW_NULL_in_columnConstraintType17380 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DEFAULT_in_columnConstraintType17401 = new BitSet(new long[]{0xDDB76D8AFF001000L,0xE75BEF777EB167B7L,0xE8FDC2ECE9183E8EL,0x7A1EED865DB6BFBEL,0xE9FDFFBDF0CBFF1DL,0x6007C9F5CDE553DCL,0x0001000000000200L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_defaultVal_in_columnConstraintType17403 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_checkConstraint_in_columnConstraintType17421 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableConstraintType_in_columnConstraintType17429 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_constant_in_defaultVal17446 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_function_in_defaultVal17454 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_castExpression_in_defaultVal17462 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_PRIMARY_in_tableConstraintType17479 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
	public static final BitSet FOLLOW_KW_KEY_in_tableConstraintType17481 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNIQUE_in_tableConstraintType17499 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_enableValidateSpecification_in_constraintOptsCreate17534 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L,0x0000000000000200L});
	public static final BitSet FOLLOW_relySpecification_in_constraintOptsCreate17536 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_enableValidateSpecification_in_constraintOptsAlter17554 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L,0x0000000000000200L});
	public static final BitSet FOLLOW_relySpecification_in_constraintOptsAlter17556 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_identifier_in_columnNameColonType17586 = new BitSet(new long[]{0x0000000000000100L});
	public static final BitSet FOLLOW_COLON_in_columnNameColonType17588 = new BitSet(new long[]{0x2007010000000000L,0x000100008C000000L,0x0000020000002000L,0x0000000000000200L,0x00C0100000000000L,0x000000080004001CL});
	public static final BitSet FOLLOW_colType_in_columnNameColonType17590 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000020L});
	public static final BitSet FOLLOW_KW_COMMENT_in_columnNameColonType17593 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_columnNameColonType17597 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_type_in_colType17681 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_colType_in_colTypeList17708 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_colTypeList17711 = new BitSet(new long[]{0x2007010000000000L,0x000100008C000000L,0x0000020000002000L,0x0000000000000200L,0x00C0100000000000L,0x000000080004001CL});
	public static final BitSet FOLLOW_colType_in_colTypeList17713 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_primitiveType_in_type17741 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_listType_in_type17749 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_structType_in_type17757 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_mapType_in_type17765 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_unionType_in_type17773 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TINYINT_in_primitiveType17795 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SMALLINT_in_primitiveType17816 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INT_in_primitiveType17836 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_BIGINT_in_primitiveType17861 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_BOOLEAN_in_primitiveType17883 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FLOAT_in_primitiveType17904 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DOUBLE_in_primitiveType17927 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
	public static final BitSet FOLLOW_KW_PRECISION_in_primitiveType17929 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DATE_in_primitiveType17951 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DATETIME_in_primitiveType17975 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TIMESTAMP_in_primitiveType17995 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TIMESTAMPLOCALTZ_in_primitiveType18014 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TIMESTAMP_in_primitiveType18036 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_KW_WITH_in_primitiveType18038 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_LOCAL_in_primitiveType18040 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TIME_in_primitiveType18042 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0004000000000000L});
	public static final BitSet FOLLOW_KW_ZONE_in_primitiveType18044 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STRING_in_primitiveType18076 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_BINARY_in_primitiveType18098 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DECIMAL_in_primitiveType18120 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_primitiveType18123 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_primitiveType18127 = new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_COMMA_in_primitiveType18130 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_primitiveType18134 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_primitiveType18138 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_VARCHAR_in_primitiveType18162 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_primitiveType18164 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_primitiveType18168 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_primitiveType18170 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CHAR_in_primitiveType18195 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_primitiveType18197 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_primitiveType18201 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_primitiveType18203 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ARRAY_in_listType18247 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
	public static final BitSet FOLLOW_LESSTHAN_in_listType18249 = new BitSet(new long[]{0x2007010000000000L,0x000100008C000000L,0x0000020000002000L,0x0000000000000200L,0x00C0100000000000L,0x000000080004001CL});
	public static final BitSet FOLLOW_type_in_listType18251 = new BitSet(new long[]{0x0000000000200000L});
	public static final BitSet FOLLOW_GREATERTHAN_in_listType18253 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STRUCT_in_structType18290 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
	public static final BitSet FOLLOW_LESSTHAN_in_structType18292 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameColonTypeList_in_structType18294 = new BitSet(new long[]{0x0000000000200000L});
	public static final BitSet FOLLOW_GREATERTHAN_in_structType18296 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MAP_in_mapType18331 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
	public static final BitSet FOLLOW_LESSTHAN_in_mapType18333 = new BitSet(new long[]{0x2007000000000000L,0x000100008C000000L,0x0000020000002000L,0x0000000000000000L,0x0040100000000000L,0x000000080000001CL});
	public static final BitSet FOLLOW_primitiveType_in_mapType18337 = new BitSet(new long[]{0x0000000000000200L});
	public static final BitSet FOLLOW_COMMA_in_mapType18339 = new BitSet(new long[]{0x2007010000000000L,0x000100008C000000L,0x0000020000002000L,0x0000000000000200L,0x00C0100000000000L,0x000000080004001CL});
	public static final BitSet FOLLOW_type_in_mapType18343 = new BitSet(new long[]{0x0000000000200000L});
	public static final BitSet FOLLOW_GREATERTHAN_in_mapType18345 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNIONTYPE_in_unionType18388 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
	public static final BitSet FOLLOW_LESSTHAN_in_unionType18390 = new BitSet(new long[]{0x2007010000000000L,0x000100008C000000L,0x0000020000002000L,0x0000000000000200L,0x00C0100000000000L,0x000000080004001CL});
	public static final BitSet FOLLOW_colTypeList_in_unionType18392 = new BitSet(new long[]{0x0000000000200000L});
	public static final BitSet FOLLOW_GREATERTHAN_in_unionType18394 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNION_in_setOperator18429 = new BitSet(new long[]{0x0000000100000000L});
	public static final BitSet FOLLOW_KW_ALL_in_setOperator18431 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UNION_in_setOperator18445 = new BitSet(new long[]{0x0000000000000002L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator18447 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INTERSECT_in_setOperator18462 = new BitSet(new long[]{0x0000000100000000L});
	public static final BitSet FOLLOW_KW_ALL_in_setOperator18464 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INTERSECT_in_setOperator18478 = new BitSet(new long[]{0x0000000000000002L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator18480 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXCEPT_in_setOperator18495 = new BitSet(new long[]{0x0000000100000000L});
	public static final BitSet FOLLOW_KW_ALL_in_setOperator18497 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_EXCEPT_in_setOperator18511 = new BitSet(new long[]{0x0000000000000002L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator18513 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MINUS_in_setOperator18528 = new BitSet(new long[]{0x0000000100000000L});
	public static final BitSet FOLLOW_KW_ALL_in_setOperator18530 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_MINUS_in_setOperator18544 = new BitSet(new long[]{0x0000000000000002L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator18546 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_withClause_in_queryStatementExpression18583 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000010000200000L,0x0000000000000200L,0x0000000200000020L,0x0080000000000000L});
	public static final BitSet FOLLOW_queryStatementExpressionBody_in_queryStatementExpression18591 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_fromStatement_in_queryStatementExpressionBody18623 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_regularBody_in_queryStatementExpressionBody18631 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WITH_in_withClause18648 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_cteStatement_in_withClause18650 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_withClause18653 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_cteStatement_in_withClause18655 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_identifier_in_cteStatement18681 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_cteStatement18683 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_cteStatement18685 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000010000200000L,0x0000000000000200L,0x0000000200000020L,0x0080200000000000L});
	public static final BitSet FOLLOW_queryStatementExpression_in_cteStatement18687 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_cteStatement18689 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_singleFromStatement_in_fromStatement18712 = new BitSet(new long[]{0x0000000000000002L,0x0800000000000000L,0x0000040000000000L,0x0000000000010000L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_setOperator_in_fromStatement18724 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
	public static final BitSet FOLLOW_singleFromStatement_in_fromStatement18728 = new BitSet(new long[]{0x0000000000000002L,0x0800000000000000L,0x0000040000000000L,0x0000000000010000L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_fromClause_in_singleFromStatement18935 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000010000000000L,0x0000000000000200L,0x0000000200000020L});
	public static final BitSet FOLLOW_body_in_singleFromStatement18945 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000010000000000L,0x0000000000000200L,0x0000000200000020L});
	public static final BitSet FOLLOW_insertClause_in_regularBody18982 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L,0x0000000200000020L,0x0080000200000000L});
	public static final BitSet FOLLOW_selectStatement_in_regularBody18994 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_valuesClause_in_regularBody19019 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_selectStatement_in_regularBody19092 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_selectClause_in_atomSelectStatement19112 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000014200000L,0x0000000000000000L,0x0000000000000000L,0x0000140000000000L});
	public static final BitSet FOLLOW_fromClause_in_atomSelectStatement19119 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000014000000L,0x0000000000000000L,0x0000000000000000L,0x0000140000000000L});
	public static final BitSet FOLLOW_whereClause_in_atomSelectStatement19127 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000014000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_groupByClause_in_atomSelectStatement19135 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000010000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_havingClause_in_atomSelectStatement19143 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_window_clause_in_atomSelectStatement19151 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_LPAREN_in_atomSelectStatement19229 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L,0x0000000200000020L,0x0080000000000000L});
	public static final BitSet FOLLOW_selectStatement_in_atomSelectStatement19232 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_atomSelectStatement19234 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_atomSelectStatement_in_selectStatement19255 = new BitSet(new long[]{0x8000000000000002L,0x0800200000000000L,0x2000040000000000L,0x0000001000010000L,0x0000400000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_setOpSelectStatement_in_selectStatement19262 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000000000000L,0x0000001000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_orderByClause_in_selectStatement19271 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_clusterByClause_in_selectStatement19279 = new BitSet(new long[]{0x0000000000000002L,0x0000200000000000L,0x2000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_distributeByClause_in_selectStatement19287 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x2000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_sortByClause_in_selectStatement19295 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_limitClause_in_selectStatement19303 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_setOperator_in_setOpSelectStatement19568 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L,0x0000000200000020L,0x0080000000000000L});
	public static final BitSet FOLLOW_atomSelectStatement_in_setOpSelectStatement19572 = new BitSet(new long[]{0x0000000000000002L,0x0800000000000000L,0x0000040000000000L,0x0000000000010000L,0x0000000000000000L,0x0000000000020000L});
	public static final BitSet FOLLOW_withClause_in_selectStatementWithCTE20207 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L,0x0000000200000020L,0x0080000000000000L});
	public static final BitSet FOLLOW_selectStatement_in_selectStatementWithCTE20215 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_insertClause_in_body20245 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L,0x0000000200000020L});
	public static final BitSet FOLLOW_selectClause_in_body20250 = new BitSet(new long[]{0x8000000000000202L,0x0000200000000000L,0x2100000014000000L,0x0000001000000000L,0x0000400000000000L,0x0000140000000000L});
	public static final BitSet FOLLOW_lateralView_in_body20255 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000014000000L,0x0000001000000000L,0x0000400000000000L,0x0000140000000000L});
	public static final BitSet FOLLOW_whereClause_in_body20261 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000014000000L,0x0000001000000000L,0x0000400000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_groupByClause_in_body20267 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000010000000L,0x0000001000000000L,0x0000400000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_havingClause_in_body20273 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000000000000L,0x0000001000000000L,0x0000400000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_window_clause_in_body20279 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000000000000L,0x0000001000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_orderByClause_in_body20285 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_clusterByClause_in_body20291 = new BitSet(new long[]{0x0000000000000002L,0x0000200000000000L,0x2000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_distributeByClause_in_body20297 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x2000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_sortByClause_in_body20303 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_limitClause_in_body20309 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_selectClause_in_body20402 = new BitSet(new long[]{0x8000000000000202L,0x0000200000000000L,0x2100000014000000L,0x0000001000000000L,0x0000400000000000L,0x0000140000000000L});
	public static final BitSet FOLLOW_lateralView_in_body20407 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000014000000L,0x0000001000000000L,0x0000400000000000L,0x0000140000000000L});
	public static final BitSet FOLLOW_whereClause_in_body20413 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000014000000L,0x0000001000000000L,0x0000400000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_groupByClause_in_body20419 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000010000000L,0x0000001000000000L,0x0000400000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_havingClause_in_body20425 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000000000000L,0x0000001000000000L,0x0000400000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_window_clause_in_body20431 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000000000000L,0x0000001000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_orderByClause_in_body20437 = new BitSet(new long[]{0x8000000000000002L,0x0000200000000000L,0x2000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_clusterByClause_in_body20443 = new BitSet(new long[]{0x0000000000000002L,0x0000200000000000L,0x2000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_distributeByClause_in_body20449 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x2000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_sortByClause_in_body20455 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_limitClause_in_body20461 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INSERT_in_insertClause20582 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000040000000000L});
	public static final BitSet FOLLOW_KW_OVERWRITE_in_insertClause20584 = new BitSet(new long[]{0x0000000000000000L,0x0000040000000000L,0x0000000000000000L,0x0000000000000001L,0x0400000000000000L});
	public static final BitSet FOLLOW_destination_in_insertClause20586 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_ifNotExists_in_insertClause20588 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_INSERT_in_insertClause20607 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_INTO_in_insertClause20609 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xEDFDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_TABLE_in_insertClause20611 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableOrPartition_in_insertClause20614 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_LPAREN_in_insertClause20617 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnNameList_in_insertClause20621 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
	public static final BitSet FOLLOW_RPAREN_in_insertClause20623 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LOCAL_in_destination20679 = new BitSet(new long[]{0x0000000000000000L,0x0000040000000000L});
	public static final BitSet FOLLOW_KW_DIRECTORY_in_destination20683 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_destination20685 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000004000000L});
	public static final BitSet FOLLOW_tableRowFormat_in_destination20687 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
	public static final BitSet FOLLOW_tableFileFormat_in_destination20690 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_TABLE_in_destination20723 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableOrPartition_in_destination20725 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LIMIT_in_limitClause20757 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_limitClause20763 = new BitSet(new long[]{0x0000000000000200L});
	public static final BitSet FOLLOW_COMMA_in_limitClause20765 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_limitClause20771 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_LIMIT_in_limitClause20794 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_limitClause20798 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
	public static final BitSet FOLLOW_KW_OFFSET_in_limitClause20800 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_limitClause20804 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DELETE_in_deleteStatement20848 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
	public static final BitSet FOLLOW_KW_FROM_in_deleteStatement20850 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_deleteStatement20852 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000040000000000L});
	public static final BitSet FOLLOW_whereClause_in_deleteStatement20855 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_tableOrColumn_in_columnAssignmentClause20888 = new BitSet(new long[]{0x0000000000040000L});
	public static final BitSet FOLLOW_EQUAL_in_columnAssignmentClause20890 = new BitSet(new long[]{0xDFB76D8AFF001000L,0xE75BEF777EB167B7L,0xE8FDCAECE9187ECEL,0x7A1EED865DB6BFBEL,0xE9FDFFBDF0CBFF1DL,0xE487C9F5CDE553DCL,0x0001000000000600L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_precedencePlusExpression_in_columnAssignmentClause20893 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_setColumnsClause20913 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause20915 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_setColumnsClause20918 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause20920 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_KW_UPDATE_in_updateStatement20962 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_updateStatement20964 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_setColumnsClause_in_updateStatement20966 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000040000000000L});
	public static final BitSet FOLLOW_whereClause_in_updateStatement20968 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_startTransactionStatement_in_sqlTransactionStatement21010 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_commitStatement_in_sqlTransactionStatement21015 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_rollbackStatement_in_sqlTransactionStatement21020 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_setAutoCommitStatement_in_sqlTransactionStatement21025 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_START_in_startTransactionStatement21039 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
	public static final BitSet FOLLOW_KW_TRANSACTION_in_startTransactionStatement21041 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_transactionMode_in_startTransactionStatement21045 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_COMMA_in_startTransactionStatement21050 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_transactionMode_in_startTransactionStatement21052 = new BitSet(new long[]{0x0000000000000202L});
	public static final BitSet FOLLOW_isolationLevel_in_transactionMode21083 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_transactionAccessMode_in_transactionMode21089 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_READ_in_transactionAccessMode21112 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000100000000L});
	public static final BitSet FOLLOW_KW_ONLY_in_transactionAccessMode21114 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_READ_in_transactionAccessMode21124 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
	public static final BitSet FOLLOW_KW_WRITE_in_transactionAccessMode21126 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ISOLATION_in_isolationLevel21145 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0800000000000000L});
	public static final BitSet FOLLOW_KW_LEVEL_in_isolationLevel21147 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
	public static final BitSet FOLLOW_levelOfIsolation_in_isolationLevel21149 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SNAPSHOT_in_levelOfIsolation21174 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COMMIT_in_commitStatement21193 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_KW_WORK_in_commitStatement21197 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ROLLBACK_in_rollbackStatement21219 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
	public static final BitSet FOLLOW_KW_WORK_in_rollbackStatement21223 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_SET_in_setAutoCommitStatement21244 = new BitSet(new long[]{0x0000200000000000L});
	public static final BitSet FOLLOW_KW_AUTOCOMMIT_in_setAutoCommitStatement21246 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000080L,0x0000000000000000L,0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_booleanValueTok_in_setAutoCommitStatement21248 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ABORT_in_abortTransactionStatement21283 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_KW_TRANSACTIONS_in_abortTransactionStatement21285 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_Number_in_abortTransactionStatement21289 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_KW_MERGE_in_mergeStatement21335 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000100000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_QUERY_HINT_in_mergeStatement21337 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
	public static final BitSet FOLLOW_KW_INTO_in_mergeStatement21340 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_tableName_in_mergeStatement21342 = new BitSet(new long[]{0xD9B06E8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5EDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_KW_AS_in_mergeStatement21345 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xE9FDEFBDF0CBFF1DL,0x0007C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_identifier_in_mergeStatement21348 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
	public static final BitSet FOLLOW_KW_USING_in_mergeStatement21352 = new BitSet(new long[]{0xD9B06C8AFD000000L,0xE75AEF777A8167B7L,0xE8FDC0EC61181E0EL,0x7A1EED8655B6BDBEL,0xEDFDEFBDF0CBFF1DL,0x0087C9F5CDE543D0L,0x0001000000000000L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_joinSourcePart_in_mergeStatement21354 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
	public static final BitSet FOLLOW_KW_ON_in_mergeStatement21356 = new BitSet(new long[]{0xDFB76D8AFF001000L,0xE75BEF777EB167B7L,0xE8FDCAECE9187ECFL,0x7A1EED865FB6BFBEL,0xE9FDFFBDF0CBFF1DL,0xE487C9F5CDE553DCL,0x0001000000000600L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_expression_in_mergeStatement21358 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
	public static final BitSet FOLLOW_whenClauses_in_mergeStatement21360 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_whenMatchedAndClause_in_whenClauses21409 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
	public static final BitSet FOLLOW_whenMatchedThenClause_in_whenClauses21411 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
	public static final BitSet FOLLOW_whenNotMatchedClause_in_whenClauses21415 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WHEN_in_whenNotMatchedClause21442 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_KW_NOT_in_whenNotMatchedClause21444 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_KW_MATCHED_in_whenNotMatchedClause21446 = new BitSet(new long[]{0x0000001000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_AND_in_whenNotMatchedClause21449 = new BitSet(new long[]{0xDFB76D8AFF001000L,0xE75BEF777EB167B7L,0xE8FDCAECE9187ECFL,0x7A1EED865FB6BFBEL,0xE9FDFFBDF0CBFF1DL,0xE487C9F5CDE553DCL,0x0001000000000600L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_expression_in_whenNotMatchedClause21451 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_THEN_in_whenNotMatchedClause21455 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
	public static final BitSet FOLLOW_KW_INSERT_in_whenNotMatchedClause21457 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000200000000L});
	public static final BitSet FOLLOW_columnParenthesesList_in_whenNotMatchedClause21462 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000200000000L});
	public static final BitSet FOLLOW_KW_VALUES_in_whenNotMatchedClause21466 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
	public static final BitSet FOLLOW_valueRowConstructor_in_whenNotMatchedClause21468 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WHEN_in_whenMatchedAndClause21515 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_KW_MATCHED_in_whenMatchedAndClause21517 = new BitSet(new long[]{0x0000001000000000L});
	public static final BitSet FOLLOW_KW_AND_in_whenMatchedAndClause21519 = new BitSet(new long[]{0xDFB76D8AFF001000L,0xE75BEF777EB167B7L,0xE8FDCAECE9187ECFL,0x7A1EED865FB6BFBEL,0xE9FDFFBDF0CBFF1DL,0xE487C9F5CDE553DCL,0x0001000000000600L,0x0000000001000000L,0x0000000000011000L,0x0000004080000022L,0x0000000800000000L});
	public static final BitSet FOLLOW_expression_in_whenMatchedAndClause21521 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_THEN_in_whenMatchedAndClause21523 = new BitSet(new long[]{0x0000000000000000L,0x0000000800000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_updateOrDelete_in_whenMatchedAndClause21525 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_WHEN_in_whenMatchedThenClause21563 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000001000L});
	public static final BitSet FOLLOW_KW_MATCHED_in_whenMatchedThenClause21565 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
	public static final BitSet FOLLOW_KW_THEN_in_whenMatchedThenClause21567 = new BitSet(new long[]{0x0000000000000000L,0x0000000800000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
	public static final BitSet FOLLOW_updateOrDelete_in_whenMatchedThenClause21569 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_UPDATE_in_updateOrDelete21598 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
	public static final BitSet FOLLOW_setColumnsClause_in_updateOrDelete21600 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_DELETE_in_updateOrDelete21618 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_KILL_in_killQueryStatement21650 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
	public static final BitSet FOLLOW_KW_QUERY_in_killQueryStatement21652 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_StringLiteral_in_killQueryStatement21656 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
	public static final BitSet FOLLOW_grantPrivileges_in_synpred1_HiveParser3043 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_revokePrivileges_in_synpred2_HiveParser3057 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_alterStatementSuffixRename_in_synpred3_HiveParser4642 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ELEM_TYPE_in_synpred4_HiveParser7833 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_KEY_TYPE_in_synpred5_HiveParser7850 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_VALUE_TYPE_in_synpred6_HiveParser7867 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_FUNCTION_in_synpred8_HiveParser8075 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_COMPUTE_in_synpred10_HiveParser8228 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_CACHE_in_synpred11_HiveParser8356 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALL_in_synpred14_HiveParser9950 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_NONE_in_synpred15_HiveParser9981 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ALL_in_synpred16_HiveParser10155 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_storedAsDirs_in_synpred17_HiveParser13421 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_STORED_in_synpred18_HiveParser14402 = new BitSet(new long[]{0x0000020000000000L});
	public static final BitSet FOLLOW_KW_AS_in_synpred18_HiveParser14404 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
	public static final BitSet FOLLOW_KW_INPUTFORMAT_in_synpred18_HiveParser14406 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_ELEM_TYPE_in_synpred19_HiveParser14844 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_KEY_TYPE_in_synpred20_HiveParser14854 = new BitSet(new long[]{0x0000000000000002L});
	public static final BitSet FOLLOW_KW_VALUE_TYPE_in_synpred21_HiveParser14864 = new BitSet(new long[]{0x0000000000000002L});
}
